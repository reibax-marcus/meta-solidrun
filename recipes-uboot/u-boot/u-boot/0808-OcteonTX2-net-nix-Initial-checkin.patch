From 33564847a20626b514deb37810f096b521009951 Mon Sep 17 00:00:00 2001
From: Aaron Williams <aaron.williams@cavium.com>
Date: Mon, 7 May 2018 22:17:06 -0700
Subject: [PATCH 0808/1239] OcteonTX2: net: nix: Initial checkin.

Note that it does not work and significant changes will be made.

Signed-off-by: Aaron Williams <aaron.williams@cavium.com>
---
 .../include/asm/arch-octeontx2/octeontx2.h    |    3 +-
 drivers/net/cavium/octeontx2/Makefile         |    2 +-
 drivers/net/cavium/octeontx2/cavm-csrs-cgx.h  |  128 +-
 drivers/net/cavium/octeontx2/cavm-csrs-npa.h  | 2528 +++++
 drivers/net/cavium/octeontx2/cgx.c            |  252 +-
 drivers/net/cavium/octeontx2/cgx.h            |   82 +-
 drivers/net/cavium/octeontx2/cgx_fw_if.h      |  225 +
 drivers/net/cavium/octeontx2/cgx_intf.c       |   43 +-
 drivers/net/cavium/octeontx2/cgx_intf.h       |   15 +-
 drivers/net/cavium/octeontx2/lmt.h            |   53 +
 drivers/net/cavium/octeontx2/lmt_hw.h         |   51 +
 drivers/net/cavium/octeontx2/lmt_reg.h        |   22 +
 drivers/net/cavium/octeontx2/nix.c            | 1605 +++
 drivers/net/cavium/octeontx2/nix.h            |  331 +
 drivers/net/cavium/octeontx2/nix_af.c         | 1479 +++
 drivers/net/cavium/octeontx2/nix_af.h         |   15 +
 drivers/net/cavium/octeontx2/nix_lf.h         |    0
 drivers/net/cavium/octeontx2/nix_regs.h       | 9009 -----------------
 drivers/net/cavium/octeontx2/npc.c            |  402 +
 drivers/net/cavium/octeontx2/npc.h            |   95 +
 drivers/net/cavium/octeontx2/npc_hw.h         |  331 +
 drivers/net/cavium/octeontx2/npc_profile.h    | 3356 ++++++
 drivers/net/cavium/octeontx2/npc_reg.h        |  632 ++
 drivers/net/cavium/octeontx2/npc_regs.h       |  362 -
 drivers/net/cavium/octeontx2/rvu.h            |   26 +-
 drivers/net/cavium/octeontx2/rvu_af.c         |   99 +-
 drivers/net/cavium/octeontx2/rvu_common.c     |   50 +
 drivers/net/cavium/octeontx2/rvu_common.h     |  202 +
 drivers/net/cavium/octeontx2/rvu_pf.c         |  111 +-
 drivers/spi/cavium_spi.c                      |   37 +-
 npc.c                                         |    1 +
 npc_profile.h                                 | 3356 ++++++
 32 files changed, 15399 insertions(+), 9504 deletions(-)
 create mode 100644 drivers/net/cavium/octeontx2/cavm-csrs-npa.h
 create mode 100644 drivers/net/cavium/octeontx2/cgx_fw_if.h
 create mode 100644 drivers/net/cavium/octeontx2/lmt.h
 create mode 100644 drivers/net/cavium/octeontx2/lmt_hw.h
 create mode 100644 drivers/net/cavium/octeontx2/lmt_reg.h
 create mode 100644 drivers/net/cavium/octeontx2/nix.c
 create mode 100644 drivers/net/cavium/octeontx2/nix.h
 create mode 100644 drivers/net/cavium/octeontx2/nix_af.c
 create mode 100644 drivers/net/cavium/octeontx2/nix_af.h
 create mode 100644 drivers/net/cavium/octeontx2/nix_lf.h
 delete mode 100644 drivers/net/cavium/octeontx2/nix_regs.h
 create mode 100644 drivers/net/cavium/octeontx2/npc.c
 create mode 100644 drivers/net/cavium/octeontx2/npc.h
 create mode 100644 drivers/net/cavium/octeontx2/npc_hw.h
 create mode 100644 drivers/net/cavium/octeontx2/npc_profile.h
 create mode 100644 drivers/net/cavium/octeontx2/npc_reg.h
 delete mode 100644 drivers/net/cavium/octeontx2/npc_regs.h
 create mode 100644 drivers/net/cavium/octeontx2/rvu_common.c
 create mode 100644 drivers/net/cavium/octeontx2/rvu_common.h
 create mode 100644 npc.c
 create mode 100644 npc_profile.h

diff --git a/arch/arm/include/asm/arch-octeontx2/octeontx2.h b/arch/arm/include/asm/arch-octeontx2/octeontx2.h
index 131dcfc505..1b6871cb83 100644
--- a/arch/arm/include/asm/arch-octeontx2/octeontx2.h
+++ b/arch/arm/include/asm/arch-octeontx2/octeontx2.h
@@ -7,7 +7,8 @@
 #define __OCTEONTX2_H__
 
 #define CN93XX	0xB2
-#define CAVIUM_IS_MODEL(model)	(p_cavm_bdt->prod_id == model)
+#define CAVIUM_CN9XXX	CN93XX	/* TODO: Fix this! */
+#define CAVIUM_IS_MODEL(model)	(p_cavm_bdt->prod_id == (model))
 
 /** Reg offsets */
 #define CAVM_RST_BOOT		0x87E006001600ULL
diff --git a/drivers/net/cavium/octeontx2/Makefile b/drivers/net/cavium/octeontx2/Makefile
index 40c7bdcb77..5c0b66e32b 100644
--- a/drivers/net/cavium/octeontx2/Makefile
+++ b/drivers/net/cavium/octeontx2/Makefile
@@ -3,6 +3,6 @@
 #
 # SPDX-License-Identifier:	GPL-2.0+
 #
-obj-$(CONFIG_OCTEONTX2_CGX) += cgx_intf.o cgx.o
+obj-$(CONFIG_OCTEONTX2_CGX) += cgx_intf.o cgx.o nix_af.o nix.o
 obj-$(CONFIG_OCTEONTX2_RVU) += rvu_pf.o rvu_af.o
 #obj-y += cgx_intf.o cgx.o rvu_pf.o rvu_af.o
diff --git a/drivers/net/cavium/octeontx2/cavm-csrs-cgx.h b/drivers/net/cavium/octeontx2/cavm-csrs-cgx.h
index adeb58e962..15842ae65e 100644
--- a/drivers/net/cavium/octeontx2/cavm-csrs-cgx.h
+++ b/drivers/net/cavium/octeontx2/cavm-csrs-cgx.h
@@ -324,9 +324,9 @@ union cavm_cgxx_active_pc {
 	/* struct cavm_cgxx_active_pc_s cn; */
 };
 
-static inline u64 CAVM_CGXX_ACTIVE_PC
+static inline u64 CAVM_CGXX_ACTIVE_PC(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_ACTIVE_PC
+static inline u64 CAVM_CGXX_ACTIVE_PC(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x2010;
@@ -1922,9 +1922,9 @@ union cavm_cgxx_cmr_bad {
 	/* struct cavm_cgxx_cmr_bad_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_BAD
+static inline u64 CAVM_CGXX_CMR_BAD(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_BAD
+static inline u64 CAVM_CGXX_CMR_BAD(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1020;
@@ -1944,9 +1944,9 @@ union cavm_cgxx_cmr_chan_msk_and {
 	/* struct cavm_cgxx_cmr_chan_msk_and_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_CHAN_MSK_AND
+static inline u64 CAVM_CGXX_CMR_CHAN_MSK_AND(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_CHAN_MSK_AND
+static inline u64 CAVM_CGXX_CMR_CHAN_MSK_AND(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x110;
@@ -1966,9 +1966,9 @@ union cavm_cgxx_cmr_chan_msk_or {
 	/* struct cavm_cgxx_cmr_chan_msk_or_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_CHAN_MSK_OR
+static inline u64 CAVM_CGXX_CMR_CHAN_MSK_OR(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_CHAN_MSK_OR
+static inline u64 CAVM_CGXX_CMR_CHAN_MSK_OR(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x118;
@@ -1989,9 +1989,9 @@ union cavm_cgxx_cmr_eco {
 	/* struct cavm_cgxx_cmr_eco_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_ECO
+static inline u64 CAVM_CGXX_CMR_ECO(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_ECO
+static inline u64 CAVM_CGXX_CMR_ECO(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1028;
@@ -2022,9 +2022,9 @@ union cavm_cgxx_cmr_global_config {
 	/* struct cavm_cgxx_cmr_global_config_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_GLOBAL_CONFIG
+static inline u64 CAVM_CGXX_CMR_GLOBAL_CONFIG(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_GLOBAL_CONFIG
+static inline u64 CAVM_CGXX_CMR_GLOBAL_CONFIG(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 8;
@@ -2046,9 +2046,9 @@ union cavm_cgxx_cmr_mem_int {
 	/* struct cavm_cgxx_cmr_mem_int_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_MEM_INT
+static inline u64 CAVM_CGXX_CMR_MEM_INT(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_MEM_INT
+static inline u64 CAVM_CGXX_CMR_MEM_INT(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x10;
@@ -2071,9 +2071,9 @@ union cavm_cgxx_cmr_mem_int_ena_w1c {
 	/* struct cavm_cgxx_cmr_mem_int_ena_w1c_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1C
+static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1C(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1C
+static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1C(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x20;
@@ -2096,9 +2096,9 @@ union cavm_cgxx_cmr_mem_int_ena_w1s {
 	/* struct cavm_cgxx_cmr_mem_int_ena_w1s_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1S
+static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1S(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1S
+static inline u64 CAVM_CGXX_CMR_MEM_INT_ENA_W1S(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x28;
@@ -2121,9 +2121,9 @@ union cavm_cgxx_cmr_mem_int_w1s {
 	/* struct cavm_cgxx_cmr_mem_int_w1s_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_MEM_INT_W1S
+static inline u64 CAVM_CGXX_CMR_MEM_INT_W1S(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_MEM_INT_W1S
+static inline u64 CAVM_CGXX_CMR_MEM_INT_W1S(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x18;
@@ -2145,9 +2145,9 @@ union cavm_cgxx_cmr_nic_nxc_adr {
 	/* struct cavm_cgxx_cmr_nic_nxc_adr_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_NIC_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIC_NXC_ADR(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_NIC_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIC_NXC_ADR(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1030;
@@ -2171,9 +2171,9 @@ union cavm_cgxx_cmr_nix0_nxc_adr {
 	/* struct cavm_cgxx_cmr_nix0_nxc_adr_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_NIX0_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIX0_NXC_ADR(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_NIX0_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIX0_NXC_ADR(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1038;
@@ -2197,9 +2197,9 @@ union cavm_cgxx_cmr_nix1_nxc_adr {
 	/* struct cavm_cgxx_cmr_nix1_nxc_adr_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_NIX1_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIX1_NXC_ADR(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_NIX1_NXC_ADR
+static inline u64 CAVM_CGXX_CMR_NIX1_NXC_ADR(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1040;
@@ -2297,9 +2297,9 @@ union cavm_cgxx_cmr_rx_lmacs {
 	/* struct cavm_cgxx_cmr_rx_lmacs_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_LMACS
+static inline u64 CAVM_CGXX_CMR_RX_LMACS(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_LMACS
+static inline u64 CAVM_CGXX_CMR_RX_LMACS(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x128;
@@ -2329,9 +2329,9 @@ union cavm_cgxx_cmr_rx_ovr_bp {
 	/* struct cavm_cgxx_cmr_rx_ovr_bp_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_OVR_BP
+static inline u64 CAVM_CGXX_CMR_RX_OVR_BP(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_OVR_BP
+static inline u64 CAVM_CGXX_CMR_RX_OVR_BP(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x130;
@@ -2353,9 +2353,9 @@ union cavm_cgxx_cmr_rx_stat10 {
 	/* struct cavm_cgxx_cmr_rx_stat10_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STAT10
+static inline u64 CAVM_CGXX_CMR_RX_STAT10(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STAT10
+static inline u64 CAVM_CGXX_CMR_RX_STAT10(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0xc0;
@@ -2380,9 +2380,9 @@ union cavm_cgxx_cmr_rx_stat11 {
 	/* struct cavm_cgxx_cmr_rx_stat11_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STAT11
+static inline u64 CAVM_CGXX_CMR_RX_STAT11(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STAT11
+static inline u64 CAVM_CGXX_CMR_RX_STAT11(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0xc8;
@@ -2404,9 +2404,9 @@ union cavm_cgxx_cmr_rx_stat12 {
 	/* struct cavm_cgxx_cmr_rx_stat12_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STAT12
+static inline u64 CAVM_CGXX_CMR_RX_STAT12(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STAT12
+static inline u64 CAVM_CGXX_CMR_RX_STAT12(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0xd0;
@@ -2437,9 +2437,9 @@ union cavm_cgxx_cmr_rx_stat9 {
 	/* struct cavm_cgxx_cmr_rx_stat9_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STAT9
+static inline u64 CAVM_CGXX_CMR_RX_STAT9(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STAT9
+static inline u64 CAVM_CGXX_CMR_RX_STAT9(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0xb8;
@@ -2553,9 +2553,9 @@ union cavm_cgxx_cmr_rx_steering_default0 {
 	/* struct cavm_cgxx_cmr_rx_steering_default0_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT0
+static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT0(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT0
+static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT0(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x3f0;
@@ -2581,9 +2581,9 @@ union cavm_cgxx_cmr_rx_steering_default1 {
 	/* struct cavm_cgxx_cmr_rx_steering_default1_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT1
+static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT1(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT1
+static inline u64 CAVM_CGXX_CMR_RX_STEERING_DEFAULT1(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x5e0;
@@ -2663,9 +2663,9 @@ union cavm_cgxx_cmr_tx_lmacs {
 	/* struct cavm_cgxx_cmr_tx_lmacs_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CMR_TX_LMACS
+static inline u64 CAVM_CGXX_CMR_TX_LMACS(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CMR_TX_LMACS
+static inline u64 CAVM_CGXX_CMR_TX_LMACS(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x1000;
@@ -2711,9 +2711,9 @@ union cavm_cgxx_const {
 	/* struct cavm_cgxx_const_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CONST
+static inline u64 CAVM_CGXX_CONST(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CONST
+static inline u64 CAVM_CGXX_CONST(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x2000;
@@ -2736,9 +2736,9 @@ union cavm_cgxx_const1 {
 	/* struct cavm_cgxx_const1_s cn; */
 };
 
-static inline u64 CAVM_CGXX_CONST1
+static inline u64 CAVM_CGXX_CONST1(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_CONST1
+static inline u64 CAVM_CGXX_CONST1(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x2008;
@@ -3991,9 +3991,9 @@ union cavm_cgxx_gmp_gmi_tx_col_attempt {
 	/* struct cavm_cgxx_gmp_gmi_tx_col_attempt_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_COL_ATTEMPT
+static inline u64 CAVM_CGXX_GMP_GMI_TX_COL_ATTEMPT(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_COL_ATTEMPT
+static inline u64 CAVM_CGXX_GMP_GMI_TX_COL_ATTEMPT(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39010;
@@ -4022,9 +4022,9 @@ union cavm_cgxx_gmp_gmi_tx_ifg {
 	/* struct cavm_cgxx_gmp_gmi_tx_ifg_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_IFG
+static inline u64 CAVM_CGXX_GMP_GMI_TX_IFG(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_IFG
+static inline u64 CAVM_CGXX_GMP_GMI_TX_IFG(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39000;
@@ -4046,9 +4046,9 @@ union cavm_cgxx_gmp_gmi_tx_jam {
 	/* struct cavm_cgxx_gmp_gmi_tx_jam_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_JAM
+static inline u64 CAVM_CGXX_GMP_GMI_TX_JAM(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_JAM
+static inline u64 CAVM_CGXX_GMP_GMI_TX_JAM(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39008;
@@ -4071,9 +4071,9 @@ union cavm_cgxx_gmp_gmi_tx_lfsr {
 	/* struct cavm_cgxx_gmp_gmi_tx_lfsr_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_LFSR
+static inline u64 CAVM_CGXX_GMP_GMI_TX_LFSR(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_LFSR
+static inline u64 CAVM_CGXX_GMP_GMI_TX_LFSR(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39028;
@@ -4094,9 +4094,9 @@ union cavm_cgxx_gmp_gmi_tx_pause_pkt_dmac {
 	/* struct cavm_cgxx_gmp_gmi_tx_pause_pkt_dmac_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_DMAC
+static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_DMAC(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_DMAC
+static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_DMAC(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39018;
@@ -4118,9 +4118,9 @@ union cavm_cgxx_gmp_gmi_tx_pause_pkt_type {
 	/* struct cavm_cgxx_gmp_gmi_tx_pause_pkt_type_s cn; */
 };
 
-static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_TYPE
+static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_TYPE(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_TYPE
+static inline u64 CAVM_CGXX_GMP_GMI_TX_PAUSE_PKT_TYPE(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x39020;
@@ -8308,9 +8308,9 @@ union cavm_cgxx_spu_dbg_control {
 	/* struct cavm_cgxx_spu_dbg_control_s cn; */
 };
 
-static inline u64 CAVM_CGXX_SPU_DBG_CONTROL
+static inline u64 CAVM_CGXX_SPU_DBG_CONTROL(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_SPU_DBG_CONTROL
+static inline u64 CAVM_CGXX_SPU_DBG_CONTROL(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x10300;
@@ -8402,9 +8402,9 @@ union cavm_cgxx_spu_usxgmii_control {
 	/* struct cavm_cgxx_spu_usxgmii_control_s cn; */
 };
 
-static inline u64 CAVM_CGXX_SPU_USXGMII_CONTROL
+static inline u64 CAVM_CGXX_SPU_USXGMII_CONTROL(void)
 	__attribute__ ((pure, always_inline));
-static inline u64 CAVM_CGXX_SPU_USXGMII_CONTROL
+static inline u64 CAVM_CGXX_SPU_USXGMII_CONTROL(void)
 {
 	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
 		return 0x10920;
diff --git a/drivers/net/cavium/octeontx2/cavm-csrs-npa.h b/drivers/net/cavium/octeontx2/cavm-csrs-npa.h
new file mode 100644
index 0000000000..49d2c40cf9
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/cavm-csrs-npa.h
@@ -0,0 +1,2528 @@
+#ifndef __CAVM_CSRS_NPA_H__
+#define __CAVM_CSRS_NPA_H__
+/* This file is auto-generated. Do not edit */
+
+/***********************license start***************
+ * Copyright (c) 2003-2018  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM  NETWORKS MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Configuration and status register (CSR) address and type definitions for
+ * Cavium NPA.
+ *
+ * This file is auto generated. Do not edit.
+ *
+ */
+
+/**
+ * Enumeration npa_af_int_vec_e
+ *
+ * NPA Admin Function Interrupt Vector Enumeration
+ * Enumerates the NPA AF MSI-X interrupt vectors.
+ */
+#define CAVM_NPA_AF_INT_VEC_E_AF_ERR (3)
+#define CAVM_NPA_AF_INT_VEC_E_AQ_DONE (2)
+#define CAVM_NPA_AF_INT_VEC_E_GEN (1)
+#define CAVM_NPA_AF_INT_VEC_E_POISON (4)
+#define CAVM_NPA_AF_INT_VEC_E_RVU (0)
+
+/**
+ * Enumeration npa_aq_comp_e
+ *
+ * NPA Admin Queue Completion Enumeration
+ * Enumerates the values of NPA_AQ_RES_S[COMPCODE].
+ */
+#define CAVM_NPA_AQ_COMP_E_CTX_FAULT (4)
+#define CAVM_NPA_AQ_COMP_E_CTX_POISON (3)
+#define CAVM_NPA_AQ_COMP_E_GOOD (1)
+#define CAVM_NPA_AQ_COMP_E_LOCKERR (5)
+#define CAVM_NPA_AQ_COMP_E_NOTDONE (0)
+#define CAVM_NPA_AQ_COMP_E_SWERR (2)
+
+/**
+ * Enumeration npa_aq_ctype_e
+ *
+ * NPA Admin Queue Context Type Enumeration
+ * Enumerates NPA_AQ_INST_S[CTYPE] values.
+ */
+#define CAVM_NPA_AQ_CTYPE_E_AURA (0)
+#define CAVM_NPA_AQ_CTYPE_E_POOL (1)
+
+/**
+ * Enumeration npa_aq_instop_e
+ *
+ * NPA Admin Queue Opcode Enumeration
+ * Enumerates NPA_AQ_INST_S[OP] values.
+ */
+#define CAVM_NPA_AQ_INSTOP_E_INIT (1)
+#define CAVM_NPA_AQ_INSTOP_E_LOCK (4)
+#define CAVM_NPA_AQ_INSTOP_E_NOP (0)
+#define CAVM_NPA_AQ_INSTOP_E_READ (3)
+#define CAVM_NPA_AQ_INSTOP_E_UNLOCK (5)
+#define CAVM_NPA_AQ_INSTOP_E_WRITE (2)
+
+/**
+ * Enumeration npa_aura_err_int_e
+ *
+ * NPA Aura Error Interrupt Enumeration
+ * Enumerates the bit index of NPA_AURA_S[ERR_INT], and NPA_AURA_S[ERR_INT_ENA].
+ */
+#define CAVM_NPA_AURA_ERR_INT_E_AURA_ADD_OVER (1)
+#define CAVM_NPA_AURA_ERR_INT_E_AURA_ADD_UNDER (2)
+#define CAVM_NPA_AURA_ERR_INT_E_AURA_FREE_UNDER (0)
+#define CAVM_NPA_AURA_ERR_INT_E_POOL_DIS (3)
+#define CAVM_NPA_AURA_ERR_INT_E_RX(a) (0 + (a))
+
+/**
+ * Enumeration npa_bpintf_e
+ *
+ * NPA Backpressure Interface Enumeration
+ * Enumerates index of NPA_AURA_S[BP_ENA].
+ */
+#define CAVM_NPA_BPINTF_E_NIXX_RX(a) (0 + (a))
+
+/**
+ * Enumeration npa_inpq_e
+ *
+ * NPA Input Queue Enumeration
+ * Enumerates ALLOC/FREE input queues from coprocessors.
+ */
+#define CAVM_NPA_INPQ_E_AURA_OP (0xe)
+#define CAVM_NPA_INPQ_E_DPI (6)
+#define CAVM_NPA_INPQ_E_INTERNAL_RSV (0xf)
+#define CAVM_NPA_INPQ_E_NIXX_RX(a) (0 + 2 * (a))
+#define CAVM_NPA_INPQ_E_NIXX_TX(a) (1 + 2 * (a))
+#define CAVM_NPA_INPQ_E_RX(a) (0 + (a))
+#define CAVM_NPA_INPQ_E_SSO (4)
+#define CAVM_NPA_INPQ_E_TIM (5)
+
+/**
+ * Enumeration npa_lf_int_vec_e
+ *
+ * NPA Local Function Interrupt Vector Enumeration
+ * Enumerates the NPA MSI-X interrupt vectors per LF.
+ */
+#define CAVM_NPA_LF_INT_VEC_E_ERR_INT (0x40)
+#define CAVM_NPA_LF_INT_VEC_E_POISON (0x41)
+#define CAVM_NPA_LF_INT_VEC_E_QINTX(a) (0 + (a))
+
+/**
+ * Enumeration npa_ndc0_port_e
+ *
+ * NPA NDC0 Port Enumeration
+ * Enumerates NPA NDC0 (NDC_IDX_E::NPA_U(0)) ports and the PORT index of
+ * NDC_AF_PORT()_RT()_RW()_REQ_PC and NDC_AF_PORT()_RT()_RW()_LAT_PC.
+ */
+#define CAVM_NPA_NDC0_PORT_E_AURA0 (0)
+#define CAVM_NPA_NDC0_PORT_E_AURA1 (1)
+#define CAVM_NPA_NDC0_PORT_E_POOL0 (2)
+#define CAVM_NPA_NDC0_PORT_E_POOL1 (3)
+#define CAVM_NPA_NDC0_PORT_E_STACK0 (4)
+#define CAVM_NPA_NDC0_PORT_E_STACK1 (5)
+
+/**
+ * Enumeration npa_pool_err_int_e
+ *
+ * NPA Pool Error Interrupt Enumeration
+ * Enumerates the bit index of NPA_POOL_S[ERR_INT] and NPA_POOL_S[ERR_INT_ENA].
+ */
+#define CAVM_NPA_POOL_ERR_INT_E_OVFLS (0)
+#define CAVM_NPA_POOL_ERR_INT_E_PERR (2)
+#define CAVM_NPA_POOL_ERR_INT_E_RX(a) (0 + (a))
+#define CAVM_NPA_POOL_ERR_INT_E_RANGE (1)
+
+/**
+ * Structure npa_aq_inst_s
+ *
+ * NPA Admin Queue Instruction Structure
+ * This structure specifies the AQ instruction.
+ * Instructions and associated software structures are stored in memory as
+ * little-endian unless NPA_AF_GEN_CFG[AF_BE] is set.
+ *
+ * Hardware reads of NPA_AQ_INST_S do not allocate into LLC.
+ *
+ * Hardware reads and writes of the context structure selected by [CTYPE], [LF]
+ * and [CINDEX] use the NDC and LLC caching style configured for that context,
+ * i.e.:
+ * * NPA_AURA_HW_S reads and writes use NPA_AF_LF()_AURAS_CFG[CACHING] and
+ * NPA_AF_LF()_AURAS_CFG[WAY_MASK].
+ * * NPA_POOL_HW_S reads and writes use NPA_AURA_HW_S[POOL_CACHING] and
+ * NPA_AURA_HW_S[POOL_WAY_MASK].
+ */
+union cavm_npa_aq_inst_s {
+	u64 u[2];
+	struct cavm_npa_aq_inst_s_s {
+		u64 op                               : 4;
+		u64 ctype                            : 4;
+		u64 lf                               : 9;
+		u64 reserved_17_23                   : 7;
+		u64 cindex                           : 20;
+		u64 reserved_44_62                   : 19;
+		u64 doneint                          : 1;
+		u64 res_addr                         : 64;
+	} s;
+	/* struct cavm_npa_aq_inst_s_s cn; */
+};
+
+/**
+ * Structure npa_aq_res_s
+ *
+ * NPA Admin Queue Result Structure
+ * NPA writes this structure after it completes the NPA_AQ_INST_S instruction.
+ * The result structure is exactly 16 bytes, and each instruction completion produces
+ * exactly one result structure.
+ *
+ * Results and associated software structures are stored in memory as
+ * little-endian unless NPA_AF_GEN_CFG[AF_BE] is set.
+ *
+ * When [OP] = NPA_AQ_INSTOP_E::INIT, WRITE or READ, this structure is
+ * immediately followed by context read or write data. See NPA_AQ_INSTOP_E.
+ *
+ * Hardware writes of NPA_AQ_RES_S and context data always allocate into LLC.
+ * Hardware reads of context data do not allocate into LLC.
+ */
+union cavm_npa_aq_res_s {
+	u64 u[2];
+	struct cavm_npa_aq_res_s_s {
+		u64 op                               : 4;
+		u64 ctype                            : 4;
+		u64 compcode                         : 8;
+		u64 doneint                          : 1;
+		u64 reserved_17_63                   : 47;
+		u64 reserved_64_127                  : 64;
+	} s;
+	/* struct cavm_npa_aq_res_s_s cn; */
+};
+
+/**
+ * Structure npa_aura_op_wdata_s
+ *
+ * NPA Aura Operation Write Data Structure
+ * This structure specifies the write data format of a 64-bit atomic load-and-add
+ * to NPA_LF_AURA_OP_ALLOC() and NPA_LF_POOL_OP_PC, and a 128-bit atomic CASP
+ * operation to NPA_LF_AURA_OP_ALLOC().
+ */
+union cavm_npa_aura_op_wdata_s {
+	u64 u;
+	struct cavm_npa_aura_op_wdata_s_s {
+		u64 aura                             : 20;
+		u64 reserved_20_62                   : 43;
+		u64 drop                             : 1;
+	} s;
+	/* struct cavm_npa_aura_op_wdata_s_s cn; */
+};
+
+/**
+ * Structure npa_aura_s
+ *
+ * NPA Aura Context Structure
+ * This structure specifies the format used by software with the NPA admin queue
+ * to read and write an aura's NPA_AURA_HW_S structure maintained by hardware in
+ * LLC/DRAM.
+ */
+union cavm_npa_aura_s {
+	u64 u[8];
+	struct cavm_npa_aura_s_s {
+		u64 pool_addr                        : 64;
+		u64 ena                              : 1;
+		u64 reserved_65_66                   : 2;
+		u64 pool_caching                     : 1;
+		u64 pool_way_mask                    : 16;
+		u64 avg_con                          : 9;
+		u64 reserved_93                      : 1;
+		u64 pool_drop_ena                    : 1;
+		u64 aura_drop_ena                    : 1;
+		u64 bp_ena                           : 2;
+		u64 reserved_98_103                  : 6;
+		u64 aura_drop                        : 8;
+		u64 shift                            : 6;
+		u64 reserved_118_119                 : 2;
+		u64 avg_level                        : 8;
+		u64 count                            : 36;
+		u64 reserved_164_167                 : 4;
+		u64 nix0_bpid                        : 9;
+		u64 reserved_177_179                 : 3;
+		u64 nix1_bpid                        : 9;
+		u64 reserved_189_191                 : 3;
+		u64 limit                            : 36;
+		u64 reserved_228_231                 : 4;
+		u64 bp                               : 8;
+		u64 reserved_240_243                 : 4;
+		u64 fc_ena                           : 1;
+		u64 fc_up_crossing                   : 1;
+		u64 fc_stype                         : 2;
+		u64 fc_hyst_bits                     : 4;
+		u64 reserved_252_255                 : 4;
+		u64 fc_addr                          : 64;
+		u64 pool_drop                        : 8;
+		u64 update_time                      : 16;
+		u64 err_int                          : 8;
+		u64 err_int_ena                      : 8;
+		u64 thresh_int                       : 1;
+		u64 thresh_int_ena                   : 1;
+		u64 thresh_up                        : 1;
+		u64 reserved_363                     : 1;
+		u64 thresh_qint_idx                  : 7;
+		u64 reserved_371                     : 1;
+		u64 err_qint_idx                     : 7;
+		u64 reserved_379_383                 : 5;
+		u64 thresh                           : 36;
+		u64 reserved_420_447                 : 28;
+		u64 reserved_448_511                 : 64;
+	} s;
+	/* struct cavm_npa_aura_s_s cn; */
+};
+
+/**
+ * Structure npa_pool_s
+ *
+ * NPA Pool Context Structure
+ * This structure specifies the format used by software with the NPA admin queue
+ * to read and write a pool's NPA_POOL_HW_S structure maintained by hardware in
+ * LLC/DRAM.
+ */
+union cavm_npa_pool_s {
+	u64 u[16];
+	struct cavm_npa_pool_s_s {
+		u64 stack_base                       : 64;
+		u64 ena                              : 1;
+		u64 nat_align                        : 1;
+		u64 reserved_66_67                   : 2;
+		u64 stack_caching                    : 1;
+		u64 reserved_69_71                   : 3;
+		u64 stack_way_mask                   : 16;
+		u64 buf_offset                       : 12;
+		u64 reserved_100_103                 : 4;
+		u64 buf_size                         : 11;
+		u64 reserved_115_127                 : 13;
+		u64 stack_max_pages                  : 32;
+		u64 stack_pages                      : 32;
+		u64 op_pc                            : 48;
+		u64 reserved_240_255                 : 16;
+		u64 stack_offset                     : 4;
+		u64 reserved_260_263                 : 4;
+		u64 shift                            : 6;
+		u64 reserved_270_271                 : 2;
+		u64 avg_level                        : 8;
+		u64 avg_con                          : 9;
+		u64 fc_ena                           : 1;
+		u64 fc_stype                         : 2;
+		u64 fc_hyst_bits                     : 4;
+		u64 fc_up_crossing                   : 1;
+		u64 reserved_297_299                 : 3;
+		u64 update_time                      : 16;
+		u64 reserved_316_319                 : 4;
+		u64 fc_addr                          : 64;
+		u64 ptr_start                        : 64;
+		u64 ptr_end                          : 64;
+		u64 reserved_512_535                 : 24;
+		u64 err_int                          : 8;
+		u64 err_int_ena                      : 8;
+		u64 thresh_int                       : 1;
+		u64 thresh_int_ena                   : 1;
+		u64 thresh_up                        : 1;
+		u64 reserved_555                     : 1;
+		u64 thresh_qint_idx                  : 7;
+		u64 reserved_563                     : 1;
+		u64 err_qint_idx                     : 7;
+		u64 reserved_571_575                 : 5;
+		u64 thresh                           : 36;
+		u64 reserved_612_639                 : 28;
+		u64 reserved_640_703                 : 64;
+		u64 reserved_704_767                 : 64;
+		u64 reserved_768_831                 : 64;
+		u64 reserved_832_895                 : 64;
+		u64 reserved_896_959                 : 64;
+		u64 reserved_960_1023                : 64;
+	} s;
+	/* struct cavm_npa_pool_s_s cn; */
+};
+
+/**
+ * Structure npa_qint_hw_s
+ *
+ * NPA Queue Interrupt Context Hardware Structure
+ * This structure contains context state maintained by hardware for each queue
+ * interrupt (QINT) in in NDC/LLC/DRAM. Software accesses this structure with the
+ * NPA_LF_QINT()_* registers.
+ * Hardware maintains a table of NPA_AF_CONST[QINTS] contiguous NPA_QINT_HW_S
+ * structures per LF starting at IOVA NPA_AF_LF()_QINTS_BASE.
+ * Always stored in byte invariant little-endian format (LE8).
+ */
+union cavm_npa_qint_hw_s {
+	u64 u;
+	struct cavm_npa_qint_hw_s_s {
+		u64 count                            : 22;
+		u64 reserved_22_30                   : 9;
+		u64 ena                              : 1;
+		u64 reserved_32_63                   : 32;
+	} s;
+	struct cavm_npa_qint_hw_s_cn {
+		u64 count                            : 22;
+		u64 reserved_22_30                   : 9;
+		u64 ena                              : 1;
+	} cn;
+};
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_active_cycles_pc
+ *
+ * NPA AF Active Cycles Register
+ */
+union cavm_npa_af_active_cycles_pc {
+	u64 u;
+	struct cavm_npa_af_active_cycles_pc_s {
+		u64 act_cyc                          : 64;
+	} s;
+	/* struct cavm_npa_af_active_cycles_pc_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ACTIVE_CYCLES_PC(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ACTIVE_CYCLES_PC(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0xf0;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_base
+ *
+ * NPA AF Admin Queue Base Address Register
+ */
+union cavm_npa_af_aq_base {
+	u64 u;
+	struct cavm_npa_af_aq_base_s {
+		u64 reserved_0_6                     : 7;
+		u64 base_addr                        : 46;
+		u64 reserved_53_63                   : 11;
+	} s;
+	/* struct cavm_npa_af_aq_base_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_BASE(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_BASE(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x610;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_cfg
+ *
+ * NPA AF Admin Queue Configuration Register
+ */
+union cavm_npa_af_aq_cfg {
+	u64 u;
+	struct cavm_npa_af_aq_cfg_s {
+		u64 qsize                            : 4;
+		u64 reserved_4_63                    : 60;
+	} s;
+	/* struct cavm_npa_af_aq_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_CFG(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_CFG(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x600;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done
+ *
+ * NPA AF AQ Done Count Register
+ */
+union cavm_npa_af_aq_done {
+	u64 u;
+	struct cavm_npa_af_aq_done_s {
+		u64 done                             : 20;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_af_aq_done_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x650;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_ack
+ *
+ * NPA AF AQ Done Count Ack Register
+ * This register is written by software to acknowledge interrupts.
+ */
+union cavm_npa_af_aq_done_ack {
+	u64 u;
+	struct cavm_npa_af_aq_done_ack_s {
+		u64 done_ack                         : 20;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_af_aq_done_ack_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_ACK(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_ACK(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x660;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_ena_w1c
+ *
+ * NPA AF AQ Done Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_af_aq_done_ena_w1c {
+	u64 u;
+	struct cavm_npa_af_aq_done_ena_w1c_s {
+		u64 done                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_aq_done_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x698;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_ena_w1s
+ *
+ * NPA AF AQ Done Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_af_aq_done_ena_w1s {
+	u64 u;
+	struct cavm_npa_af_aq_done_ena_w1s_s {
+		u64 done                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_aq_done_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x690;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_int
+ *
+ * NPA AF AQ Done Interrupt Register
+ */
+union cavm_npa_af_aq_done_int {
+	u64 u;
+	struct cavm_npa_af_aq_done_int_s {
+		u64 done                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_aq_done_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x680;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_int_w1s
+ *
+ * INTERNAL: NPA AF AQ Done Interrupt Set Register
+ */
+union cavm_npa_af_aq_done_int_w1s {
+	u64 u;
+	struct cavm_npa_af_aq_done_int_w1s_s {
+		u64 done                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_aq_done_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_INT_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_INT_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x688;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_timer
+ *
+ * NPA AF Admin Queue Done Interrupt Timer Register
+ * Used to debug the queue interrupt coalescing timer.
+ */
+union cavm_npa_af_aq_done_timer {
+	u64 u;
+	struct cavm_npa_af_aq_done_timer_s {
+		u64 count                            : 16;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_af_aq_done_timer_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_TIMER(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_TIMER(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x670;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_done_wait
+ *
+ * NPA AF AQ Done Interrupt Coalescing Wait Register
+ * Specifies the queue interrupt coalescing settings.
+ */
+union cavm_npa_af_aq_done_wait {
+	u64 u;
+	struct cavm_npa_af_aq_done_wait_s {
+		u64 num_wait                         : 20;
+		u64 reserved_20_31                   : 12;
+		u64 time_wait                        : 16;
+		u64 reserved_48_63                   : 16;
+	} s;
+	/* struct cavm_npa_af_aq_done_wait_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DONE_WAIT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DONE_WAIT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x640;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_door
+ *
+ * NPA AF Admin Queue Doorbell Register
+ * Software writes to this register to enqueue one or more entries to AQ.
+ */
+union cavm_npa_af_aq_door {
+	u64 u;
+	struct cavm_npa_af_aq_door_s {
+		u64 count                            : 16;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_af_aq_door_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AQ_DOOR(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_DOOR(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x630;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_aq_status
+ *
+ * NPA AF Admin Queue Status Register
+ */
+union cavm_npa_af_aq_status {
+	u64 u;
+	struct cavm_npa_af_aq_status_s {
+		u64 reserved_0_3                     : 4;
+		u64 head_ptr                         : 20;
+		u64 reserved_24_35                   : 12;
+		u64 tail_ptr                         : 20;
+		u64 reserved_56_61                   : 6;
+		u64 aq_busy                          : 1;
+		u64 aq_err                           : 1;
+	} s;
+	struct cavm_npa_af_aq_status_cn {
+		u64 reserved_0_3                     : 4;
+		u64 head_ptr                         : 20;
+		u64 reserved_24_31                   : 8;
+		u64 reserved_32_35                   : 4;
+		u64 tail_ptr                         : 20;
+		u64 reserved_56_61                   : 6;
+		u64 aq_busy                          : 1;
+		u64 aq_err                           : 1;
+	} cn;
+};
+
+static inline u64 CAVM_NPA_AF_AQ_STATUS(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AQ_STATUS(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x620;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_avg_delay
+ *
+ * NPA AF Queue Average Delay Register
+ */
+union cavm_npa_af_avg_delay {
+	u64 u;
+	struct cavm_npa_af_avg_delay_s {
+		u64 avg_dly                          : 19;
+		u64 reserved_19_23                   : 5;
+		u64 avg_timer                        : 16;
+		u64 reserved_40_62                   : 23;
+		u64 avg_timer_dis                    : 1;
+	} s;
+	/* struct cavm_npa_af_avg_delay_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_AVG_DELAY(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_AVG_DELAY(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x100;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_bar2_alias#
+ *
+ * INTERNAL: NPA Admin Function  BAR2 Alias Registers
+ *
+ * These registers alias to the NPA BAR2 registers for the PF and function
+ * selected by NPA_AF_BAR2_SEL[PF_FUNC].
+ *
+ * Internal:
+ * Not implemented. Placeholder for bug33464.
+ */
+union cavm_npa_af_bar2_aliasx {
+	u64 u;
+	struct cavm_npa_af_bar2_aliasx_s {
+		u64 data                             : 64;
+	} s;
+	/* struct cavm_npa_af_bar2_aliasx_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_BAR2_ALIASX(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_BAR2_ALIASX(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 131071))
+		return 0x9100000 + 8 * ((a) & 0x1ffff);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_bar2_sel
+ *
+ * INTERNAL: NPA Admin Function BAR2 Select Register
+ *
+ * This register configures BAR2 accesses from the NPA_AF_BAR2_ALIAS() registers in BAR0.
+ * Internal:
+ * Not implemented. Placeholder for bug33464.
+ */
+union cavm_npa_af_bar2_sel {
+	u64 u;
+	struct cavm_npa_af_bar2_sel_s {
+		u64 alias_pf_func                    : 16;
+		u64 alias_ena                        : 1;
+		u64 reserved_17_63                   : 47;
+	} s;
+	/* struct cavm_npa_af_bar2_sel_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_BAR2_SEL(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_BAR2_SEL(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x9000000;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_blk_rst
+ *
+ * NPA AF Block Reset Register
+ */
+union cavm_npa_af_blk_rst {
+	u64 u;
+	struct cavm_npa_af_blk_rst_s {
+		u64 rst                              : 1;
+		u64 reserved_1_62                    : 62;
+		u64 busy                             : 1;
+	} s;
+	/* struct cavm_npa_af_blk_rst_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_BLK_RST(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_BLK_RST(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_bp_test
+ *
+ * INTERNAL: NPA AF Backpressure Test Register
+ */
+union cavm_npa_af_bp_test {
+	u64 u;
+	struct cavm_npa_af_bp_test_s {
+		u64 lfsr_freq                        : 12;
+		u64 reserved_12_15                   : 4;
+		u64 bp_cfg                           : 32;
+		u64 enable                           : 16;
+	} s;
+	/* struct cavm_npa_af_bp_test_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_BP_TEST(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_BP_TEST(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x200;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_const
+ *
+ * NPA AF Constants Register
+ * This register contains constants for software discovery.
+ */
+union cavm_npa_af_const {
+	u64 u;
+	struct cavm_npa_af_const_s {
+		u64 stack_page_bytes                 : 8;
+		u64 stack_page_ptrs                  : 8;
+		u64 lfs                              : 12;
+		u64 qints                            : 12;
+		u64 num_ndc                          : 3;
+		u64 reserved_43_63                   : 21;
+	} s;
+	/* struct cavm_npa_af_const_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_CONST(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_CONST(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x10;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_const1
+ *
+ * NPA AF Constants Register 1
+ * This register contains constants for software discovery.
+ */
+union cavm_npa_af_const1 {
+	u64 u;
+	struct cavm_npa_af_const1_s {
+		u64 aura_log2bytes                   : 4;
+		u64 pool_log2bytes                   : 4;
+		u64 qint_log2bytes                   : 4;
+		u64 reserved_12_63                   : 52;
+	} s;
+	/* struct cavm_npa_af_const1_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_CONST1(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_CONST1(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x18;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_dtx_filter_ctl
+ *
+ * NPA AF DTX LF Filter Control Register
+ */
+union cavm_npa_af_dtx_filter_ctl {
+	u64 u;
+	struct cavm_npa_af_dtx_filter_ctl_s {
+		u64 ena                              : 1;
+		u64 reserved_1_3                     : 3;
+		u64 lf                               : 7;
+		u64 reserved_11_63                   : 53;
+	} s;
+	/* struct cavm_npa_af_dtx_filter_ctl_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_DTX_FILTER_CTL(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_DTX_FILTER_CTL(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x10040;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_eco
+ *
+ * INTERNAL: NPA AF ECO Register
+ */
+union cavm_npa_af_eco {
+	u64 u;
+	struct cavm_npa_af_eco_s {
+		u64 eco_rw                           : 32;
+		u64 reserved_32_63                   : 32;
+	} s;
+	/* struct cavm_npa_af_eco_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ECO(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ECO(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x300;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_err_int
+ *
+ * NPA Admin Function Error Interrupt Register
+ */
+union cavm_npa_af_err_int {
+	u64 u;
+	struct cavm_npa_af_err_int_s {
+		u64 reserved_0_11                    : 12;
+		u64 aq_door_err                      : 1;
+		u64 aq_res_fault                     : 1;
+		u64 aq_inst_fault                    : 1;
+		u64 reserved_15_63                   : 49;
+	} s;
+	/* struct cavm_npa_af_err_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ERR_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ERR_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x180;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_err_int_ena_w1c
+ *
+ * NPA Admin Function Error Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_af_err_int_ena_w1c {
+	u64 u;
+	struct cavm_npa_af_err_int_ena_w1c_s {
+		u64 reserved_0_11                    : 12;
+		u64 aq_door_err                      : 1;
+		u64 aq_res_fault                     : 1;
+		u64 aq_inst_fault                    : 1;
+		u64 reserved_15_63                   : 49;
+	} s;
+	/* struct cavm_npa_af_err_int_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ERR_INT_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ERR_INT_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x198;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_err_int_ena_w1s
+ *
+ * NPA Admin Function Error Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_af_err_int_ena_w1s {
+	u64 u;
+	struct cavm_npa_af_err_int_ena_w1s_s {
+		u64 reserved_0_11                    : 12;
+		u64 aq_door_err                      : 1;
+		u64 aq_res_fault                     : 1;
+		u64 aq_inst_fault                    : 1;
+		u64 reserved_15_63                   : 49;
+	} s;
+	/* struct cavm_npa_af_err_int_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ERR_INT_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ERR_INT_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x190;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_err_int_w1s
+ *
+ * NPA Admin Function Error Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_af_err_int_w1s {
+	u64 u;
+	struct cavm_npa_af_err_int_w1s_s {
+		u64 reserved_0_11                    : 12;
+		u64 aq_door_err                      : 1;
+		u64 aq_res_fault                     : 1;
+		u64 aq_inst_fault                    : 1;
+		u64 reserved_15_63                   : 49;
+	} s;
+	/* struct cavm_npa_af_err_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_ERR_INT_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_ERR_INT_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x188;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_gen_cfg
+ *
+ * NPA AF General Configuration Register
+ * This register provides NPA control and status information.
+ */
+union cavm_npa_af_gen_cfg {
+	u64 u;
+	struct cavm_npa_af_gen_cfg_s {
+		u64 reserved_0                       : 1;
+		u64 af_be                            : 1;
+		u64 reserved_2                       : 1;
+		u64 force_cond_clk_en                : 1;
+		u64 force_intf_clk_en                : 1;
+		u64 reserved_5_9                     : 5;
+		u64 ocla_bp                          : 1;
+		u64 reserved_11                      : 1;
+		u64 ratem1                           : 4;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_af_gen_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_GEN_CFG(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_GEN_CFG(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x30;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_gen_int
+ *
+ * NPA AF General Interrupt Register
+ * This register contains general error interrupt summary bits.
+ */
+union cavm_npa_af_gen_int {
+	u64 u;
+	struct cavm_npa_af_gen_int_s {
+		u64 free_dis                         : 16;
+		u64 alloc_dis                        : 16;
+		u64 unmapped_pf_func                 : 1;
+		u64 reserved_33_63                   : 31;
+	} s;
+	/* struct cavm_npa_af_gen_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_GEN_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_GEN_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x140;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_gen_int_ena_w1c
+ *
+ * NPA AF General Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_af_gen_int_ena_w1c {
+	u64 u;
+	struct cavm_npa_af_gen_int_ena_w1c_s {
+		u64 free_dis                         : 16;
+		u64 alloc_dis                        : 16;
+		u64 unmapped_pf_func                 : 1;
+		u64 reserved_33_63                   : 31;
+	} s;
+	/* struct cavm_npa_af_gen_int_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_GEN_INT_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_GEN_INT_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x158;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_gen_int_ena_w1s
+ *
+ * NPA AF General Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_af_gen_int_ena_w1s {
+	u64 u;
+	struct cavm_npa_af_gen_int_ena_w1s_s {
+		u64 free_dis                         : 16;
+		u64 alloc_dis                        : 16;
+		u64 unmapped_pf_func                 : 1;
+		u64 reserved_33_63                   : 31;
+	} s;
+	/* struct cavm_npa_af_gen_int_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_GEN_INT_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_GEN_INT_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x150;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_gen_int_w1s
+ *
+ * NPA AF General Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_af_gen_int_w1s {
+	u64 u;
+	struct cavm_npa_af_gen_int_w1s_s {
+		u64 free_dis                         : 16;
+		u64 alloc_dis                        : 16;
+		u64 unmapped_pf_func                 : 1;
+		u64 reserved_33_63                   : 31;
+	} s;
+	/* struct cavm_npa_af_gen_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_GEN_INT_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_GEN_INT_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x148;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_inp_ctl
+ *
+ * NPA AF Input Control Register
+ */
+union cavm_npa_af_inp_ctl {
+	u64 u;
+	struct cavm_npa_af_inp_ctl_s {
+		u64 free_dis                         : 16;
+		u64 alloc_dis                        : 16;
+		u64 reserved_32_63                   : 32;
+	} s;
+	/* struct cavm_npa_af_inp_ctl_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_INP_CTL(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_INP_CTL(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0xd0;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_lf#_auras_cfg
+ *
+ * NPA AF Local Function Auras Configuration Registers
+ */
+union cavm_npa_af_lfx_auras_cfg {
+	u64 u;
+	struct cavm_npa_af_lfx_auras_cfg_s {
+		u64 way_mask                         : 16;
+		u64 loc_aura_size                    : 4;
+		u64 loc_aura_offset                  : 14;
+		u64 caching                          : 1;
+		u64 reserved_35                      : 1;
+		u64 rmt_aura_size                    : 4;
+		u64 rmt_aura_offset                  : 14;
+		u64 rmt_lf                           : 7;
+		u64 reserved_61_63                   : 3;
+	} s;
+	/* struct cavm_npa_af_lfx_auras_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_LFX_AURAS_CFG(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_LFX_AURAS_CFG(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x4000 + 0x40000 * ((a) & 0x7f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_lf#_loc_auras_base
+ *
+ * NPA AF Local Function Auras Base Registers
+ */
+union cavm_npa_af_lfx_loc_auras_base {
+	u64 u;
+	struct cavm_npa_af_lfx_loc_auras_base_s {
+		u64 reserved_0_6                     : 7;
+		u64 addr                             : 46;
+		u64 reserved_53_63                   : 11;
+	} s;
+	/* struct cavm_npa_af_lfx_loc_auras_base_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_LFX_LOC_AURAS_BASE(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_LFX_LOC_AURAS_BASE(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x4010 + 0x40000 * ((a) & 0x7f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_lf#_qints_base
+ *
+ * NPA AF Local Function Queue Interrupts Base Registers
+ */
+union cavm_npa_af_lfx_qints_base {
+	u64 u;
+	struct cavm_npa_af_lfx_qints_base_s {
+		u64 reserved_0_6                     : 7;
+		u64 addr                             : 46;
+		u64 reserved_53_63                   : 11;
+	} s;
+	/* struct cavm_npa_af_lfx_qints_base_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_LFX_QINTS_BASE(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_LFX_QINTS_BASE(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x4110 + 0x40000 * ((a) & 0x7f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_lf#_qints_cfg
+ *
+ * NPA AF Local Function Queue Interrupts Configuration Registers
+ * This register controls access to the LF's queue interrupt context table in
+ * LLC/DRAM. The table consists of NPA_AF_CONST[QINTS] contiguous NPA_QINT_HW_S
+ * structures. The size of each structure is 1 \<\< NPA_AF_CONST1[QINT_LOG2BYTES]
+ * bytes.
+ */
+union cavm_npa_af_lfx_qints_cfg {
+	u64 u;
+	struct cavm_npa_af_lfx_qints_cfg_s {
+		u64 reserved_0_19                    : 20;
+		u64 way_mask                         : 16;
+		u64 caching                          : 2;
+		u64 reserved_38_63                   : 26;
+	} s;
+	/* struct cavm_npa_af_lfx_qints_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_LFX_QINTS_CFG(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_LFX_QINTS_CFG(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x4100 + 0x40000 * ((a) & 0x7f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_lf_rst
+ *
+ * NPA Admin Function LF Reset Register
+ */
+union cavm_npa_af_lf_rst {
+	u64 u;
+	struct cavm_npa_af_lf_rst_s {
+		u64 lf                               : 8;
+		u64 reserved_8_11                    : 4;
+		u64 exec                             : 1;
+		u64 reserved_13_63                   : 51;
+	} s;
+	/* struct cavm_npa_af_lf_rst_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_LF_RST(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_LF_RST(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x20;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ndc_cfg
+ *
+ * NDC AF General Configuration Register
+ * This register provides NDC control.
+ */
+union cavm_npa_af_ndc_cfg {
+	u64 u;
+	struct cavm_npa_af_ndc_cfg_s {
+		u64 ndc_bypass                       : 1;
+		u64 ndc_ign_pois                     : 1;
+		u64 byp_aura                         : 1;
+		u64 byp_pool                         : 1;
+		u64 byp_stack                        : 1;
+		u64 byp_qint                         : 1;
+		u64 reserved_6_63                    : 58;
+	} s;
+	/* struct cavm_npa_af_ndc_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_NDC_CFG(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_NDC_CFG(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x40;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ndc_sync
+ *
+ * NPA AF NDC Sync Register
+ * Used to synchronize the NPA NDC.
+ */
+union cavm_npa_af_ndc_sync {
+	u64 u;
+	struct cavm_npa_af_ndc_sync_s {
+		u64 lf                               : 8;
+		u64 reserved_8_11                    : 4;
+		u64 exec                             : 1;
+		u64 reserved_13_63                   : 51;
+	} s;
+	/* struct cavm_npa_af_ndc_sync_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_NDC_SYNC(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_NDC_SYNC(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x50;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ras
+ *
+ * NPA AF RAS Interrupt Register
+ * This register is intended for delivery of RAS events to the SCP, so should be
+ * ignored by OS drivers.
+ */
+union cavm_npa_af_ras {
+	u64 u;
+	struct cavm_npa_af_ras_s {
+		u64 reserved_0_31                    : 32;
+		u64 aq_ctx_poison                    : 1;
+		u64 aq_res_poison                    : 1;
+		u64 aq_inst_poison                   : 1;
+		u64 reserved_35_63                   : 29;
+	} s;
+	/* struct cavm_npa_af_ras_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RAS(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RAS(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x1a0;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ras_ena_w1c
+ *
+ * NPA AF RAS Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_af_ras_ena_w1c {
+	u64 u;
+	struct cavm_npa_af_ras_ena_w1c_s {
+		u64 reserved_0_31                    : 32;
+		u64 aq_ctx_poison                    : 1;
+		u64 aq_res_poison                    : 1;
+		u64 aq_inst_poison                   : 1;
+		u64 reserved_35_63                   : 29;
+	} s;
+	/* struct cavm_npa_af_ras_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RAS_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RAS_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x1b8;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ras_ena_w1s
+ *
+ * NPA AF RAS Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_af_ras_ena_w1s {
+	u64 u;
+	struct cavm_npa_af_ras_ena_w1s_s {
+		u64 reserved_0_31                    : 32;
+		u64 aq_ctx_poison                    : 1;
+		u64 aq_res_poison                    : 1;
+		u64 aq_inst_poison                   : 1;
+		u64 reserved_35_63                   : 29;
+	} s;
+	/* struct cavm_npa_af_ras_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RAS_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RAS_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x1b0;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_ras_w1s
+ *
+ * NPA AF RAS Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_af_ras_w1s {
+	u64 u;
+	struct cavm_npa_af_ras_w1s_s {
+		u64 reserved_0_31                    : 32;
+		u64 aq_ctx_poison                    : 1;
+		u64 aq_res_poison                    : 1;
+		u64 aq_inst_poison                   : 1;
+		u64 reserved_35_63                   : 29;
+	} s;
+	/* struct cavm_npa_af_ras_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RAS_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RAS_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x1a8;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_rvu_int
+ *
+ * NPA AF RVU Interrupt Register
+ * This register contains RVU error interrupt summary bits.
+ */
+union cavm_npa_af_rvu_int {
+	u64 u;
+	struct cavm_npa_af_rvu_int_s {
+		u64 unmapped_slot                    : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_rvu_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RVU_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RVU_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x160;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_rvu_int_ena_w1c
+ *
+ * NPA AF RVU Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_af_rvu_int_ena_w1c {
+	u64 u;
+	struct cavm_npa_af_rvu_int_ena_w1c_s {
+		u64 unmapped_slot                    : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_rvu_int_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RVU_INT_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RVU_INT_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x178;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_rvu_int_ena_w1s
+ *
+ * NPA AF RVU Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_af_rvu_int_ena_w1s {
+	u64 u;
+	struct cavm_npa_af_rvu_int_ena_w1s_s {
+		u64 unmapped_slot                    : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_rvu_int_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RVU_INT_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RVU_INT_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x170;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_rvu_int_w1s
+ *
+ * NPA AF RVU Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_af_rvu_int_w1s {
+	u64 u;
+	struct cavm_npa_af_rvu_int_w1s_s {
+		u64 unmapped_slot                    : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_af_rvu_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RVU_INT_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RVU_INT_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x168;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_af_rvu_lf_cfg_debug
+ *
+ * NPA Privileged LF Configuration Debug Register
+ * This debug register allows software to lookup the reverse mapping from VF/PF
+ * slot to LF. The forward mapping is programmed with NPA_PRIV_LF()_CFG.
+ */
+union cavm_npa_af_rvu_lf_cfg_debug {
+	u64 u;
+	struct cavm_npa_af_rvu_lf_cfg_debug_s {
+		u64 lf                               : 12;
+		u64 lf_valid                         : 1;
+		u64 exec                             : 1;
+		u64 reserved_14_15                   : 2;
+		u64 slot                             : 8;
+		u64 pf_func                          : 16;
+		u64 reserved_40_63                   : 24;
+	} s;
+	/* struct cavm_npa_af_rvu_lf_cfg_debug_s cn; */
+};
+
+static inline u64 CAVM_NPA_AF_RVU_LF_CFG_DEBUG(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_AF_RVU_LF_CFG_DEBUG(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x10030;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_alloc#
+ *
+ * NPA Aura Allocate Operation Registers
+ * These registers are used to allocate one or two pointers from a given aura's pool.
+ * A 64-bit atomic load-and-add to NPA_LF_AURA_OP_ALLOC(0) allocates a single pointer.
+ * A 128-bit atomic CASP operation to NPA_LF_AURA_OP_ALLOC(0..1) allocates two pointers.
+ * The atomic write data format is NPA_AURA_OP_WDATA_S.
+ * For CASP, the first SWAP word in the write data contains NPA_AURA_OP_WDATA_S
+ * and the remaining write data words are ignored.
+ *
+ * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_allocx {
+	u64 u;
+	struct cavm_npa_lf_aura_op_allocx_s {
+		u64 addr                             : 64;
+	} s;
+	/* struct cavm_npa_lf_aura_op_allocx_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_ALLOCX(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_ALLOCX(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 1))
+		return 0x10 + 8 * ((a) & 0x1);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_cnt
+ *
+ * NPA LF Aura Count Register
+ * A 64-bit atomic load-and-add to this register returns a given aura's
+ * count. A write sets or adds the aura's count. A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_cnt {
+	u64 u;
+	struct cavm_npa_lf_aura_op_cnt_s {
+		u64 count                            : 36;
+		u64 reserved_36_41                   : 6;
+		u64 op_err                           : 1;
+		u64 cnt_add                          : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_aura_op_cnt_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_CNT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_CNT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x30;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_free0
+ *
+ * NPA LF Aura Free Operation Register 0
+ * A 128-bit write to the NPA_LF_AURA_OP_FREE0 and NPA_LF_AURA_OP_FREE1
+ * registers frees a pointer into a given aura's pool.
+ * All other accesses to these registers (e.g. reads and 64-bit writes) are
+ * RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_free0 {
+	u64 u;
+	struct cavm_npa_lf_aura_op_free0_s {
+		u64 addr                             : 64;
+	} s;
+	/* struct cavm_npa_lf_aura_op_free0_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_FREE0(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_FREE0(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x20;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_free1
+ *
+ * NPA LF Aura Free Operation Register 1
+ * See NPA_LF_AURA_OP_FREE0.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_free1 {
+	u64 u;
+	struct cavm_npa_lf_aura_op_free1_s {
+		u64 aura                             : 20;
+		u64 reserved_20_62                   : 43;
+		u64 fabs                             : 1;
+	} s;
+	/* struct cavm_npa_lf_aura_op_free1_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_FREE1(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_FREE1(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x28;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_int
+ *
+ * NPA LF Aura Interrupt Operation Register
+ * A 64-bit atomic load-and-add to this register reads
+ * NPA_AURA_HW_S[ERR_INT,ERR_INT_ENA,THRESH_INT,THRESH_INT_ENA]. A write
+ * optionally sets or clears these fields. A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_int {
+	u64 u;
+	struct cavm_npa_lf_aura_op_int_s {
+		u64 err_int                          : 8;
+		u64 err_int_ena                      : 8;
+		u64 thresh_int                       : 1;
+		u64 thresh_int_ena                   : 1;
+		u64 reserved_18_41                   : 24;
+		u64 op_err                           : 1;
+		u64 setop                            : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_aura_op_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x60;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_limit
+ *
+ * NPA LF Aura Allocation Limit Register
+ * A 64-bit atomic load-and-add to this register returns a given aura's
+ * limit. A write sets the aura's limit. A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_limit {
+	u64 u;
+	struct cavm_npa_lf_aura_op_limit_s {
+		u64 limit                            : 36;
+		u64 reserved_36_41                   : 6;
+		u64 op_err                           : 1;
+		u64 reserved_43                      : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_aura_op_limit_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_LIMIT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_LIMIT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x50;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_aura_op_thresh
+ *
+ * NPA LF Aura Threshold Operation Register
+ * A 64-bit atomic load-and-add to this register reads
+ * NPA_AURA_HW_S[THRESH_UP,THRESH]. A write to the register writes
+ * NPA_AURA_HW_S[THRESH_UP,THRESH] and recomputes NPA_AURA_HW_S[THRESH_INT].
+ * A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_aura_op_thresh {
+	u64 u;
+	struct cavm_npa_lf_aura_op_thresh_s {
+		u64 thresh                           : 36;
+		u64 reserved_36_41                   : 6;
+		u64 op_err                           : 1;
+		u64 thresh_up                        : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_aura_op_thresh_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_AURA_OP_THRESH(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_AURA_OP_THRESH(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x70;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_err_int
+ *
+ * NPA LF Error Interrupt Register
+ */
+union cavm_npa_lf_err_int {
+	u64 u;
+	struct cavm_npa_lf_err_int_s {
+		u64 aura_dis                         : 1;
+		u64 aura_oor                         : 1;
+		u64 reserved_2                       : 1;
+		u64 rmt_req_oor                      : 1;
+		u64 reserved_4_11                    : 8;
+		u64 aura_fault                       : 1;
+		u64 pool_fault                       : 1;
+		u64 stack_fault                      : 1;
+		u64 qint_fault                       : 1;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_lf_err_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_ERR_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_ERR_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x200;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_err_int_ena_w1c
+ *
+ * NPA LF Error Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_lf_err_int_ena_w1c {
+	u64 u;
+	struct cavm_npa_lf_err_int_ena_w1c_s {
+		u64 aura_dis                         : 1;
+		u64 aura_oor                         : 1;
+		u64 reserved_2                       : 1;
+		u64 rmt_req_oor                      : 1;
+		u64 reserved_4_11                    : 8;
+		u64 aura_fault                       : 1;
+		u64 pool_fault                       : 1;
+		u64 stack_fault                      : 1;
+		u64 qint_fault                       : 1;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_lf_err_int_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_ERR_INT_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_ERR_INT_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x210;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_err_int_ena_w1s
+ *
+ * NPA LF Error Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_lf_err_int_ena_w1s {
+	u64 u;
+	struct cavm_npa_lf_err_int_ena_w1s_s {
+		u64 aura_dis                         : 1;
+		u64 aura_oor                         : 1;
+		u64 reserved_2                       : 1;
+		u64 rmt_req_oor                      : 1;
+		u64 reserved_4_11                    : 8;
+		u64 aura_fault                       : 1;
+		u64 pool_fault                       : 1;
+		u64 stack_fault                      : 1;
+		u64 qint_fault                       : 1;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_lf_err_int_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_ERR_INT_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_ERR_INT_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x218;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_err_int_w1s
+ *
+ * NPA LF Error Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_lf_err_int_w1s {
+	u64 u;
+	struct cavm_npa_lf_err_int_w1s_s {
+		u64 aura_dis                         : 1;
+		u64 aura_oor                         : 1;
+		u64 reserved_2                       : 1;
+		u64 rmt_req_oor                      : 1;
+		u64 reserved_4_11                    : 8;
+		u64 aura_fault                       : 1;
+		u64 pool_fault                       : 1;
+		u64 stack_fault                      : 1;
+		u64 qint_fault                       : 1;
+		u64 reserved_16_63                   : 48;
+	} s;
+	/* struct cavm_npa_lf_err_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_ERR_INT_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_ERR_INT_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x208;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_available
+ *
+ * NPA LF Pool Available Count Operation Register
+ * A 64-bit atomic load-and-add to this register returns a given pool's free
+ * pointer count. Reads and writes are RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_available {
+	u64 u;
+	struct cavm_npa_lf_pool_op_available_s {
+		u64 count                            : 36;
+		u64 reserved_36_41                   : 6;
+		u64 op_err                           : 1;
+		u64 reserved_43                      : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_pool_op_available_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_AVAILABLE(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_AVAILABLE(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x110;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_int
+ *
+ * NPA LF Pool Interrupt Operation Register
+ * A 64-bit atomic load-and-add to this register reads
+ * NPA_POOL_S[ERR_INT,ERR_INT_ENA,THRESH_INT,THRESH_INT_ENA]. A write optionally
+ * sets or clears these fields. A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_int {
+	u64 u;
+	struct cavm_npa_lf_pool_op_int_s {
+		u64 err_int                          : 8;
+		u64 err_int_ena                      : 8;
+		u64 thresh_int                       : 1;
+		u64 thresh_int_ena                   : 1;
+		u64 reserved_18_41                   : 24;
+		u64 op_err                           : 1;
+		u64 setop                            : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_pool_op_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_INT(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_INT(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x160;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_pc
+ *
+ * NPA LF Pool Performance Count Register
+ * A 64-bit atomic load-and-add to this register reads NPA_POOL_S[OP_PC] from a
+ * given aura's pool. The aura is slected by the atomic write data, whose format
+ * is NPA_AURA_OP_WDATA_S. Reads and writes are RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_pc {
+	u64 u;
+	struct cavm_npa_lf_pool_op_pc_s {
+		u64 op_pc                            : 48;
+		u64 op_err                           : 1;
+		u64 reserved_49_63                   : 15;
+	} s;
+	/* struct cavm_npa_lf_pool_op_pc_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_PC(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_PC(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x100;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_end0
+ *
+ * NPA LF Pool Pointer End Operation Register 0
+ * A 128-bit write to the NPA_LF_POOL_OP_PTR_END0 and NPA_LF_POOL_OP_PTR_END1
+ * registers writes to a given pool's pointer end value.
+ * All other accesses to these registers (e.g. reads and 64-bit writes) are
+ * RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_ptr_end0 {
+	u64 u;
+	struct cavm_npa_lf_pool_op_ptr_end0_s {
+		u64 ptr_end                          : 64;
+	} s;
+	/* struct cavm_npa_lf_pool_op_ptr_end0_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_END0(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_END0(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x130;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_end1
+ *
+ * NPA LF Pool Pointer End Operation Register 1
+ * See NPA_LF_POOL_OP_PTR_END0.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_ptr_end1 {
+	u64 u;
+	struct cavm_npa_lf_pool_op_ptr_end1_s {
+		u64 aura                             : 20;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_lf_pool_op_ptr_end1_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_END1(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_END1(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x138;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_start0
+ *
+ * NPA LF Pool Pointer Start Operation Register 0
+ * A 128-bit write to the NPA_LF_POOL_OP_PTR_START0 and NPA_LF_POOL_OP_PTR_START1
+ * registers writes to a given pool's pointer start value.
+ * All other accesses to these registers (e.g. reads and 64-bit writes) are
+ * RAZ/WI.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_ptr_start0 {
+	u64 u;
+	struct cavm_npa_lf_pool_op_ptr_start0_s {
+		u64 ptr_start                        : 64;
+	} s;
+	/* struct cavm_npa_lf_pool_op_ptr_start0_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_START0(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_START0(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x120;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_start1
+ *
+ * NPA LF Pool Pointer Start Operation Register 1
+ * See NPA_LF_POOL_OP_PTR_START0.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_ptr_start1 {
+	u64 u;
+	struct cavm_npa_lf_pool_op_ptr_start1_s {
+		u64 aura                             : 20;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_lf_pool_op_ptr_start1_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_START1(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_PTR_START1(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x128;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_pool_op_thresh
+ *
+ * NPA LF Pool Threshold Operation Register
+ * A 64-bit atomic load-and-add to this register reads
+ * NPA_POOL_S[THRESH_UP,THRESH]. A write to the register writes
+ * NPA_POOL_S[THRESH_UP,THRESH]. A read is RAZ.
+ *
+ * RSL accesses to this register are RAZ/WI.
+ */
+union cavm_npa_lf_pool_op_thresh {
+	u64 u;
+	struct cavm_npa_lf_pool_op_thresh_s {
+		u64 thresh                           : 36;
+		u64 reserved_36_41                   : 6;
+		u64 op_err                           : 1;
+		u64 thresh_up                        : 1;
+		u64 aura                             : 20;
+	} s;
+	/* struct cavm_npa_lf_pool_op_thresh_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_POOL_OP_THRESH(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_POOL_OP_THRESH(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x170;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_qint#_cnt
+ *
+ * NPA LF Queue Interrupt Count Registers
+ */
+union cavm_npa_lf_qintx_cnt {
+	u64 u;
+	struct cavm_npa_lf_qintx_cnt_s {
+		u64 count                            : 22;
+		u64 reserved_22_63                   : 42;
+	} s;
+	/* struct cavm_npa_lf_qintx_cnt_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_QINTX_CNT(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_QINTX_CNT(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 63))
+		return 0x300 + 0x1000 * ((a) & 0x3f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_qint#_ena_w1c
+ *
+ * NPA LF Queue Interrupt Enable Clear Registers
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_lf_qintx_ena_w1c {
+	u64 u;
+	struct cavm_npa_lf_qintx_ena_w1c_s {
+		u64 intr                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_lf_qintx_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_QINTX_ENA_W1C(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_QINTX_ENA_W1C(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 63))
+		return 0x330 + 0x1000 * ((a) & 0x3f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_qint#_ena_w1s
+ *
+ * NPA LF Queue Interrupt Enable Set Registers
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_lf_qintx_ena_w1s {
+	u64 u;
+	struct cavm_npa_lf_qintx_ena_w1s_s {
+		u64 intr                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_lf_qintx_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_QINTX_ENA_W1S(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_QINTX_ENA_W1S(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 63))
+		return 0x320 + 0x1000 * ((a) & 0x3f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_qint#_int
+ *
+ * NPA LF Queue Interrupt Registers
+ */
+union cavm_npa_lf_qintx_int {
+	u64 u;
+	struct cavm_npa_lf_qintx_int_s {
+		u64 intr                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_lf_qintx_int_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_QINTX_INT(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_QINTX_INT(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 63))
+		return 0x310 + 0x1000 * ((a) & 0x3f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_qint#_int_w1s
+ *
+ * INTERNAL: NPA LF Queue Interrupt Set Registers
+ */
+union cavm_npa_lf_qintx_int_w1s {
+	u64 u;
+	struct cavm_npa_lf_qintx_int_w1s_s {
+		u64 intr                             : 1;
+		u64 reserved_1_63                    : 63;
+	} s;
+	/* struct cavm_npa_lf_qintx_int_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_QINTX_INT_W1S(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_QINTX_INT_W1S(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 63))
+		return 0x318 + 0x1000 * ((a) & 0x3f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_ras
+ *
+ * NPA LF RAS Interrupt Register
+ */
+union cavm_npa_lf_ras {
+	u64 u;
+	struct cavm_npa_lf_ras_s {
+		u64 aura_poison                      : 1;
+		u64 pool_poison                      : 1;
+		u64 stack_poison                     : 1;
+		u64 qint_poison                      : 1;
+		u64 reserved_4_63                    : 60;
+	} s;
+	/* struct cavm_npa_lf_ras_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_RAS(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_RAS(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x220;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_ras_ena_w1c
+ *
+ * NPA LF RAS Interrupt Enable Clear Register
+ * This register clears interrupt enable bits.
+ */
+union cavm_npa_lf_ras_ena_w1c {
+	u64 u;
+	struct cavm_npa_lf_ras_ena_w1c_s {
+		u64 aura_poison                      : 1;
+		u64 pool_poison                      : 1;
+		u64 stack_poison                     : 1;
+		u64 qint_poison                      : 1;
+		u64 reserved_4_63                    : 60;
+	} s;
+	/* struct cavm_npa_lf_ras_ena_w1c_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_RAS_ENA_W1C(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_RAS_ENA_W1C(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x230;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_ras_ena_w1s
+ *
+ * NPA LF RAS Interrupt Enable Set Register
+ * This register sets interrupt enable bits.
+ */
+union cavm_npa_lf_ras_ena_w1s {
+	u64 u;
+	struct cavm_npa_lf_ras_ena_w1s_s {
+		u64 aura_poison                      : 1;
+		u64 pool_poison                      : 1;
+		u64 stack_poison                     : 1;
+		u64 qint_poison                      : 1;
+		u64 reserved_4_63                    : 60;
+	} s;
+	/* struct cavm_npa_lf_ras_ena_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_RAS_ENA_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_RAS_ENA_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x238;
+	return -1;
+}
+
+/**
+ * Register (RVU_PFVF_BAR2) npa_lf_ras_w1s
+ *
+ * NPA LF RAS Interrupt Set Register
+ * This register sets interrupt bits.
+ */
+union cavm_npa_lf_ras_w1s {
+	u64 u;
+	struct cavm_npa_lf_ras_w1s_s {
+		u64 aura_poison                      : 1;
+		u64 pool_poison                      : 1;
+		u64 stack_poison                     : 1;
+		u64 qint_poison                      : 1;
+		u64 reserved_4_63                    : 60;
+	} s;
+	/* struct cavm_npa_lf_ras_w1s_s cn; */
+};
+
+static inline u64 CAVM_NPA_LF_RAS_W1S(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_LF_RAS_W1S(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x228;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_priv_af_int_cfg
+ *
+ * NPA Privileged AF Interrupt Configuration Register
+ */
+union cavm_npa_priv_af_int_cfg {
+	u64 u;
+	struct cavm_npa_priv_af_int_cfg_s {
+		u64 msix_offset                      : 11;
+		u64 reserved_11                      : 1;
+		u64 msix_size                        : 8;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_priv_af_int_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_PRIV_AF_INT_CFG(void)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_PRIV_AF_INT_CFG(void)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX))
+		return 0x10000;
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_priv_lf#_cfg
+ *
+ * NPA Privileged Local Function Configuration Registers
+ * These registers allow each NPA local function (LF) to be provisioned to a VF/PF
+ * slot for RVU. See also NPA_AF_RVU_LF_CFG_DEBUG.
+ *
+ * Software should read this register after write to ensure that the LF is mapped to
+ * [PF_FUNC] before issuing transactions to the mapped PF and function.
+ *
+ * [SLOT] must be zero.
+ *
+ * Internal:
+ * Hardware ignores [SLOT] and always assumes 0x0.
+ */
+union cavm_npa_priv_lfx_cfg {
+	u64 u;
+	struct cavm_npa_priv_lfx_cfg_s {
+		u64 slot                             : 8;
+		u64 pf_func                          : 16;
+		u64 reserved_24_62                   : 39;
+		u64 ena                              : 1;
+	} s;
+	/* struct cavm_npa_priv_lfx_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_PRIV_LFX_CFG(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_PRIV_LFX_CFG(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x10010 + 0x100 * ((a) & 0x7f);
+	return -1;
+}
+
+/**
+ * Register (RVU_PF_BAR0) npa_priv_lf#_int_cfg
+ *
+ * NPA Privileged LF Interrupt Configuration Registers
+ */
+union cavm_npa_priv_lfx_int_cfg {
+	u64 u;
+	struct cavm_npa_priv_lfx_int_cfg_s {
+		u64 msix_offset                      : 11;
+		u64 reserved_11                      : 1;
+		u64 msix_size                        : 8;
+		u64 reserved_20_63                   : 44;
+	} s;
+	/* struct cavm_npa_priv_lfx_int_cfg_s cn; */
+};
+
+static inline u64 CAVM_NPA_PRIV_LFX_INT_CFG(u64 a)
+	__attribute__ ((pure, always_inline));
+static inline u64 CAVM_NPA_PRIV_LFX_INT_CFG(u64 a)
+{
+	if (CAVIUM_IS_MODEL(CAVIUM_CN9XXX) && (a <= 127))
+		return 0x10020 + 0x100 * ((a) & 0x7f);
+	return -1;
+}
+
+#endif /* __CAVM_CSRS_NPA_H__ */
diff --git a/drivers/net/cavium/octeontx2/cgx.c b/drivers/net/cavium/octeontx2/cgx.c
index 6a99ca1b17..49e225d1bf 100644
--- a/drivers/net/cavium/octeontx2/cgx.c
+++ b/drivers/net/cavium/octeontx2/cgx.c
@@ -7,8 +7,7 @@
  * the License, or (at your option) any later version.
  *
  */
-
-#include <config.h>
+#define DEBUG
 #include <common.h>
 #include <net.h>
 #include <netdev.h>
@@ -17,39 +16,270 @@
 #include <misc.h>
 #include <asm/io.h>
 #include <errno.h>
+#include <linux/list.h>
+#include <asm/arch/octeontx2.h>
 
+#include "cavm-csrs-cgx.h"
+#include "cgx_intf.h"
 #include "cgx.h"
 
+static LIST_HEAD(cgx_list);
 
-void enumerate_lmacs(void)
+static inline struct lmac *lmac_pdata(u8 lmac_id, struct cgx *cgx)
 {
+	if (!cgx || lmac_id > MAX_LMAC_PER_CGX)
+		return NULL;
 
+	return cgx->lmac_idmap[lmac_id];
 }
 
-int cgx_probe(struct udevice *dev)
+int cgx_get_cgx_cnt(void)
 {
-	struct cgx *p_cgx = dev_get_priv(dev);
-	size_t size;
+	struct cgx *cgx_dev;
+	int count = 0;
+
+	list_for_each_entry(cgx_dev, &cgx_list, cgx_list)
+		count++;
+
+	return count;
+}
+
+int cgx_get_lmac_cnt(void *cgxd)
+{
+	struct cgx *cgx = cgxd;
+
+	if (!cgx)
+		return -ENODEV;
+
+	return cgx->lmac_count;
+}
+
+void *cgx_get_pdata(int cgx_id)
+{
+	struct cgx *cgx_dev;
+
+	list_for_each_entry(cgx_dev, &cgx_list, cgx_list) {
+		if (cgx_dev->cgx_id == cgx_id)
+			return cgx_dev;
+	}
+	return NULL;
+}
+
+/**
+ * Given an LMAC instance number, return the lmac
+ *
+ * @param instance	instance to find
+ *
+ * @return	pointer to lmac data structure or NULL if not found
+ */
+struct lmac *cgx_get_lmac(int instance)
+{
+	struct cgx *cgx;
+	int i;
+
+	list_for_each_entry(cgx, &cgx_list, cgx_list) {
+		for (i = 0; i < MAX_LMAC_PER_CGX; i++) {
+			if (cgx->lmac_idmap[i] &&
+			    cgx->lmac_idmap[i]->instance == instance)
+				return cgx->lmac_idmap[i];
+		}
+	}
+	return NULL;
+}
+
+static void cgx_write(struct cgx *cgx, u64 lmac, u64 offset, u64 val)
+{
+	writeq(val, cgx->reg_base + (lmac << 18) + offset);
+}
+
+static u64 cgx_read(struct cgx *cgx, u64 lmac, u64 offset)
+{
+	return readq(cgx->reg_base + (lmac << 18) + offset);
+}
+
+int cgx_set_pkind(void *cgxd, u8 lmac_id, int pkind)
+{
+	struct cgx *cgx = cgxd;
+
+	if (!cgx || lmac_id >= cgx->lmac_count)
+		return -ENODEV;
+
+	cgx_write(cgx, lmac_id, CAVM_CGXX_CMRX_RX_ID_MAP(0), (pkind & 0x3f));
+	return 0;
+}
+
+/**
+ * Given a linear link number, get the cgx and lmac
+ *
+ * @param	linear_link_number	Linear link number
+ * @param[out]	cgx_id			cgx_id number
+ * @parma[out]	lmac_id			lmac_id number
+ *
+ * @return 0 for success or -1 if not found
+ */
+int cgx_get_identifiers(int linear_link_number, int *cgx_id, int *lmac_id)
+{
+	int index = 0;
+	struct cgx *cgx;
+
+	for (cgx = cgx_get_pdata(index); cgx; index++) {
+		if (linear_link_number < cgx->lmac_count) {
+			*cgx_id = cgx->cgx_id;
+			*lmac_id = linear_link_number;
+			return 0;
+		} else {
+			linear_link_number -= cgx->lmac_count;
+		}
+	}
+	return -1;
+}
+
+int cgx_channel_number(int linear_link_number)
+{
+	int cgx_id, lmac_id, err;
+
+	err = cgx_get_identifiers(linear_link_number, &cgx_id, &lmac_id);
+	if (err)
+		return -1;
+	else
+		return (0x800 + 0x100 * cgx_id + 0x10 * lmac_id + 0);
+}
+
+int cgx_link_number(int linear_link_number)
+{
+	int cgx_id, lmac_id, err;
+
+	err = cgx_get_identifiers(linear_link_number, &cgx_id, &lmac_id);
+	if (err)
+		return -1;
+	else
+		return (4 * cgx_id + lmac_id);
+}
 
-	p_cgx->base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
+u64 cgx_get_channel_number(struct cgx *cgx, int linear_link_number)
+{
+	int lmac_id;
+	if (!cgx->lmac_idmap[linear_link_number]) {
+		printf("%s: Invalid link number %d for cgx %d\n", __func__,
+		       linear_link_number, cgx->cgx_id);
+		return 0;
+	}
 
-	debug("CGX BAR %p\n", p_cgx->base);
+	lmac_id = cgx->lmac_idmap[linear_link_number]->lmac_id;
+	return (0x800 + 0x100 * cgx->cgx_id + 0x10 * lmac_id + 0);
+}
+
+int cgx_lmac_internal_loopback(void *cgxd, int lmac_id, bool enable)
+{
+	struct cgx *cgx = cgxd;
+	union cavm_cgxx_cmrx_config cmrx_cfg;
+	union cavm_cgxx_gmp_pcs_mrx_control mrx_control;
+	union cavm_cgxx_spux_control1 spux_control1;
+	enum lmac_type lmac_type;
 
-	enumerate_lmacs();
+	if (!cgx || lmac_id >= cgx->lmac_count)
+		return -ENODEV;
 
+	cmrx_cfg.u = cgx_read(cgx, lmac_id, CAVM_CGXX_CMRX_CONFIG(0));
+	lmac_type = cmrx_cfg.s.lmac_type;
+	if (lmac_type == LMAC_MODE_SGMII || lmac_type == LMAC_MODE_QSGMII) {
+		mrx_control.u = cgx_read(cgx, lmac_id,
+					 CAVM_CGXX_GMP_PCS_MRX_CONTROL(0));
+		mrx_control.s.loopbck1 = enable ? 1 : 0;
+		cgx_write(cgx, lmac_id, CAVM_CGXX_GMP_PCS_MRX_CONTROL(0),
+			  mrx_control.u);
+	} else {
+		spux_control1.u = cgx_read(cgx, lmac_id,
+					   CAVM_CGXX_SPUX_CONTROL1(0));
+		spux_control1.s.loopbck = enable ? 1 : 0;
+		cgx_write(cgx, lmac_id, CAVM_CGXX_SPUX_CONTROL1(0),
+			  spux_control1.u);
+	}
 	return 0;
 }
 
-int cgx_remove(struct udevice *dev)
+int cgx_lmac_rx_tx_enable(void *cgxd, int lmac_id, bool enable)
 {
+	struct cgx *cgx = cgxd;
+	union cavm_cgxx_cmrx_config cmrx_config;
+
+	if (!cgx || lmac_id >= cgx->lmac_count)
+		return -ENODEV;
+
+	cmrx_config.u = cgx_read(cgx, lmac_id, CAVM_CGXX_CMRX_CONFIG(0));
+	cmrx_config.s.enable =
+		cmrx_config.s.data_pkt_rx_en =
+		cmrx_config.s.data_pkt_tx_en = enable ? 1 : 0;
+	cgx_write(cgx, lmac_id, CAVM_CGXX_CMRX_CONFIG(0), cmrx_config.u);
 	return 0;
 }
 
+static int cgx_lmac_init(struct cgx *cgx)
+{
+	struct lmac *lmac;
+	int i;
+	union cavm_cgxx_cmrx_config cmrx_cfg;
+	static int instance = 0;
+
+	cgx->lmac_count = cgx_read(cgx, 0, CAVM_CGXX_CMR_RX_LMACS());
+	debug("%s: Found %d lmacs for cgx %d@%p\n", __func__, cgx->lmac_count,
+	      cgx->cgx_id, cgx->reg_base);
+	if (cgx->lmac_count > MAX_LMAC_PER_CGX)
+		cgx->lmac_count = MAX_LMAC_PER_CGX;
+
+	for (i = 0; i < cgx->lmac_count; i++) {
+		lmac = calloc(1, sizeof(*lmac));
+		if (!lmac)
+			return -ENOMEM;
+		lmac->instance = instance++;
+		snprintf(lmac->name, sizeof(lmac->name), "cgx_fwi_%d_%d",
+			 cgx->cgx_id, i);
+		/* Get LMAC type */
+		cmrx_cfg.u = cgx_read(cgx, i, CAVM_CGXX_CMRX_CONFIG(0));
+		lmac->lmac_type = cmrx_cfg.s.lmac_type;
+
+		lmac->lmac_id = i;
+		lmac->cgx = cgx;
+		cgx->lmac_idmap[i] = lmac;
+		debug("%s: mapping id %d to lmac %p (%s), lmac type: %d\n",
+		      __func__, i, lmac, lmac->name, lmac->lmac_type);
+	}
+	return 0;
+}
+
+void enumerate_lmacs(void)
+{
+
+}
+
+int cgx_probe(struct udevice *dev)
+{
+	struct cgx *cgx = dev_get_priv(dev);
+	size_t size;
+	int err;
+	static int instance = 0;
+
+	cgx->reg_base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
+	cgx->dev = dev;
+	cgx->cgx_id = ((u64)(cgx->reg_base) >> 24) & 0x7;
+	cgx->instance = instance++;
+
+	debug("CGX BAR %p, id: %d, instance: %d\n",
+	      cgx->reg_base, cgx->cgx_id, cgx->instance);
+
+	/*enumerate_lmacs();*/
+
+	err = cgx_lmac_init(cgx);
+	if (!err)
+		list_add(&cgx->cgx_list, &cgx_list);
+
+	return err;
+}
+
 U_BOOT_DRIVER(cgx) = {
         .name   = "cgx",
         .id     = UCLASS_MISC,
         .probe  = cgx_probe,
-	.remove	= cgx_remove,
         .priv_auto_alloc_size = sizeof(struct cgx),
 };
 
diff --git a/drivers/net/cavium/octeontx2/cgx.h b/drivers/net/cavium/octeontx2/cgx.h
index 9983e39a37..78125c595a 100644
--- a/drivers/net/cavium/octeontx2/cgx.h
+++ b/drivers/net/cavium/octeontx2/cgx.h
@@ -8,12 +8,36 @@
  *
  */
 
-//#include "cavm-csrs-cgx.h"
+#ifndef __CGX_H__
+#define __CGX_H__
 
-#define LMAC_PER_CGX 4
-#define CGX_PER_NODE 3
 #define PCI_DEVICE_ID_OCTEONTX2_CGX	0xA059
 
+#define CGX_FIRWARE_MAJOR_VER		1
+#define CGX_FIRWARE_MINOR_VER		0
+#define MAX_LMAC_PER_CGX		4
+#define CGX_PER_NODE 			3
+
+/* Register offsets */
+#define CGX_CMR_SCRATCH0	0x87e0e0001050
+#define CGX_CMR_SCRATCH1	0x87e0e0001058
+
+#define CGX_SHIFT(x)		(0x1000000 * (x & 0x3))
+#define CMR_SHIFT(x)		(0x40000 * (x & 0x3))
+
+enum lmac_type {
+	LMAC_MODE_SGMII		= 0,
+	LMAC_MODE_XAUI		= 1,
+	LMAC_MODE_RXAUI		= 2,
+	LMAC_MODE_10G_R		= 3,
+	LMAC_MODE_40G_R		= 4,
+	LMAC_MODE_QSGMII	= 6,
+	LMAC_MODE_25G_R		= 7,
+	LMAC_MODE_50G_R		= 8,
+	LMAC_MODE_100G_R	= 9,
+	LMAC_MODE_USXGMII	= 10,
+};
+
 struct lmac_priv {
 	u8 enable:1;
 	u8 full_duplex:1;
@@ -23,12 +47,54 @@ struct lmac_priv {
 	u8 mac_addr[6];
 };
 
-struct cgx_priv {
-	u8 enable;
-	struct lmac_priv lmac[LMAC_PER_CGX];
+struct cgx;
+struct nix_handle;
+struct nix_af_handle;
+
+struct lmac {
+	struct cgx	*cgx;
+	struct nix_handle *nix;
+	char		name[16];
+	enum lmac_type	lmac_type;
+	bool		cmd_pend;
+	u8		instance;
+	u8		lmac_id;
+	u32		linear_link_number;
 };
 
 struct cgx {
-	void *__iomem base;
-	struct cgx_priv cgx;
+	struct nix_af_handle	*nix_af;
+	void __iomem		*reg_base;
+	struct udevice		*dev;
+	struct lmac		*lmac_idmap[MAX_LMAC_PER_CGX];
+	struct list_head	cgx_list;
+	u8			instance;
+	u8			cgx_id;
+	u8			lmac_count;
 };
+
+int cgx_get_cgx_cnt(void);
+int cgx_get_lmac_cnt(void *cgxd);
+/**
+ * Given an LMAC instance number, return the lmac
+ *
+ * @param instance	instance to find
+ *
+ * @return	pointer to lmac data structure or NULL if not found
+ */
+struct lmac *cgx_get_lmac(int instance);
+void *cgx_get_pdata(int cgx_id);
+int cgx_set_pkind(void *cgxd, u8 lmac_id, int pkind);
+u64 cgx_get_channel_number(struct cgx *cgx, int linear_link_number);
+/**
+ * Given a linear link number, get the cgx and lmac
+ *
+ * @param	linear_link_number	Linear link number
+ * @param[out]	cgx_id			cgx_id number
+ * @parma[out]	lmac_id			lmac_id number
+ *
+ * @return 0 for success or -1 if not found
+ */
+int cgx_get_identifiers(int linear_link_number, int *cgx_id, int *lmac_id);
+
+#endif /* __CGX_H__ */
diff --git a/drivers/net/cavium/octeontx2/cgx_fw_if.h b/drivers/net/cavium/octeontx2/cgx_fw_if.h
new file mode 100644
index 0000000000..c83ba7c3f5
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/cgx_fw_if.h
@@ -0,0 +1,225 @@
+/*
+ * Copyright (C) 2017 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of version 2 of the GNU General Public License
+ * as published by the Free Software Foundation.
+ */
+
+#ifndef __CGX_FW_INTF_H__
+#define __CGX_FW_INTF_H__
+
+#define CGX_FIRMWARE_MAJOR_VER		1
+#define CGX_FIRMWARE_MINOR_VER		0
+
+#define CGX_EVENT_ACK                   1UL
+
+/** CGX error types. set for cmd response status as CGX_STAT_FAIL */
+enum cgx_error_type {
+	CGX_ERR_NONE,
+	CGX_ERR_LMAC_NOT_ENABLED,
+	CGX_ERR_LMAC_MODE_INVALID,
+	CGX_ERR_REQUEST_ID_INVALID,
+	CGX_ERR_PREV_ACK_NOT_CLEAR,
+	CGX_ERR_PHY_LINK_DOWN,
+	CGX_ERR_PCS_RESET_FAIL,
+	CGX_ERR_AN_CPT_FAIL,
+	CGX_ERR_TX_NOT_IDLE,
+	CGX_ERR_RX_NOT_IDLE,
+	CGX_ERR_SPUX_BR_BLKLOCK_FAIL,
+	CGX_ERR_SPUX_RX_ALIGN_FAIL,
+	CGX_ERR_SPUX_TX_FAULT,
+	CGX_ERR_SPUX_RX_FAULT,
+	CGX_ERR_SPUX_RESET_FAIL,
+	CGX_ERR_SMUX_RX_LINK_NOT_OK,
+	CGX_ERR_PCS_RECV_LINK_FAIL,
+	CGX_ERR_TRAINING_FAIL,
+	CGX_ERR_RX_EQU_FAIL,		/* = 18 */
+	/* FIXME : add more error types when adding support for new modes */
+};
+
+/* LINK speed types */
+enum cgx_link_speed {
+	CGX_LINK_NONE,
+	CGX_LINK_10M,
+	CGX_LINK_100M,
+	CGX_LINK_1G,
+	CGX_LINK_10G,
+	CGX_LINK_25G,
+	CGX_LINK_40G,
+	CGX_LINK_50G,
+	CGX_LINK_100G,
+};
+
+/* REQUEST ID types. Input to firmware */
+enum cgx_cmd_id {
+	CGX_CMD_NONE,
+	CGX_CMD_GET_FW_VER,
+	CGX_CMD_GET_MAC_ADDR,
+	CGX_CMD_SET_MTU,
+	CGX_CMD_GET_LINK_STS,		/* optional to user */
+	CGX_CMD_LINK_BRING_UP,
+	CGX_CMD_LINK_BRING_DOWN,
+	CGX_CMD_INTERNAL_LBK,
+	CGX_CMD_EXTERNAL_LBK,
+	CGX_CMD_HIGIG,
+	CGX_CMD_LINK_STATE_CHANGE,
+	CGX_CMD_MODE_CHANGE,		/* hot plug support */
+	CGX_CMD_INTF_SHUTDOWN,
+	CGX_CMD_IRQ_ENABLE,
+	CGX_CMD_IRQ_DISABLE,
+};
+
+/* async event ids */
+enum cgx_evt_id {
+	CGX_EVT_NONE,
+	CGX_EVT_LINK_CHANGE,
+};
+
+/* event types - cause of interrupt */
+enum cgx_evt_type {
+	CGX_EVT_ASYNC,
+	CGX_EVT_CMD_RESP
+};
+
+enum cgx_stat {
+	CGX_STAT_SUCCESS,
+	CGX_STAT_FAIL
+};
+
+enum cgx_cmd_own {
+	/* set by kernel/uefi/u-boot after posting a new request to ATF */
+	/* set by firmware */
+	CGX_CMD_OWN_NS,
+	CGX_CMD_OWN_FIRMWARE,
+};
+
+/* scratchx(0) CSR used for ATF->non-secure SW communication.
+ * This acts as the status register
+ * Provides details on command ack/status, link status, error details
+ */
+
+/* CAUTION : below structures are placed in order based on the bit positions
+ * For any updates/new bitfields, corresponding structures needs to be updated
+ */
+struct cgx_evt_sts {			/* start from bit 0 */
+	uint64_t ack:1;
+	uint64_t evt_type:1;		/* cgx_evt_type */
+	uint64_t stat:1;		/* cgx_stat */
+	uint64_t id:6;			/* cgx_evt_id/cgx_cmd_id */
+	uint64_t reserved:55;
+};
+
+/* all the below structures are in the same memory location of SCRATCHX(0)
+ * value can be read/written based on command ID
+ */
+
+/* Resp to command IDs with command status as CGX_STAT_FAIL
+ *
+ * Not applicable for commands :
+ * CGX_CMD_LINK_BRING_UP/DOWN/CGX_EVT_LINK_CHANGE
+ * check struct cgx_lnk_sts comments
+ */
+struct cgx_err_sts_s {			/* start from bit 9 */
+	uint64_t reserved1:9;
+	uint64_t type:10;		/* cgx_error_type */
+	uint64_t reserved2:35;
+};
+
+/* Resp to cmd ID as CGX_CMD_GET_FW_VER with cmd status as CGX_STAT_SUCCESS */
+struct cgx_ver_s {			/* start from bit 9 */
+	uint64_t reserved1:9;
+	uint64_t major_ver:4;
+	uint64_t minor_ver:4;
+	uint64_t reserved2:47;
+};
+
+/* Resp to cmd ID as CGX_CMD_GET_MAC_ADDR with cmd status as CGX_STAT_SUCCESS */
+struct cgx_mac_addr_s {			/* start from bit 9 */
+	uint64_t reserved1:9;
+	uint64_t local_mac_addr:48;
+	uint64_t reserved2:7;
+};
+
+/* Resp to cmd ID - CGX_CMD_LINK_BRING_UP/DOWN, event ID CGX_EVT_LINK_CHANGE
+ * status can be either CGX_STAT_FAIL or CGX_STAT_SUCCESS
+ * In case of CGX_STAT_FAIL, it indicates CGX configuration failed
+ * when processing link up/down/change command.
+ * Both err_type and current link status will be updated
+ * In case of CGX_STAT_SUCCESS, err_type will be CGX_ERR_NONE and current
+ * link status will be updated
+ */
+struct cgx_lnk_sts {
+	uint64_t reserved1:9;
+	uint64_t link_up:1;
+	uint64_t full_duplex:1;
+	uint64_t speed:4;		/* cgx_link_speed */
+	uint64_t err_type:10;
+	uint64_t reserved2:39;
+};
+
+union cgx_evtreg {
+	u64 val;
+	struct cgx_evt_sts evt_sts; /* common for all commands/events */
+	struct cgx_lnk_sts link_sts; /* response to LINK_BRINGUP/DOWN/CHANGE */
+	struct cgx_ver_s ver;		/* response to CGX_CMD_GET_FW_VER */
+	struct cgx_mac_addr_s mac_addr;	/* response to CGX_CMD_GET_MAC_ADDR */
+	struct cgx_err_sts_s err;	/* response if evt_status = CMD_FAIL */
+};
+
+/* scratchx(1) CSR used for non-secure SW->ATF communication
+ * This CSR acts as a command register
+ */
+struct cgx_cmd {			/* start from bit 2 */
+	uint64_t own:2;			/* cgx_csr_own */
+	uint64_t id:6;			/* cgx_request_id */
+	uint64_t reserved2:56;
+};
+
+/* all the below structures are in the same memory location of SCRATCHX(1)
+ * corresponding arguments for command Id needs to be updated
+ */
+
+/* Any command using enable/disable as an argument need
+ * to pass the option via this structure.
+ * Ex: Loopback, HiGig...
+ */
+struct cgx_ctl_args {			/* start from bit 8 */
+	uint64_t reserved1:8;
+	uint64_t enable:1;
+	uint64_t reserved2:55;
+};
+
+/* command argument to be passed for cmd ID - CGX_CMD_SET_MTU */
+struct cgx_mtu_args {
+	uint64_t reserved1:8;
+	uint64_t size:16;
+	uint64_t reserved2:40;
+};
+
+/* command argument to be passed for cmd ID - CGX_CMD_LINK_CHANGE */
+struct cgx_link_change_args {		/* start from bit 8 */
+	uint64_t reserved1:8;
+	uint64_t link_up:1;
+	uint64_t full_duplex:1;
+	uint64_t speed:4;		/* cgx_link_speed */
+	uint64_t reserved2:50;
+};
+
+struct cgx_irq_cfg {
+	uint64_t reserved1:8;
+	uint64_t irq_phys:32;
+	uint64_t reserved2:24;
+};
+
+union cgx_cmdreg {
+	u64 val;
+	struct cgx_cmd cmd;
+	struct cgx_ctl_args cmd_args;
+	struct cgx_mtu_args mtu_size;
+	struct cgx_irq_cfg irq_cfg; /* Input to CGX_CMD_IRQ_ENABLE */
+	struct cgx_link_change_args lnk_args;/* Input to CGX_CMD_LINK_CHANGE */
+	/* any other arg for command id * like : mtu, dmac filtering control */
+};
+
+#endif /* __CGX_FW_INTF_H__ */
diff --git a/drivers/net/cavium/octeontx2/cgx_intf.c b/drivers/net/cavium/octeontx2/cgx_intf.c
index 175db485c0..fd7c4df68f 100644
--- a/drivers/net/cavium/octeontx2/cgx_intf.c
+++ b/drivers/net/cavium/octeontx2/cgx_intf.c
@@ -7,7 +7,6 @@
  * the License, or (at your option) any later version.
  */
 
-#include <config.h>
 #include <common.h>
 #include <net.h>
 #include <netdev.h>
@@ -16,64 +15,67 @@
 #include <misc.h>
 #include <asm/io.h>
 #include <errno.h>
+#include <linux/list.h>
+#include <asm/arch/octeontx2.h>
 
+#include "cgx.h"
 #include "cgx_intf.h"
 
-static uint64_t cgx_rd_scrx(u8 cgx, u8 lmac, u8 index)
+static u64 cgx_rd_scrx(u8 cgx, u8 lmac, u8 index)
 {
-	uint64_t addr;
+	u64 addr;
 
 	addr = (index == 1) ? CGX_CMR_SCRATCH1 : CGX_CMR_SCRATCH0;
 	addr += CGX_SHIFT(cgx) + CMR_SHIFT(lmac);
 	return readq(addr);
 }
 
-static void cgx_wr_scrx(u8 cgx, u8 lmac, u8 index, uint64_t val)
+static void cgx_wr_scrx(u8 cgx, u8 lmac, u8 index, u64 val)
 {
-	uint64_t addr;
+	u64 addr;
 
 	addr = (index == 1) ? CGX_CMR_SCRATCH1 : CGX_CMR_SCRATCH0;
 	addr += CGX_SHIFT(cgx) + CMR_SHIFT(lmac);
 	writeq(val, addr);
 }
 
-static uint64_t cgx_rd_scr0(u8 cgx, u8 lmac)
+static u64 cgx_rd_scr0(u8 cgx, u8 lmac)
 {
 	return cgx_rd_scrx(cgx, lmac, 0);
 }
 
-static uint64_t cgx_rd_scr1(u8 cgx, u8 lmac)
+static u64 cgx_rd_scr1(u8 cgx, u8 lmac)
 {
 	return cgx_rd_scrx(cgx, lmac, 1);
 }
 
-static void cgx_wr_scr0(u8 cgx, u8 lmac, uint64_t val)
+static void cgx_wr_scr0(u8 cgx, u8 lmac, u64 val)
 {
 	return cgx_wr_scrx(cgx, lmac, 0, val);
 }
 
-static void cgx_wr_scr1(u8 cgx, u8 lmac, uint64_t val)
+static void cgx_wr_scr1(u8 cgx, u8 lmac, u64 val)
 {
 	return cgx_wr_scrx(cgx, lmac, 1, val);
 }
 
-void set_ownership(u8 cgx, u8 lmac, u8 val)
+static void set_ownership(u8 cgx, u8 lmac, u8 val)
 {
 	union cgx_scratchx1 scr1;
 	scr1.u = cgx_rd_scr1(cgx, lmac);
 	scr1.s.own_status = val;
-	cgx_wr_scr1(cgx, lmac, scr1.u);		
+	cgx_wr_scr1(cgx, lmac, scr1.u);
 }
 
-int wait_for_ownership(u8 cgx, u8 lmac)
+static int wait_for_ownership(u8 cgx, u8 lmac)
 {
 	union cgx_scratchx1 scr1;
 	union cgx_scratchx0 scr0;
 	int timeout = 5000;
-	
+
 	scr1.u = cgx_rd_scr1(cgx, lmac);
 	scr0.u = cgx_rd_scr0(cgx, lmac);
-	
+
 	while (scr1.s.own_status == CGX_OWN_FIRMWARE &&
 		scr0.s.evt_sts.ack) {
 		if (timeout-- < 0) {
@@ -87,7 +89,7 @@ int wait_for_ownership(u8 cgx, u8 lmac)
 	return 0;
 }
 
-int cgx_intf_req(u8 cgx, u8 lmac, u8 cmd, uint64_t *rsp)
+int cgx_intf_req(u8 cgx, u8 lmac, u8 cmd, u64 *rsp)
 {
 	union cgx_scratchx1 scr1;
 	union cgx_scratchx0 scr0;
@@ -161,6 +163,8 @@ int cgx_intf_get_ver(u8 cgx, u8 lmac, u8 *ver)
 
 	scr0.u >>= 9;
 	*ver = scr0.u & 0xFFFF;
+
+	return 0;
 }
 
 int cgx_intf_get_link_sts(u8 cgx, u8 lmac, u8 *lnk_sts)
@@ -174,7 +178,7 @@ int cgx_intf_get_link_sts(u8 cgx, u8 lmac, u8 *lnk_sts)
 		return -1;
 
 	scr0.u >>= 9;
-	/* pass the same format as cgx_lnk_sts_s 
+	/* pass the same format as cgx_lnk_sts_s
 	 * err_type:10, speed:4, full_duplex:1, link_up:1
 	 */
 	*lnk_sts = scr0.u & 0xFFFF;
@@ -196,7 +200,7 @@ int cgx_intf_link_up_dwn(u8 cgx, u8 lmac, u8 up_dwn, u8 *lnk_sts)
 		return -1;
 
 	scr0.u >>= 9;
-	/* pass the same format as cgx_lnk_sts_s 
+	/* pass the same format as cgx_lnk_sts_s
 	 * err_type:10, speed:4, full_duplex:1, link_up:1
 	 */
 	*lnk_sts = scr0.u & 0xFFFF;
@@ -207,10 +211,7 @@ void cgx_intf_shutdown(void)
 {
 	union cgx_scratchx0 scr0;
 
-	int ret;
-
-	ret = cgx_intf_req(0, 0,
-				CGX_CMD_INTF_SHUTDOWN, &scr0.u);
+	cgx_intf_req(0, 0, CGX_CMD_INTF_SHUTDOWN, &scr0.u);
 }
 
 
diff --git a/drivers/net/cavium/octeontx2/cgx_intf.h b/drivers/net/cavium/octeontx2/cgx_intf.h
index f99957f956..67dee06d62 100644
--- a/drivers/net/cavium/octeontx2/cgx_intf.h
+++ b/drivers/net/cavium/octeontx2/cgx_intf.h
@@ -10,6 +10,13 @@
 #ifndef __OCTEONTX2_CGX_INTF_H__
 #define __OCTEONTX2_CGX_INTF_H__
 
+#define PCI_DEVICE_ID_OCTEONTX2_CGX	0xA059
+
+#define CGX_FIRWARE_MAJOR_VER		1
+#define CGX_FIRWARE_MINOR_VER		0
+#define MAX_LMAC_PER_CGX		4
+#define CGX_PER_NODE 			3
+
 /* Register offsets */
 #define CGX_CMR_SCRATCH0	0x87e0e0001050
 #define CGX_CMR_SCRATCH1	0x87e0e0001058
@@ -17,14 +24,6 @@
 #define CGX_SHIFT(x)		(0x1000000 * (x & 0x3))
 #define CMR_SHIFT(x)		(0x40000 * (x & 0x3))
 
-#define CGX_FIRWARE_MAJOR_VER		1
-#define CGX_FIRWARE_MINOR_VER		0
-
-<<<<<<< HEAD
-void cgx_intf_shutdown(void);
-
-=======
->>>>>>> drivers: net: octeontx2: add initial code for rvu af/pf, cgx
 /* CGX error types. set for cmd response status as CGX_STAT_FAIL */
 enum cgx_error_type {
 	CGX_ERR_NONE,
diff --git a/drivers/net/cavium/octeontx2/lmt.h b/drivers/net/cavium/octeontx2/lmt.h
new file mode 100644
index 0000000000..61b92f62f1
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/lmt.h
@@ -0,0 +1,53 @@
+/*
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ */
+
+/**
+ * Atomically adds a signed value to a 64 bit (aligned) memory location,
+ * and returns previous value.
+ *
+ * This version does not perform 'sync' operations to enforce memory
+ * operations.  This should only be used when there are no memory operation
+ * ordering constraints.  (This should NOT be used for reference counting -
+ * use the standard version instead.)
+ *
+ * @param ptr    address in memory to add incr to
+ * @param incr   amount to increment memory location by (signed)
+ *
+ * @return Value of memory location before increment
+ */
+static inline s64 cavm_atomic_fetch_and_add64_nosync(s64 *ptr, s64 incr)
+{
+	s64 result;
+	/* Atomic add with no ordering */
+	asm volatile("ldadd %x[i], %x[r], [%[b]]"
+		     : [r] "=r" (result), "+m" (*ptr)
+		     : [i] "r" (incr), [b] "r" (ptr)
+		     : "memory");
+	return result;
+}
+
+static inline void cavm_lmt_cancel(const struct nix_handle *nix)
+{
+	writeq(0, nix->lmt_base + CAVM_LMT_LF_LMTCANCEL());
+}
+
+static inline volatile u64 *cavm_lmt_store_ptr(struct nix_handle *nix)
+{
+	return (volatile u64 *)((u8 *)(nix->lmt_base) +
+				       CAVM_LMT_LF_LMTLINEX(0));
+}
+
+static inline s64 cavm_lmt_submit(u64 io_address)
+{
+	s64 result = 0;
+
+	asm volatile("ldeor xzr, %x[rf],[%[rs]]"
+			: [rf] "=r"(result) : [rs] "r"(io_address));
+	return result;
+}
diff --git a/drivers/net/cavium/octeontx2/lmt_hw.h b/drivers/net/cavium/octeontx2/lmt_hw.h
new file mode 100644
index 0000000000..41c47c34f6
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/lmt_hw.h
@@ -0,0 +1,51 @@
+/* This file is auto-generated. Do not edit */
+
+/***********************license start***************
+ * Copyright (c) 2003-2018  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export
+ * control laws, including the U.S. Export Administration Act and its
+ * associated regulations, and may be subject to export or import regulations
+ * in other countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+ * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+ * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+ * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+ * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+ * OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+ * PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT,
+ * QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING
+ * OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+#ifndef __LMT_HW_H__
+#define __LMT_HW_H__
+
+/* Register offsets */
+
+#define CAVM_LMT_LF_LMTLINEX(a)    (0x0ull | (u64)(a) << 3)
+#define CAVM_LMT_LF_LMTCANCEL      (0x400ull)
+
+
+#endif /* __LMT_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/lmt_reg.h b/drivers/net/cavium/octeontx2/lmt_reg.h
new file mode 100644
index 0000000000..6f57996f6d
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/lmt_reg.h
@@ -0,0 +1,22 @@
+
+/* Register definitions */
+
+/**
+ * RVU VF LMT Line Registers
+ */
+union cavm_lmt_lf_lmtlinex {
+	u64 u;
+	struct lmt_lf_lmtlinex_s {
+		u64 data;                           
+	} s;
+};
+
+/**
+ * RVU VF LMT Cancel Register
+ */
+union cavm_lmt_lf_lmtcancel {
+	u64 u;
+	struct lmt_lf_lmtcancel_s {
+		u64 data;                           
+	} s;
+};
diff --git a/drivers/net/cavium/octeontx2/nix.c b/drivers/net/cavium/octeontx2/nix.c
new file mode 100644
index 0000000000..b220ba9bd6
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/nix.c
@@ -0,0 +1,1605 @@
+/*
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ */
+
+#include <common.h>
+#include <net.h>
+#include <netdev.h>
+#include <malloc.h>
+#include <dm.h>
+#include <misc.h>
+#include <pci.h>
+#include <memalign.h>
+#include <watchdog.h>
+#include <asm/types.h>
+#include <asm/io.h>
+#include <linux/types.h>
+#include <asm/arch/octeontx2.h>
+#include "cavm-csrs-nix.h"
+#include "cavm-csrs-npa.h"
+#include "cavm-csrs-lmt.h"
+#include "rvu_common.h"
+#include "nix.h"
+#include "lmt.h"
+#include "cgx.h"
+
+#define CAVM_NUMA_MAX_NODES	2	/** TODO: Move this elsewhere */
+#define CAVM_MAX_GATHER		1	/** Maximum scatter/gather */
+
+/** Offset from RVU PFVF BAR 2 */
+#define CAVM_LMT_LMTLINE(x)		((x) * 0x8)
+#define CAVM_LMT_LF_LMTCANCEL		(0x400)
+
+static const int USE_SSO = 0;	/** Do not use SSO, use completion queues */
+static const int MAX_MTU = 9212;/** Maximum packet size */
+static const int MAX_CQS = 32;	/** Maximum of 32 completion queues */
+static const int MAX_SQS = 32;	/** Maximum of 32 send queues */
+static const int MAX_RQS = 32;	/** Maximum of 32 receive queues */
+/** Size of RSS table (256) See NIX_AF_LFX_RSS_CFG[size] */
+static const int RSS_SIZE = 0;
+/** Each completion queue contains 256 entries, see NIC_CQ_CTX_S[qsize] */
+static const unsigned int CQS_QSIZE = 2;
+/** Number of CQ entries */
+static const unsigned int CQ_ENTRIES = 16 << (2 /*CQS_QSIZE*/ * 2);
+static const int AQ_RING_SIZE = 16 << (AQ_SIZE * 2);
+/**
+ * Each completion queue entry contains 512 bytes, see
+ * NIXX_AF_LFX_CFG[xqe_size]
+ */
+static const int CQ_ENTRY_SIZE = 512;
+
+struct nix_node_state {
+	int next_free_lf;
+	int next_free_sq;
+	int next_free_rq;
+	int next_free_cq;
+	int next_free_rssi;
+	int next_free_bpid;
+};
+
+/* Globals */
+static struct nix_node_state global_node_state[CAVM_NUMA_MAX_NODES];
+static const struct pci_device_id npc_devid = {
+
+};
+
+#if 0
+static u64 npc_reg_read(struct nix_handle *nix, u64 offset)
+{
+	return readq(nix->npc_base + offset);
+}
+
+static void npc_reg_write(struct nix_handle *nix, u64 offset, u64 val)
+{
+	writeq(val, nix->npc_base + offset);
+}
+#endif
+
+/**
+ * NIX needs a lot of memory areas. Rather than handle all the failure cases,
+ * we'll use a wrapper around alloc that prints an error if a memory
+ * allocation fails.
+ *
+ * @param num_elements
+ *                  Number of elements to allocate
+ * @param elem_size Size of each element
+ * @param msge      Text string to show when allocation fails
+ *
+ * @return A valid memory location or NULL on failure
+ */
+static void *nix_memalloc(int num_elements, size_t elem_size, const char *msg)
+{
+	size_t alloc_size = num_elements * elem_size;
+	void *base = memalign(CONFIG_SYS_CACHELINE_SIZE, alloc_size);
+
+	if (!base)
+		printf("NIX: Memory alloc failed for %s (%d * %zu = %zu bytes)\n",
+		       msg ? msg : __func__, num_elements, elem_size,
+		       alloc_size);
+	else
+		memset(base, 0, alloc_size);
+
+	return base;
+}
+
+static int npa_setup_pool(struct nix_handle *nix, u32 pool_id,
+			  size_t buffer_size, u32 queue_length, void *buffers[])
+{
+	struct {
+		union cavm_npa_lf_aura_op_free0 f0;
+		union cavm_npa_lf_aura_op_free1 f1;
+	} aura_descr;
+	int index;
+
+	for (index = 0; index < queue_length; index++) {
+		buffers[index] = memalign(CONFIG_SYS_CACHELINE_SIZE,
+					  buffer_size);
+		if (!buffers[index]) {
+			printf("%s: Out of memory allocating buffer %d, size: %zu\n",
+			       __func__, index, buffer_size);
+			return -ENOMEM;
+		}
+
+		/* Add the newly obtained pointer to the pool.  128 bit
+		 * writes only.
+		 */
+		aura_descr.f0.s.addr = (u64)buffers[index];
+		aura_descr.f1.u = 0;
+		aura_descr.f1.s.fabs = 1;
+		aura_descr.f1.s.aura = pool_id;
+		cavm_st128(nix->npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
+			   aura_descr.f0.u, aura_descr.f1.u);
+	}
+
+	return 0;
+}
+
+static int npa_lf_setup(struct nix_handle *nix)
+{
+	struct npa_handle *npa = nix->npa;
+	struct nix_af_handle *nix_af = nix->nix_af;
+	union cavm_npa_aura_s aura_ctx[NPA_POOL_COUNT];
+	union cavm_npa_pool_s pool_ctx[NPA_POOL_COUNT];
+	union cavm_npa_af_const npa_af_const;
+	int pool;
+	int queue_len[NPA_POOL_COUNT];
+	int buffer_size[NPA_POOL_COUNT];
+	int stack_page_pointers;
+	int stack_page_bytes;
+	int err;
+	int lf = 0;
+
+	npa->aura_ctx = memalign(CONFIG_SYS_CACHELINE_SIZE,
+				 NPA_AURA_HW_CTX_SIZE * NPA_POOL_COUNT);
+	if (!npa->aura_ctx) {
+		printf("%s: Out of memory for aura context\n", __func__);
+		return -ENOMEM;
+	}
+	npa_af_const.u = npa_af_reg_read(nix->nix_af->npa_af,
+					 CAVM_NPA_AF_CONST());
+	stack_page_pointers = npa_af_const.s.stack_page_ptrs;
+	stack_page_bytes = npa_af_const.s.stack_page_bytes;
+	npa->rx_pool_stack_pages = (RQ_QLEN + stack_page_pointers - 1) /
+							stack_page_pointers;
+	npa->tx_pool_stack_pages = (SQ_QLEN + stack_page_pointers - 1) /
+							stack_page_pointers;
+
+	npa->pool_stack_pointers = stack_page_pointers;
+
+	npa->q_len[NPA_POOL_RX] = RQ_QLEN;
+	npa->q_len[NPA_POOL_TX] = SQ_QLEN;
+
+	npa->buf_size[NPA_POOL_RX] = NIX_MAX_HW_MTU + CONFIG_SYS_CACHELINE_SIZE;
+	npa->buf_size[NPA_POOL_TX] = NIX_MAX_HW_MTU + CONFIG_SYS_CACHELINE_SIZE;
+
+	npa->stack_pages[NPA_POOL_RX] = npa->rx_pool_stack_pages;
+	npa->stack_pages[NPA_POOL_TX] = npa->tx_pool_stack_pages;
+
+	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
+		npa->pool_ctx[pool] = memalign(CONFIG_SYS_CACHELINE_SIZE,
+					       npa->stack_pages[pool] *
+					       sizeof(union cavm_npa_pool_s));
+		if (!npa->pool_ctx[pool]) {
+			printf("%s: Out of memory for pool context\n",
+			       __func__);
+			return -ENOMEM;
+		}
+		npa->pool_stack[pool] = memalign(CONFIG_SYS_CACHELINE_SIZE,
+						 npa->stack_pages[pool] *
+						 stack_page_bytes);
+		if (!npa->pool_stack[pool]){
+			printf("%s: Out of memory for pool stack\n", __func__);
+			return -ENOMEM;
+		}
+	}
+	/* Set up the auras */
+	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
+		union cavm_npa_aura_s *aura = &aura_ctx[pool];
+		union cavm_npa_pool_s *poo = &pool_ctx[pool];
+		memset(aura, 0, sizeof(union cavm_npa_aura_s));
+		aura->s.fc_ena = 0;
+		aura->s.pool_addr = (u64)&npa->pool_ctx[pool];
+		aura->s.shift = 64 - __builtin_clzll(npa->q_len[pool]) - 8;
+		aura->s.count = npa->q_len[pool];
+		aura->s.limit = npa->q_len[pool];
+		aura->s.ena = 1;
+
+		memset(poo, 0, sizeof(*poo));
+		poo->s.fc_ena = 0;
+		poo->s.stack_base = (u64)(&npa->pool_stack[pool]);
+		poo->s.buf_size = npa->buf_size[pool];
+		poo->s.stack_max_pages = npa->stack_pages[pool];
+		poo->s.shift =
+			64 - __builtin_clzll(npa->pool_stack_pointers) - 8;
+		poo->s.ptr_start = 0;
+		poo->s.ptr_end = (1ULL << 40) -  1;
+		poo->s.ena = 1;
+	}
+
+	err = npa_lf_admin_setup(nix_af, lf, NPA_AURA_SIZE_DEFAULT,
+				 aura_ctx, (dma_addr_t)&(npa->aura_ctx),
+				 pool_ctx, NPA_POOL_COUNT);
+	if (err) {
+		printf("%s: Error setting up NPA LF admin for lf %d\n",
+		       __func__, lf);
+		return err;
+	}
+
+	npa->rx_buffers = calloc(queue_len[NPA_POOL_RX], sizeof(void *));
+	if (!npa->rx_buffers) {
+		printf("%s: Out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	npa->tx_buffers = calloc(queue_len[NPA_POOL_TX], sizeof(void *));
+	if (!npa->tx_buffers) {
+		printf("%s: Out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
+		err = npa_setup_pool(nix, pool, buffer_size[pool],
+				     queue_len[pool], pool == NPA_POOL_RX ?
+				     npa->rx_buffers : npa->tx_buffers);
+		if (err) {
+			printf("%s: Error setting up pool %d\n",
+			       __func__, pool);
+			return err;
+		}
+	}
+	return 0;
+}
+
+int npa_lf_shutdown(struct nix_handle *nix)
+{
+	struct npa_handle *npa = nix->npa;
+	int err;
+	int pool;
+
+	err = npa_lf_admin_shutdown(nix->nix_af, nix->lf, NPA_POOL_COUNT);
+	if (err) {
+		printf("%s: Error %d shutting down NPA LF admin\n",
+		       __func__, err);
+		return err;
+	}
+	free(npa->aura_ctx);
+	npa->aura_ctx = NULL;
+
+	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
+		free(npa->pool_ctx[pool]);
+		npa->pool_ctx[pool] = NULL;
+		free(npa->pool_stack[pool]);
+		npa->pool_stack[pool] = NULL;
+	}
+
+	free(npa->rx_buffers);
+	npa->rx_buffers = NULL;
+	free(npa->tx_buffers);
+	npa->tx_buffers = NULL;
+
+	return 0;
+}
+
+int nix_rx_tx_iface_setup(struct nix_handle *nix)
+{
+	union cavm_nixx_af_rx_linkx_cfg link_cfg;
+
+	link_cfg.u = 0;
+	link_cfg.s.maxlen = NIX_MAX_HW_MTU;
+	link_cfg.s.minlen = NIX_MIN_HW_MTU;
+	nix_af_reg_write(nix->nix_af,
+			 CAVM_NIXX_AF_RX_LINKX_CFG(nix->lmac->lmac_id),
+			 link_cfg.u);
+
+	return 0;
+}
+
+int nix_lf_setup(struct nix_handle *nix)
+{
+	union cavm_nix_rq_ctx_s rq;
+	union cavm_nix_sq_ctx_s sq;
+	union cavm_nix_cq_ctx_s cq[NIX_CQ_COUNT];
+	int index;
+	int err;
+	bool admin_setup = false;
+
+	nix->rq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
+				    sizeof(union cavm_nix_rq_ctx_hw_s));
+	if (!nix->rq_ctx_base) {
+		printf("%s: Out of memory\n", __func__);
+		return -ENOMEM;
+	}
+	memset(nix->rq_ctx_base, 0, sizeof(union cavm_nix_rq_ctx_hw_s));
+
+	nix->sq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
+				    sizeof(union cavm_nix_sq_ctx_hw_s));
+	if (!nix->sq_ctx_base) {
+		printf("%s: Out of memory\n", __func__);
+		err = -ENOMEM;
+		goto error;
+	}
+	memset(nix->sq_ctx_base, 0, sizeof(union cavm_nix_sq_ctx_hw_s));
+
+	nix->cq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
+				sizeof(union cavm_nix_cq_ctx_s) * NIX_CQ_COUNT);
+	if (!nix->cq_ctx_base) {
+		printf("%s: Out of memory\n", __func__);
+		err = -ENOMEM;
+		goto error;
+	}
+	memset(nix->cq_ctx_base, 0,
+	       sizeof(union cavm_nix_cq_ctx_s) * NIX_CQ_COUNT);
+
+	for (index = 0; index < NIX_CQ_COUNT; index++) {
+		err = qmem_alloc(&nix->cq[index], NIX_CQE_SIZE_W64,
+				 Q_COUNT(Q_SIZE_256));
+		if (err) {
+			printf("%s: Error allocating completion queue\n",
+			       __func__);
+			goto error;
+		}
+	}
+
+	for (index = 0; index < NIX_CQ_COUNT; index++) {
+		memset(&cq[index], 0, sizeof(union cavm_nix_cq_ctx_s));
+
+		cq[index].s.qsize = Q_SIZE_256;
+		cq[index].s.ena = 1;
+		cq[index].s.caching = 1;
+		cq[index].s.base = nix->cq[index].iova;
+		cq[index].s.cint_idx = 0;
+	}
+
+	memset(&sq, 0, sizeof(union cavm_nix_sq_ctx_s));
+	sq.s.cq = NIX_CQ_TX;
+	sq.s.max_sqe_size = CAVM_NIX_MAXSQESZ_E_W16;
+	sq.s.cq_ena = 1;
+	sq.s.ena = 1;
+	sq.s.sqb_aura = NPA_POOL_TX;
+	sq.s.sqe_stype = CAVM_NIX_STYPE_E_STF;
+	sq.s.default_chan = nix->lmac->lmac_id;
+
+	err = nix_lf_admin_setup(nix->nix_af, nix->lf, nix->pf,
+				 cq, (dma_addr_t)nix->cq_ctx_base, NIX_CQ_COUNT,
+				 &rq, (dma_addr_t)nix->rq_ctx_base, 1,
+				 &sq, (dma_addr_t)nix->sq_ctx_base, 1);
+	if (err) {
+		printf("%s: Error setting up LF\n", __func__);
+		goto error;
+	}
+	admin_setup = true;
+
+	memset(nix->send_descriptors, 0, sizeof(nix->send_descriptors));
+	for (index = 0; index < SQ_QLEN; index++) {
+		nix->send_descriptors[index].hdr.s.sqe_id = index;
+		nix->free_send_descriptors[index] =
+			&nix->send_descriptors[index];
+	}
+
+	nix->current_free_send_descriptor = 0;
+
+	return 0;
+error:
+	if (admin_setup)
+		nix_lf_admin_shutdown(nix->nix_af, nix->lf, NIX_CQ_COUNT, 1, 1);
+
+	if (nix->rq_ctx_base)
+		free(nix->rq_ctx_base);
+	nix->rq_ctx_base = NULL;
+	if (nix->rq_ctx_base)
+		free(nix->rq_ctx_base);
+	nix->rq_ctx_base = NULL;
+	if (nix->sq_ctx_base)
+		free(nix->sq_ctx_base);
+	nix->sq_ctx_base = NULL;
+	if (nix->cq_ctx_base)
+		free(nix->cq_ctx_base);
+	nix->cq_ctx_base = NULL;
+
+	for (index = 0; index < NIX_CQ_COUNT; index++)
+		qmem_free(&nix->cq[index]);
+
+	return err;
+}
+
+int nix_lf_shutdown(struct nix_handle *nix)
+{
+	struct nix_af_handle *nix_af = nix->nix_af;
+	int index;
+	int err;
+
+	err = nix_lf_admin_shutdown(nix_af, nix->lf, NIX_CQ_COUNT, 1, 1);
+	if (err) {
+		printf("%s: Error shutting down LF admin\n", __func__);
+		return err;
+	}
+
+	if (nix->rq_ctx_base)
+		free(nix->rq_ctx_base);
+	nix->rq_ctx_base = NULL;
+	if (nix->rq_ctx_base)
+		free(nix->rq_ctx_base);
+	nix->rq_ctx_base = NULL;
+	if (nix->sq_ctx_base)
+		free(nix->sq_ctx_base);
+	nix->sq_ctx_base = NULL;
+	if (nix->cq_ctx_base)
+		free(nix->cq_ctx_base);
+	nix->cq_ctx_base = NULL;
+
+	for (index = 0; index < NIX_CQ_COUNT; index++)
+		qmem_free(&nix->cq[index]);
+
+	return 0;
+}
+
+struct nix_tx_descr *nix_alloc_send_descriptor(struct nix_handle *nix)
+{
+	if (nix->current_free_send_descriptor == SQ_QLEN)
+		return NULL;
+
+	return nix->free_send_descriptors[nix->current_free_send_descriptor++];
+}
+
+void nix_free_send_descriptor(struct nix_handle *nix,
+			      struct nix_tx_descr *tx_descr)
+{
+	nix->free_send_descriptors[nix->current_free_send_descriptor] =
+		tx_descr;
+}
+
+static inline void nix_write_lmt(struct nix_handle *nix, void *buffer,
+				 int num_words)
+{
+	int i;
+	u64 *ptr = buffer;
+
+	for (i = 0; i < num_words; i++)
+		writeq(ptr[i], nix->lmt_base + CAVM_LMT_LF_LMTLINEX(i));
+}
+
+static int nix_xmit(struct eth_device *netdev, void *pkt, int pkt_len)
+{
+	struct nix_handle *nix = netdev->priv;
+	struct nix_tx_descr *tx_descr;
+	const int descr_size = (sizeof(struct nix_tx_descr) + 15) / 16 - 1;
+	s64 result;
+
+	tx_descr = nix_alloc_send_descriptor(nix);
+	if (!tx_descr) {
+		printf("%s: Error: out of tx descriptors\n", __func__);
+		return -1;
+	}
+	tx_descr->hdr.s.aura = 0xa5a5;
+	tx_descr->hdr.s.df = 1;
+	tx_descr->hdr.s.pnc = 1;
+	tx_descr->hdr.s.sq = 0;
+	tx_descr->hdr.s.total = pkt_len;
+	tx_descr->hdr.s.sizem1 = descr_size;
+	tx_descr->segments.s.segs = 1;
+	tx_descr->segments.s.subdc = CAVM_NIX_SUBDC_E_SG;
+	tx_descr->segments.s.seg1_size = pkt_len;
+	tx_descr->segments.s.ld_type = CAVM_NIX_SENDLDTYPE_E_LDT;
+	tx_descr->dev_addr = (dma_addr_t)pkt;
+	tx_descr->host_addr = pkt;
+
+	do {
+		nix_write_lmt(nix, tx_descr, sizeof(*tx_descr) / sizeof(u64));
+		__iowmb();
+		result = cavm_lmt_submit((u64)(nix->nix_base +
+					       CAVM_NIXX_LF_OP_SENDX(0)));
+		WATCHDOG_RESET();
+	} while (result == 0);
+
+	return 0;
+}
+
+int nix_get_pf_num(const struct nix_handle *nix)
+{
+	return (((u64)(nix->nix_base)) >> 36) & 0x0f;
+}
+
+int nix_linear_link_number(const struct nix_handle *nix)
+{
+	return nix_get_pf_num(nix) - 1;
+}
+
+int npc_lf_setup(struct nix_handle *nix)
+{
+	struct nix_af_handle *nix_af = nix->nix_af;
+	int link_num = nix_linear_link_number(nix);
+	int err;
+
+	err = npc_lf_admin_setup(nix_af, nix->lmac->cgx, link_num);
+	if (err) {
+		printf("%s: Error setting up npc lf admin\n", __func__);
+		return err;
+	}
+
+	return 0;
+}
+
+int nix_rx_tx_completion(struct nix_handle *nix, uint queue_idx,
+			 u32 *completion_type)
+{
+	union cavm_nixx_lf_cq_op_status op_status;
+	union cavm_nix_cqe_hdr_s *completion;
+	u32 head, tail;
+
+	op_status.u =
+		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
+						   CAVM_NIXX_LF_CQ_OP_STATUS(),
+						   (u64)queue_idx << 32);
+	head = op_status.s.head;
+	tail = op_status.s.tail;
+	if (head != tail) {
+		head &= (nix->cq[queue_idx].qsize - 1);
+		tail &= (nix->cq[queue_idx].qsize - 1);
+		completion = (union cavm_nix_cqe_hdr_s *)
+					(nix->cq[queue_idx].base) + head;
+		debug("%s: completion: %p (%d)\n", __func__, completion,
+		      completion->s.cqe_type);
+		*completion_type = completion->s.cqe_type;
+	}
+	return tail > head ?
+	       tail - head : (nix->cq[queue_idx].qsize - head) + tail;
+}
+
+void *nix_dequeue_tx_packet(struct nix_handle *nix)
+{
+	u32 head, tail;
+	union cavm_nixx_lf_cq_op_status op_status;
+	union cavm_nix_cqe_hdr_s *completion;
+	union cavm_nix_send_comp_s *send_comp;
+	struct nix_tx_descr *tx_descr;
+	void *packet = NULL;
+
+	op_status.u =
+		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
+						   CAVM_NIXX_LF_CQ_OP_STATUS(),
+						   NIX_CQ_TX << 32);
+	head = op_status.s.head;
+	tail = op_status.s.tail;
+
+	if (head == tail)
+		return NULL;
+
+	head &= (nix->cq[NIX_CQ_TX].qsize - 1);
+
+	completion = (union cavm_nix_cqe_hdr_s *)
+			((void *)(nix->cq[NIX_CQ_TX].base) +
+				head * sizeof(nix->cq[NIX_CQ_TX].entry_sz));
+
+	debug("%s: completion: %p\n", __func__, completion);
+
+	if (completion->s.cqe_type != CAVM_NIX_XQE_TYPE_E_SEND)
+		return NULL;
+
+	send_comp= (union cavm_nix_send_comp_s *)(completion + 1);
+
+	tx_descr = &nix->send_descriptors[send_comp->s.sqe_id];
+
+	debug("%s: tx descriptor: %p\n", __func__, tx_descr);
+
+	packet = tx_descr->host_addr;
+
+	nix_free_send_descriptor(nix, tx_descr);
+
+	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(), (NIX_CQ_TX << 32) | 1);
+
+	return packet;
+}
+
+static int nix_recv(struct eth_device *netdev)
+{
+	return 0;
+}
+
+static int nix_xmmit(struct eth_device *netdev, void *pkt, int pkt_len)
+{
+	return 0;
+}
+
+int nix_dequeue_rx_packet(struct nix_handle *nix, void *buffer, int *buf_size)
+{
+	struct nix_rx_descr *rx_descr;
+	union cavm_nixx_lf_cq_op_status op_status;
+	u8 *ptr = (u8 *)buffer;
+	u64 *addr;
+	u32 head, tail;
+	int seg;
+
+	op_status.u =
+		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
+						   CAVM_NIXX_LF_CQ_OP_STATUS(),
+						   NIX_CQ_RX << 32);
+	head = op_status.s.head;
+	tail = op_status.s.tail;
+
+	if (head == tail)
+		return -1;
+
+	head &= (nix->cq[NIX_CQ_RX].qsize - 1);
+	rx_descr = (struct nix_rx_descr *)(nix->cq[NIX_CQ_RX].base) + head;
+	debug("%s: completion: %p\n", __func__, rx_descr);
+
+	if (rx_descr->hdr.s.cqe_type != CAVM_NIX_XQE_TYPE_E_RX)
+		return -1;
+
+	addr = (dma_addr_t *)(rx_descr + 1);
+	debug("%s: segs: %d (%d@0x%llx, %d@0x%llx, %d@0x%llx)\n", __func__,
+	      rx_descr->rx_sg.s.segs, rx_descr->rx_sg.s.seg1_size, addr[0],
+	      rx_descr->rx_sg.s.seg2_size, addr[1],
+	      rx_descr->rx_sg.s.seg3_size, addr[2]);
+	if (*buf_size < rx_descr->rx_sg.s.seg1_size +
+			rx_descr->rx_sg.s.seg2_size +
+			rx_descr->rx_sg.s.seg3_size) {
+		debug("%s: Error: rx buffer size %d too small\n",
+		      __func__, *buf_size);
+		return -1;
+	}
+
+	memcpy(ptr, (void *)addr[0], rx_descr->rx_sg.s.seg1_size);
+	ptr += rx_descr->rx_sg.s.seg1_size;
+	if (rx_descr->rx_sg.s.seg2_size) {
+		memcpy(ptr, (void *)addr[1], rx_descr->rx_sg.s.seg2_size);
+		ptr += rx_descr->rx_sg.s.seg2_size;
+	}
+	if (rx_descr->rx_sg.s.seg3_size) {
+		memcpy(ptr, (void *)addr[2], rx_descr->rx_sg.s.seg3_size);
+		ptr += rx_descr->rx_sg.s.seg3_size;
+	}
+
+	for (seg = 0; seg < rx_descr->rx_sg.s.segs; seg++)
+		cavm_st128(nix->npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
+			   addr[seg], (1ULL << 63) | NPA_POOL_RX);
+
+	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(), (NIX_CQ_RX << 32) | 1);
+
+	return 0;
+}
+
+#if 0
+
+static int nix_lf_alloc(struct nix_handle *nix)
+{
+	struct nix_node_state *state = &global_node_state[nix->hw->node];
+	union cavm_nixx_af_const2 const2;
+	union cvmx_rvu_pf_func rvu_pf_func;
+	union cvmx_nixx_af_lfx_cfg lfx_cfg;
+	union cavm_nix_af_lfx_cqs_cfg lfx_cqs_cfg;
+	union cavm_nix_af_lfx_rqs_cfg rqs_cfg;
+	union cavm_nix_af_lfx_rss_cfg rss_cfg;
+	union cavm_nix_af_lfx_sqs_cfg sqs_cfg;
+	union cavm_nix_af_lfx_tx_cfg tx_cfg;
+	union cavm_nix_af_lfx_tx_cfg2 tx_cfg2;
+	union cavm_nix_af_lfx_tx_parse_cfg tx_parse_cfg;
+	int lf;
+	void *cint_base = NULL, *cq_base = NULL, *qint_base = NULL;
+	void *rq_base = NULL, *rss_base = NULL, *sqs_base = NULL;
+	int retcode = -1;
+
+	const2.u = nix_reg_read(nix, CAVM_NIX_AF_CONST2);
+
+	if (state->next_free_lf >= const2.s.lfs) {
+		printf("N%d NIX: Ran out of LFs\n", nix->hw->node);
+		return -1;
+	}
+	lf = state->next_free_lf++;
+
+	rvu_pf_func.u = 0;
+	rvu_pf_func.s.pf = 0;
+	rvu_pf_func.s.func = 0;
+	lfx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_CFG(lf));
+	lfx_cfg.s.xqe_size = (CQ_ENTRY_SIZE == 128) ?
+			CAVM_NIX_XQESZ_E_W16 : CAVM_NIX_XQESZ_E_W64;
+	lfx_cfg.s.sso_pf_func = rvu_pf_func.s.func;
+	lfx_cfg.s.npa_pf_func = rvu_pf_func.s.func;
+	/* Allocate space for storing LF Completion Interrupts */
+	cint_base = nix_memaloc(const2.s.cints,
+				sizeof(union cavm_nix_cint_hw_s), __func__);
+	if (!cint_base)
+		goto error;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_CINTS_BASE(lf), (u64)cints_base);
+
+	/* Allocate space for storing LF Completion Queues Admin */
+	cq_base = nix_memalloc(MAX_CQS, sizeof(union cavm_nix_cq_ctx_s),
+			       __func__);
+	if (!cq_base)
+		goto error;
+
+	nix_reg_write(nix, CAVM_NIXX_AF_LFX_CQS_BASE(lf), (u64)cq_base);
+	lfx_cqs_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_CQS_CFG(lf));
+	lfx_cqs_cfg.s.max_queuesm1 = MAX_CQS - 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_CQS_CFG(lf), lfx_cqs_cfg.u);
+	/* Allocate space for storing LF Queue Interrupts */
+	qint_base = nix_memalloc(const2.s.qints,
+				 sizeof(union cavm_nix_qint_hw_s), __func__);
+	if (!qint_base)
+		goto error;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_QINTS_BASE(lf),
+		      (u64)qint_base);
+
+	rq_base = nix_memalloc(MAX_RQS, sizeof(union cavm_nix_rq_ctx_s),
+			       __func__);
+	if (!rq_base)
+		goto error;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_RQS_BASE(lf), (u64)rq_base);
+	rqs_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_RQS_CFG(lf));
+	rqs_cfg.s.max_queuesm1 = MAX_RQS - 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_RQS_CFG(lf), rqs_cfg.u);
+
+	/* Allocate space for storing LF RSS tables */
+	rss_base = nix_memalloc(256 << RSS_SIZE, sizeof(union cavm_nix_rsse_s),
+				__func__);
+	if (!rss_base)
+		goto error;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_RSS_BASE(lf),
+		      (u64)rss_base);
+	rss_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_RSS_CFG(lf));
+	rss_cfg.s.ena = 1;
+	rss_cfg.s.size = RSS_SIZE;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_RSS_CFG(lf), rss_cfg.u);
+
+	/* Allocate space for storing LF Send Queues */
+	sqs_base = nix_memalloc(MAX_SQS, sizeof(union cavm_nix_sq_ctx_s),
+				__func__);
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_SQS_BASE(lf), (u64)sqs_base);
+	sqs_cfg.u nix_reg_read(nix, CAVM_NIX_AF_LFX_SQS_CFG(lf));
+	sqs_cfg.s.queuesm1 = MAX_SQS - 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_SQS_CFG(lf), sqs_cfg.u);
+
+	/* NIX AF Local Function Transmit Configuration Register */
+	tx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_TX_CFG(lf));
+	tx_cfg.s.lock_ena = 1;
+	tx_cfg.s.lock_viol_cqe_ena = 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_TX_CFG(lf), tx_cfg.u);
+	tx_cfg2.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_TX_CFG2(lf));
+	tx_cfg2.s.lmt_ena = 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_TX_CFG2(lf), tx_cfg2.u);
+
+	tx_parse_cfg.u = nix_reg_read(nix,
+				      CAVM_NIX_AF_LFX_PARSE_CFG(lf));
+	tx_parse_cfg.s.pkind = 1;
+	nix_reg_write(nix, CAVM_NIX_AF_LFX_PARSE_CFG(lf),
+		      tx_parse_cfg.u);
+
+	nix->cint_base = cint_base;
+	nix->cq_ctx_base = cq_base;
+	nix->qint_base = qint_base;
+	nix->rq_ctx_base = rq_base;
+	nix->rss_base = rss_base;
+	nix->sq_ctx_base = sqs_base;
+
+	return 0;
+error:
+
+	if (cint_base)
+		free(cint_base);
+	if (cq_base)
+		free(cq_base);
+	if (qint_base)
+		free(qint_base);
+	if (rq_base)
+		free(rq_base);
+	if (rss_base)
+		free(rss_base);
+	if (sqs_base)
+		free(sqs_base);
+	return retcode;
+}
+
+/**
+ * Issue a command to the NIX AF Admin Queue
+ *
+ * @param nix    nix handle
+ * @param op     Operation
+ * @param ctype  Context type
+ * @param cindex Context index
+ * @param resp   Result pointer
+ *
+ * @return	0 for success, -1 on failure
+ */
+static int nix_aq_issue_command(struct nix_handle *nix, enum nix_aq_instop_e op,
+				enum nix_aq_ctype_e ctype,
+				int cindex, void *resp)
+{
+	union cavm_nix_af_aq_status aq_status;
+	union cavm_nix_aq_inst_s *aq_inst = nix->aq_base + aq_status.s.head_ptr;
+	volatile union cavm_nix_aq_res_s *result = resp;
+	int lf = nix->lf;
+
+	aq_inst->u[0] = 0;
+	aq_inst->u[1] = 0;
+	aq_inst->s.op = op;
+	aq_inst->s.ctype = ctype;
+	aq_inst->s.lf = lf;
+	aq_inst->s.cindex = cindex;
+	aq_inst->s.doneint = 0;
+	aq_inst->s.res_addr = resp;
+	__iowmb();
+	nix_reg_write(nix, CAVM_NIX_AF_AQ_DOOR, 1);
+
+	/* Wait for completion */
+	do {
+		WATCHDOG_RESET();
+	} while (result->s.compcode == 0);
+	if (result->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("N%d, NIX: Admin Queue failed with code %d\n",
+		       nix->hw->node, result->s.compcode);
+		return -1;
+	}
+	return 0;
+}
+
+/**
+ * Allocate and setup a new Completion Queue for use
+ *
+ * @param nix Handle for port to config
+ *
+ * @return Completion Queue number, or negative on failure
+ */
+static int nix_lf_alloc_cq(struct nix_handle *nix)
+{
+	struct nix_node_state *state = &global_node_state[nix->hw->node];
+	struct nix_aq_cq_request aq_request
+					__aligned(CONFIG_SYS_CACHELINE_SIZE);
+	int cq = state->next_free_cq++;
+	static const int cqe_size = 16 << (CQS_QSIZE * 2);
+	void *cqe_mem = nix_memalloc(cqe_size, CQ_ENTRY_SIZE,
+				     __func__ "CQ Data");
+	int retcode;
+
+	memset(&aq_request, 0, sizeof(aq_request));
+	aq_request.cq.s.ena = 1;
+	aq_request.cq.s.bpid = nix->pki_channel;
+	aq_request.cq.s.substream = 0;	/* FIXME: Substream IDs? */
+	aq_request.cq.s.drop_ena = 1;
+	aq_request.cq.s.caching = 1;
+	aq_request.cq.s.qsize = CQS_QSIZE;
+	aq_request.cq.s.drop = 255 * 7 / 8;
+	aq_request.cq.s.qint_idx = 0;
+	aq_request.cq.s.cint_idx = 0;
+	aq_request.cq.s.base = (u64)cqe_mem;
+
+	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
+				       CAVM_NIX_AQ_CTYPE_E_CQ, nix->lf, cq,
+				       &aq_request.resp);
+	if (retcode) {
+		printf("%s: Error requesting completion queue\n", __func__);
+		return -1;
+	}
+	debug("%s: CQ(%d) allocated, base %p\n", __func__, cq, cqe_mem);
+
+	nix->cq = cq;
+	nix->cqe_base = cqe_mem;
+	return cq;
+}
+
+/**
+ * Allocate and setup a new Receive Queue for use
+ *
+ * @param nix Handle for port to config
+ *
+ * @return Receive Queue number, or negative on failure
+ */
+static int nix_lf_alloc_rq(struct nix_handle *nix)
+{
+	struct nix_node_state *state = &global_node_state[nix->hw->node];
+	struct nix_aq_rq_request aq_request __aligned(CONFIG_SYS_CACHELINE_SIZE);
+	int cq = nix->cq;
+	int rq;
+	int retcode;
+
+	if (state->next_free_rq >= MAX_RQS) {
+		printf("%s: NIX: Ran out of Receive Queues\n", __func__);
+		return -1;
+	}
+	rq = state->next_free_rq++;
+
+	memset(&aq_request, 0, sizeof(aq_request));
+
+	aq_request.rq.s.ena = 1;
+	aq_request.rq.s.sso_ena = USE_SSO;
+	aq_request.rq.s.ipsech_ena = 0;
+	aq_request.rq.s.ena_wqwd = 1;
+	aq_request.rq.s.cq = cq;
+	aq_request.rq.s.substream = 0;	/* FIXME: Substream IDs? */
+	aq_request.rq.s.wqe_aura = -1;	/* No WQE aura */
+	aq_request.rq.s.spb_aura = CAVM_NPA_PACKET_POOL;	/* TODO */
+	aq_request.rq.s.lpb_aura = CAVM_NPA_PACKET_POOL;	/* TODO */
+	/* U-Boot doesn't use WQE group for anything */
+	aq_request.rq.s.sso_grp = 0;
+	aq_request.rq.s.sso_tt = CAVM_SSO_TT_E_ORDERED;		/* TODO */
+	aq_request.rq.s.pb_caching = 1;
+	aq_request.rq.s.wqe_caching = 1;
+	aq_request.rq.s.xqe_drop_ena = 0;	/* Disable RED dropping */
+	aq_request.rq.s.spb_drop_ena = 0;
+	aq_request.rq.s.lpb_drop_ena = 0;
+	aq_request.rq.s.spb_sizem1 =
+		nix_npa_get_block_size(nix, CAVM_NPA_PACKET_POOL) / 8 - 1;
+	aq_request.rq.s.sbp_ena = 1;
+	aq_request.rq.s.lpb_sizem1 =
+		nix_npa_get_block_size(nix, CAVM_NPA_PACKET_POOL) / 8 - 1;
+	aq_request.rq.s.first_skip =
+			(!USE_SSO) ? 0 : (CQ_ENTRY_SIZE == 128) ? 16 : 64;
+	aq_request.rq.s.later_skip = 0;
+	aq_request.rq.s.xqe_imm_copy = 0;
+	aq_request.rq.s.xqe_hdr_split = 0;
+	aq_request.rq.s.xqe_drop = 255;
+	aq_request.rq.s.xqe_pass = 255;
+	aq_request.rq.s.wqe_pool_drop = 0;	/* No WQE pool */
+	aq_request.rq.s.wqe_pool_pass = 0;	/* No WQE pool */
+	aq_request.rq.s.spb_aura_drop = 255;
+	aq_request.rq.s.spb_aura_pass = 255;
+	aq_request.rq.s.spb_pool_drop = 0;
+	aq_request.rq.s.spb_pool_pass = 0;
+	aq_request.rq.s.lpb_aura_drop = 255;
+	aq_request.rq.s.lpb_aura_pass = 255;
+	aq_request.rq.s.lpb_pool_drop = 0;
+	aq_request.rq.s.lpb_pool_pass = 0;
+	aq_request.rq.s.qint_idx = 0;
+	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
+				       CAVM_NIX_AQ_CTYPE_E_RQ, rq,
+				       &aq_request.resp);
+
+	debug("%s: RQ(%d) allocated\n", __func__, rq);
+	if (retcode < 0)
+		return retcode;
+
+	nix->rq = rq;
+	return rq;
+}
+
+/**
+ * Setup SMQ -> TL4 -> TL3 -> TL2 -> TL1 -> MAC mapping
+ *
+ * @param nix     Handle to setup
+ * @param nix_link_e NIX link number enumeration
+ *
+ * @return SMQ number, or negative on failure
+ */
+static int nix_af_setup_sq(struct nix_handle *nix, int nix_link_e)
+{
+	union cavm_nixx_af_tl1x_schedule tl1_sched;
+	union cavm_nixx_af_tl2x_parent tl2_parent;
+	union cavm_nixx_af_tl3x_parent tl3_parent;
+	union cavm_nixx_af_tl3_tl2x_cfg tl3_tl2_cfg;
+	union cavm_nixx_af_tl3_tl2x_linkx_cfg tl3_tl2_link_cfg;
+	union cavm_nixx_af_tl4x_parent tl4_parent;
+	union cavm_nixx_af_tl4x_sdp_link_cfg tl4_sdp_link_cfg;
+	union cavm_nixx_af_smqx_cfg smq_cfg;
+	union cavm_nixx_af_mdqx_schedule mdq_sched;
+	union cavm_nixx_af_mdqx_parent mdq_parent;
+	union cavm_npc_af_pkindx_action0 pkindx_action0;
+	union cavm_npc_intfx_miss_act miss_act;
+	int tl1_index = nix_link_e; /* NIX_LINK_E enum */
+	int tl2_index = tl1_index;
+	int tl3_index = tl2_index;
+	int tl4_index = tl3_index;
+	int smq_index = tl4_index;
+
+	tl1_sched.u = nix_reg_read(nix,
+				CAVM_NIX_AF_TL1X_SCHEDULE(tl1_index));
+	tl1_sched.s.rr_quantum = MAX_MTU;
+	nix_reg_write(nix, CAVM_NIX_AF_TL1X_SCHEDULE(tl1_index),
+		      tl1_sched.u);
+	tl2_parent.u = nix_reg_read(nix,
+				CAVM_NIX_AF_TL2X_PARENT(tl2_index));
+	tl2_parent.s.parent = tl1_index;
+	nix_reg_write(nix, CAVM_NIX_AF_TL2X_PARENT(tl2_index),
+		      tl2_parent.u);
+	tl3_parent.u = nix_reg_read(nix,
+				CAVM_NIX_AF_TL3X_PARENT(tl3_index));
+	tl3_parent.s.parent = tl2_index;
+	nix_reg_write(nix, CAVM_NIX_AF_TL3X_PARENT(tl3_index),
+		      tl3_parent.u);
+	tl3_tl2_cfg.u = nix_reg_read(nix,
+				CAVM_NIX_AF_TL3_TL2X_CFG(tl3_index));
+	tl3_tl2_cfg.s.express = 0;
+	nix_reg_write(nix, CAVM_NIX_AF_TL3_TL2X_CFG(tl3_index),
+		      tl3_tl2_cfg.u);
+
+	if (nix_link_e != CAVM_NIX_LINK_E_SDP) {
+		tl3_tl2_link_cfg.u =
+			nix_reg_read(nix,
+			  CAVM_NIX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
+								  nix_link_e));
+		tl3_tl2_link_cfg.s.bp_ena = 1;
+		tl3_tl2_link_cfg.s.ena = 1;
+		tl3_tl2_link_cfg.s.relchan = 0;
+		nix_reg_write(nix,
+			      CAVM_NIX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
+								nix_link_e));
+	}
+	tl4_parent.u = nix_reg_read(nix,
+				CAVM_NIX_AF_TL4X_PARENT(tl4_index));
+	tl4_parent.s.parent = tl3_index;
+	nix_reg_write(nix, CAVM_NIX_AF_TL4X_PARENT(tl4_index),
+		      tl4_parent.u);
+	tl4_sdp_link_cfg.u =
+		nix_reg_read(nix,
+			     CAVM_NIX_AF_TL4X_SDP_LINK_CFG(tl4_index));
+	tl4_sdp_link_cfg.s.bp_ena = (nix_link_e == CAVM_NIX_LINK_E_SDP);
+	tl4_sdp_link_cfg.s.ena = (nix_link_e == CAVM_NIX_LINK_E_SDP);
+	tl4_sdp_link_cfg.s.relchan = nix->index;
+	nix_reg_write(nix, CAVM_NIX_AF_TL4X_SDP_LINK_CFG_RBU_BAR0(tl4_index),
+		      tl4_sdp_link_cfg.u);
+	smq_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_SMQX_CFG(smq_index));
+	smq_cfg.s.express = 0;
+	smq_cfg.s.lf = nix->lf;
+	smq_cfg.s.maxlen = MAX_MTU;
+	smq_cfg.s.minlen = 60;
+	nix_reg_write(nix, CAVM_NIX_AF_SMQX_CFG(smq_index), smq_cfg.u);
+	mdq_sched.u = nix_reg_read(nix,
+				CAVM_NIX_AF_MDQX_SCHEDULE(smq_index));
+	mdq_sched.s.rr_quantum = MAX_MTU;
+	nix_reg_write(nix, CAVM_NIX_AF_MDQX_SCHEDULE(smq_index),
+		      mdq_sched.u);
+	mdq_parent.u = nix_reg_read(nix,
+				CAVM_NIX_AF_MDQX_PARENT(smq_index));
+	mdq_parent.s.parent = tl4_index;
+	nix_reg_write(nix, CAVM_NIX_AF_MDQX_PARENT(smq_index),
+		      mdq_parent.u);
+	pkindx_action0.u = npc_reg_read(nix,
+				CAVM_NPC_AF_PKINDX_ACTION0_RBU_BAR0(nix->pknd));
+	pkindx_action0.s.parse_done = 1;
+	npc_reg_write(nix, CAVM_NPC_AF_PKINDX_ACTION0_RBU_BAR0(nix->pknd),
+		      pkindx_action0.u);
+	miss_act.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_MISS_ACT(
+						CAVM_NPC_INTF_E_NIXX_RX(0)));
+	miss_act.s.action = CAVM_NIX_RX_ACTIONOP_E_UCAST;
+	npc_reg_write(nix,
+		CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_RX(0)),
+		      miss_act.u);
+	miss_act.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_MISS_ACT(
+						CAVM_NPC_INTF_E_NIXX_TX(0)));
+	miss_act.s.action = CAVM_NIX_TX_ACTIONOP_E_UCAST_DEFAULT;
+	npc_reg_write(nix,
+		CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_TX(0)),
+		      miss_act.u);
+
+	return smq_index;
+}
+
+/**
+ * Allocate and setup a new Send Queue for use
+ *
+ * @param nix     Handle for port to config
+ * @param nix_link_e NIX link number enumeration
+ *
+ * @return Send Queue number, or negative on failure
+ */
+static int nix_lf_alloc_sq(struct nix_handle *nix, int nix_link_e)
+{
+    struct nix_node_state *state = &global_node_state[nix->hw->node];
+    struct nix_aq_sq_request aq_request;
+    int sq;
+    int smq;
+
+    if (state->next_free_sq >= MAX_SQS) {
+        printf("%s NIX: Ran out of Send Queues\n", __func__);
+        return -1;
+    }
+    sq = state->next_free_sq++;
+    smq = nix_af_setup_sq(nix, sq, nix_link_e);
+
+    memset(&aq_request, 0, sizeof(aq_request));
+
+    aq_request.sq.s.ena = 1;
+    aq_request.sq.s.cq_ena = !USE_SSO;
+    aq_request.sq.s.max_sqe_size = CAVM_NIX_MAXSQESZ_E_W16;
+    aq_request.sq.s.substream = 0; // FIXME: Substream IDs?
+    aq_request.sq.s.sdp_mcast = 0;
+    aq_request.sq.s.cq = nix->cq;
+    aq_request.sq.s.cq_limit = 0;
+    aq_request.sq.s.smq = smq;
+    aq_request.sq.s.sso_ena = 1; /* Always allow a SQ to submit work */
+    aq_request.sq.s.smq_rr_quantum = MAX_MTU / 4;
+    aq_request.sq.s.default_chan = nix->pki_channel;
+    aq_request.sq.s.sqe_stype = CAVM_NIX_STYPE_E_STP;
+    aq_request.sq.s.qint_idx = 0;
+    aq_request.sq.s.sqb_aura = CAVM_NPA_PKO_POOL;
+    nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
+			 CAVM_NIX_AQ_CTYPE_E_SQ, sq, &aq_request.resp);
+    nix->sq = sq;
+    return sq;
+}
+
+/**
+ * Setup the NPC MCAM to route incoming packets to the NIX
+ *
+ * @param rq     NIX receive queue
+ */
+static void nix_setup_mcam(struct nix_handle *nix)
+{
+	union cavm_npc_af_mcamex_bankx_camx_intf camx_intf;
+	union cavm_npc_af_mcamex_bankx_camx_w0 camx_w0;
+	union cavm_npc_af_mcamex_bankx_camx_w1 camx_w1;
+	union cavm_npc_af_mcamex_bankx_cfg bankx_cfg;
+	union cavm_nix_rx_action_s rx_action;
+	union cavm_npc_intf_e_nixx_rx nixx_rx;
+	union cavm_npc_intf_e_nixx_tx nixx_tx;
+	union cavm_npc_af_mcamex_kex_cfg kex_cfg;
+	u64 key0 = nix->pki_channel;
+	int mcam = nix->pko_queue;
+	int rq = nix->rq;
+	int bank = 0;
+
+	/* Setup receive direction MCAM match */
+	/* First require interface direction to exactly match  */
+	camx_intf.u = npc_reg_read(nix,
+			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
+								    bank, 0));
+	/* Mask for bits that must be zero */
+	camx_intf.s.intf = ~CAVM_NPC_INTF_E_NIXX_RX(0);
+	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
+								       bank, 0),
+		      camx_intf.u);
+	/* Second set of bits to match, must be zero */
+	camx_intf.u = npc_reg_read(nix,
+			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
+								    bank, 1));
+	/* Mask for bits that must be zero */
+	camx_intf.s.intf = CAVM_NPC_INTF_E_NIXX_RX(0);
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
+								  bank, 1),
+		      camx_intf.u);
+
+	/* Second require the first 12 bits of the key to match, the channel */
+	camx_w0.u = npc_reg_read(nix,
+			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam,
+								  bank, 0));
+	/* Mask for bits that must be zero */
+	camx_w0.s.md = ~key0 & ~((~0x0ull) << 12);
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam, bank, 0),
+		      camx_w0.u);
+	camx_w0.u = npc_reg_read(nix,
+				 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam,
+								       bank, 1));
+	/* Mask for bits that must be one */
+	camx_w0.s.md = key0;
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam, bank, 1),
+		      camx_w0.u);
+
+	/* Third requires none of the other key bits to match */
+	camx_w1.u = npc_reg_read(nix,
+				 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam,
+								       bank, 0));
+	camx_w1.s.md = 0;
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam, bank, 0),
+		      camx_w1.u);
+	camx_w1.u = npc_reg_read(nix,
+			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam,
+								  bank, 1));
+	camx_w1.s.md = 0;
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam, bank, 1),
+		      camx_w1.u);
+
+	/* Setup receive direction action */
+	rx_action.u = 0;
+	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_UCAST;
+	rx_action.s.pf_func = nix->lf;
+	rx_action.s.index = nix->rq;
+	rx_action.s.match_id = 0;
+	rx_action.s.flow_key_alg = 0;
+	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_ACTION(mcam, bank),
+		      rx_action.u);
+
+	/* Enable the MCAM entry */
+	bankx_cfg.u = npc_reg_read(nix,
+				   CAVM_NPC_AF_MCAMEX_BANKX_CFG(mcam,
+									 bank));
+	bankx_cfg.s.ena = 1;
+	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_CFG(mcam, bank),
+		      bankx_cfg.u);
+
+	/* Program key size and nibbles to include */
+	kex_cfg.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_KEX_CFG(
+						CAVM_NPC_INTF_E_NIXX_RX(0)));
+	kex_cfg.s.keyw = CAVM_NPC_MCAMKEYW_E_X1;
+	kex_cfg.s.parse_nibble_ena = 0x7;
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_INTFX_KEX_CFG(
+					CAVM_NPC_INTF_E_NIXX_RX(0)),
+		      kex_cfg.u);
+	kex_cfg.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_KEX_CFG(
+						CAVM_NPC_INTF_E_NIXX_TX(0)));
+	kex_cfg.s.keyw = CAVM_NPC_MCAMKEYW_E_X1;
+	kex_cfg.s.parse_nibble_ena = 0xfffffff;
+	npc_reg_write(nix,
+		      CAVM_NPC_AF_INTFX_KEX_CFG(
+					CAVM_NPC_INTF_E_NIXX_TX(0)),
+		      kex_cfg.u);
+}
+
+static void nix_assign_channel_bp(struct nix_handle *nix)
+{
+	int channel;
+	int bpid = 0;
+
+
+}
+
+/**
+ * Allocates the nix handle and performs low-level initialization
+ *
+ * @param	node		CPU node number
+ * @param	nix_base	NIX BAR 0 base address
+ * @param	nix2_base	NIX BAR 2 base address
+ * @param	npc_base	NPC BAR 0 base address
+ * @param	rvu_pf_func	RVU pf function number
+ *
+ * @return	Pointer to nix handle or NULL if failure
+ */
+static struct *nix_handle nix_init_handle(int node, void *nix_base,
+					  void *nix2_base, void *npc_base,
+					  int rvu_pf_func)
+{
+	union cavm_nixx_af_cfg af_cfg;
+	union cavm_nixx_af_status af_status;
+	union cavm_nixx_af_rx_cfg rx_cfg;
+	union cavm_nixx_af_ndc_cfg ndc_cfg;
+	union cavm_nixx_priv_lfx_cfg lfx_cfg;
+	union cavm_nixx_af_rx_chanx_cfg chanx_cfg;
+	struct nix_node_state *state = &global_node_state[node];
+	struct nix_handle *nix = NULL;
+	int channel;
+	int bpid = 0;
+
+	debug("%s(%d, %p, %p, %d)\n", __func__,
+	      nix_base, npc_base, rvu_pf_func);
+	nix = calloc(1, sizeof(*nix));
+	if (!nix)
+		goto out_of_mem;
+	nix->hw = calloc(1, sizeof(struct hw_info));
+	if (!nix->hw)
+		goto out_of_mem;
+	nix->nix_base = nix_base;
+	nix->npc_base = npc_base;
+	/* Fill the NPA pool */
+
+
+	nix->aq_base = nix_memalloc(AQ_RING_SIZE,
+				    sizeof(union c avm_nix_aq_inst_s),
+				    __func__);
+	debug("%s: aq base: %p\n", __func__, nix->aq_base);
+	if (!nix->aq_base)
+		goto out_of_mem;
+
+#if 0	/* Don't do this in ASIM */
+	af_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_CFG);
+	af_cfg.s.calibrate_x2p = 1;
+	nix_reg_write(nix, CAVM_NIX_AF_CFG, af_cfg.u);
+
+	do {
+		af_status.u = nix_reg_read(nix, CAVM_NIXX_AF_STATUS);
+	} while (!af_status.s.calibrate_done);
+	af_status.u = nix_reg_read(nix, CAVM_NIXX_AF_STATUS);
+	if (!af_status.s.calibrate_status) {
+		printf("N%d NIX: AF failed X2P calibration\n", node);
+		goto error;
+	}
+#endif
+	/* Enable channel backpressure */
+	rx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_RX_CFG);
+	rx_cfg.s.cbp_ena = 1;
+	nix_reg_write(nix, CAVM_NIX_AF_RX_CFG, rx_cfg.u);
+
+	/* Assign channel BP numbers sequentially */
+	for (channel = 0; channel < 4096; channel++) {
+		chanx_cfg.u = nix_reg_read(nix,
+				CAVM_NIXX_AF_RX_CHANX_CFG(channel));
+		if (!chanx_cfg.s.imp)
+			continue;
+
+		debug("%s: implementing back-pressure channel %d\n",
+		      __func__, channel);
+		chanx_cfg.s.bp_ena = 1;
+		chanx_cfg.s.bpid = bpid;
+		nix_reg_write(nix,
+			      CAVM_NIXX_AF_RX_CHANX_CFG(channel),
+			      chanx_cfg.u);
+		if (bpid < 512) {
+			bpid++;
+		} else {
+			printf("N%d NIX: Ran out of BPID at channel %d\n",
+			       node, channel);
+			break;
+		}
+	}
+
+	/* Enable NDC cache */
+	ndc_cfg.u = 0;
+	nix_reg_write(nix, CAVM_NIX_AF_NDC_CFG(), ndc_cfg.u);
+
+	/* Allocate MSIX space for NPA AF (not needed?) */
+	/* Enable NIX */
+
+
+	if (nix_lf_alloc(nix) < 0) {
+		printf("%s: Could not allocate lf\n", __func__);
+		goto error;
+	}
+
+	lfx_cfg.u = nix_reg_read(nix, CAVM_NIX_PRIV_LFX_CFG(nix->lf));
+	lfx_cfg.s.ena = 1;
+	lfx_cfg.s.pf_func = rvu_pf_func;
+	lfx_cfg.s.slot = 0;
+	nix_reg_write(nix, CAVM_NIX_PRIV_LFX_CFG(nix->lf), lfx_cfg.u);
+
+	return nix;
+
+out_of_mem:
+	printf("%s(%d): Error: out of memory\n", __func__, node);
+error:
+	if (nix) {
+		if (nix->hw)
+			free(nix->hw);
+		free(nix);
+	}
+	return NULL;
+}
+
+/**
+ * Transmits an Ethernet packet
+ *
+ * @param	netdev		Ethernet device
+ * @param	pkt		Pointer to packet data
+ * @param	pkt_len		Length of packet
+ *
+ * @return	0 for success, -1 on error
+ */
+static int nix_xmit(struct eth_device *netdev, void *pkt, int pkt_len)
+{
+	struct nix_handle *nix = netdev->priv;
+	union cavm_nix_op_q_wdata_s q_wdata_s;
+	union cavm_nix_send_hdr_s send_hdr_s;
+	union cavm_nixx_lf_sq_op_status sq_op_status;
+	union cavm_nix_send_sg_s send_sg_s;
+	volatile u64 *lmt_ptr;
+	u64 depth;
+	u64 io_address;
+	s64 lmt_status;
+
+	debug("%s(%s, %p, %d)\n", __func__, netdev->name, pkt, pkt_len);
+	q_wdata_s.u = 0;
+	q_wdata_s.q = nix->pko_queue;
+	sq_op_status.u = cavm_atomic_fetch_and_add64_nosync(nix->reg2_base +
+				CAVM_NIX_LF_SQ_OP_STATUS_RVU_BAR2, q_wdata_s.u);
+	depth = sq_op_status.s.sqb_count;
+	if (depth > 64)
+		return -1;
+	io_address = nix->reg_base + CAVM_NIX_LF_OP_SENDX(0);
+	do {
+		cavm_lmt_cancel(nix);
+		lmt_ptr = cavm_lmt_store_ptr();
+
+		send_hdr_s.u[0] = 0;
+		send_hdr_s.u[1] = 0;
+		send_hdr_s.s.total = pkt_len;
+		send_hdr_s.s.df = 1;
+		send_hdr_s.s.aura = CAVM_NPA_PACKET_POOL;
+		send_hdr_s.s.sizem1 = 0;
+		send_hdr_s.s.pnc = 0;	/* No completion posted */
+		send_hdr_s.s.sq = nix->pko_queue;
+		send_hdr_s.s.sqe_id = 0;
+		/* Don't worry about TCP/UDP checksum support here */
+
+		send_sg_s.u = 0;
+		send_sg_s.s.seg1_size = pktlen;
+		send_sg_s.s.ld_type = CAVM_NIX_SENDLDTYPE_E_LDD;
+		send_sg_s.s.subdc = CAVM_NIX_SUBDC_E_SG;
+		send_sg_s.s.segs = 1;
+		debug("%s(%s): Sending packet, hdr: 0x%lx 0x%lx sg: 0x%lx, pkt: %p\n",
+		      __func__, ethdev->name, send_hdr_s.u[0], send_hdr_s.u[1],
+		      send_sg_s.u, pkt);
+		*lmt_ptr++ = send_hdr_s.u[0];
+		*lmt_ptr++ = send_hdr_s.u[1];
+		*lmt_ptr++ = send_sg_s.u;
+		*lmt_ptr++ = pkt;
+		/* We only have one segment to worry about */
+		__iowmb();
+		lmt_status = cavm_lmt_submit(io_address);
+		if (!lmt_status) {
+			debug("%s: Error: unexpected lmt_status 0x%lx\n",
+			      __func__, lmt_status);
+		}
+	} while (lmt_status == 0);
+
+	nix->stats.tx.packets++;
+	nix->stats.tx.octets += pkt_len;
+
+	return 0;
+}
+
+static int nix_process_rx_complete(struct eth_device *netdev,
+				   union cavm_nix_rx_parse_s *rx_parse)
+{
+	struct nix_handle *nix = netdev->priv;
+	const union cavm_nix_rx_sg_s *rx_sg_ptr =
+			(const union cavm_nix_rx_sg_s *)(rx_parse + 1);
+	union cavm_nix_rx_sg_s rx_sg;
+	int qwords;
+	int num_segs;
+	int segments;
+	int segment_length;
+	int pkt_len;
+	void *pkt;
+	u64 addr;
+
+	qwords = rx_parse->s.desc_sizem1 + 1;
+	while (qwords > 0) {
+		pkt_len = rx_parse->s.pkt_lenm1 + 1;
+		rx_sg.u = rx_sg_ptr->u;
+		num_segs = rx_sg.s.segs;
+		segment_length += rx_sg_ptr->s.seg1_size;
+		addr = rx_sg_ptr[1].u;
+		pkt = (void *)addr;
+		prefetch(pkt);
+		if (num_segs < 2)
+			break;
+		printf("%s(%s): Only one segment supported\n", __func__,
+		       netdev->name);
+		qwords -= 2;
+	}
+	net_process_received_packet(pkt, pkt_len);
+
+	return pkt_len;
+}
+static int nix_recv(struct eth_device *netdev)
+{
+	struct nix_handle *nix = netdev->priv;
+	struct nix_aq_cq_request aq_request;
+	union cavm_nix_cqe_hdr_s *cq_next;
+	union cavm_nixx_lf_cq_op_status cq_op_status;
+	union cavm_nix_op_q_wdata_s q_wdata_s;
+	union cavm_nix_cqe_hdr_s cq_hdr;
+	union cavm_nix_rx_parse_s *rx_parse;
+	s64 *cq_op_status_ptr;
+	union cavm_nix_cqe_header_s *cq_ptr;
+	union cavm_nixx_lf_cq_op_door op_door;
+	const union cavm_nix_rx_sg_s *rx_sg_ptr;
+	union cavm_nix_rx_sg_s rg_sg;
+	u64 addr;
+	int loc;
+	int retcode;
+	int pkt_len = 0;
+
+	memset(&aq_request, 0, sizeof(aq_request));
+	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_READ,
+				       CAVM_NIX_AQ_CTYPE_E_CQ,
+				       &aq_request.resp);
+	if (retcode) {
+		printf("%s(%s): Error issuing command\n", __func__,
+		       netdev->name);
+		return -1;
+	}
+	cq_ptr = (void *)aq_request.cq.s.base;
+	cq_op_status_ptr = (s64 *)(nix->reg2_base +
+				   CAVM_NIX_LF_CQ_OP_STATUS_RVU_BAR2);
+	q_wdata_s.u = 0;
+	q_wdata_s.s.q = nix->cq;
+
+		cq_op_status.u =
+			cavm_atomic_fetch_and_add64_nosync(cq_op_status_ptr,
+							   q_wdata_s.u);
+	if (cq_op_status.s.head == cq_op_status.s.tail)
+		return 0;
+
+	loc = cq_op_status.s.head;
+	cq_next = cq_ptr + loc;
+	cq_hdr.u = cq->next.u;
+	rx_parse = (const union cavm_nix_rx_parse_s *)(cq_next + 1);
+	loc++;
+	loc &= CQ_ENTRIES - 1;
+	cq_next = cq_ptr + loc;
+	prefetch(cq_next);
+	if (cq_hdr.s.cqe_type == CAVM_NIX_XQE_TYPE_E_RX)
+		pkt_len = nix_process_rx_complete(nix, rx_parse);
+	else
+		printf("%s(%s): Error: Unsupported CQ header type %d\n",
+		       __func__, ethdev->name, cq_hdr.s.cqe_type);
+	op_door.u = 0;
+	op_door.s.cq = nix->cq;
+	op_door.s.count = 1;
+	nix_reg2_write(nix, CAVM_NIX_LF_CQ_OP_DOOR_RVU_BAR2, op_door.u);
+
+	return pkt_len;
+}
+
+static int nix_open(struct eth_device *netdev)
+{
+	return 0;
+}
+
+static int nix_halt(struct eth_device *netdev)
+{
+	return 0;
+}
+
+int nix_initialize(struct udevice *pdev, int vf_num)
+{
+	struct eth_device *netdev;
+	struct nix_handle *nix = NULL;
+	struct udevice *npcdev;
+	struct udevice *pci_bus;
+	size_t size;
+	void *reg_base;
+	void *reg2_base;
+
+	int retcode;
+
+	netdev = calloc(1, sizeof(struct eth_device));
+	if (!netdev) {
+		retcode = -ENOMEM;
+		goto fail;
+	}
+
+	reg_base = dm_pci_map_bar(pdev, 0, &size, PCI_REGION_MEM);
+	reg2_base = dm_pci_map_bar(pdev, 2, &size, PCI_REGION_MEM);
+	pci_bus =
+	retcode = pci_find_device_id()
+	netdev->halt = nix_halt;
+	netdev->init = nix_open;
+	netdev->send = nix_xmit;
+	netdev->recv = nix_recv;
+
+
+	retcode = eth_register(netdev);
+
+fail:
+	return retcode;
+
+}
+#endif
+#if 0
+int octeontx2_nix_probe(struct udevice *dev)
+{
+	int vf;
+	void *nix_regs;
+	void *nix_regs2;
+	size_t size;
+
+	nix_regs = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
+	nix_regs2 = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
+
+	debug("%s: %d, bar0: %p, bar2: %p\n", __func__, __LINE__,
+	      nix_regs, nix_regs2);
+
+	return 0;
+}
+
+static const struct misc_ops octeontx2_nix_ops = {
+};
+
+static const struct udevice_id octeontx2_nix_ids[] = {
+	{ .compatible = "cavium,nix" },
+};
+
+U_BOOT_DRIVER(octeontx2_nix) = {
+	.name	= "octeontx2_nix",
+	.id	= UCLASS_MISC,
+	.probe	= octeontx2_nix_probe,
+	.of_match = octeontx2_nix_ids,
+	.ops = &octeontx2_nix_ops,
+	.priv_auto_alloc_size = sizeof(struct nix_handle),
+};
+
+static const struct pci_device_id octeontx2_nix_supported[] = {
+	{ PCI_VDEVICE(CAVIUM, PCI_DEVICE_ID_OCTEONTX2_RVU) },
+	{}
+};
+
+U_BOOT_PCI_DEVICE(octeontx2_nix, octeontx2_nix_supported);
+#endif
diff --git a/drivers/net/cavium/octeontx2/nix.h b/drivers/net/cavium/octeontx2/nix.h
new file mode 100644
index 0000000000..4ebdf03a2b
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/nix.h
@@ -0,0 +1,331 @@
+/*
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ */
+
+#ifndef __NIX_H__
+#define	__NIX_H__
+
+#include "rvu_common.h"
+#include "cavm-csrs-nix.h"
+
+/** Maximum number of LMACs supported */
+#define MAX_LMAC				12
+
+#define PCI_DEVICE_ID_OCTEONTX2_RVU		0xa063
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_SSO_TIM_PF	0xa0f9
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_SSO_TIM_VF	0xa0fa
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_NPA_PF	0xa0fb
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_NPA_VF	0xa0fc
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_CPT_PF	0xa0fd
+#define PCI_DEVICE_ID_OCTEONTX2_RVU_CPT_VF	0xa0fe
+
+#define NIX_PCI_NPC_FN
+#define NIX_PCI_FN
+
+/* NIX RX action operation*/
+#define NIX_RX_ACTIONOP_DROP		(0x0ull)
+#define NIX_RX_ACTIONOP_UCAST		(0x1ull)
+#define NIX_RX_ACTIONOP_UCAST_IPSEC	(0x2ull)
+#define NIX_RX_ACTIONOP_MCAST		(0x3ull)
+#define NIX_RX_ACTIONOP_RSS		(0x4ull)
+
+/* NIX TX action operation*/
+#define NIX_TX_ACTIONOP_DROP		(0x0ull)
+#define NIX_TX_ACTIONOP_UCAST_DEFAULT	(0x1ull)
+#define NIX_TX_ACTIONOP_UCAST_CHAN	(0x2ull)
+#define NIX_TX_ACTIONOP_MCAST		(0x3ull)
+#define NIX_TX_ACTIONOP_DROP_VIOL	(0x5ull)
+
+#define NIX_INTF_RX			0
+#define NIX_INTF_TX			1
+
+#define NIX_INTF_TYPE_CGX		0
+#define NIX_INTF_TYPE_LBK		1
+#define NIX_MAX_HW_MTU			9212
+#define NIX_MIN_HW_MTU			64
+
+#define NPA_POOL_COUNT			2
+#define NPA_AURA_COUNT(x)		(1ULL << ((x) + 6))
+#define NPA_POOL_RX			0ULL
+#define NPA_POOL_TX			1ULL
+#define RQ_QLEN				1024
+#define SQ_QLEN				128
+
+#define NIX_CQ_RX			0ULL
+#define NIX_CQ_TX			1ULL
+#define NIX_CQ_COUNT			2ULL
+#define NIX_CQE_SIZE_W16		(16 * sizeof(u64))
+#define NIX_CQE_SIZE_W64		(64 * sizeof(u64))
+
+/** Size of aura hardware context */
+#define NPA_AURA_HW_CTX_SIZE		48
+/** Size of pool hardware context */
+#define NPA_POOL_HW_CTX_SIZE		64
+
+#define NPA_DEFAULT_PF_FUNC		0xffff
+
+#define NIX_CHAN_CGX_LMAC_CHX(a, b, c)	(0x800 + 0x100 * (a) + 0x10 * (b) + (c))
+#define NIX_LINK_CGX_LMAC(a, b)		(0 + 4 * (a) + (b))
+#define NIX_LINK_LBK(a)			(12 + (a))
+#define NIX_CHAN_LBK_CHX(a, b)		(0 + 0x100 * (a) + (b))
+#define MAX_LMAC_PKIND			12
+
+enum npa_aura_size {
+	NPA_AURA_SZ_0,
+	NPA_AURA_SZ_128,
+	NPA_AURA_SZ_256,
+	NPA_AURA_SZ_512,
+	NPA_AURA_SZ_1K,
+	NPA_AURA_SZ_2K,
+	NPA_AURA_SZ_4K,
+	NPA_AURA_SZ_8K,
+	NPA_AURA_SZ_16K,
+	NPA_AURA_SZ_32K,
+	NPA_AURA_SZ_64K,
+	NPA_AURA_SZ_128K,
+	NPA_AURA_SZ_256K,
+	NPA_AURA_SZ_512K,
+	NPA_AURA_SZ_1M,
+	NPA_AURA_SZ_MAX,
+};
+#define NPA_AURA_SIZE_DEFAULT		NPA_AURA_SZ_128
+
+/* NIX Transmit schedulers */
+enum nix_scheduler {
+	NIX_TXSCH_LVL_SMQ = 0x0,
+	NIX_TXSCH_LVL_MDQ = 0x0,
+	NIX_TXSCH_LVL_TL4 = 0x1,
+	NIX_TXSCH_LVL_TL3 = 0x2,
+	NIX_TXSCH_LVL_TL2 = 0x3,
+	NIX_TXSCH_LVL_TL1 = 0x4,
+	NIX_TXSCH_LVL_CNT = 0x5,
+};
+
+struct cgx;
+struct rvu_pf;
+
+struct nix_stats {
+	u64	num_packets;
+	u64	num_bytes;
+};
+
+struct nix_af_handle;
+
+struct nix_txsch {
+	struct rsrc_bmap rsrc;
+	u8	lvl;
+	u16	*pfvf_map;
+};
+
+struct nix_handle;
+struct cgx;
+struct lmac;
+
+struct npa_af_handle {
+	void __iomem		*npa_base;
+	struct admin_queue	aq;
+	u32			aura;
+};
+
+struct npa_handle {
+	struct npa_af_handle	*npa_af;
+	void __iomem		*npa_base;
+	void __iomem		*npc_base;
+	void __iomem		*lmt_base;
+	/** Hardware aura context */
+	void			*aura_ctx;
+	/** Hardware pool context */
+	void			*pool_ctx[NPA_POOL_COUNT];
+	void			*pool_stack[NPA_POOL_COUNT];
+	void			**rx_buffers;
+	void			**tx_buffers;
+	u32			rx_pool_stack_pages;
+	u32			tx_pool_stack_pages;
+	u32			pool_stack_pointers;
+	u32			q_len[NPA_POOL_COUNT];
+	u32			buf_size[NPA_POOL_COUNT];
+	u32			stack_pages[NPA_POOL_COUNT];
+};
+
+struct nix_af_handle {
+	struct udevice			*dev;
+	struct list_head		nix_af_list;
+	struct nix_handle		*lmacs[MAX_LMAC];
+	struct npa_af_handle		*npa_af;
+	void __iomem			*nix_af_base;
+	void __iomem			*npc_af_base;
+	struct admin_queue		aq;
+	u8				num_lmacs;
+	s8				index;
+	u8				xqe_size;
+};
+
+struct nix_tx_descr {
+	union cavm_nix_send_hdr_s	hdr;
+	union cavm_nix_send_sg_s	segments;
+	dma_addr_t			dev_addr;
+	void				*host_addr;
+};
+
+struct nix_rx_descr {
+	union cavm_nix_cqe_hdr_s hdr;
+	union cavm_nix_rx_parse_s rx_parse;
+	union cavm_nix_rx_sg_s rx_sg;
+};
+
+struct nix_handle {
+	struct udevice			*dev;
+	struct eth_device		*netdev;
+	struct list_head		nix_list;
+	struct nix_af_handle		*nix_af;
+	struct npa_handle		*npa;
+	struct lmac			*lmac;
+	union cavm_nix_cint_hw_s	*cint_base;
+	union cavm_nix_cq_ctx_s		*cq_ctx_base;
+	union cavm_nix_qint_hw_s	*qint_base;
+	union cavm_nix_rq_ctx_s		*rq_ctx_base;
+	union cavm_nix_rsse_s		*rss_base;
+	union cavm_nix_sq_ctx_s		*sq_ctx_base;
+	void				*cqe_base;
+	struct qmem			sq;
+	struct qmem			cq[NIX_CQ_COUNT];
+	struct qmem			rq;
+	struct qmem			rss;
+	struct qmem			cq_ints;
+	struct qmem			qints;
+	char				name[16];
+	void __iomem			*nix_base;	/** PF reg base */
+	void __iomem			*npc_base;
+	void __iomem			*lmt_base;
+	struct nix_tx_descr		send_descriptors[SQ_QLEN];
+	struct nix_tx_descr		*free_send_descriptors[SQ_QLEN];
+	u32				current_free_send_descriptor;
+	struct nix_stats		tx_stats;
+	struct nix_stats		rx_stats;
+	u32				aura;
+	int				pknd;
+	u16				pki_channel;
+	u16				pki_dstat;
+	u16				pko_queue;
+	u16				nic_id;
+	int				lf;
+	int				pf;
+	int				rq_idx;
+	int				sq_idx;
+	int				cq_idx;
+};
+
+struct nix_lf_alloc_req {
+	u32	rq_cnt;		/** Number of receive queues */
+	u32	sq_cnt;		/** Number of send squeues */
+	u32	cq_cnt;		/** Number of completion queues */
+	u16	rss_sz;
+	u8	rss_grps;
+	u8	xqe_sz;
+	u16	npa_func;
+};
+
+struct nix_lf_alloc_rsp {
+	u16	sqb_size;
+	u16	chan_base;
+	u8	chan_cnt;
+#if 0
+	u8	lso_tsov4_idx;
+	u8	lso_tsov6_idx;
+#endif
+	u8	mac_addr[6];
+};
+
+static inline u64 nix_af_reg_read(struct nix_af_handle *nix_af, u64 offset)
+{
+	return readq(nix_af->nix_af_base + offset);
+}
+
+static inline void nix_af_reg_write(struct nix_af_handle *nix_af, u64 offset,
+				    u64 val)
+{
+	writeq(val, nix_af->nix_af_base + offset);
+}
+
+static inline u64 nix_pf_reg_read(struct nix_handle *nix, u64 offset)
+{
+	return readq(nix->nix_base + offset);
+}
+
+static inline void nix_pf_reg_write(struct nix_handle *nix, u64 offset,
+				    u64 val)
+{
+	writeq(val, nix->nix_base + offset);
+}
+
+static inline u64 npa_af_reg_read(struct npa_af_handle *npa_af, u64 offset)
+{
+	return readq(npa_af->npa_base + offset);
+}
+
+static inline void npa_af_reg_write(struct npa_af_handle *npa_af, u64 offset,
+				    u64 val)
+{
+	writeq(val, npa_af->npa_base + offset);
+}
+
+static inline u64 npc_af_reg_read(struct nix_af_handle *nix_af, u64 offset)
+{
+	return readq(nix_af->npc_af_base + offset);
+}
+
+static inline void npc_af_reg_write(struct nix_af_handle *nix_af, u64 offset,
+				    u64 val)
+{
+	writeq(val, nix_af->npc_af_base + offset);
+}
+
+struct nix_af_handle *nix_af_initialize(int instance, struct udevice *dev,
+					void *bar0_ptr, void *bar2_ptr,
+					void *npa_bar0_ptr);
+int npa_lf_admin_setup(struct nix_af_handle *nix_af, int lf,
+		       u32 aura_size,
+		       const union cavm_npa_aura_s *aura_ctx,
+		       dma_addr_t auras_dev_addr,
+		       const union cavm_npa_pool_s *pool_ctx,
+		       u32 pool_cnt);
+
+int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count);
+
+int npc_lf_admin_setup(struct nix_af_handle *nix_af, struct cgx *cgx,
+		       u64 link_num);
+
+int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
+		       union cavm_nix_cq_ctx_s *cq_descriptors,
+		       dma_addr_t cq_dev_addr,
+		       u32 cq_count,
+		       union cavm_nix_rq_ctx_s *rq_descriptors,
+		       dma_addr_t rq_dev_addr,
+		       u32 rq_count,
+		       union cavm_nix_sq_ctx_s *sq_descriptors,
+		       dma_addr_t sq_dev_addr,
+		       u32 sq_count);
+int nix_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf,
+			  u32 cq_count, u32 rq_count, u32 sq_count);
+struct nix_handle *nix_get_pdata(int nic_id);
+int nix_get_nix_cnt(void);
+int nix_get_pf_num(const struct nix_handle *nix);
+int nix_linear_link_number(const struct nix_handle *nix);
+struct nix_af_handle *nix_get_af(u64 nix_pf_base);
+struct nix_handle *cavm_nix_lf_alloc(struct nix_af_handle *nix_af,
+				     struct udevice *dev,
+				     u16 pcifunc,
+				     u16 nix_lf,
+				     void __iomem *nix_base,
+				     void __iomem *npc_base,
+				     void __iomem *lmt_base,
+				     int cgx_id, int lmac_id,
+				     struct nix_lf_alloc_req *req,
+				     struct nix_lf_alloc_rsp *rsp);
+
+#endif /* __NIX_H__ */
diff --git a/drivers/net/cavium/octeontx2/nix_af.c b/drivers/net/cavium/octeontx2/nix_af.c
new file mode 100644
index 0000000000..9330839b05
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/nix_af.c
@@ -0,0 +1,1479 @@
+/*
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ */
+#define DEBUG
+#include <common.h>
+#include <net.h>
+#include <netdev.h>
+#include <malloc.h>
+#include <dm.h>
+#include <misc.h>
+#include <pci.h>
+#include <memalign.h>
+#include <watchdog.h>
+#include <asm/io.h>
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/log2.h>
+#include <asm/arch/octeontx2.h>
+#include "cavm-csrs-lmt.h"
+#include "cavm-csrs-nix.h"
+#include "cavm-csrs-npa.h"
+#include "cavm-csrs-npc.h"
+#include "cavm-csrs-rvu.h"
+#include "rvu_common.h"
+#include "rvu.h"
+#include "nix_af.h"
+#include "nix.h"
+#include "lmt.h"
+#include "cgx.h"
+
+static const int USE_SSO = 0;	/** Do not use SSO, use completion queues */
+static const int MAX_MTU = 9212;/** Maximum packet size */
+static const int MAX_CQS = 32;	/** Maximum of 32 completion queues */
+static const int MAX_SQS = 32;	/** Maximum of 32 send queues */
+static const int MAX_RQS = 32;	/** Maximum of 32 receive queues */
+/** Size of RSS table (256) See NIX_AF_LFX_RSS_CFG[size] */
+static const int RSS_SIZE = 0;
+/** Each completion queue contains 256 entries, see NIC_CQ_CTX_S[qsize] */
+static const int CQS_QSIZE = Q_SIZE_256;
+/** Number of CQ entries */
+static const int AQ_RING_SIZE = 16 << (AQ_SIZE * 2);
+/**
+ * Each completion queue entry contains 512 bytes, see
+ * NIXX_AF_LFX_CFG[xqe_size]
+ */
+static const int CQ_ENTRY_SIZE = 64;
+
+struct nix_aq_cq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_cq_ctx_s	cq	ALIGNED;
+};
+
+struct nix_aq_rq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_rq_ctx_s	rq	ALIGNED;
+};
+
+struct nix_aq_sq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_sq_ctx_s	sq	ALIGNED;
+};
+
+static struct nix_af_state {
+	int next_free_lf;
+	int next_free_sq;
+	int next_free_rq;
+	int next_free_cq;
+	int next_free_rssi;
+	int next_free_bpid;
+} af_state;
+
+static int nix_lf_alloc_cq(struct nix_af_handle *nix_af,
+			   struct nix_handle *nix);
+
+static struct nix_af_handle nix_afs[MAX_NIX];
+static int nix_afs_references[MAX_NIX] = {0,};
+static LIST_HEAD(nix_list);
+/**
+ * NIX needs a lot of memory areas. Rather than handle all the failure cases,
+ * we'll use a wrapper around alloc that prints an error if a memory
+ * allocation fails.
+ *
+ * @param num_elements
+ *                  Number of elements to allocate
+ * @param elem_size Size of each element
+ * @param msge      Text string to show when allocation fails
+ *
+ * @return A valid memory location or NULL on failure
+ */
+void *nix_memalloc(int num_elements, size_t elem_size, const char *msg)
+{
+	size_t alloc_size = num_elements * elem_size;
+	void *base = memalign(CONFIG_SYS_CACHELINE_SIZE, alloc_size);
+
+	if (!base)
+		printf("NIX: Memory alloc failed for %s (%d * %zd = %zd bytes)\n",
+		       msg ? msg : __func__, num_elements, elem_size,
+		       alloc_size);
+	else
+		memset(base, 0, alloc_size);
+
+	return base;
+}
+
+int nix_get_af_num(u64 base_addr)
+{
+	return (base_addr >> 28) & 0;
+}
+
+struct nix_handle *nix_get_pdata(int nic_id)
+{
+	struct nix_handle *nix;
+
+	list_for_each_entry(nix, &nix_list, nix_list) {
+		if (nix->nic_id == nic_id)
+			return nix;
+	}
+	return NULL;
+}
+
+int nix_get_nix_cnt(void)
+{
+	struct nix_handle *nix;
+	int count = 0;
+
+	list_for_each_entry(nix, &nix_list, nix_list)
+		count++;
+
+	return count;
+}
+
+static int npa_setup_admin(struct nix_af_handle *nix_af)
+{
+	int err;
+	struct npa_af_handle *npa = nix_af->npa_af;
+	union cavm_npa_af_gen_cfg npa_cfg;
+	union cavm_npa_af_ndc_cfg ndc_cfg;
+	union cavm_npa_af_aq_cfg aq_cfg;
+
+	err = cavm_rvu_aq_alloc(&npa->aq, Q_COUNT(AQ_SIZE),
+				sizeof(union cavm_npa_aq_inst_s),
+				sizeof(union cavm_npa_aq_res_s));
+	if (err) {
+		printf("%s: Error %d allocating admin queue\n", __func__, err);
+		return err;
+	}
+	debug("%s: NPA admin queue allocated at %p\n", __func__,
+	      npa->aq.inst.base);
+
+	/* Set little Endian */
+	npa_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_GEN_CFG());
+	npa_cfg.s.af_be = 0;
+	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_GEN_CFG(), npa_cfg.u);
+	/* Enable NDC cache */
+	ndc_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_NDC_CFG());
+	ndc_cfg.s.ndc_bypass = 0;
+	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_NDC_CFG(), ndc_cfg.u);
+	/* Set up queue size */
+	aq_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_AQ_CFG());
+	aq_cfg.s.qsize = AQ_SIZE;
+	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_AQ_CFG(), aq_cfg.u);
+	/* Set up queue base address */
+	npa_af_reg_write(npa, CAVM_NPA_AF_AQ_BASE(), npa->aq.inst.iova);
+
+	return 0;
+}
+
+static int npa_attach_aura(struct nix_af_handle *nix_af, int lf,
+			   const union cavm_npa_aura_s *desc, u32 aura_id)
+{
+	struct npa_af_handle *npa = nix_af->npa_af;
+	union cavm_npa_aq_inst_s *inst;
+	volatile union cavm_npa_aq_res_s *res;
+	union cavm_npa_af_aq_status aq_stat;
+	union cavm_npa_aura_s *context;
+	u64 head;
+	ulong start;
+
+	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, aura_id);
+	aq_stat.u = npa_af_reg_read(npa, CAVM_NPA_AF_AQ_STATUS());
+	head = aq_stat.s.head_ptr;
+	inst = (union cavm_npa_aq_inst_s *)(npa->aq.inst.base) + head;
+	res = (volatile union cavm_npa_aq_res_s *)(npa->aq.res.base);
+
+	memset(inst, 0, sizeof(*inst));
+	inst->s.lf = lf;
+	inst->s.doneint = 0;
+	inst->s.ctype = CAVM_NPA_AQ_CTYPE_E_AURA;
+	inst->s.op = CAVM_NPA_AQ_INSTOP_E_INIT;
+	inst->s.res_addr = npa->aq.res.iova;
+	inst->s.cindex = aura_id;
+
+	context = (union cavm_npa_aura_s *)(npa->aq.res.base +
+						CONFIG_SYS_CACHELINE_SIZE);
+	memset(npa->aq.res.base, 0, npa->aq.res.entry_sz);
+	memcpy(context, desc, sizeof(union cavm_npa_aura_s));
+	__iowmb();
+	npa_af_reg_write(npa, CAVM_NPA_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	while ((res->s.compcode == CAVM_NPA_AQ_COMP_E_NOTDONE) &&
+	       (get_timer(start) < 1000))
+		WATCHDOG_RESET();
+	if (res->s.compcode != CAVM_NPA_AQ_COMP_E_GOOD) {
+		printf("%s: Error: result 0x%x not good\n",
+		       __func__, res->s.compcode);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int npa_attach_pool(struct nix_af_handle *nix_af, int lf,
+			   const union cavm_npa_pool_s *desc, u32 pool_id)
+{
+	union cavm_npa_aq_inst_s *inst;
+	volatile union cavm_npa_aq_res_s *res;
+	union cavm_npa_af_aq_status aq_stat;
+	struct npa_af_handle *npa = nix_af->npa_af;
+	union cavm_npa_aura_s *context;
+	u64 head;
+	ulong start;
+
+	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, pool_id);
+	aq_stat.u = npa_af_reg_read(npa, CAVM_NPA_AF_AQ_STATUS());
+	head = aq_stat.s.head_ptr;
+
+	inst = (union cavm_npa_aq_inst_s *)(npa->aq.inst.base) + head;
+	res = (union cavm_npa_aq_res_s *)(npa->aq.res.base);
+
+	memset(inst, 0, sizeof(*inst));
+	inst->s.cindex = pool_id;
+	inst->s.lf = lf;
+	inst->s.doneint = 0;
+	inst->s.ctype = CAVM_NPA_AQ_CTYPE_E_POOL;
+	inst->s.op = CAVM_NPA_AQ_INSTOP_E_INIT;
+	inst->s.res_addr = npa->aq.res.iova;
+
+	context = (union cavm_npa_aura_s *)(npa->aq.res.base +
+						CONFIG_SYS_CACHELINE_SIZE);
+	memset(npa->aq.res.base, 0, npa->aq.res.entry_sz);
+	memcpy(context, desc, sizeof(union cavm_npa_aura_s));
+	__iowmb();
+	npa_af_reg_write(npa, CAVM_NPA_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	while ((res->s.compcode == CAVM_NPA_AQ_COMP_E_NOTDONE) &&
+	       (get_timer(start) < 1000))
+		WATCHDOG_RESET();
+
+	if (res->s.compcode != CAVM_NPA_AQ_COMP_E_GOOD) {
+		printf("%s: Error: result 0x%x not good\n",
+		       __func__, res->s.compcode);
+		return -1;
+	}
+
+	return 0;
+}
+
+int npa_lf_admin_setup(struct nix_af_handle *nix_af, int lf,
+		       u32 aura_size,
+		       const union cavm_npa_aura_s *aura_ctx,
+		       dma_addr_t auras_dev_addr,
+		       const union cavm_npa_pool_s *pool_ctx,
+		       u32 pool_cnt)
+{
+	union cavm_npa_af_lf_rst lf_rst;
+	union cavm_npa_af_const af_const;
+	union cavm_npa_af_lfx_auras_cfg auras_cfg;
+	struct npa_af_handle *npa = nix_af->npa_af;
+	int index;
+	int err;
+
+	debug("%s(%p, %d, %u, %p, 0x%llx, %p, %u)\n", __func__, nix_af, lf,
+	      aura_size, aura_ctx, auras_dev_addr, pool_ctx, pool_cnt);
+	lf_rst.u = 0;
+	lf_rst.s.exec = 1;
+	lf_rst.s.lf = lf;
+	npa_af_reg_write(npa, CAVM_NPA_AF_LF_RST(), lf_rst.u);
+
+	do {
+		lf_rst.u = npa_af_reg_read(npa, CAVM_NPA_AF_LF_RST());
+		WATCHDOG_RESET();
+	} while (lf_rst.s.exec);
+
+	/* TODO: remove this */
+	af_const.u = npa_af_reg_read(npa, CAVM_NPA_AF_CONST());
+	debug("%s: %d NPA local functions\n", __func__, af_const.s.lfs);
+	/* Set Aura size and enable caching of contexts */
+	auras_cfg.u = npa_af_reg_read(npa, CAVM_NPA_AF_LFX_AURAS_CFG(lf));
+	auras_cfg.s.loc_aura_size = aura_size;
+	auras_cfg.s.caching = 1;
+	auras_cfg.s.rmt_aura_size = 0;
+	auras_cfg.s.rmt_aura_offset = 0;
+	auras_cfg.s.rmt_lf = 0;
+	npa_af_reg_write(npa, CAVM_NPA_AF_LFX_AURAS_CFG(lf), auras_cfg.u);
+	/* Configure aura HW context base */
+	npa_af_reg_write(npa, CAVM_NPA_AF_LFX_LOC_AURAS_BASE(lf),
+			 auras_dev_addr);
+
+	/* Set up the auras */
+	for (index = 0; index < pool_cnt; index++) {
+		err = npa_attach_aura(nix_af, lf, &aura_ctx[index], index);
+		if (err)
+			return err;
+		err = npa_attach_pool(nix_af, lf, &pool_ctx[index], index);
+		if (err)
+			return err;
+	}
+	return 0;
+}
+
+int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count)
+{
+	int pool_id;
+	u32 head;
+	union cavm_npa_aq_inst_s *inst;
+	volatile union cavm_npa_aq_res_s *res;
+	union cavm_npa_aura_s *aura_ctx;
+	union cavm_npa_pool_s *pool_ctx;
+	union cavm_npa_af_aq_status aq_stat;
+	union cavm_npa_af_lf_rst lf_rst;
+	struct npa_af_handle *npa = nix_af->npa_af;
+	ulong start;
+
+	for (pool_id = 0; pool_id < pool_count; pool_id++) {
+		aq_stat.u = npa_af_reg_read(npa, CAVM_NPA_AF_AQ_STATUS());
+		head = aq_stat.s.head_ptr;
+		inst = (union cavm_npa_aq_inst_s *)(npa->aq.inst.base) + head;
+		res = npa->aq.res.base;
+
+		memset(inst, 0, sizeof(*inst));
+		inst->s.cindex = pool_id;
+		inst->s.lf = lf;
+		inst->s.doneint = 0;
+		inst->s.ctype = CAVM_NPA_AQ_CTYPE_E_POOL;
+		inst->s.op = CAVM_NPA_AQ_INSTOP_E_WRITE;
+		inst->s.res_addr = npa->aq.res.iova;
+
+		/* Context base address */
+		pool_ctx = (union cavm_npa_pool_s *)
+				(npa->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
+		memset(npa->aq.res.base, 0, npa->aq.res.entry_sz);
+		pool_ctx[0].s.ena = 0;
+		pool_ctx[1].s.ena = 1;	/* Write mask */
+		__iowmb();
+
+		npa_af_reg_write(npa, CAVM_NPA_AF_AQ_DOOR(), 1);
+
+		start = get_timer(0);
+		while ((res->s.compcode == CAVM_NPA_AQ_COMP_E_NOTDONE) &&
+		       (get_timer(start) < 1000))
+			WATCHDOG_RESET();
+
+		if (res->s.compcode != CAVM_NPA_AQ_COMP_E_GOOD) {
+			printf("%s: Error: result 0x%x not good\n",
+			       __func__, res->s.compcode);
+			return -1;
+		}
+	}
+
+	for (pool_id = 0; pool_id < pool_count; pool_id++) {
+		aq_stat.u = npa_af_reg_read(npa, CAVM_NPA_AF_AQ_STATUS());
+		head = aq_stat.s.head_ptr;
+		inst = (union cavm_npa_aq_inst_s *)(npa->aq.inst.base) + head;
+		res = npa->aq.res.base;
+
+		memset(inst, 0, sizeof(*inst));
+		inst->s.cindex = pool_id;
+		inst->s.lf = lf;
+		inst->s.doneint = 0;
+		inst->s.ctype = CAVM_NPA_AQ_CTYPE_E_AURA;
+		inst->s.op = CAVM_NPA_AQ_INSTOP_E_WRITE;
+		inst->s.res_addr = npa->aq.res.iova;
+
+		/* Context base address */
+		aura_ctx = (union cavm_npa_aura_s *)
+				(npa->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
+		memset(npa->aq.res.base, 0, npa->aq.res.entry_sz);
+		aura_ctx[0].s.ena = 0;
+		aura_ctx[1].s.ena = 1;	/* Write mask */
+		__iowmb();
+
+		npa_af_reg_write(npa, CAVM_NPA_AF_AQ_DOOR(), 1);
+
+		start = get_timer(0);
+		while ((res->s.compcode == CAVM_NPA_AQ_COMP_E_NOTDONE) &&
+		       (get_timer(start) < 1000))
+			WATCHDOG_RESET();
+
+		if (res->s.compcode != CAVM_NPA_AQ_COMP_E_GOOD) {
+			printf("%s: Error: result 0x%x not good\n",
+			       __func__, res->s.compcode);
+			return -1;
+		}
+	}
+
+	/* Reset the LF */
+	lf_rst.u = 0;
+	lf_rst.s.exec = 1;
+	lf_rst.s.lf = lf;
+	npa_af_reg_write(npa, CAVM_NPA_AF_LF_RST(), lf_rst.u);
+
+	do {
+		lf_rst.u = npa_af_reg_read(npa, CAVM_NPA_AF_LF_RST());
+		WATCHDOG_RESET();
+	} while (lf_rst.s.exec);
+
+	return 0;
+}
+
+static int nix_af_setup(struct nix_af_handle *nix_af)
+{
+	int err;
+	union cavm_nixx_af_cfg af_cfg;
+	union cavm_nixx_af_ndc_cfg ndc_cfg;
+	union cavm_nixx_af_aq_cfg aq_cfg;
+
+	debug("%s(%p)\n", __func__, nix_af);
+	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
+				sizeof(union cavm_nix_aq_inst_s),
+				sizeof(union cavm_nix_aq_res_s));
+	if (err) {
+		printf("%s: Error allocating nix admin queue\n", __func__);
+		return err;
+	}
+
+	/* Put in LE mode */
+	af_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CFG());
+	if (af_cfg.s.force_cond_clk_en ||
+	    af_cfg.s.calibrate_x2p || af_cfg.s.force_intf_clk_en) {
+		    printf("%s: Error: Invalid NIX_AF_CFG value 0x%llx\n",
+			   __func__, af_cfg.u);
+		    return -1;
+	}
+	af_cfg.s.af_be = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_CFG(), af_cfg.u);
+
+	/* Enable NDC cache */
+	ndc_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_NDC_CFG());
+	ndc_cfg.s.ndc_ign_pois = 0;
+	ndc_cfg.s.byp_sq = 0;
+	ndc_cfg.s.byp_sqb = 0;
+	ndc_cfg.s.byp_cqs = 0;
+	ndc_cfg.s.byp_cints = 0;
+	ndc_cfg.s.byp_dyno = 0;
+	ndc_cfg.s.byp_mce = 0;
+	ndc_cfg.s.byp_rqc = 0;
+	ndc_cfg.s.byp_rsse = 0;
+	ndc_cfg.s.byp_mc_data = 0;
+	ndc_cfg.s.byp_mc_wqe = 0;
+	ndc_cfg.s.byp_mr_data = 0;
+	ndc_cfg.s.byp_mr_wqe = 0;
+	ndc_cfg.s.byp_qints = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_NDC_CFG(), ndc_cfg.u);
+
+	/* Set up queue size */
+	aq_cfg.u = 0;
+	aq_cfg.s.qsize = AQ_SIZE;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_CFG(), aq_cfg.u);
+
+	/* Set up queue base address */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_BASE(), nix_af->aq.inst.iova);
+
+	return 0;
+}
+
+static int nix_attach_receive_queue(struct nix_af_handle *nix_af, int lf,
+				    union cavm_nix_rq_ctx_s *desc, u32 index)
+{
+	union cavm_nix_aq_inst_s *inst;
+	volatile union cavm_nix_aq_res_s *res;
+	union cavm_nix_rq_ctx_s *context;
+	union cavm_nixx_af_aq_status aq_status;
+	ulong start;
+
+	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
+	aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+
+	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+						aq_status.s.head_ptr;
+	memset(inst, 0, sizeof(*inst));
+	inst->s.cindex = index;
+	inst->s.doneint = 0;
+	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_RQ;
+	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
+	inst->s.res_addr = nix_af->aq.res.iova;
+
+	res = nix_af->aq.res.base;
+
+	/* Context base address */
+	context = (union cavm_nix_rq_ctx_s *)
+			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
+	memset((void *)res, 0, nix_af->aq.res.entry_sz);
+	memcpy(context, desc, sizeof(*context));
+	__iowmb();
+
+	/* Submit the aura context to HW */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+	       (get_timer(start) < 1000))
+		WATCHDOG_RESET();
+	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("%s: Bad result code 0x%x\n",
+		       __func__, res->s.compcode);
+		return -1;
+	}
+	return 0;
+}
+
+static int nix_attach_send_queue(struct nix_af_handle *nix_af, int lf,
+				 const union cavm_nix_sq_ctx_s *desc,
+				 u32 index)
+{
+	union cavm_nix_aq_inst_s *inst;
+	volatile union cavm_nix_aq_res_s *res;
+	union cavm_nix_sq_ctx_s *context;
+	union cavm_nixx_af_aq_status aq_stat;
+	ulong start;
+
+	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
+	res = (union cavm_nix_aq_res_s *)nix_af->aq.res.base;
+	aq_stat.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+							aq_stat.s.head_ptr;
+	memset(inst, 0, sizeof(*inst));
+	inst->s.cindex = index;
+	inst->s.lf = lf;
+	inst->s.doneint = 0;
+	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_SQ;
+	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
+	inst->s.res_addr = nix_af->aq.res.iova;
+
+	context = (union cavm_nix_sq_ctx_s *)
+			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
+	memset((void *)res, 0, nix_af->aq.res.entry_sz);
+	memcpy(context, desc, sizeof(*context));
+	__iowmb();
+
+	/* Now submit the aura context to HW */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+	       (get_timer(start) < 1000))
+		WATCHDOG_RESET();
+	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("%s: Bad result code 0x%x\n",
+		       __func__, res->s.compcode);
+		return -1;
+	}
+	return 0;
+}
+
+static int nix_attach_completion_queue(struct nix_af_handle *nix_af, int lf,
+				       const union cavm_nix_cq_ctx_s *desc,
+				       u32 index)
+{
+	union cavm_nix_aq_inst_s *inst;
+	volatile union cavm_nix_aq_res_s *res;
+	union cavm_nix_cq_ctx_s *context;
+	union cavm_nixx_af_aq_status aq_stat;
+	ulong start;
+
+	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
+	aq_stat.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+							aq_stat.s.head_ptr;
+	res = (union cavm_nix_aq_res_s *)nix_af->aq.res.base;
+	memset(inst, 0, sizeof(*inst));
+	inst->s.cindex = index;
+	inst->s.lf = lf;
+	inst->s.doneint = 0;
+	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_CQ;
+	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
+	inst->s.res_addr = nix_af->aq.res.iova;
+
+	context = (union cavm_nix_cq_ctx_s *)
+			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
+	memset((void *)res, 0, nix_af->aq.res.entry_sz);
+	memcpy(context, desc, sizeof(*context));
+	__iowmb();
+
+	/* Now submit the aura context to HW */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+	       (get_timer(start) < 1000))
+		WATCHDOG_RESET();
+	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("%s: Bad result code 0x%x\n",
+		       __func__, res->s.compcode);
+		return -1;
+	}
+	return 0;
+}
+
+int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
+		       union cavm_nix_cq_ctx_s *cq_descriptors,
+		       dma_addr_t cq_dev_addr,
+		       u32 cq_count,
+		       union cavm_nix_rq_ctx_s *rq_descriptors,
+		       dma_addr_t rq_dev_addr,
+		       u32 rq_count,
+		       union cavm_nix_sq_ctx_s *sq_descriptors,
+		       dma_addr_t sq_dev_addr,
+		       u32 sq_count)
+{
+	union cavm_nixx_af_lfx_rqs_cfg rqs_cfg;
+	union cavm_nixx_af_lfx_rqs_cfg sqs_cfg;
+	union cavm_nixx_af_lfx_rqs_cfg cqs_cfg;
+	union cavm_nixx_af_lfx_tx_cfg2 tx_cfg2;
+	union cavm_nixx_af_lfx_cfg lfx_cfg;
+	union cavm_nixx_af_smqx_cfg smqx_cfg;
+	u32 index;
+	int err;
+
+	debug("%s(%p, %d, %d, %p, 0x%llx, %u, %p, 0x%llx, %u, %p, 0x%llx, %u)\n",
+	      __func__, nix_af, lf, pf, cq_descriptors, cq_dev_addr, cq_count,
+	      rq_descriptors, rq_dev_addr, rq_count,
+	      sq_descriptors, sq_dev_addr, sq_count);
+	/* Request queues */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_BASE(lf), rq_dev_addr);
+	rqs_cfg.u = 0;
+	rqs_cfg.s.caching = 1;
+	rqs_cfg.s.max_queuesm1 = rq_count - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(lf), rqs_cfg.u);
+
+	/* Send queues */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_BASE(lf), sq_dev_addr);
+	sqs_cfg.u = 0;
+	sqs_cfg.s.caching = 1;
+	sqs_cfg.s.max_queuesm1 = sq_count - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(lf), sqs_cfg.u);
+
+	/* Completion queues */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_BASE(lf), cq_dev_addr);
+	cqs_cfg.u = 0;
+	cqs_cfg.s.caching = 1;
+	cqs_cfg.s.max_queuesm1 = cq_count - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(lf), cqs_cfg.u);
+
+	/* Enable LMTST for this NIX LF */
+	tx_cfg2.u = 0;
+	tx_cfg2.s.lmt_ena = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(lf), tx_cfg2.u);
+
+	/* Use 16-word XQEs, write the NPA PF|LF number only */
+	lfx_cfg.u = 0;
+	lfx_cfg.s.npa_pf_func = pf << 10;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CFG(lf), lfx_cfg.u);
+
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RX_CFG(lf), 0);
+
+	for (index = 0; index < cq_count; index++) {
+		err = nix_attach_completion_queue(nix_af, lf,
+						  &cq_descriptors[index],
+						  index);
+		if (err) {
+			printf("%s: Error attaching completion queue %d\n",
+			       __func__, index);
+			return err;
+		}
+	}
+
+	for (index = 0; index < rq_count; index++) {
+		err = nix_attach_receive_queue(nix_af, lf,
+					       &rq_descriptors[index], index);
+		if (err) {
+			printf("%s: Error attaching receive queue %d\n",
+			       __func__, index);
+			return err;
+		}
+	}
+
+	for (index = 0; index < sq_count; index++) {
+		err = nix_attach_send_queue(nix_af, lf,
+					    &sq_descriptors[index], index);
+		if (err) {
+			printf("%s: Error attaching send queue %d\n",
+			       __func__, index);
+			return err;
+		}
+	}
+
+	smqx_cfg.u = 0;
+	/* Disable shaper control for packets */
+	smqx_cfg.s.desc_shp_ctl_dis = 1;
+	smqx_cfg.s.minlen = NIX_MIN_HW_MTU;
+	smqx_cfg.s.maxlen = NIX_MIN_HW_MTU;
+	smqx_cfg.s.lf = lf;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_SMQX_CFG(lf), smqx_cfg.u);
+
+	return 0;
+}
+
+int nix_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf,
+			  u32 cq_count, u32 rq_count, u32 sq_count)
+{
+	union cavm_nixx_af_rx_sw_sync sw_sync;
+	union cavm_nix_aq_inst_s *inst;
+	volatile union cavm_nix_aq_res_s *res;
+	union cavm_nix_cq_ctx_s *cq_context;
+	union cavm_nix_rq_ctx_s *rq_context;
+	union cavm_nix_sq_ctx_s *sq_context;
+	union cavm_nixx_af_aq_status aq_status;
+	union cavm_nixx_af_lf_rst lf_rst;
+	ulong start;
+	int index;
+
+	/* Flush all tx packets */
+	sw_sync.u = 0;
+	sw_sync.s.ena = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_RX_SW_SYNC(), sw_sync.u);
+
+	do {
+		sw_sync.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_RX_SW_SYNC());
+		WATCHDOG_RESET();
+	} while (sw_sync.s.ena);
+
+	for (index = 0; index < rq_count; index++) {
+		aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+		inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+							aq_status.s.head_ptr;
+		inst->s.cindex = index;
+		inst->s.lf = lf;
+		inst->s.doneint = 0;
+		inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_RQ;
+		inst->s.op = CAVM_NPA_AQ_INSTOP_E_WRITE;
+		inst->s.res_addr = nix_af->aq.res.iova;
+
+		res = (union cavm_nix_aq_res_s *)(nix_af->aq.res.base);
+		rq_context = nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE;
+
+		memset((void *)res, 0, sizeof(*res));
+
+		rq_context[0].s.ena = 0;	/* Context */
+		rq_context[1].s.ena = 1;	/* Mask */
+		__iowmb();
+
+		nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+		start = get_timer(0);
+		while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+		       (get_timer(start) < 1000))
+			WATCHDOG_RESET();
+		if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+			printf("%s: Bad result code 0x%x\n",
+			       __func__, res->s.compcode);
+			return -1;
+		}
+	}
+
+	for (index = 0; index < rq_count; index++) {
+		aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+		inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+							aq_status.s.head_ptr;
+		inst->s.cindex = index;
+		inst->s.lf = lf;
+		inst->s.doneint = 0;
+		inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_SQ;
+		inst->s.op = CAVM_NPA_AQ_INSTOP_E_WRITE;
+		inst->s.res_addr = nix_af->aq.res.iova;
+
+		res = nix_af->aq.res.base;
+		sq_context = nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE;
+
+		memset((void *)res, 0, sizeof(*res));
+
+		sq_context[0].s.ena = 0;	/* Context */
+		sq_context[1].s.ena = 1;	/* Mask */
+		__iowmb();
+
+		nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+		start = get_timer(0);
+		while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+		       (get_timer(start) < 1000))
+			WATCHDOG_RESET();
+		if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+			printf("%s: Bad result code 0x%x\n",
+			       __func__, res->s.compcode);
+			return -1;
+		}
+	}
+
+	for (index = 0; index < rq_count; index++) {
+		aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+		inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+							aq_status.s.head_ptr;
+		inst->s.cindex = index;
+		inst->s.lf = lf;
+		inst->s.doneint = 0;
+		inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_CQ;
+		inst->s.op = CAVM_NPA_AQ_INSTOP_E_WRITE;
+		inst->s.res_addr = nix_af->aq.res.iova;
+
+		res = nix_af->aq.res.base;
+		cq_context = nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE;
+
+		memset((void *)res, 0, sizeof(*res));
+
+		cq_context[0].s.ena = 0;	/* Context */
+		cq_context[1].s.ena = 1;	/* Mask */
+		__iowmb();
+
+		nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+		start = get_timer(0);
+		while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
+		       (get_timer(start) < 1000))
+			WATCHDOG_RESET();
+		if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+			printf("%s: Bad result code 0x%x\n",
+			       __func__, res->s.compcode);
+			return -1;
+		}
+	}
+
+	/* Reset the LF */
+	lf_rst.u = 0;
+	lf_rst.s.lf = lf;
+	lf_rst.s.exec = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LF_RST(), lf_rst.u);
+
+	do {
+		lf_rst.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LF_RST());
+		WATCHDOG_RESET();
+	} while (lf_rst.s.exec);
+
+	return 0;
+}
+
+struct nix_af_handle *nix_af_initialize(int instance, struct udevice *dev,
+					void *bar0_ptr, void *bar2_ptr,
+					void *npa_bar0_ptr)
+{
+	struct nix_af_handle *nix_af;
+	struct npa_af_handle *npa;
+	int err;
+
+	if (instance >= MAX_NIX)
+		return NULL;
+
+	nix_af = &nix_afs[instance];
+	debug("%s(%d, %s, %p, %p, %p): nix_af: %p\n",
+	      __func__, instance, dev->name, bar0_ptr, bar2_ptr, npa_bar0_ptr,
+	      nix_af);
+
+	if (nix_afs_references[instance]++) {
+		debug("%s: NIX %d already initialized\n", __func__, instance);
+		return nix_af;
+	}
+
+	nix_af->index = instance;
+	nix_af->dev = dev;
+	nix_af->nix_af_base = bar0_ptr;
+	if (!nix_af->npa_af) {
+		nix_af->npa_af = calloc(1, sizeof(struct npa_af_handle));
+		if (!nix_af->npa_af) {
+			printf("%s: out of memory\n", __func__);
+			goto error;
+		}
+	}
+	npa = nix_af->npa_af;
+	npa->npa_base = npa_bar0_ptr;
+
+	debug("%s: Setting up npa admin\n", __func__);
+	err = npa_setup_admin(nix_af);
+	if (err) {
+		printf("%s: Error %d setting up NPA admin\n", __func__, err);
+		goto error;
+	}
+	debug("%s: Setting up nix af\n", __func__);
+	err = nix_af_setup(nix_af);
+	if (err) {
+		printf("%s: Error %d setting up NIX admin\n", __func__, err);
+		goto error;
+	}
+	debug("%s: nix_af: %p\n", __func__, nix_af);
+	return nix_af;
+
+error:
+	nix_afs_references[instance]--;
+	if (nix_af->npa_af) {
+		free(nix_af->npa_af);
+		memset(nix_af, 0, sizeof(*nix_af));
+	}
+	return NULL;
+}
+
+static int nix_af_shutdown(struct nix_af_handle *nix_af)
+{
+	union cavm_nixx_af_blk_rst blk_rst;
+
+	if (!nix_afs_references[nix_af->index])
+		return 0;
+	if (--nix_afs_references[nix_af->index])
+		return 0;
+
+	blk_rst.u = 0;
+	blk_rst.s.rst = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
+
+	/* Wait for reset to complete */
+	do {
+		blk_rst.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_BLK_RST());
+		WATCHDOG_RESET();
+	} while (blk_rst.s.busy);
+
+	blk_rst.u = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
+	cavm_rvu_aq_free(&nix_af->npa_af->aq);
+	cavm_rvu_aq_free(&nix_af->aq);
+
+	return 0;
+}
+
+static int nix_aq_init(struct nix_af_handle *nix_af)
+{
+	union cavm_nixx_af_cfg cfg;
+	union cavm_nixx_af_ndc_cfg ndc_cfg;
+	union cavm_nixx_af_aq_cfg aq_cfg;
+	int err;
+
+	if (nix_af->aq.inst.base)
+		return 0;
+
+	debug("%s(%p)\n", __func__, nix_af);
+	nix_af->xqe_size = CAVM_NIX_XQESZ_E_W16;
+
+	/* Set admin queue endianess */
+	cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CFG());
+	cfg.s.af_be = 0;	/* Force little-endian */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_CFG(), cfg.u);
+
+	/* Do not bypass NDC cache */
+	ndc_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_NDC_CFG());
+	ndc_cfg.s.ndc_ign_pois = 0;
+	ndc_cfg.s.byp_sq = 0;
+	ndc_cfg.s.byp_sqb = 0;
+	ndc_cfg.s.byp_cqs = 0;
+	ndc_cfg.s.byp_cints = 0;
+	ndc_cfg.s.byp_dyno = 0;
+	ndc_cfg.s.byp_mce = 0;
+	ndc_cfg.s.byp_rqc = 0;
+	ndc_cfg.s.byp_rsse = 0;
+	ndc_cfg.s.byp_mc_data = 0;
+	ndc_cfg.s.byp_mc_wqe = 0;
+	ndc_cfg.s.byp_mr_data = 0;
+	ndc_cfg.s.byp_mr_wqe = 0;
+	ndc_cfg.s.byp_qints = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_NDC_CFG(), ndc_cfg.u);
+
+	/* Result structure can be followed by RQ/SQ/CQ context at
+	 * res + 128 bytes and a write mask at RES + 256 bytes depending on
+	 * the operation type.  Alloc sufficient result memory for all
+	 * operations.
+	 */
+	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
+				sizeof(union cavm_nix_aq_inst_s),
+				ALIGN(sizeof(union cavm_nix_aq_res_s),
+				      CONFIG_SYS_CACHELINE_SIZE) + 256);
+	if (err)
+		return err;
+
+	aq_cfg.u = 0;
+	aq_cfg.s.qsize = AQ_SIZE;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_CFG(), aq_cfg.u);
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_BASE(), nix_af->aq.inst.iova);
+
+	return 0;
+}
+
+/**
+ * Issue a command to the NIX AF Admin Queue
+ *
+ * @param nix    nix handle
+ * @param lf     Logical function number for command
+ * @param op     Operation
+ * @param ctype  Context type
+ * @param cindex Context index
+ * @param resp   Result pointer
+ *
+ * @return	0 for success, -EBUSY on failure
+ */
+static int nix_aq_issue_command(struct nix_af_handle *nix_af,
+				int lf,
+				int op,
+				int ctype,
+				int cindex, union cavm_nix_aq_res_s *resp)
+{
+	union cavm_nixx_af_aq_status aq_status;
+	union cavm_nix_aq_inst_s *aq_inst;
+	volatile union cavm_nix_aq_res_s *result = resp;
+	ulong start;
+
+	debug("%s(%p, 0x%x, 0x%x, 0x%x, 0x%x, %p)\n", __func__, nix_af, lf,
+	      op, ctype, cindex, resp);
+	memset(result, 0, sizeof(*result));
+	aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
+	aq_inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+						aq_status.s.head_ptr;
+	aq_inst->u[0] = 0;
+	aq_inst->u[1] = 0;
+	aq_inst->s.op = op;
+	aq_inst->s.ctype = ctype;
+	aq_inst->s.lf = lf;
+	aq_inst->s.cindex = cindex;
+	aq_inst->s.doneint = 0;
+	aq_inst->s.res_addr = (u64)resp;
+	debug("%s: inst@%p: 0x%llx 0x%llx\n", __func__, aq_inst,
+	      aq_inst->u[0], aq_inst->u[1]);
+	__iowmb();
+
+	/* Ring doorbell and wait for result */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+
+	start = get_timer(0);
+	/* Wait for completion */
+	do {
+		WATCHDOG_RESET();
+	} while (result->s.compcode == 0 && get_timer(start) < 2);
+
+	if (result->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("NIX: Admin Queue failed or timed out with code %d after %ld ms\n",
+		       result->s.compcode, get_timer(start));
+		return -EBUSY;
+	}
+	return 0;
+}
+
+static void nix_get_cgx_lmac_id(u8 map, u8 *cgx_id, u8 *lmac_id)
+{
+	*cgx_id = (map >> 4) & 0xf;
+	*lmac_id = (map & 0xf);
+}
+
+int nix_af_get_pf_num(const struct nix_af_handle *nix)
+{
+	return (((u64)(nix->nix_af_base)) >> 36) & 0x0f;
+}
+
+int npc_lf_admin_setup(struct nix_af_handle *nix_af,
+		       struct cgx *cgx, u64 link_num)
+{
+	union cavm_npc_af_const af_const;
+	union cavm_npc_af_pkindx_action0 action0;
+	union cavm_npc_af_pkindx_action1 action1;
+	union cavm_npc_af_intfx_kex_cfg kex_cfg;
+	union cavm_npc_af_mcamex_bankx_camx_intf camx_intf;
+	union cavm_npc_af_mcamex_bankx_camx_w0 camx_w0;
+	union cavm_npc_af_mcamex_bankx_cfg bankx_cfg;
+	union cavm_nix_rx_action_s rx_action;
+	union cavm_nix_tx_action_s tx_action;
+	int pf = nix_af_get_pf_num(nix_af);
+	u32 kpus;
+	int pkind = link_num;
+	int index;
+
+	debug("%s(%p, 0x%llx)\n", __func__, nix_af, link_num);
+	if (!cgx) {
+		printf("%s: No CGX data found for link number 0x%llx\n",
+		       __func__, link_num);
+		return -1;
+	}
+	af_const.u = npc_af_reg_read(nix_af, CAVM_NPC_AF_CONST());
+	kpus = af_const.s.kpus;
+
+	action0.u = 0;
+	action0.s.parse_done = 1;
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_PKINDX_ACTION0(pkind), action0.u);
+
+	action1.u = 0;
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_PKINDX_ACTION1(pkind), action1.u);
+
+	kex_cfg.u = 0;
+	kex_cfg.s.parse_nibble_ena = 0x07;
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_INTFX_KEX_CFG(CAVM_NPC_INTF_E_NIXX_RX(0)),
+			 kex_cfg.u);
+
+	camx_intf.u = 0;
+	camx_intf.s.intf = ~CAVM_NPC_INTF_E_NIXX_RX(0);
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(pkind, 0, 0),
+			 camx_intf.u);
+
+	camx_intf.u = 0;
+	camx_intf.s.intf = CAVM_NPC_INTF_E_NIXX_RX(0);
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(pkind, 0, 1),
+			 camx_intf.u);
+
+	camx_w0.u = 0;
+	camx_w0.s.md = ~cgx_get_channel_number(cgx, link_num);
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(pkind, 0, 0),
+			 camx_w0.u);
+
+	camx_w0.u = 0;
+	camx_w0.s.md = cgx_get_channel_number(cgx, link_num);
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(pkind, 0, 1),
+			 camx_w0.u);
+
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(pkind, 0, 0),
+			 0);
+
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(pkind, 0, 1),
+			 0);
+
+	bankx_cfg.u = 0;
+	bankx_cfg.s.ena = 1;
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_MCAMEX_BANKX_CFG(pkind, 0),
+			 bankx_cfg.u);
+
+	rx_action.u = 0;
+	rx_action.s.pf_func = pf << 10;
+	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_UCAST;
+	npc_af_reg_write(nix_af, CAVM_NPC_AF_MCAMEX_BANKX_ACTION(pkind, 0),
+			 rx_action.u);
+
+	for (index = 0; index < kpus; index++)
+		npc_af_reg_write(nix_af, CAVM_NPC_AF_KPUX_CFG(index), 0);
+
+	rx_action.u = 0;
+	rx_action.s.pf_func = pf << 10;
+	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_DROP;
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_RX(0)),
+			 rx_action.u);
+	tx_action.u = 0;
+	tx_action.s.op = CAVM_NIX_TX_ACTIONOP_E_UCAST_DEFAULT;
+	npc_af_reg_write(nix_af,
+			 CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_TX(0)),
+			 tx_action.u);
+
+	return 0;
+}
+
+static int nix_interface_init(struct nix_af_handle *nix_af,
+			      struct nix_handle *nix, u16 pcifunc,
+			      int type, int nixlf)
+{
+	union cavm_rvu_pf_func_s pf_func;
+	struct cgx *cgx = nix->lmac->cgx;
+	int err;
+	int pkind, pf, lmac_cnt;
+	u64 tx_credit;
+	u16 link;
+	u8 cgx_id = nix->lmac->cgx->cgx_id;
+	u8 lmac_id = nix->lmac->lmac_id;
+
+	pf = rvu_get_pf(pcifunc);
+
+	debug("%s(%p, %p, 0x%x, 0x%x, 0x%x) pf: 0x%x\n", __func__, nix_af, nix,
+	      pcifunc, type, nixlf, pf);
+
+	switch (type) {
+	case NIX_INTF_TYPE_CGX:
+		pkind = npc_get_pkind(nix_af, pf);
+		if (pkind < 0) {
+			printf("%s: Error: invalid pkind 0x%x for pf 0x%x\n",
+			       __func__, pkind, pf);
+			return -EINVAL;
+		}
+		cgx_set_pkind(cgx, lmac_id, pkind);
+		link = NIX_LINK_CGX_LMAC(cgx_id, lmac_id);
+		break;
+	case NIX_INTF_TYPE_LBK:
+		link = NIX_LINK_LBK(0);
+		break;
+	}
+	return 0;
+}
+
+struct nix_handle *cavm_nix_lf_alloc(struct nix_af_handle *nix_af,
+				     struct udevice *dev,
+				     u16 pcifunc,
+				     u16 nix_lf,
+				     void __iomem *nix_base,
+				     void __iomem *npc_base,
+				     void __iomem *lmt_base,
+				     int cgx_id, int lmac_id,
+				     struct nix_lf_alloc_req *req,
+				     struct nix_lf_alloc_rsp *rsp)
+{
+	union cavm_nixx_af_sq_const sq_const;
+	union cavm_nixx_af_const2 af_const2;
+	union cavm_nixx_af_const3 af_const3;
+	union cavm_nixx_af_lfx_rqs_cfg rqs_cfg;
+	union cavm_nixx_af_lfx_sqs_cfg sqs_cfg;
+	union cavm_nixx_af_lfx_cqs_cfg cqs_cfg;
+	union cavm_nixx_af_lfx_rss_cfg rss_cfg;
+	union cavm_nixx_af_lfx_cints_cfg cints_cfg;
+	union cavm_nixx_af_lfx_qints_cfg qints_cfg;
+	union cavm_nixx_af_lfx_rss_grpx rss_grp;
+	union cavm_nixx_af_lfx_tx_cfg2 tx_cfg2;
+	union cavm_nixx_af_lfx_cfg lfx_cfg;
+	int idx, hwctx_size;
+	int qints;
+	struct nix_handle *nix;
+	int err;
+	static int instance = 0;
+
+	debug("%s(%p, %s, 0x%x, 0x%x, %p, %p, %p, 0x%x, 0x%x, %p, %p)\n",
+	      __func__, nix_af, dev->name, pcifunc, nix_lf, nix_base, npc_base,
+	      lmt_base, cgx_id, lmac_id, req, rsp);
+
+	if (!nix_lf)
+		return NULL;
+
+	if (!req->rq_cnt || !req->sq_cnt || !req->cq_cnt)
+		return NULL;
+
+	af_const3.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST3());
+	hwctx_size = 1ULL << af_const3.s.rq_ctx_log2bytes;
+
+	nix = (struct nix_handle *)calloc(1, sizeof(*nix));
+	if (!nix) {
+		printf("%s: Out of memory\n", __func__);
+		return NULL;
+	}
+	nix->nic_id = instance++;
+	nix->nix_af = nix_af;
+	nix->nix_base = nix_base;
+	nix->npc_base = npc_base;
+	nix->lmt_base = lmt_base;
+	nix->lf = nix_lf;
+	nix->dev = dev;
+	nix->pf = pcifunc;
+	nix->lmac = cgx_get_lmac(pcifunc - 1);
+	if (!nix->lmac) {
+		printf("%s: Error: could not find lmac for pf %d\n",
+		       __func__, nix->pf);
+		free(nix);
+		return NULL;
+	}
+
+	/* Alloc NIX RQ HW context memory and config base */
+	err = qmem_alloc(&(nix->rq), req->rq_cnt, hwctx_size);
+	if (err)
+		goto error;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_BASE(nix_lf),
+			 nix->rq.iova);
+
+	/* Set caching and queue count in HW */
+	rqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix_lf));
+	rqs_cfg.s.caching = 1;
+	rqs_cfg.s.max_queuesm1 = req->rq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix_lf), rqs_cfg.u);
+
+	/* Alloc NIX SQ HW context memory and config the base */
+	hwctx_size = 1ULL << af_const3.s.sq_ctx_log2bytes;
+	err = qmem_alloc(&(nix->sq), req->sq_cnt, hwctx_size);
+	if (err)
+		goto error;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_BASE(nix_lf),
+			 nix->sq.iova);
+	sqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix_lf));
+	sqs_cfg.s.caching = 1;
+	sqs_cfg.s.max_queuesm1 = req->sq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix_lf), sqs_cfg.u);
+
+	/* Alloc NIX CQ HW context memory and config the base */
+	hwctx_size = 1ULL << af_const3.s.cq_ctx_log2bytes;
+	for (idx = 0; idx < NIX_CQ_COUNT; idx++) {
+		err = qmem_alloc(&(nix->cq[idx]), req->cq_cnt, hwctx_size);
+		if (err)
+			goto error;
+	}
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_BASE(nix_lf),
+			 nix->cq[NIX_CQ_TX].iova);
+	cqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix_lf));
+	cqs_cfg.s.caching = 1;
+	cqs_cfg.s.max_queuesm1 = req->cq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix_lf), cqs_cfg.u);
+
+	/* Alloc NIX RSS HW context memory and config the base */
+	hwctx_size = 1ULL << af_const3.s.rsse_log2bytes;
+	err = qmem_alloc(&(nix->rss), req->rss_sz * req->rss_grps, hwctx_size);
+	if (err)
+		goto error;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_BASE(nix_lf),
+			 nix->rss.iova);
+	rss_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix_lf));
+	rss_cfg.s.ena = 1;
+	rss_cfg.s.size = ilog2(req->rss_sz) / 256;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix_lf), rss_cfg.u);
+
+	for (idx = 0; idx < req->rss_grps; idx++) {
+		rss_grp.u = 0;
+		rss_grp.s.sizem1 = 0x7;
+		rss_grp.s.offset = req->rss_sz * idx;
+		nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_GRPX(nix_lf, idx),
+				 rss_grp.u);
+	}
+
+	/* Alloc memory for CQints HW contextxs */
+	af_const2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST2());
+	qints = af_const2.s.cints;
+	hwctx_size = 1ULL << af_const3.s.cint_log2bytes;
+	err = qmem_alloc(&nix->cq_ints, qints, hwctx_size);
+	if (err)
+		goto error;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_BASE(nix_lf),
+			 nix->cq_ints.iova);
+	cints_cfg.u = nix_af_reg_read(nix_af,
+				      CAVM_NIXX_AF_LFX_CINTS_CFG(nix_lf));
+	cints_cfg.s.caching = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_CFG(nix_lf),
+			 cints_cfg.u);
+
+	/* Alloc memory for Qints HW contexts */
+	qints = af_const2.s.qints;
+	hwctx_size = 1ULL << af_const3.s.qint_log2bytes;
+	err = qmem_alloc(&(nix->qints), qints, hwctx_size);
+	if (err)
+		goto error;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_BASE(nix_lf),
+			 nix->qints.iova);
+	qints_cfg.u = nix_af_reg_read(nix_af,
+				      CAVM_NIXX_AF_LFX_QINTS_CFG(nix_lf));
+	qints_cfg.s.caching = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_CFG(nix_lf),
+			 qints_cfg.u);
+
+	/* Enable LMTST for this NIX LF */
+	tx_cfg2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix_lf));
+	tx_cfg2.s.lmt_ena = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix_lf), tx_cfg2.u);
+
+	lfx_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CFG(nix_lf));
+	lfx_cfg.s.xqe_size = req->xqe_sz;
+	lfx_cfg.s.npa_pf_func = pcifunc;
+	lfx_cfg.s.sso_pf_func = pcifunc;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CFG(nix_lf), lfx_cfg.u);
+
+	/* Config Rx pkt length, csum checks and apad enable/disable */
+
+	sq_const.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_SQ_CONST());
+	rsp->sqb_size = sq_const.s.sqb_size;
+	rsp->chan_base = CAVM_NIX_CHAN_E_CGXX_LMACX_CHX(cgx_id, lmac_id, 0);
+	rsp->chan_cnt = 1;
+
+	err = nix_lf_alloc_cq(nix_af, nix);
+	if (err) {
+		printf("%s: Error %d allocating completion queue for pf %d\n",
+		       __func__, err, pcifunc);
+		return NULL;
+	}
+#if 0
+	rsp->lso_tsov4_idx = NIX_LSO_FORMAT_IDX_TSOV4;
+	rsp->lso_tsov6_idx = NIX_LSO_FORMAT_IDX_TSOV6;
+#endif
+	list_add(&nix->nix_list, &nix_list);
+
+	return nix;
+
+error:
+	qmem_free(&(nix->rq));
+	qmem_free(&(nix->sq));
+	for (idx = 0; idx < NIX_CQ_COUNT; idx++)
+		qmem_free(&(nix->cq[idx]));
+	qmem_free(&(nix->rss));
+	qmem_free(&(nix->cq_ints));
+	qmem_free(&(nix->qints));
+	return NULL;
+}
+
+/**
+ * Allocate and setup a new Completion Queue for use
+ *
+ * @param nix_af	Handle for admin function
+ * @param nix		Handle for pf
+ *
+ * @return Completion Queue number, or negative on failure
+ */
+static int nix_lf_alloc_cq(struct nix_af_handle *nix_af, struct nix_handle *nix)
+{
+	struct nix_aq_cq_request aq_request ALIGNED;
+	int cq = af_state.next_free_cq++;
+	int err;
+
+	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
+			sizeof(union cavm_nix_aq_inst_s),
+			ALIGN(sizeof(union cavm_nix_aq_res_s), 128) + 256);
+
+	if (err) {
+		printf("%s: Error %d allocating completion queue\n",
+		       __func__, err);
+		return err;
+	}
+
+	memset(&aq_request, 0, sizeof(aq_request));
+	aq_request.cq.s.ena = 1;
+	aq_request.cq.s.bpid = nix->pki_channel;
+	aq_request.cq.s.substream = 0;	/* FIXME: Substream IDs? */
+	aq_request.cq.s.drop_ena = 1;
+	aq_request.cq.s.caching = 1;
+	aq_request.cq.s.qsize = CQS_QSIZE;
+	aq_request.cq.s.drop = 255 * 7 / 8;
+	aq_request.cq.s.qint_idx = 0;
+	aq_request.cq.s.cint_idx = 0;
+	aq_request.cq.s.base = nix->cq[NIX_CQ_TX].iova;
+
+	err = nix_aq_issue_command(nix_af, CAVM_NIX_AQ_INSTOP_E_INIT,
+				   CAVM_NIX_AQ_CTYPE_E_CQ, nix->lf, cq,
+				   &aq_request.resp);
+	if (err) {
+		printf("%s: Error requesting completion queue\n", __func__);
+		return err;
+	}
+	debug("%s: CQ(%d) allocated, base %p, %p\n", __func__, cq,
+	      nix->cq[NIX_CQ_TX].base, nix->cq[NIX_CQ_RX].base);
+
+	nix->cq_idx = cq;
+
+	return nix->cq_idx;
+}
+#if 0
+int nix_af_setup_tx_resources(struct nix_af_handle *nix)
+{
+	struct rvu_hwinfo *hw = nix->hw;
+	struct nix_txsch *txsch;
+	union cavm_nixx_af_const af_const;
+	union cavm_nixx_af_tl1_const tl_const;
+	u64 reg;
+	int err, lvl;
+
+	/* Set number of links of each type */
+	af_const.u = nix_af_reg_read(nix, CAVM_NIXX_AF_CONST());
+	hw->cgx = af_const.s.num_cgx;
+	hw->lmac_per_cgx = af_const.s.cgx_lmacs;
+	hw->cgx_links = hw->cgx * hw->lmac_per_cgx;
+	hw->lbk_links = 1;
+	hw->sdp_links = 1;
+
+	for (lvl = 0; lvl < NIX_TXSCH_LVL_CNT; lvl++) {
+		txsch = &hw->txsch[lvl];
+		txsch->lvl = lvl;
+		switch (lvl) {
+		case NIX_TXSCH_LVL_SMQ:
+			reg = CAVM_NIXX_AF_MDQ_CONST();
+			break;
+		case NIX_TXSCH_LVL_TL4:
+			reg = CAVM_NIXX_AF_TL4_CONST();
+			break;
+		case NIX_TXSCH_LVL_TL3:
+			reg = CAVM_NIXX_AF_TL3_CONST();
+			break;
+		case NIX_TXSCH_LVL_TL2:
+			reg = CAVM_NIXX_AF_TL2_CONST();
+			break;
+		case NIX_TXSCH_LVL_TL1:
+			reg = CAVM_NIXX_AF_TL1_CONST();
+			break;
+		}
+		tl_const.u = nix_af_reg_read(reg);
+		txsch->rsrc.max = tl_const.s.count;
+		err = rvu_alloc_bitmap(&txsch->rsrc);
+		if (err)
+			return err;
+
+		/* Allocate mem for scheduler to PF/VF pcifunc mapping info */
+		txsch->pfvf_map = calloc(txsch->rsrc.max, sizeof(u16));
+		if (!txsch->pfvf_map)
+			return -ENOMEM;
+	}
+	return 0;
+}
+#endif
diff --git a/drivers/net/cavium/octeontx2/nix_af.h b/drivers/net/cavium/octeontx2/nix_af.h
new file mode 100644
index 0000000000..805d99b939
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/nix_af.h
@@ -0,0 +1,15 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Cavium OcteonTx2 RVU Admin function driver
+ *
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __NIX_AF_H__
+#define __NIX_AF_H__
+
+
+#endif /* __NIX_AF_H__ */
diff --git a/drivers/net/cavium/octeontx2/nix_lf.h b/drivers/net/cavium/octeontx2/nix_lf.h
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/drivers/net/cavium/octeontx2/nix_regs.h b/drivers/net/cavium/octeontx2/nix_regs.h
deleted file mode 100644
index c7b25cf006..0000000000
--- a/drivers/net/cavium/octeontx2/nix_regs.h
+++ /dev/null
@@ -1,9009 +0,0 @@
-/*
- * Copyright (C) 2018 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This file defines the NIX registers for the Cavium OcteonTX2.
- */
-
-#ifndef __NIX_REGS_H__
-#define __NIX_REGS_H__
-
-/**
- * Enumeration nix_af_int_vec_e
- *
- * NIX Admin Function Interrupt Vector Enumeration
- * Enumerates the NIX AF MSI-X interrupt vectors.
- */
-enum nix_af_int_vec_e = {
-	CAVM_NIX_AF_INT_VEC_E_AF_ERR = 3,
-	CAVM_NIX_AF_INT_VEC_E_AQ_DONE = 2,
-	CAVM_NIX_AF_INT_VEC_E_GEN = 1,
-	CAVM_NIX_AF_INT_VEC_E_POISON = 4,
-	CAVM_NIX_AF_INT_VEC_E_RVU = 0
-};
-
-/**
- * Enumeration nix_aq_comp_e
- *
- * NIX Completion Enumeration
- * Enumerates the values of NIX_AQ_RES_S[COMPCODE].
- */
-#define CAVM_NIX_AQ_COMP_E_CTX_FAULT (4)
-#define CAVM_NIX_AQ_COMP_E_CTX_POISON (3)
-#define CAVM_NIX_AQ_COMP_E_GOOD (1)
-#define CAVM_NIX_AQ_COMP_E_LOCKERR (5)
-#define CAVM_NIX_AQ_COMP_E_NOTDONE (0)
-#define CAVM_NIX_AQ_COMP_E_SQB_ALLOC_FAIL (6)
-#define CAVM_NIX_AQ_COMP_E_SWERR (2)
-
-/**
- * Enumeration nix_aq_ctype_e
- *
- * NIX Context Type Enumeration
- * Enumerates NIX_AQ_INST_S[CTYPE] values.
- */
-enum nix_aq_ctype_e {
-	CAVM_NIX_AQ_CTYPE_E_CQ = 2,
-	CAVM_NIX_AQ_CTYPE_E_DYNO = 5,
-	CAVM_NIX_AQ_CTYPE_E_MCE = 3,
-	CAVM_NIX_AQ_CTYPE_E_RQ = 0,
-	CAVM_NIX_AQ_CTYPE_E_RSS = 4,
-	CAVM_NIX_AQ_CTYPE_E_SQ = 1
-};
-
-/**
- * Enumeration nix_aq_instop_e
- *
- * NIX Admin Queue Opcode Enumeration
- * Enumerates NIX_AQ_INST_S[OP] values.
- */
-enum nix_aq_instop_e {
-	CAVM_NIX_AQ_INSTOP_E_INIT = 1,
-	CAVM_NIX_AQ_INSTOP_E_LOCK = 4,
-	CAVM_NIX_AQ_INSTOP_E_NOP = 0,
-	CAVM_NIX_AQ_INSTOP_E_READ = 3,
-	CAVM_NIX_AQ_INSTOP_E_UNLOCK = 5,
-	CAVM_NIX_AQ_INSTOP_E_WRITE = 2
-};
-
-/**
- * Enumeration nix_chan_e
- *
- * NIX Channel Number Enumeration
- * Enumerates the receive and transmit channels, and values of
- * NIX_RX_PARSE_S[CHAN], NIX_SQ_CTX_S[DEFAULT_CHAN]. CNXXXX implements a subset of
- * these channels. Specifically, only channels for links enumerated by NIX_LINK_E
- * are implemented.
- *
- * Internal:
- * P2X/X2P channel enumeration for t9x.
- */
-#define CAVM_NIX_CHAN_E_CGXX_LMACX_CHX(a,b,c)	\
-	(0x800 + 0x100 * (a) + 0x10 * (b) + (c))
-#define CAVM_NIX_CHAN_E_LBKX_CHX(a,b) (0 + 0x100 * (a) + (b))
-#define CAVM_NIX_CHAN_E_RX(a) (0 + 0x100 * (a))
-#define CAVM_NIX_CHAN_E_SDP_CHX(a) (0x700 + (a))
-
-/**
- * Enumeration nix_colorresult_e
- *
- * NIX Color Result Enumeration
- * Enumerates the values of NIX_MEM_RESULT_S[COLOR], NIX_AF_TL1()_MD_DEBUG1[COLOR]
- * and NIX_AF_TL1()_MD_DEBUG1[COLOR].
- */
-enum nix_colorresult_e {
-	CAVM_NIX_COLORRESULT_E_GREEN = (0),
-	CAVM_NIX_COLORRESULT_E_RED_DROP = (3),
-	CAVM_NIX_COLORRESULT_E_RED_SEND = (2),
-	CAVM_NIX_COLORRESULT_E_YELLOW = (1)
-};
-
-/**
- * Enumeration nix_cqerrint_e
- *
- * NIX Completion Queue Interrupt Enumeration
- * Enumerates the bit index of NIX_CQ_CTX_S[CQ_ERR_INT,CQ_ERR_INT_ENA].
- */
-enum nix_cqerrint_e {
-	CAVM_NIX_CQERRINT_E_CQE_FAULT = (2),
-	CAVM_NIX_CQERRINT_E_DOOR_ERR = (0),
-	CAVM_NIX_CQERRINT_E_WR_FULL = (1)
-};
-
-/**
- * Enumeration nix_lf_int_vec_e
- *
- * NIX Local Function Interrupt Vector Enumeration
- * Enumerates the NIX MSI-X interrupt vectors per LF.
- */
-#define CAVM_NIX_LF_INT_VEC_E_CINTX(a) (0x40 + (a))
-#define CAVM_NIX_LF_INT_VEC_E_ERR_INT (0x81)
-#define CAVM_NIX_LF_INT_VEC_E_GINT (0x80)
-#define CAVM_NIX_LF_INT_VEC_E_POISON (0x82)
-#define CAVM_NIX_LF_INT_VEC_E_QINTX(a) (0 + (a))
-
-/**
- * Enumeration nix_link_e
- *
- * NIX Link Number Enumeration
- * Enumerates the receive and transmit links, and LINK index of
- * NIX_AF_RX_LINK()_CFG, NIX_AF_RX_LINK()_WRR_CFG,
- * NIX_AF_TX_LINK()_NORM_CREDIT, NIX_AF_TX_LINK()_EXPR_CREDIT,
- * NIX_AF_TX_LINK()_HW_XOFF and NIX_AF_TX_LINK()_SW_XOFF,
- * NIX_AF_TL3_TL2()_LINK()_CFG.
- */
-#define CAVM_NIX_LINK_E_CGXX_LMACX(a,b) (0 + 4 * (a) + (b))
-#define CAVM_NIX_LINK_E_LBKX(a) (0xc + (a))
-#define CAVM_NIX_LINK_E_MC (0xe)
-#define CAVM_NIX_LINK_E_SDP (0xd)
-
-/**
- * Enumeration nix_lsoalg_e
- *
- * NIX Large Send Offload Algorithm Enumeration
- * Enumerates NIX_AF_LSO_FORMAT()_FIELD()[ALG] values. Specifies algorithm for
- * modifying the associated LSO packet field.
- */
-#define CAVM_NIX_LSOALG_E_ADD_OFFSET (3)
-#define CAVM_NIX_LSOALG_E_ADD_PAYLEN (2)
-#define CAVM_NIX_LSOALG_E_ADD_SEGNUM (1)
-#define CAVM_NIX_LSOALG_E_NOP (0)
-#define CAVM_NIX_LSOALG_E_TCP_FLAGS (4)
-
-/**
- * Enumeration nix_maxsqesz_e
- *
- * NIX Maximum SQE Size Enumeration
- * Enumerates the values of NIX_SQ_CTX_S[MAX_SQE_SIZE].
- */
-#define CAVM_NIX_MAXSQESZ_E_W16 (0)
-#define CAVM_NIX_MAXSQESZ_E_W8 (1)
-
-/**
- * Enumeration nix_mdtype_e
- *
- * NIX Meta Descriptor Type Enumeration
- * Enumerates values of NIX_AF_MDQ()_MD_DEBUG[MD_TYPE].
- */
-#define CAVM_NIX_MDTYPE_E_FLUSH (1)
-#define CAVM_NIX_MDTYPE_E_PMD (2)
-#define CAVM_NIX_MDTYPE_E_RSVD (0)
-
-/**
- * Enumeration nix_mnqerr_e
- *
- * NIX Meta-Descriptor Enqueue Error Enumeration
- * Enumerates NIX_LF_MNQ_ERR_DBG[ERRCODE] values.
- */
-#define CAVM_NIX_MNQERR_E_CQ_QUERY_ERR (6)
-#define CAVM_NIX_MNQERR_E_LSO_ERR (5)
-#define CAVM_NIX_MNQERR_E_MAXLEN_ERR (8)
-#define CAVM_NIX_MNQERR_E_MAX_SQE_SIZE_ERR (7)
-#define CAVM_NIX_MNQERR_E_SQB_FAULT (2)
-#define CAVM_NIX_MNQERR_E_SQB_POISON (3)
-#define CAVM_NIX_MNQERR_E_SQ_CTX_FAULT (0)
-#define CAVM_NIX_MNQERR_E_SQ_CTX_POISON (1)
-#define CAVM_NIX_MNQERR_E_TOTAL_ERR (4)
-
-/**
- * Enumeration nix_ndc_rx_port_e
- *
- * NIX Receive NDC Port Enumeration
- * Enumerates NIX receive NDC (NDC_IDX_E::NIX()_RX) ports and the PORT index of
- * NDC_AF_PORT()_RT()_RW()_REQ_PC and NDC_AF_PORT()_RT()_RW()_LAT_PC.
- */
-#define CAVM_NIX_NDC_RX_PORT_E_AQ (0)
-#define CAVM_NIX_NDC_RX_PORT_E_CINT (2)
-#define CAVM_NIX_NDC_RX_PORT_E_CQ (1)
-#define CAVM_NIX_NDC_RX_PORT_E_MC (3)
-#define CAVM_NIX_NDC_RX_PORT_E_PKT (4)
-#define CAVM_NIX_NDC_RX_PORT_E_RQ (5)
-
-/**
- * Enumeration nix_ndc_tx_port_e
- *
- * NIX Transmit NDC Port Enumeration
- * Enumerates NIX transmit NDC (NDC_IDX_E::NIX()_TX) ports and the PORT index of
- * NDC_AF_PORT()_RT()_RW()_REQ_PC and NDC_AF_PORT()_RT()_RW()_LAT_PC.
- */
-#define CAVM_NIX_NDC_TX_PORT_E_DEQ (3)
-#define CAVM_NIX_NDC_TX_PORT_E_DMA (4)
-#define CAVM_NIX_NDC_TX_PORT_E_ENQ (1)
-#define CAVM_NIX_NDC_TX_PORT_E_LMT (0)
-#define CAVM_NIX_NDC_TX_PORT_E_MNQ (2)
-#define CAVM_NIX_NDC_TX_PORT_E_XQE (5)
-
-/**
- * Enumeration nix_re_opcode_e
- *
- * NIX Receive Error Opcode Enumeration
- * Enumerates NIX_RX_PARSE_S[ERRCODE] values when NIX_RX_PARSE_S[ERRLEV] =
- * NPC_ERRLEV_E::RE.
- */
-#define CAVM_NIX_RE_OPCODE_E_OL2_LENMISM (0x12)
-#define CAVM_NIX_RE_OPCODE_E_OVERSIZE (0x11)
-#define CAVM_NIX_RE_OPCODE_E_RE_DMAPKT (0xf)
-#define CAVM_NIX_RE_OPCODE_E_RE_FCS (7)
-#define CAVM_NIX_RE_OPCODE_E_RE_FCS_RCV (8)
-#define CAVM_NIX_RE_OPCODE_E_RE_JABBER (2)
-#define CAVM_NIX_RE_OPCODE_E_RE_NONE (0)
-#define CAVM_NIX_RE_OPCODE_E_RE_PARTIAL (1)
-#define CAVM_NIX_RE_OPCODE_E_RE_RX_CTL (0xb)
-#define CAVM_NIX_RE_OPCODE_E_RE_SKIP (0xc)
-#define CAVM_NIX_RE_OPCODE_E_RE_TERMINATE (9)
-#define CAVM_NIX_RE_OPCODE_E_UNDERSIZE (0x10)
-
-/**
- * Enumeration nix_redalg_e
- *
- * NIX Red Algorithm Enumeration
- * Enumerates the different algorithms of NIX_SEND_EXT_S[SHP_RA].
- */
-#define CAVM_NIX_REDALG_E_DISCARD (3)
-#define CAVM_NIX_REDALG_E_SEND (1)
-#define CAVM_NIX_REDALG_E_STALL (2)
-#define CAVM_NIX_REDALG_E_STD (0)
-
-/**
- * Enumeration nix_rqint_e
- *
- * NIX Receive Queue Interrupt Enumeration
- * Enumerates the bit index of NIX_RQ_CTX_S[RQ_INT,RQ_INT_ENA].
- */
-#define CAVM_NIX_RQINT_E_DROP (0)
-#define CAVM_NIX_RQINT_E_RX(a) (0 + (a))
-#define CAVM_NIX_RQINT_E_RED (1)
-
-/**
- * Enumeration nix_rx_actionop_e
- *
- * NIX Receive Action Opcode Enumeration
- * Enumerates the values of NIX_RX_ACTION_S[OP].
- */
-#define CAVM_NIX_RX_ACTIONOP_E_DROP (0)
-#define CAVM_NIX_RX_ACTIONOP_E_MCAST (3)
-#define CAVM_NIX_RX_ACTIONOP_E_MIRROR (6)
-#define CAVM_NIX_RX_ACTIONOP_E_PF_FUNC_DROP (5)
-#define CAVM_NIX_RX_ACTIONOP_E_RSS (4)
-#define CAVM_NIX_RX_ACTIONOP_E_UCAST (1)
-#define CAVM_NIX_RX_ACTIONOP_E_UCAST_IPSEC (2)
-
-/**
- * Enumeration nix_rx_mcop_e
- *
- * NIX Receive Multicast/Mirror Opcode Enumeration
- * Enumerates the values of NIX_RX_MCE_S[OP].
- */
-#define CAVM_NIX_RX_MCOP_E_RQ (0)
-#define CAVM_NIX_RX_MCOP_E_RSS (1)
-
-/**
- * Enumeration nix_rx_perrcode_e
- *
- * NIX Receive Protocol Error Code Enumeration
- * Enumerates NIX_RX_PARSE_S[ERRCODE] values when NIX_RX_PARSE_S[ERRLEV] =
- * NPC_ERRLEV_E::NIX.
- */
-#define CAVM_NIX_RX_PERRCODE_E_BUFS_OFLOW (0xa)
-#define CAVM_NIX_RX_PERRCODE_E_DATA_FAULT (8)
-#define CAVM_NIX_RX_PERRCODE_E_IL3_LEN (0x20)
-#define CAVM_NIX_RX_PERRCODE_E_IL4_CHK (0x22)
-#define CAVM_NIX_RX_PERRCODE_E_IL4_LEN (0x21)
-#define CAVM_NIX_RX_PERRCODE_E_IL4_PORT (0x23)
-#define CAVM_NIX_RX_PERRCODE_E_MCAST_FAULT (4)
-#define CAVM_NIX_RX_PERRCODE_E_MCAST_POISON (6)
-#define CAVM_NIX_RX_PERRCODE_E_MEMOUT (9)
-#define CAVM_NIX_RX_PERRCODE_E_MIRROR_FAULT (5)
-#define CAVM_NIX_RX_PERRCODE_E_MIRROR_POISON (7)
-#define CAVM_NIX_RX_PERRCODE_E_NPC_RESULT_ERR (2)
-#define CAVM_NIX_RX_PERRCODE_E_OL3_LEN (0x10)
-#define CAVM_NIX_RX_PERRCODE_E_OL4_CHK (0x12)
-#define CAVM_NIX_RX_PERRCODE_E_OL4_LEN (0x11)
-#define CAVM_NIX_RX_PERRCODE_E_OL4_PORT (0x13)
-
-/**
- * Enumeration nix_send_status_e
- *
- * NIX Send Completion Status Enumeration
- * Enumerates values of NIX_SEND_COMP_S[STATUS] and NIX_LF_SEND_ERR_DBG[ERRCODE].
- * Internal:
- * TODO.
- */
-#define CAVM_NIX_SEND_STATUS_E_DATA_FAULT (0x16)
-#define CAVM_NIX_SEND_STATUS_E_DATA_POISON (0x17)
-#define CAVM_NIX_SEND_STATUS_E_GOOD (0)
-#define CAVM_NIX_SEND_STATUS_E_INVALID_SUBDC (0x14)
-#define CAVM_NIX_SEND_STATUS_E_JUMP_FAULT (7)
-#define CAVM_NIX_SEND_STATUS_E_JUMP_POISON (8)
-#define CAVM_NIX_SEND_STATUS_E_LOCK_VIOL (0x21)
-#define CAVM_NIX_SEND_STATUS_E_NPC_DROP_ACTION (0x20)
-#define CAVM_NIX_SEND_STATUS_E_NPC_MCAST_ABORT (0x24)
-#define CAVM_NIX_SEND_STATUS_E_NPC_MCAST_CHAN_ERR (0x23)
-#define CAVM_NIX_SEND_STATUS_E_NPC_UCAST_CHAN_ERR (0x22)
-#define CAVM_NIX_SEND_STATUS_E_NPC_VTAG_PTR_ERR (0x25)
-#define CAVM_NIX_SEND_STATUS_E_NPC_VTAG_SIZE_ERR (0x26)
-#define CAVM_NIX_SEND_STATUS_E_SEND_CRC_ERR (0x10)
-#define CAVM_NIX_SEND_STATUS_E_SEND_EXT_ERR (6)
-#define CAVM_NIX_SEND_STATUS_E_SEND_HDR_ERR (5)
-#define CAVM_NIX_SEND_STATUS_E_SEND_IMM_ERR (0x11)
-#define CAVM_NIX_SEND_STATUS_E_SEND_MEM_ERR (0x13)
-#define CAVM_NIX_SEND_STATUS_E_SEND_MEM_FAULT (0x27)
-#define CAVM_NIX_SEND_STATUS_E_SEND_SG_ERR (0x12)
-#define CAVM_NIX_SEND_STATUS_E_SQB_FAULT (3)
-#define CAVM_NIX_SEND_STATUS_E_SQB_POISON (4)
-#define CAVM_NIX_SEND_STATUS_E_SQ_CTX_FAULT (1)
-#define CAVM_NIX_SEND_STATUS_E_SQ_CTX_POISON (2)
-#define CAVM_NIX_SEND_STATUS_E_SUBDC_ORDER_ERR (0x15)
-
-/**
- * Enumeration nix_sendcrcalg_e
- *
- * NIX Send CRC Algorithm Enumeration
- * Enumerates the CRC algorithm used, see NIX_SEND_CRC_S[ALG].
- */
-#define CAVM_NIX_SENDCRCALG_E_CRC32 (0)
-#define CAVM_NIX_SENDCRCALG_E_CRC32C (1)
-#define CAVM_NIX_SENDCRCALG_E_ONES16 (2)
-
-/**
- * Enumeration nix_sendl3type_e
- *
- * NIX Send Layer 3 Header Type Enumeration
- * Enumerates values of NIX_SEND_HDR_S[OL3TYPE], NIX_SEND_HDR_S[IL3TYPE].
- * Internal:
- * Encoding matches DPDK TX IP types:
- * \<pre\>
- * PKT_TX_IP_CKSUM      (1ULL \<\< 54)
- * PKT_TX_IPV4          (1ULL \<\< 55)
- * PKT_TX_IPV6          (1ULL \<\< 56)
- *
- * PKT_TX_OUTER_IP_CKSUM(1ULL \<\< 58)
- * PKT_TX_OUTER_IPV4    (1ULL \<\< 59)
- * PKT_TX_OUTER_IPV6    (1ULL \<\< 60)
- * \</pre\>
- */
-#define CAVM_NIX_SENDL3TYPE_E_IP4 (2)
-#define CAVM_NIX_SENDL3TYPE_E_IP4_CKSUM (3)
-#define CAVM_NIX_SENDL3TYPE_E_IP6 (4)
-#define CAVM_NIX_SENDL3TYPE_E_NONE (0)
-
-/**
- * Enumeration nix_sendl4type_e
- *
- * NIX Send Layer 4 Header Type Enumeration
- * Enumerates values of NIX_SEND_HDR_S[OL4TYPE], NIX_SEND_HDR_S[IL4TYPE].
- * Internal:
- * Encoding matches DPDK TX L4 types.
- * \<pre\>
- * PKT_TX_L4_NO_CKSUM   (0ULL \<\< 52)  // Disable L4 cksum of TX pkt.
- * PKT_TX_TCP_CKSUM     (1ULL \<\< 52)  // TCP cksum of TX pkt. computed by nic.
- * PKT_TX_SCTP_CKSUM    (2ULL \<\< 52)  // SCTP cksum of TX pkt. computed by nic.
- * PKT_TX_UDP_CKSUM     (3ULL \<\< 52)  // UDP cksum of TX pkt. computed by nic.
- * \</pre\>
- */
-#define CAVM_NIX_SENDL4TYPE_E_NONE (0)
-#define CAVM_NIX_SENDL4TYPE_E_SCTP_CKSUM (2)
-#define CAVM_NIX_SENDL4TYPE_E_TCP_CKSUM (1)
-#define CAVM_NIX_SENDL4TYPE_E_UDP_CKSUM (3)
-
-/**
- * Enumeration nix_sendldtype_e
- *
- * NIX Send Load Type Enumeration
- * Enumerates the load transaction types for reading segment bytes specified by
- * NIX_SEND_SG_S[LD_TYPE] and NIX_SEND_JUMP_S[LD_TYPE].
- *
- * Internal:
- * The hardware implementation treats undefined encodings as LDD load type.
- */
-#define CAVM_NIX_SENDLDTYPE_E_LDD (0)
-#define CAVM_NIX_SENDLDTYPE_E_LDT (1)
-#define CAVM_NIX_SENDLDTYPE_E_LDWB (2)
-
-/**
- * Enumeration nix_sendmemalg_e
- *
- * NIX Memory Modify Algorithm Enumeration
- * Enumerates the different algorithms for modifying memory; see
- * NIX_SEND_MEM_S[ALG]. mbufs_freed is the number of gather buffers freed to NPA
- * for the send descriptor. See NIX_SEND_HDR_S[DF] and NIX_SEND_SG_S[I*].
- */
-#define CAVM_NIX_SENDMEMALG_E_ADD (8)
-#define CAVM_NIX_SENDMEMALG_E_ADDLEN (0xa)
-#define CAVM_NIX_SENDMEMALG_E_ADDMBUF (0xc)
-#define CAVM_NIX_SENDMEMALG_E_SET (0)
-#define CAVM_NIX_SENDMEMALG_E_SETRSLT (2)
-#define CAVM_NIX_SENDMEMALG_E_SETTSTMP (1)
-#define CAVM_NIX_SENDMEMALG_E_SUB (9)
-#define CAVM_NIX_SENDMEMALG_E_SUBLEN (0xb)
-#define CAVM_NIX_SENDMEMALG_E_SUBMBUF (0xd)
-
-/**
- * Enumeration nix_sendmemdsz_e
- *
- * NIX Memory Data Size Enumeration
- * Enumerates the datum size for modifying memory; see NIX_SEND_MEM_S[DSZ].
- */
-#define CAVM_NIX_SENDMEMDSZ_E_B16 (2)
-#define CAVM_NIX_SENDMEMDSZ_E_B32 (1)
-#define CAVM_NIX_SENDMEMDSZ_E_B64 (0)
-#define CAVM_NIX_SENDMEMDSZ_E_B8 (3)
-
-/**
- * Enumeration nix_sqint_e
- *
- * NIX Send Queue Interrupt Enumeration
- * Enumerates the bit index of NIX_SQ_CTX_S[SQ_INT,SQ_INT_ENA].
- */
-#define CAVM_NIX_SQINT_E_LMT_ERR (0)
-#define CAVM_NIX_SQINT_E_MNQ_ERR (1)
-#define CAVM_NIX_SQINT_E_SEND_ERR (2)
-#define CAVM_NIX_SQINT_E_SQB_ALLOC_FAIL (3)
-
-/**
- * Enumeration nix_sqoperr_e
- *
- * NIX SQ Operation Error Enumeration
- * Enumerates NIX_LF_SQ_OP_ERR_DBG[ERRCODE] values.
- */
-#define CAVM_NIX_SQOPERR_E_MAX_SQE_SIZE_ERR (4)
-#define CAVM_NIX_SQOPERR_E_SQB_FAULT (7)
-#define CAVM_NIX_SQOPERR_E_SQB_NULL (6)
-#define CAVM_NIX_SQOPERR_E_SQE_OFLOW (5)
-#define CAVM_NIX_SQOPERR_E_SQ_CTX_FAULT (1)
-#define CAVM_NIX_SQOPERR_E_SQ_CTX_POISON (2)
-#define CAVM_NIX_SQOPERR_E_SQ_DISABLED (3)
-#define CAVM_NIX_SQOPERR_E_SQ_OOR (0)
-
-/**
- * Enumeration nix_stat_lf_rx_e
- *
- * NIX Local Function Receive Statistics Enumeration
- * Enumerates the last index of NIX_AF_LF()_RX_STAT() and NIX_LF_RX_STAT().
- */
-#define CAVM_NIX_STAT_LF_RX_E_RX_BCAST (2)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DROP (4)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DROP_OCTS (5)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DRP_BCAST (8)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DRP_L3BCAST (0xa)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DRP_L3MCAST (0xb)
-#define CAVM_NIX_STAT_LF_RX_E_RX_DRP_MCAST (9)
-#define CAVM_NIX_STAT_LF_RX_E_RX_ERR (7)
-#define CAVM_NIX_STAT_LF_RX_E_RX_FCS (6)
-#define CAVM_NIX_STAT_LF_RX_E_RX_MCAST (3)
-#define CAVM_NIX_STAT_LF_RX_E_RX_OCTS (0)
-#define CAVM_NIX_STAT_LF_RX_E_RX_UCAST (1)
-
-/**
- * Enumeration nix_stat_lf_tx_e
- *
- * NIX Local Function Transmit Statistics Enumeration
- * Enumerates the index of NIX_AF_LF()_TX_STAT() and NIX_LF_TX_STAT().
- * These statistics do not account for packet replication due to
- * NIX_TX_ACTION_S[OP] = NIX_TX_ACTIONOP_E::MCAST.
- */
-#define CAVM_NIX_STAT_LF_TX_E_TX_BCAST (1)
-#define CAVM_NIX_STAT_LF_TX_E_TX_DROP (3)
-#define CAVM_NIX_STAT_LF_TX_E_TX_MCAST (2)
-#define CAVM_NIX_STAT_LF_TX_E_TX_OCTS (4)
-#define CAVM_NIX_STAT_LF_TX_E_TX_UCAST (0)
-
-/**
- * Enumeration nix_stype_e
- *
- * NIX SQB Caching Type Enumeration
- * Enumerates the values of NIX_SQ_CTX_S[SQE_STYPE].
- */
-#define CAVM_NIX_STYPE_E_STF (0)
-#define CAVM_NIX_STYPE_E_STP (2)
-#define CAVM_NIX_STYPE_E_STT (1)
-
-/**
- * Enumeration nix_subdc_e
- *
- * NIX Subdescriptor Operation Enumeration
- * Enumerates send and receive subdescriptor codes. The codes differentiate
- * subdescriptors within a NIX send or receive descriptor, excluding NIX_SEND_HDR_S for
- * send and NIX_CQE_HDR_S/NIX_WQE_HDR_S for receive, which are determined by their
- * position as the first subdescriptor, and NIX_RX_PARSE_S, which is determined by its
- * position as the second subdescriptor.
- */
-#define CAVM_NIX_SUBDC_E_CRC (2)
-#define CAVM_NIX_SUBDC_E_EXT (1)
-#define CAVM_NIX_SUBDC_E_IMM (3)
-#define CAVM_NIX_SUBDC_E_JUMP (6)
-#define CAVM_NIX_SUBDC_E_MEM (5)
-#define CAVM_NIX_SUBDC_E_NOP (0)
-#define CAVM_NIX_SUBDC_E_SG (4)
-#define CAVM_NIX_SUBDC_E_SOD (0xf)
-#define CAVM_NIX_SUBDC_E_WORK (7)
-
-/**
- * Enumeration nix_tx_actionop_e
- *
- * NIX Transmit Action Opcode Enumeration
- * Enumerates the values of NIX_TX_ACTION_S[OP].
- */
-#define CAVM_NIX_TX_ACTIONOP_E_DROP (0)
-#define CAVM_NIX_TX_ACTIONOP_E_DROP_VIOL (5)
-#define CAVM_NIX_TX_ACTIONOP_E_MCAST (3)
-#define CAVM_NIX_TX_ACTIONOP_E_UCAST_CHAN (2)
-#define CAVM_NIX_TX_ACTIONOP_E_UCAST_DEFAULT (1)
-
-/**
- * Enumeration nix_tx_vtagop_e
- *
- * NIX Transmit Vtag Opcode Enumeration
- * Enumerates the values of NIX_TX_VTAG_ACTION_S[VTAG0_OP,VTAG1_OP].
- */
-#define CAVM_NIX_TX_VTAGOP_E_INSERT (1)
-#define CAVM_NIX_TX_VTAGOP_E_NOP (0)
-#define CAVM_NIX_TX_VTAGOP_E_REPLACE (2)
-
-/**
- * Enumeration nix_txlayer_e
- *
- * NIX Transmit Layer Enumeration
- * Enumerates the values of NIX_AF_LSO_FORMAT()_FIELD()[LAYER].
- */
-#define CAVM_NIX_TXLAYER_E_IL3 (2)
-#define CAVM_NIX_TXLAYER_E_IL4 (3)
-#define CAVM_NIX_TXLAYER_E_OL3 (0)
-#define CAVM_NIX_TXLAYER_E_OL4 (1)
-
-/**
- * Enumeration nix_vtagsize_e
- *
- * NIX Vtag Size Enumeration
- * Enumerates the values of NIX_AF_TX_VTAG_DEF()_CTL[SIZE] and NIX_AF_LF()_RX_VTAG_TYPE()[SIZE].
- */
-#define CAVM_NIX_VTAGSIZE_E_T4 (0)
-#define CAVM_NIX_VTAGSIZE_E_T8 (1)
-
-/**
- * Enumeration nix_xqe_type_e
- *
- * NIX WQE/CQE Type Enumeration
- * Enumerates the values of NIX_WQE_HDR_S[WQE_TYPE], NIX_CQE_HDR_S[CQE_TYPE].
- */
-#define CAVM_NIX_XQE_TYPE_E_INVALID (0)
-#define CAVM_NIX_XQE_TYPE_E_RX (1)
-#define CAVM_NIX_XQE_TYPE_E_RX_IPSECD (4)
-#define CAVM_NIX_XQE_TYPE_E_RX_IPSECH (3)
-#define CAVM_NIX_XQE_TYPE_E_RX_IPSECS (2)
-#define CAVM_NIX_XQE_TYPE_E_SEND (8)
-
-/**
- * Enumeration nix_xqesz_e
- *
- * NIX WQE/CQE Size Enumeration
- * Enumerates the values of NIX_AF_LF()_CFG[XQE_SIZE].
- */
-#define CAVM_NIX_XQESZ_E_W16 (1)
-#define CAVM_NIX_XQESZ_E_W64 (0)
-
-/* Hardware PF_BAR0 register offsets */
-#define CAVM_NIX_AF_AQ_CFG			(0x0000)
-#define CAVM_NIX_AF_STATUS			(0x0010)
-#define CAVM_NIX_AF_NDC_CFG			(0x0018)
-#define CAVM_NIX_AF_CONST			(0x0020)
-#define CAVM_NIX_AF_CONST1			(0x0028)
-#define CAVM_NIX_AF_CONST2			(0x0030)
-#define CAVM_NIX_AF_SQ_CONST			(0x0040)
-#define CAVM_NIX_AF_CQ_CONST			(0x0048)
-#define CAVM_NIX_AF_RQ_CONST			(0x0050)
-#define CAVM_NIX_AF_PSE_CONST			(0x0060)
-#define CAVM_NIX_AF_TL1_CONST			(0x0070)
-#define CAVM_NIX_AF_TL2_CONST			(0x0078)
-#define CAVM_NIX_AF_TL3_CONST			(0x0080)
-#define CAVM_NIX_AF_TL4_CONST			(0x0088)
-#define CAVM_NIX_AF_MDQ_CONST			(0x0090)
-#define CAVM_NIX_AF_MC_MIRROR_CONST		(0x0098)
-#define CAVM_NIX_AF_LSO_CFG			(0x00a8)
-#define CAVM_NIX_AF_BLK_RST			(0x00b0)
-#define CAVM_NIX_AF_TX_TSTMP_CFG		(0x00c0)
-#define CAVM_NIX_AF_RX_CFG			(0x00d0)
-#define CAVM_NIX_AF_AVG_DELAY			(0x00e0)
-#define CAVM_NIX_AF_CINT_DELAY			(0x00f0)
-#define CAVM_NIX_AF_RX_MCAST_BASE		(0x0100)
-#define CAVM_NIX_AF_RX_MCAST_CFG		(0x0110)
-#define CAVM_NIX_AF_RX_MCAST_BUF_BASE		(0x0120)
-#define CAVM_NIX_AF_RX_MCAST_BUF_CFG		(0x0130)
-#define CAVM_NIX_AF_RX_MIRROR_BUF_BASE		(0x0140)
-#define CAVM_NIX_AF_RX_MIRROR_BUF_CFG		(0x0148)
-#define CAVM_NIX_AF_LF_RST			(0x0150)
-#define CAVM_NIX_AF_GEN_INT			(0x0160)
-#define CAVM_NIX_AF_GEN_INT_W1S			(0x0168)
-#define CAVM_NIX_AF_GEN_INT_ENA_W1S		(0x0170)
-#define CAVM_NIX_AF_GEN_INT_ENA_W1C		(0x0178)
-#define CAVM_NIX_AF_ERR_INT			(0x0180)
-#define CAVM_NIX_AF_ERR_INT_W1S			(0x0188)
-#define CAVM_NIX_AF_ERR_INT_ENA_W1S		(0x0190)
-#define CAVM_NIX_AF_ERR_INT_ENA_W1C		(0x0198)
-#define CAVM_NIX_AF_RAS				(0x01a0)
-#define CAVM_NIX_AF_RAS_W1S			(0x01a8)
-#define CAVM_NIX_AF_RAS_ENA_W1S			(0x01b0)
-#define CAVM_NIX_AF_RAS_ENA_W1C			(0x01b8)
-#define CAVM_NIX_AF_RVU_INT			(0x01c0)
-#define CAVM_NIX_AF_RVU_INT_W1S			(0x01c8)
-#define CAVM_NIX_AF_RVU_INT_ENA_W1S		(0x01d0)
-#define CAVM_NIX_AF_RVU_INT_ENA_W1C		(0x01d8)
-#define CAVM_NIX_AF_TCP_TIMER			(0x01e0)
-#define CAVM_NIX_AF_RX_DEF_OL2			(0x0200)
-#define CAVM_NIX_AF_RX_DEF_OIP4			(0x0210)
-#define CAVM_NIX_AF_RX_DEF_IIP4			(0x0220)
-#define CAVM_NIX_AF_RX_DEF_OIP6			(0x0230)
-#define CAVM_NIX_AF_RX_DEF_IIP6			(0x0240)
-#define CAVM_NIX_AF_RX_DEF_OTCP			(0x0250)
-#define CAVM_NIX_AF_RX_DEF_ITCP			(0x0260)
-#define CAVM_NIX_AF_RX_DEF_OUDP			(0x0270)
-#define CAVM_NIX_AF_RX_DEF_IUDP			(0x0280)
-#define CAVM_NIX_AF_RX_DEF_OSCTP		(0x0290)
-#define CAVM_NIX_AF_RX_DEF_ISCTP		(0x02a0)
-#define CAVM_NIX_AF_RX_DEF_IPSECX(x)		(0x02b0 + (x) * 8)
-
-#define CAVM_NIX_AF_RX_IPSEC_GEN_CFG		(0x0300)
-#define CAVM_NIX_AF_RX_CPTX_INST_QSEL(x)	(0x0320 + (x) * 8)
-
-#define CAVM_NIX_AF_AQ_CFG			(0x0400)
-#define CAVM_NIX_AF_AQ_BASE			(0x0410)
-#define CAVM_NIX_AF_AQ_STATUS			(0x0420)
-#define CAVM_NIX_AF_AQ_DOOR			(0x0430)
-#define CAVM_NIX_AF_AQ_DONE_WAIT		(0x0440)
-#define CAVM_NIX_AF_AQ_DONE			(0x0450)
-#define CAVM_NIX_AF_AQ_DONE_ACK			(0x0460)
-#define CAVM_NIX_AF_AQ_DONE_TIME		(0x0470)
-#define CAVM_NIX_AF_AQ_DONE_INT			(0x0480)
-#define CAVM_NIX_AF_AQ_DONE_INT_W1S		(0x0488)
-#define CAVM_NIX_AF_AQ_DONE_ENA_W1S		(0x0490)
-#define CAVM_NIX_AF_AQ_DONE_ENA_W1C		(0x0498)
-
-#define CAVM_NIX_AF_RX_LINKX_SLX_SPKT_CNT(a, b)	\
-			(0x0500 + ((a) & 0xf) * 0x10000 + ((0xb) & 0x1) * 8)
-#define CAVM_NIX_AF_RX_LINKX_CFG(x)		\
-			(0x0540 + ((x) & 0xf) * 0x10000)
-#define CAVM_NIX_AF_RX_SW_SYNC			(0x0550)
-#define CAVM_NIX_AF_RX_LINKX_WRR_CFG(x)		\
-			(0x0560 + ((x) & 0xf) * 0x10000)
-
-#define CAVM_NIX_AF_SEB_ECO			(0x0600)
-#define CAVM_NIX_AF_SEB_TEST_BP			(0x0610)
-#define CAVM_NIX_AF_NORM_TX_FIFO_STATUS		(0x0648)
-#define CAVM_NIX_AF_EXPR_TX_FIFO_STATUS		(0x0640)
-#define CAVM_NIX_AF_SDP_TX_FIFO_STATUS		(0x0650)
-#define CAVM_NIX_AF_TX_NPC_CAPTURE_CONFIG	(0x0660)
-#define CAVM_NIX_AF_TX_NPC_CAPTURE_INFO		(0x0670)
-#define CAVM_NIX_AF_TX_NPC_CAPTURE_RESPX(x)	\
-			(0x0680 + ((x) & 0x7) * 8)
-
-#define CAVM_NIX_AF_SMQX_CFG(x)			\
-			(0x0700 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_SMQX_HEAD(x)		\
-			(0x0710 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_SMQX_TAIL(x)		\
-			(0x0720 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_SMQX_STATUS(x)		\
-			(0x0730 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_SMQX_NXT_HEAD(x)		\
-			(0x0740 + ((x) & 0x1ff) * 0x10000)
-
-#define CAVM_NIX_AF_PSE_CHANNEL_LEVEL		(0x0800)
-#define CAVM_NIX_AF_PSE_SHAPER_CFG		(0x0810)
-
-#define CAVM_NIX_AF_MARK_FORMATX_CTL(x)		\
-			(0x0900 + ((x) & 0x7f) * 0x40000)
-
-#define CAVM_NIX_AF_TX_LINKX_NORM_CREDIT(x)	\
-			(0x0a00 + ((x) & 0xf) * 0x10000)
-#define CAVM_NIX_AF_TX_LINKX_EXPR_CREDIT(x)	\
-			(0x0a10 + ((x) & 0xf) * 0x10000)
-#define CAVM_NIX_AF_TX_LINKX_SW_XOFF(x)		\
-			(0x0a20 + ((x) & 0xf) * 0x10000)
-
-#define CAVM_NIX_AF_TX_LINKX_HW_XOFF(x)		\
-			(0x0a30 + ((x) & 0xf) * 0x10000)
-#define CAVM_NIX_AF_SDP_LINK_CREDIT		(0x0a40)
-#define CAVM_NIX_AF_SDP_SW_XOFFX(x)		\
-			(0x0a60 + ((x) & 0x3) * 8)
-#define CAVM_NIX_AF_SDP_HW_XOFFX(x)		\
-			(0x0ac0 + ((x) & 0x3) * 8)
-
-#define CAVM_NIX_AF_TL4X_BP_STATUS(x)		\
-			(0x0b00 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_SDP_LINK_CFG(x)	\
-			(0x0b10 + ((x) & 0x1ff) * 0x10000)
-
-#define CAVM_NIX_AF_TL1X_SCHEDULE(x)		\
-			(0x0c00 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_SHAPE(x)		\
-			(0x0c10 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_CIR(x)			\
-			(0x0c20 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_SHAPE_STATE(x)		\
-			(0x0c50 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_SW_XOFF(x)		\
-			(0x0c70 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_TOPOLOGY		(0x0c80)
-#define CAVM_NIX_AF_TL1X_GREEN(x)		\
-			(0x0c90 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_YELLOW(x)		\
-			(0x0ca0 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_RED(x)			\
-			(0x0cb0 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_MD_DEBUG0(x)		\
-			(0x0cc0 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_MD_DEBUG1(x)		\
-			(0x0cc8 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_MD_DEBUG2(x)		\
-			(0x0cd0 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_MD_DEBUG3(x)		\
-			(0x0cd8 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_DROPPED_PACKETS(x)	\
-			(0x0d20 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_DROPPED_BYTES(x)	\
-			(0x0d30 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_RED_PACKETS(x)		\
-			(0x0d40 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_RED_BYTES(x)		\
-			(0x0d50 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_YELLOW_PACKETS(x)	\
-			(0x0d60 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_YELLOW_BYTES(x)	\
-			(0x0d70 + ((x) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_GREEN_PACKETS(x)	\
-			(0x0d80 + ((X) & 0x1f) * 0x10000)
-#define CAVM_NIX_AF_TL1X_GREEN_BYTES(x)		\
-			(0x0d90 + ((x) & 0x1f) * 0x10000)
-
-#define CAVM_NIX_AF_TL2X_SCHEDULE(x)		\
-			(0x0e00 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_SHAPE(x)		\
-			(0x0e10 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_CIR(x)			\
-			(0x0e20 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_PIR(x)		\
-			(0x0e30 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_SCHED_STATE(x)		\
-			(0x0e40 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_SHAPE_STATE(x)		\
-			(0x0e50 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_POINTERS(x)		\
-			(0x0e60 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_SW_XOFF(x)		\
-			(0x0e70 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_TOPOLOGY(x)		\
-			(0x0e80 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_PARENT(x)		\
-			(0x0e88 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_GREEN(x)		\
-			(0x0e90 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_YELLOW(x)		\
-			(0x0ea0 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL2X_RED(x)		\
-			(0x0eb0 + ((x) & 0xff) * 0x10000)
-
-#define CAVM_NIX_AF_TL3X_SCHEDULE(x)		\
-			(0x1000 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_SHAPE(x)		\
-			(0x1010 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_CIR(x)			\
-			(0x1020 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_PIR(x)		\
-			(0x1030 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_SCHED_STATE(x)		\
-			(0x1040 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_SHAPE_STATE(x)		\
-			(0x1050 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_POINTERS(x)		\
-			(0x1060 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_SW_XOFF(x)		\
-			(0x1070 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_TOPOLOGY(x)		\
-			(0x1080 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_PARENT(x)		\
-			(0x1088 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_GREEN(x)		\
-			(0x1090 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_YELLOW(x)		\
-			(0x10a0 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3X_RED(x)			\
-			(0x10b0 + ((x) & 0xff) * 0x10000)
-
-#define CAVM_NIX_AF_TL4X_SCHEDULE(x)		\
-			(0x1200 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_SHAPE(x)		\
-			(0x1210 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_CIR(x)			\
-			(0x1220 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_PIR(x)			\
-			(0x1230 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_SCHED_STATE(x)		\
-			(0x1240 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_SHAPE_STATE(x)		\
-			(0x1250 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_POINTERS(x)		\
-			(0x1260 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_SW_XOFF(x)		\
-			(0x1270 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_TOPOLOGY(x)		\
-			(0x1280 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_PARENT(x)		\
-			(0x1288 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_GREEN(x)		\
-			(0x1290 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_YELLOW(x)		\
-			(0x12a0 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_TL4X_RED(x)			\
-			(0x12b0 + ((x) & 0x1ff) * 0x10000)
-
-#define CAVM_NIX_AF_MDQX_SCHEDULE(x)		\
-			(0x1400 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_SHAPE(x)		\
-			(0x1410 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_CIR(x)			\
-			(0x1420 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_PIR(x)			\
-			(0x1430 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_SCHED_STATE(x)		\
-			(0x1440 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_SHAPE_STATE(x)		\
-			(0x1450 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_POINTERS(x)		\
-			(0x1460 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_SW_XOFF(x)		\
-			(0x1470 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_PARENT(x)		\
-			(0x1280 + ((x) & 0x1ff) * 0x10000)
-#define CAVM_NIX_AF_MDQX_DEBUG(x)		\
-			(0x14c0 + ((x) & 0x1ff) * 0x10000)
-
-#define CAVM_NIX_AF_TL3_TL2X_CFG(x)		\
-			(0x1600 + ((x) & 0xff) * 0x10000)
-#define CAVM_NIX_AF_TL3_TL2X_BP_STATUS(x)	\
-			(0x1610 + ((x) & 0xff) * 0x10000)
-
-#define CAVM_NIX_AF_TL3_TL2X_LINKX_CFG(a, b)	\
-			(0x1700 + ((a) & 0xff) * 0x1000 + ((b) & 0xf) * 8)
-
-#define CAVM_NIX_AF_RX_FLOW_KEY_ALGX_FIELDX(a, b)	\
-			(0x1800 + ((a) & 0x1f) * 0x40000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_TX_MCASTX(x)		\
-			(0x1900 + ((x) & 0x7ff) * 0x8000)
-
-#define CAVM_NIX_AF_TX_VTAG_DEFX_CTL(x)		\
-			(0x1a00 + ((x) & 0x3ff) * 0x10000)
-#define CAVM_NIX_AF_TX_VTAG_DEFX_DATA(x)	\
-			(0x1a10 + ((x) & 0x3ff) * 0x10000)
-#define CAVM_NIX_AF_RX_BPIDX_STATUS(x)		\
-			(0x1a20 + ((x) & 0x1ff) * 0x20000)
-#define CAVM_NIX_AF_RX_CHANX_CFG(x)		\
-			(0x1a30 + ((x) & 0xfff) * 0x8000)
-#define CAVM_NIX_AF_CINT_TIMERX(x)		\
-			(0x1a40 + ((x) & 0xff) * 0x40000)
-
-#define CAVM_NIX_AF_LSO_FORMATX_FIELDX(a, b)	\
-			(0x1b00 + ((a) & 0x1f) * 0x1000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_LFX_CFG(x)			\
-			(0x4000 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_SQS_CFG(x)		\
-			(0x4020 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_SQS_BASE(x)		\
-			(0x4030 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RQS_CFG(x)		\
-			(0x4040 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RQS_BASE(x)		\
-			(0x4050 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_CQS_CFG(x)		\
-			(0x4060 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_CQS_BASE(x)		\
-			(0x4070 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_TX_CFG(x)		\
-			(0x4080 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_TX_PARSE_CFG(x)		\
-			(0x4090 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_CFG(x)		\
-			(0x40a0 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RSS_CFG(x)		\
-			(0x40c0 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RSS_BASE(x)		\
-			(0x40d0 + ((x) & 0x7f) * 0x20000)
-
-#define CAVM_NIX_AF_LFX_QINTS_CFG(x)		\
-			(0x4100 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_QINTS_BASE(x)		\
-			(0x4110 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_CINTS_CFG(x)		\
-			(0x4120 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_CINTS_BASE(x)		\
-			(0x4130 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_IPSEC_CFG0(x)		\
-			(0x4140 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_IPSEC_CFG1(x)		\
-			(0x4148 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_IPSEC_DYNO_CFG(x)	\
-			(0x4150 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_IPSEC_DYNO_BASE(x)	\
-			(0x4158 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_RX_IPSEC_SA_BASE(x)	\
-			(0x4170 + ((x) & 0x7f) * 0x20000)
-#define CAVM_NIX_AF_LFX_TX_STATUS(x)		\
-			(0x4180 + ((x) & 0x7f) * 0x20000)
-
-#define CAVM_NIX_AF_LFX_RX_VTAG_TYPEX(a, b)	\
-			(0x4200 + ((a) & 0x7f) * 0x20000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_LFX_LOCKX(a, b)		\
-			(0x4300 + ((a) & 0x7f) * 0x20000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_LFX_TX_STATX(a, b)		\
-			(0x4400 + ((a) & 0x7f) * 0x20000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_LFX_RX_STATX(a, b)		\
-			(0x4500 + ((a) & 0x7f) * 0x20000 + ((b) & 0xf) * 8)
-
-#define CAVM_NIX_AF_LFX_RSS_GRPX(a, b)		\
-			(0x4600 + ((a) & 0x7f) * 0x20000 + ((b) & 0x7) * 8)
-
-#define CAVM_NIX_AF_RX_NPC_MC_RCV		(0x4700)
-#define CAVM_NIX_AF_RX_NPC_MC_DROP		(0x4710)
-#define CAVM_NIX_AF_RX_NPC_MIRROR_RCV		(0x4720)
-#define CAVM_NIX_AF_RX_NPC_MIRROR_DROP		(0x4730)
-
-/* PF (BAR 2) registers and VF bar 0 */
-#define CAVM_NIX_LF_RX_SECRETX(x)		(0x0000 + ((x) & 0x7) * 8)
-#define CAVM_NIX_LF_GINT			(0x0200)
-#define CAVM_NIX_LF_GINT_W1S			(0x0208)
-#define CAVM_NIX_LF_GINT_ENA_W1C		(0x0210)
-#define CAVM_NIX_LF_GINT_ENA_W1S		(0x0218)
-#define CAVM_NIX_LF_ERR_INT			(0x0220)
-#define CAVM_NIX_LF_ERR_INT_W1S			(0x0228)
-#define CVMX_NIX_LF_ERR_INT_ENA_W1C			(0x0230)
-#define CVMX_NIX_LF_ERR_INT_W1S			(0x0238)
-#define CVMX_NIX_LF_RAS				(0x0240)
-#define CVMX_NIX_LF_RAS_W1S			(0x0248)
-#define CVMX_NIX_LF_RAS_ENA_W1C			(0x0250)
-#define CVMX_NIX_LF_RAS_ENA_W1S			(0x0258)
-#define CVMX_NIX_LF_SQ_OP_ERR_DBG		(0x0260)
-#define CVMX_NIX_LF_MNQ_ERR_DBG			(0x0270)
-#define CVMX_NIX_LF_SEND_ERR_DBG		(0x0280)
-
-#define CAVM_NIX_LF_TX_STATX(x)			(0x0300 + ((x) & 0x7) * 8)
-#define CAVM_NIX_LF_RX_STATX(x)			(0x0400 + ((x) & 0xf) * 8)
-#define CAVM_NIX_LF_OP_SENDX(x)			(0x0800 + ((x) & 0xf) * 8)
-
-#define CAVM_NIX_LF_RQ_OP_INT			(0x0900)
-#define CAVM_NIX_LF_RQ_OP_OCTS			(0x0910)
-#define CAVM_NIX_LF_RQ_OP_PKTS			(0x0920)
-#define CAVM_NIX_LF_RQ_OP_RE_PKTS		(0x0950)
-
-#define CAVM_NIX_LF_SQ_OP_INT			(0x0a00)
-#define CAVM_NIX_LF_SQ_OP_OCTS			(0x0a10)
-#define CAVM_NIX_LF_SQ_OP_PKTS			(0x0a20)
-#define CAVM_NIX_LF_SQ_OP_STATUS		(0x0a30)
-
-#define CAVM_NIX_LF_CQ_OP_INT			(0x0b00)
-#define CAVM_NIX_LF_CQ_OP_DOOR			(0x0b30)
-#define CAVM_NIX_LF_CQ_OP_STATUS		(0x0b40)
-
-#define CAVM_NIX_LF_QINTX_CNT(x)		\
-			(0x0c00 + ((x) & 0x3f) * 0x10000)
-#define CAVM_NIX_LF_QINTX_INT(x)		\
-			(0x0c10 + ((x) & 0x3f) * 0x10000)
-#define CAVM_NIX_LF_QINTX_INT_W1S(x)		\
-			(0x0c18 + ((x) & 0x3f) * 0x10000)
-#define CAVM_NIX_LF_QINTX_ENA_W1S(x)		\
-			(0x0c20 + ((x) & 0x3f) * 0x10000)
-#define CAVM_NIX_LF_QINTX_ENA_W1C(x)		\
-			(0x0c30 + ((x) & 0x3f) * 0x10000)
-
-#define CAVM_NIX_LF_CINTX_CNT(x)		\
-			(0x0d00 + ((x) & 0x3f) * 0x1000)
-#define CAVM_NIX_LF_CINTX_WAIT(x)		\
-			(0x0d10 + ((x) & 0x3f) * 0x1000)
-#define CAVM_NIX_LF_CINTX_INT(x)		\
-			(0x0d20 + ((x) & 0x3f) * 0x1000)
-#define CAVM_NIX_LF_CINTX_INT_W1S(x)		\
-			(0x0d30 + ((x) & 0x3f) * 0x1000)
-#define CAVM_NIX_LF_CINTX_ENA_W1S(x)		\
-			(0x0d40 + ((x) & 0x3f) * 0x1000)
-#define CAVM_NIX_LF_CINTX_ENA_W1C(x)		\
-			(0x0d50 + ((x) & 0x3f) * 0x1000)
-
-/** NOTE: BAR2 address */
-#define CAVM_NIX_AF_BAR2_ALIASX(x)		(0x100000 + ((x) & 0x1ffff) * 0x8)
-#define CAVM_NIX_AF_BAR2_SEL			(0x000000)
-/* Data structures */
-/**
- * Structure nix_aq_inst_s
- *
- * NIX Admin Queue Instruction Structure
- * This structure specifies the AQ instruction.
- * Instructions and associated software structures are stored in memory as
- * little-endian unless NIX_AF_CFG[AF_BE] is set.
- *
- * Hardware reads of NIX_AQ_INST_S do not allocate into LLC.
- *
- * Hardware reads and writes of the context structure selected by [CTYPE], [LF]
- * and [CINDEX] use the NDC and LLC caching style configured for that context. For
- * example:
- * * When [CTYPE] = NIX_AQ_CTYPE_E::RQ: use NIX_AF_LF()_RSS_CFG[CACHING] and
- * NIX_AF_LF()_RSS_CFG[WAY_MASK].
- * * When [CTYPE] = NIX_AQ_CTYPE_E::MCE: use NIX_AF_RX_MCAST_CFG[CACHING] and
- * NIX_AF_RX_MCAST_CFG[WAY_MASK].
- */
-union cavm_nix_aq_inst_s {
-	u64 u[2];
-	struct cavm_nix_aq_inst_s_s {
-		u64 op:4;		     /**< [  3:  0] Instruction op code enumerated by NIX_AQ_INSTOP_E. */
-		u64 ctype:4;	     /**< [  7:  4] Context type of instruction enumerated by NIX_AQ_CTYPE_E. */
-		u64 lf:7;		     /**< [ 14:  8] Local function. Software must map the LF to a PF and function with
-                                                                 NIX_PRIV_LF()_CFG[PF_FUNC] before issuing the AQ instruction.
-                                                                 NIX_PRIV_LF()_CFG[ENA] is not required to be set when executing AQ
-                                                                 instructions.
-
-                                                                 Internal:
-                                                                 Hardware uses PF(0)'s stream ID when accessing hardware context structures
-                                                                 in LLC/DRAM, but NDC tracks the LF for context structures in its cache
-                                                                 using the NIX_PRIV_LF()_CFG[PF_FUNC]'s stream ID. */
-		u64 reserved_15_23:9;
-		u64 cindex:20;	     /**< [ 43: 24] Context index. Index of context of type [CTYPE] within [LF]. For example,
-                                                                 if [CTYPE] = NIX_AQ_CTYPE_E::RQ, this is the RQ index within the [LF].
-
-                                                                 If [CTYPE] = NIX_AQ_CTYPE_E::DYNO, index to array of
-                                                                 1 \<\< NIX_AF_CONST3[DYNO_ARRAY_LOG2COUNTERS]
-                                                                 IPSEC dynamic ordering counters, starting at counter index
-                                                                 (1 \<\< NIX_AF_CONST3[DYNO_ARRAY_LOG2COUNTERS]) * [CINDEX].
-                                                                 See NIX_AF_LF()_RX_IPSEC_DYNO_CFG[DYNO_ENA]. */
-		u64 reserved_44_62:19;
-		u64 doneint:1;	     /**< [ 63: 63] Done interrupt.
-                                                                 0 = No interrupts related to this instruction.
-                                                                 1 = When the instruction completes, NIX_AF_AQ_DONE[DONE] will be incremented,
-                                                                 and based on the rules described there, an interrupt may occur. */
-		u64 res_addr:64;	     /**< [127: 64] Result IOVA. Specifies where to write NIX_AQ_RES_S.
-
-                                                                 Bits \<6:0\> must be zero; address must be 16-byte aligned. Bits \<63:53\> are
-                                                                 ignored by hardware; software should use a sign-extended bit \<52\> for forward
-                                                                 compatibility.
-
-                                                                 Software must reserve one, two or three 128-byte cache lines at this
-                                                                 address, as follows:
-                                                                 * When [OP] = NIX_AQ_INSTOP_E::INIT or READ, software must reserve at least
-                                                                 two cache lines.
-                                                                 * When [OP] = NIX_AQ_INSTOP_E::WRITE, software must reserve at least three
-                                                                 cache lines.
-                                                                 * Otherwise, software must reserve at least one cache line.
-
-                                                                 Hardware always stores full cache lines when writing NIX_AQ_RES_S and
-                                                                 following context structures (e.g. NIX_RQ_CTX_S), if any.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-	} s;
-	/* struct cavm_nix_aq_inst_s_s cn; */
-};
-
-/**
- * Structure nix_aq_res_s
- *
- * NIX Admin Queue Result Structure
- * NIX writes this structure after it completes the NIX_AQ_INST_S instruction.
- * The result structure is exactly 16 bytes, and each instruction completion produces
- * exactly one result structure.
- *
- * Results and associated software structures are stored in memory as
- * little-endian unless NIX_AF_CFG[AF_BE] is set.
- *
- * When [OP] = NIX_AQ_INSTOP_E::INIT, WRITE or READ, this structure is
- * immediately followed by context read or write data. See NIX_AQ_INSTOP_E.
- *
- * Hardware writes of NIX_AQ_RES_S and context data always allocate into LLC.
- * Hardware reads of context data do not allocate into LLC.
- */
-union cavm_nix_aq_res_s {
-	u64 u[2];
-	struct cavm_nix_aq_res_s_s {
-		u64 op:4;		     /**< [  3:  0] Copy of NIX_AQ_INST_S[OP] for the completed instruction; enumerated by
-                                                                 NIX_AQ_INSTOP_E. */
-		u64 ctype:4;	     /**< [  7:  4] Copy of NIX_AQ_INST_S[CTYPE] for the completed instruction; enumerated by
-                                                                 NIX_AQ_CTYPE_E. */
-		u64 compcode:8;	     /**< [ 15:  8] Indicates completion/error status of the NIX coprocessor for the associated
-                                                                 instruction, as enumerated by NIX_AQ_COMP_E. Core software may write the memory
-                                                                 location containing [COMPCODE] to 0x0 before ringing the doorbell, and then poll
-                                                                 for completion by checking for a nonzero value.
-
-                                                                 Once the core observes a nonzero [COMPCODE] value in this case, NIX will have also
-                                                                 completed LLC/DRAM reads and writes for the operation. */
-		u64 doneint:1;	     /**< [ 16: 16] Done interrupt. This bit is copied from the corresponding instruction's
-                                                                 NIX_AQ_INST_S[DONEINT]. */
-		u64 reserved_17_63:47;
-		u64 reserved_64_127:64;
-	} s;
-	/* struct cavm_nix_aq_res_s_s cn; */
-};
-
-/**
- * Structure nix_cint_hw_s
- *
- * NIX Completion Interrupt Context Hardware Structure
- * This structure contains context state maintained by hardware for each
- * completion interrupt (CINT) in NDC/LLC/DRAM. Software accesses this structure
- * with the NIX_LF_CINT()* registers.
- * Hardware maintains a table of NIX_AF_CONST2[CINTS] contiguous NIX_CINT_HW_S
- * structures per LF starting at AF IOVA NIX_AF_LF()_CINTS_BASE.
- * Always stored in byte invariant little-endian format (LE8).
- */
-union cavm_nix_cint_hw_s {
-	u64 u[2];
-	struct cavm_nix_cint_hw_s_s {
-		u64 ecount:32;	     /**< [ 31:  0] Entry count. See NIX_LF_CINT()_CNT[ECOUNT]. */
-		u64 qcount:16;	     /**< [ 47: 32] Active queue count. See NIX_LF_CINT()_CNT[QCOUNT]. */
-		u64 intr:1;	     /**< [ 48: 48] Interrupt status. See also NIX_LF_CINT()_INT and NIX_LF_CINT()_INT_W1S. */
-		u64 ena:1;		     /**< [ 49: 49] Interrupt enable. See also NIX_LF_CINT()_ENA_W1S and
-                                                                 NIX_LF_CINT()_ENA_W1C. */
-		u64 timer_idx:8;	     /**< [ 57: 50] Timer index of NIX_AF_CINT_TIMER(). Select the TIMER for the CINT. */
-		u64 reserved_58_63:6;
-		u64 ecount_wait:32;	/**< [ 95: 64] Entry count hold-off. See NIX_LF_CINT()_WAIT[ECOUNT_WAIT]. */
-		u64 qcount_wait:16;	/**< [111: 96] Active queue count hold-off. See NIX_LF_CINT()_WAIT[QCOUNT_WAIT]. */
-		u64 time_wait:8;	     /**< [119:112] Time hold-off. See NIX_LF_CINT()_WAIT[TIME_WAIT]. */
-		u64 reserved_120_127:8;
-	} s;
-	/* struct cavm_nix_cint_hw_s_s cn; */
-};
-
-/**
- * Structure nix_cq_ctx_s
- *
- * NIX Completion Queue Context Structure
- * This structure contains context state maintained by hardware for each CQ in
- * NDC/LLC/DRAM.
- * Software uses the same structure format to read and write an CQ context with
- * the NIX admin queue.
- */
-union cavm_nix_cq_ctx_s {
-	u64 u[4];
-	struct cavm_nix_cq_ctx_s_s {
-		u64 base:64;	     /**< [ 63:  0] Base LF IOVA of CQ ring in LLC/DRAM.
-
-                                                                 Bits \<8:0\> must be zero; address must be 512-byte aligned.
-                                                                 Bits \<63:53\> are ignored by hardware; software should use a sign-extended
-                                                                 bit \<52\> for forward compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-		u64 qsize:4;	     /**< [ 67: 64] Specifies CQ ring size in number of CQEs:
-                                                                 0x0 = 16 CQEs.
-                                                                 0x1 = 64 CQEs.
-                                                                 0x2 = 256 CQEs.
-                                                                 0x3 = 1K CQEs.
-                                                                 0x4 = 4K CQEs.
-                                                                 0x5 = 16K CQEs.
-                                                                 0x6 = 64K CQEs.
-                                                                 0x7 = 256K CQEs.
-                                                                 0x8 = 1M CQEs.
-                                                                 0x9-0xF = Reserved.
-
-                                                                 The CQE size is selected by NIX_AF_LF()_CFG[XQE_SIZE].
-
-                                                                 Note that the usable size of the ring is the specified size minus one
-                                                                 ([HEAD]==[TAIL] always means empty). */
-		u64 drop_ena:1;	     /**< [ 68: 68] Enable RQ packet DROP based on the [DROP] level. */
-		u64 reserved_69_71:3;
-		u64 drop:8;	     /**< [ 79: 72] If [DROP_ENA] is set for a received packet, the packet will be
-                                                                 dropped if the current 8-bit shifted count is less than or equal to this
-                                                                 value.
-                                                                 See shifted_CNT in [AVG_CON]. */
-		u64 ena:1;		     /**< [ 80: 80] CQ enable. */
-		u64 reserved_81_83:3;
-		u64 qint_idx:7;	     /**< [ 90: 84] Error queue interrupt index. Select the QINT within LF (index {a} of
-                                                                 NIX_LF_QINT()*) which receives [CQ_ERR_INT] events.
-
-                                                                 Internal:
-                                                                 See QINT message generation note in NIX_RQ_CTX_S[QINT_IDX]. */
-		u64 cq_err:1;	     /**< [ 91: 91] CQ error. Set along with the NIX_CQERRINT_E::WR_FULL bit in [CQ_ERR_INT]
-                                                                 when the corresponding error is detected for a transmit CQE. The CQ is
-                                                                 stopped and all new CQEs to be added to it are dropped. */
-		u64 cint_idx:7;	     /**< [ 98: 92] Completion interrupt index. Select the CINT within LF (index {a} of
-                                                                 NIX_LF_CINT()*) which receives completion events for
-                                                                 this CQ. */
-		u64 avg_con:9;	     /**< [107: 99] This value controls how much of the present average resource level is used
-                                                                 to calculate the new resource level. The value is a number from zero to 256,
-                                                                 which represents [AVG_CON]/256 of the average resource level that will be
-                                                                 used in the calculation.
-
-                                                                 NIX updates the average resource level as follows whenever the immediate resource
-                                                                 count changes:
-
-                                                                 \<pre\>
-                                                                 // Eight-bit shifted count (1/256 units of queue size); higher count
-                                                                 // indicates more free resources:
-                                                                 if ([QSIZE] \>= 2) {
-                                                                   shifted_CNT = 255 - ((([TAIL] - [HEAD]) \>\> (2 * ([QSIZE] - 2))) % 256);
-                                                                 } else {
-                                                                   shifted_CNT = 255 - ((([TAIL] - [HEAD]) \<\< (2 * (2 - [QSIZE]))) % 256);
-                                                                 }
-                                                                 adjusted_CON = [AVG_CON] \>\> ceil(log2(NIX_AF_AVG_DELAY[AVG_TIMER] - [UPDATE_TIME]));
-                                                                 [AVG_LEVEL] = (adjusted_CON * [AVG_LEVEL] + (256 - adjusted_CON)
-                                                                               * shifted_CNT) / 256;
-                                                                 [UPDATE_TIME] = NIX_AF_AVG_DELAY[AVG_TIMER];
-                                                                 \</pre\>
-
-                                                                 Note setting this value to zero will disable averaging, and always use the most
-                                                                 immediate levels. NIX_AF_AVG_DELAY[AVG_DLY] controls the periodicity of the level
-                                                                 calculations. */
-		u64 wrptr:20;	     /**< [127:108] Internal pointer for writing to the CQ ring. */
-		u64 tail:20;	     /**< [147:128] Tail CQE pointer.
-                                                                 Hardware advances [TAIL] when an entry written to the CQ is committed and
-                                                                 visible to software.
-                                                                 The tail LF IOVA is [BASE] + ([TAIL] * 512) when NIX_AF_LF()_CFG[XQE_SIZE] = NIX_XQESZ_E::W64,
-                                                                 [BASE] + ([TAIL] * 128) when NIX_AF_LF()_CFG[XQE_SIZE] = NIX_XQESZ_E::W16. */
-		u64 head:20;	     /**< [167:148] Head CQE pointer.
-                                                                 Hardware advances [HEAD] when software writes to NIX_LF_CQ_OP_DOOR for
-                                                                 this CQ.
-                                                                 The head LF IOVA is [BASE] + ([HEAD] * 512) when NIX_AF_LF()_CFG[XQE_SIZE] = NIX_XQESZ_E::W64,
-                                                                 [BASE] + ([HEAD] * 128) when NIX_AF_LF()_CFG[XQE_SIZE] = NIX_XQESZ_E::W16. */
-		u64 avg_level:8;	     /**< [175:168] Current moving average of the eight-bit shifted count. The higher [AVG_LEVEL]
-                                                                 is, the more free resources. The lower levels indicate buffer exhaustion.
-                                                                 See [AVG_CON].
-
-                                                                 NIX uses [AVG_LEVEL] in receive queue QOS calculations. See
-                                                                 NIX_RQ_CTX_S[XQE_DROP]. */
-		u64 update_time:16;	/**< [191:176] NIX_AF_AVG_DELAY[AVG_TIMER] value captured when [AVG_LEVEL] is updated. */
-		u64 bp:8;		     /**< [199:192] Backpressure is asserted if [BP_ENA] bit is set and the current eight-bit
-                                                                 shifted count is less than or equal to this value.
-                                                                 See shifted_CNT in [AVG_CON]. */
-		u64 bpid:9;	     /**< [208:200] Backpressure ID (index {a} of NIX_AF_RX_BPID()_STATUS) to which
-                                                                 backpressure is asserted when [BP_ENA] bit is set. */
-		u64 bp_ena:1;	     /**< [209:209] Enable CQ backpressure based on [BP] level. */
-		u64 reserved_210_211:2;
-		u64 substream:20;	     /**< [231:212] Substream ID used for writing CQEs to the CQ ring. When zero, no substream ID is used. */
-		u64 caching:1;	     /**< [232:232] Selects the style of CQE write to the LLC.
-                                                                 0 = Writes of CQE data will not allocate into the LLC.
-                                                                 1 = Writes of CQE data are allocated into the LLC. */
-		u64 reserved_233_239:7;
-		u64 cq_err_int:8;	     /**< [247:240] Error interrupts. Bits enumerated by NIX_CQERRINT_E, which also defines when
-                                                                 hardware sets each bit. Software can read, set or clear these bits with
-                                                                 NIX_LF_CQ_OP_INT. */
-		u64 cq_err_int_ena:8;	/**< [255:248] Error interrupt enables. Bits enumerated by NIX_CQERRINT_E. Software can read,
-                                                                 set or clear these bits with NIX_LF_CQ_OP_INT. */
-	} s;
-	/* struct cavm_nix_cq_ctx_s_s cn; */
-};
-
-/**
- * Structure nix_cqe_hdr_s
- *
- * NIX Completion Queue Entry Header Structure
- * This 64-bit structure defines the first word of every CQE. It is immediately
- * followed by NIX_RX_PARSE_S in a receive CQE, and by NIX_SEND_COMP_S in a send
- * completion CQE.
- * Stored in memory as little-endian unless NIX_AF_LF()_CFG[BE] is set.
- */
-union cavm_nix_cqe_hdr_s {
-	u64 u;
-	struct cavm_nix_cqe_hdr_s_s {
-		u64 tag:32;	     /**< [ 31:  0] Tag computed for the RX packet. Valid for receive descriptor only.
-                                                                 See pseudocode in NIX_RQ_CTX_S[LTAG]. */
-		u64 q:20;		     /**< [ 51: 32] RQ or SQ within VF/PF. */
-		u64 reserved_52_57:6;
-		u64 node:2;	     /**< [ 59: 58] Node number on which the packet was received or transmitted.
-                                                                 Internal:
-                                                                 This is needed by software; do not remove on single-node parts. */
-		u64 cqe_type:4;	     /**< [ 63: 60] Completion queue entry type. Enumerated by NIX_XQE_TYPE_E. */
-	} s;
-	/* struct cavm_nix_cqe_hdr_s_s cn; */
-};
-
-/**
- * Structure nix_inst_hdr_s
- *
- * NIX Instruction Header Structure
- * This structure defines the instruction header that precedes the packet header
- * supplied to NPC for packets to be transmitted by NIX.
- */
-union cavm_nix_inst_hdr_s {
-	u64 u;
-	struct cavm_nix_inst_hdr_s_s {
-		u64 pf_func:16;	     /**< [ 15:  0] PF and function transmitting the packet. Format specified by
-                                                                 RVU_PF_FUNC_S. */
-		u64 sq:20;		     /**< [ 35: 16] Send queue within [PF_FUNC]. */
-		u64 reserved_36_63:28;
-	} s;
-	/* struct cavm_nix_inst_hdr_s_s cn; */
-};
-
-/**
- * Structure nix_iova_s
- *
- * NIX I/O Virtual Address Structure
- */
-union cavm_nix_iova_s {
-	u64 u;
-	struct cavm_nix_iova_s_s {
-		u64 addr:64;	     /**< [ 63:  0] I/O virtual address. Bits \<63:53\> are ignored by hardware; software should use a
-                                                                 sign-extended bit \<52\> for forward compatibility. */
-	} s;
-	/* struct cavm_nix_iova_s_s cn; */
-};
-
-/**
- * Structure nix_mem_result_s
- *
- * NIX Memory Value Structure
- * When NIX_SEND_MEM_S[ALG]=NIX_SENDMEMALG_E::SETRSLT, the value written to memory is formed with
- * this structure.
- */
-union cavm_nix_mem_result_s {
-	u64 u;
-	struct cavm_nix_mem_result_s_s {
-		u64 v:1;		     /**< [  0:  0] Valid. Always set by hardware so software can distinguish from data that was (presumed to
-                                                                 be) zeroed by software before the send operation. */
-		u64 color:2;	     /**< [  2:  1] Final color of the packet. Enumerated by NIX_COLORRESULT_E. */
-		u64 reserved_3_63:61;
-	} s;
-	/* struct cavm_nix_mem_result_s_s cn; */
-};
-
-/**
- * Structure nix_op_q_wdata_s
- *
- * NIX Statistics Operation Write Data Structure
- * This structure specifies the write data format of an atomic 64-bit load-and-add
- * of some NIX_LF_RQ_OP_*, NIX_LF_SQ_OP* and NIX_LF_CQ_OP* registers.
- */
-union cavm_nix_op_q_wdata_s {
-	u64 u;
-	struct cavm_nix_op_q_wdata_s_s {
-		u64 reserved_0_31:32;
-		u64 q:20;		     /**< [ 51: 32] Queue within LF (RQ, SQ or CQ). */
-		u64 reserved_52_63:12;
-	} s;
-	/* struct cavm_nix_op_q_wdata_s_s cn; */
-};
-
-/**
- * Structure nix_qint_hw_s
- *
- * NIX Queue Interrupt Context Hardware Structure
- * This structure contains context state maintained by hardware for each queue
- * interrupt (QINT) in NDC/LLC/DRAM. Software accesses this structure with the
- * NIX_LF_QINT()* registers.
- * Hardware maintains a table of NIX_AF_CONST2[QINTS] contiguous NIX_QINT_HW_S
- * structures per LF starting at IOVA NIX_AF_LF()_QINTS_BASE.
- * Always stored in byte invariant little-endian format (LE8).
- */
-union cavm_nix_qint_hw_s {
-	uint32_t u;
-	struct cavm_nix_qint_hw_s_s {
-		uint32_t count:22;	     /**< [ 21:  0] Interrupt count. See NIX_LF_QINT()_CNT[COUNT]. */
-		uint32_t reserved_22_30:9;
-		uint32_t ena:1;		     /**< [ 31: 31] Interrupt enable. See also NIX_LF_QINT()_ENA_W1S[INTR] and
-                                                                 NIX_LF_QINT()_ENA_W1C[INTR]. */
-	} s;
-	/* struct cavm_nix_qint_hw_s_s cn; */
-};
-
-/**
- * Structure nix_rq_ctx_hw_s
- *
- * NIX Receive Queue Context Structure
- * This structure contains context state maintained by hardware for each RQ in
- * NDC/LLC/DRAM. Software uses the equivalent NIX_RQ_CTX_S structure format to
- * read and write an RQ context with the NIX admin queue.
- * Always stored in byte invariant little-endian format (LE8).
- */
-union cavm_nix_rq_ctx_hw_s {
-	u64 u[16];
-	struct cavm_nix_rq_ctx_hw_s_s {
-		u64 ena:1;		     /**< [  0:  0] See NIX_RQ_CTX_S[ENA]. */
-		u64 sso_ena:1;	     /**< [  1:  1] See NIX_RQ_CTX_S[SSO_ENA]. */
-		u64 ipsech_ena:1;	     /**< [  2:  2] See NIX_RQ_CTX_S[IPSECH_ENA]. */
-		u64 ena_wqwd:1;	     /**< [  3:  3] See NIX_RQ_CTX_S[ENA_WQWD]. */
-		u64 cq:20;		     /**< [ 23:  4] See NIX_RQ_CTX_S[CQ]. */
-		u64 substream:20;	     /**< [ 43: 24] See NIX_RQ_CTX_S[SUBSTREAM]. */
-		u64 wqe_aura:20;	     /**< [ 63: 44] See NIX_RQ_CTX_S[WQE_AURA]. */
-		u64 spb_aura:20;	     /**< [ 83: 64] See NIX_RQ_CTX_S[SPB_AURA]. */
-		u64 lpb_aura:20;	     /**< [103: 84] See NIX_RQ_CTX_S[LPB_AURA]. */
-		u64 sso_grp:10;	     /**< [113:104] See NIX_RQ_CTX_S[SSO_GRP]. */
-		u64 sso_tt:2;	     /**< [115:114] See NIX_RQ_CTX_S[SSO_TT]. */
-		u64 pb_caching:2;	     /**< [117:116] See NIX_RQ_CTX_S[PB_CACHING]. */
-		u64 wqe_caching:1;	     /**< [118:118] See NIX_RQ_CTX_S[WQE_CACHING]. */
-		u64 xqe_drop_ena:1;	/**< [119:119] See NIX_RQ_CTX_S[XQE_DROP_ENA]. */
-		u64 spb_drop_ena:1;	/**< [120:120] See NIX_RQ_CTX_S[SPB_DROP_ENA]. */
-		u64 lpb_drop_ena:1;	/**< [121:121] See NIX_RQ_CTX_S[LPB_DROP_ENA]. */
-		u64 wqe_skip:2;	     /**< [123:122] See NIX_RQ_CTX_S[WQE_SKIP]. */
-		u64 reserved_124_127:4;
-		u64 reserved_128_139:12;
-		u64 spb_sizem1:6;	     /**< [145:140] See NIX_RQ_CTX_S[SPB_SIZEM1]. */
-		u64 reserved_146_150:5;
-		u64 spb_ena:1;	     /**< [151:151] See NIX_RQ_CTX_S[SPB_ENA]. */
-		u64 lpb_sizem1:12;	     /**< [163:152] See NIX_RQ_CTX_S[LPB_SIZEM1]. */
-		u64 first_skip:7;	     /**< [170:164] See NIX_RQ_CTX_S[FIRST_SKIP]. */
-		u64 reserved_171:1;
-		u64 later_skip:6;	     /**< [177:172] See NIX_RQ_CTX_S[LATER_SKIP]. */
-		u64 xqe_imm_size:6;	/**< [183:178] See NIX_RQ_CTX_S[XQE_IMM_SIZE]. */
-		u64 reserved_184_189:6;
-		u64 xqe_imm_copy:1;	/**< [190:190] See NIX_RQ_CTX_S[XQE_IMM_COPY]. */
-		u64 xqe_hdr_split:1;	/**< [191:191] See NIX_RQ_CTX_S[XQE_HDR_SPLIT]. */
-		u64 xqe_drop:8;	     /**< [199:192] See NIX_RQ_CTX_S[XQE_DROP]. */
-		u64 xqe_pass:8;	     /**< [207:200] See NIX_RQ_CTX_S[XQE_PASS]. */
-		u64 wqe_pool_drop:8;	/**< [215:208] See NIX_RQ_CTX_S[WQE_POOL_DROP]. */
-		u64 wqe_pool_pass:8;	/**< [223:216] See NIX_RQ_CTX_S[WQE_POOL_PASS]. */
-		u64 spb_aura_drop:8;	/**< [231:224] See NIX_RQ_CTX_S[SPB_AURA_DROP]. */
-		u64 spb_aura_pass:8;	/**< [239:232] See NIX_RQ_CTX_S[SPB_AURA_PASS]. */
-		u64 spb_pool_drop:8;	/**< [247:240] See NIX_RQ_CTX_S[SPB_POOL_DROP]. */
-		u64 spb_pool_pass:8;	/**< [255:248] See NIX_RQ_CTX_S[SPB_POOL_PASS]. */
-		u64 lpb_aura_drop:8;	/**< [263:256] See NIX_RQ_CTX_S[LPB_AURA_DROP]. */
-		u64 lpb_aura_pass:8;	/**< [271:264] See NIX_RQ_CTX_S[LPB_AURA_PASS]. */
-		u64 lpb_pool_drop:8;	/**< [279:272] See NIX_RQ_CTX_S[LPB_POOL_DROP]. */
-		u64 lpb_pool_pass:8;	/**< [287:280] See NIX_RQ_CTX_S[LPB_POOL_PASS]. */
-		u64 reserved_288_319:32;
-		u64 ltag:24;	     /**< [343:320] See NIX_RQ_CTX_S[LTAG]. */
-		u64 good_utag:8;	     /**< [351:344] See NIX_RQ_CTX_S[GOOD_UTAG]. */
-		u64 bad_utag:8;	     /**< [359:352] See NIX_RQ_CTX_S[BAD_UTAG]. */
-		u64 flow_tagw:6;	     /**< [365:360] See NIX_RQ_CTX_S[FLOW_TAGW]. */
-		u64 reserved_366_383:18;
-		u64 octs:48;	     /**< [431:384] See NIX_RQ_CTX_S[OCTS]. */
-		u64 reserved_432_447:16;
-		u64 pkts:48;	     /**< [495:448] See NIX_RQ_CTX_S[PKTS]. */
-		u64 reserved_496_511:16;
-		u64 drop_octs:48;	     /**< [559:512] See NIX_RQ_CTX_S[DROP_OCTS]. */
-		u64 reserved_560_575:16;
-		u64 drop_pkts:48;	     /**< [623:576] See NIX_RQ_CTX_S[DROP_PKTS]. */
-		u64 reserved_624_639:16;
-		u64 re_pkts:48;	     /**< [687:640] See NIX_RQ_CTX_S[RE_PKTS]. */
-		u64 reserved_688_702:15;
-		u64 ena_copy:1;	     /**< [703:703] See NIX_RQ_CTX_S[ENA] */
-		u64 reserved_704_739:36;
-		u64 rq_int:8;	     /**< [747:740] See NIX_RQ_CTX_S[RQ_INT]. */
-		u64 rq_int_ena:8;	     /**< [755:748] See NIX_RQ_CTX_S[RQ_INT_ENA]. */
-		u64 qint_idx:7;	     /**< [762:756] See NIX_RQ_CTX_S[QINT_IDX]. */
-		u64 reserved_763_767:5;
-		u64 reserved_768_831:64;
-		u64 reserved_832_895:64;
-		u64 reserved_896_959:64;
-		u64 reserved_960_1023:64;
-	} s;
-	/* struct cavm_nix_rq_ctx_hw_s_s cn; */
-};
-
-/**
- * Structure nix_rq_ctx_s
- *
- * NIX Receive Queue Context Structure
- * This structure specifies the format used by software to read and write an RQ context with
- * the NIX admin queue.
- */
-union cavm_nix_rq_ctx_s {
-	u64 u[16];
-	struct cavm_nix_rq_ctx_s_s {
-		u64 ena:1;		     /**< [  0:  0] RQ enable. */
-		u64 sso_ena:1;	     /**< [  1:  1] WQE enable. Selects the receive descriptor type and destination generated for the LF.
-                                                                 0 = The descriptor type is a CQE written to the CQ ring selected by NIX_RQ_CTX_S[CQ].
-                                                                 1 = The descriptor type is a WQE sent to SSO. */
-		u64 ipsech_ena:1;	     /**< [  2:  2] IPSEC hardware fast-path enable. When set along with [SSO_ENA], packets
-                                                                 with NIX_RX_ACTION_S[OP] = NIX_RX_ACTIONOP_E::UCAST_IPSEC may use the IPSEC
-                                                                 hardware fast-path subject to other packet checks. */
-		u64 ena_wqwd:1;	     /**< [  3:  3] Enable WQE with data. Not used when [SSO_ENA] is clear.
-
-                                                                 When [SSO_ENA] and [ENA_WQWD] are both set, [SPB_ENA] must be clear and the WQE is
-                                                                 written at the beginning of the packet's first buffer allocated from [LPB_AURA], and
-                                                                 the packet data starts at word offset [FIRST_SKIP] in the buffer.
-
-                                                                 When [SSO_ENA] is set and [ENA_WQWD] is clear, the WQE is written to a
-                                                                 dedicated buffer allocated from [WQE_AURA]. */
-		u64 cq:20;		     /**< [ 23:  4] Completion Queue for this SQ. */
-		u64 substream:20;	     /**< [ 43: 24] Substream ID of LF IOVA pointers allocated from [WQE_AURA,SPB_AURA,LPB_AURA].
-                                                                 When zero, no substream ID is used. */
-		u64 wqe_aura:20;	     /**< [ 63: 44] WQE aura. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] for allocating SSO
-                                                                 work-queue entry buffers.
-                                                                 Valid when [SSO_ENA] is set and [ENA_WQWD] is clear. */
-		u64 spb_aura:20;	     /**< [ 83: 64] Small packet buffer aura. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] for
-                                                                 allocating data buffers for small packets.
-                                                                 Packet data is written to WQE/CQE, SPB and/or LPBs as
-                                                                 described by the following pseudocode:
-
-                                                                 \<pre\>
-                                                                 apad = nix_calc_alignment_pad(...); // see NIX_AF_LF()_RX_CFG[DIS_APAD]
-                                                                 pkt_bytes_padded = NIX_RX_PARSE_S[PKT_LENM1] + 1 + apad;
-                                                                 spb_bytes = 8*([SPB_SIZEM1] + 1 - [FIRST_SKIP]);
-                                                                 imm_write = False;
-                                                                 spb_write = False;
-                                                                 lpb_write = False;
-
-                                                                 if ([XQE_HDR_SPLIT]) {
-                                                                    imm_bytes = min(NIX_RX_PARSE_S[EOH_PTR], 8*[XQE_IMM_SIZE]);
-                                                                 } else {
-                                                                    imm_bytes = 8*[XQE_IMM_SIZE];
-                                                                 }
-
-                                                                 if (imm_bytes == 0) {
-                                                                    if ([SPB_ENA] && (pkt_bytes_padded \<= spb_bytes)) {
-                                                                       spb_write = True;  // Write packet to an SPB
-                                                                    } else {
-                                                                       lpb_write = True;  // Write packet to one or more LPBs
-                                                                    }
-                                                                 }
-                                                                 else { // imm_bytes \> 0
-                                                                    // Write alignment pad and first imm_bytes of packet (or entire packet
-                                                                    // if smaller) to WQE/CQE.
-                                                                    imm_write = True;
-                                                                    imm_bytes_padded = imm_bytes + apad;
-
-                                                                    if ([XQE_IMM_COPY]) {
-                                                                       // Include copy of first imm_bytes in SPB or LPB.
-                                                                       if (pkt_bytes_padded \<= spb_bytes) {
-                                                                          spb_write = True;  // Write packet to an SPB
-                                                                       } else {
-                                                                          lpb_write = True;  // Write packet to one or more LPBs
-                                                                       }
-                                                                    }
-                                                                    else {
-                                                                       if (pkt_bytes_padded \<= imm_bytes_padded) {
-                                                                          ;  // No remaining packet data. Done.
-                                                                       } else if ((pkt_bytes_padded - imm_bytes_padded) \<= spb_bytes) {
-                                                                          // Write remaining packet data to an SPB
-                                                                          spb_write = True;
-                                                                       } else {
-                                                                          // Write remaining packet data to one or more LPBs
-                                                                          lpb_write = True;
-                                                                       }
-                                                                    }
-                                                                 }
-                                                                 \</pre\> */
-		u64 lpb_aura:20;	     /**< [103: 84] Large packet buffer aura. See [SPB_AURA]. */
-		u64 sso_grp:10;	     /**< [113:104] SSO group for the packet's SSO add work, and to store in NIX_WQE_HDR_S[GRP]. Valid
-                                                                 when [SSO_ENA] is set.
-                                                                 Bits \<9..8\> must be zero. */
-		u64 sso_tt:2;	     /**< [115:114] SSO tag type for the packet's SSO add work and to store in NIX_WQE_HDR_S[TT].
-                                                                 Enumerated by SSO_TT_E. Valid when [SSO_ENA] is set. */
-		u64 pb_caching:2;	     /**< [117:116] Packet buffer caching. Selects the style of packet buffer write to LLC/DRAM packet.
-                                                                 0x0 = Writes of SPB/LPB data will not allocate into the LLC.
-                                                                 0x1 = All writes of SPB/LPB data are allocated into the LLC.
-                                                                 0x2 = First aligned cache block is allocated into the LLC. All remaining cache
-                                                                 blocks are not allocated.
-                                                                 0x3 = First two aligned cache blocks are allocated into the LLC. All remaining
-                                                                 cache blocks are not allocated. */
-		u64 wqe_caching:1;	     /**< [118:118] WQE caching. Selects the style of work-queue entry write to LLC/DRAM.
-                                                                 0 = Writes of WQE data will not allocate into LLC.
-                                                                 1 = Writes of WQE data are allocated into LLC.
-
-                                                                 Valid when [SSO_ENA] is set. */
-		u64 xqe_drop_ena:1;	/**< [119:119] WQE/CQE drop enable. When [SSO_ENA] is set and [ENA_WQWD] is clear, request
-                                                                 NPA to do DROP processing on [WQE_AURA]; see NPA_AURA_S[AURA_DROP] and
-                                                                 NPA_AURA_S[POOL_DROP]. When [SSO_ENA] is clear, request CQ DROP processing;
-                                                                 see NIX_CQ_CTX_S[DROP] and NIX_CQ_CTX_S[DROP_ENA]. */
-		u64 spb_drop_ena:1;	/**< [120:120] Request NPA to do DROP processing on [SPB_AURA] if an SPB is requested.
-                                                                 See NPA_AURA_S[AURA_DROP] and NPA_AURA_S[POOL_DROP]. */
-		u64 lpb_drop_ena:1;	/**< [121:121] Request NPA to do DROP processing on [LPB_AURA] if a first LPB is requested
-                                                                 for a packet. See NPA_AURA_S[AURA_DROP] and NPA_AURA_S[POOL_DROP]. If
-                                                                 multiple LPBs are requested for a packet, DROP processing is never
-                                                                 requested for the second and subsequent LPBs. */
-		u64 reserved_122_127:6;
-		u64 reserved_128_139:12;
-		u64 spb_sizem1:6;	     /**< [145:140] Small packet buffer size minus one. The number of eight-byte words (minus one)
-                                                                 between the start of a buffer from [SPB_AURA] and the last word that NIX may
-                                                                 write into that buffer. See [SPB_AURA].
-
-                                                                 Internal:
-                                                                 Limited to 6 bits (512 bytes) to enable early SPB/LBP decision and avoid
-                                                                 store-and-forward of larger packets. */
-		u64 wqe_skip:2;	     /**< [147:146] WQE start offset. The number of 128-byte cache lines to skip from the WQE
-                                                                 buffer pointer (from [LPB_AURA] when [ENA_WQWD] is set and [WQE_AURA]
-                                                                 otherwise) to the first WQE byte stored in the buffer. */
-		u64 reserved_148_150:3;
-		u64 spb_ena:1;	     /**< [151:151] Small packet buffer enable:
-
-                                                                 0 = Do not use small packet buffers. All receive packets are stored in
-                                                                 buffers from [LPB_AURA].
-
-                                                                 1 = Use a single small packet buffer from [SPB_AURA] when a receive packet
-                                                                 fits within that buffer.
-
-                                                                 Must be clear when [ENA_WQWD] is set.
-                                                                 See [SPB_AURA]. */
-		u64 lpb_sizem1:12;	     /**< [163:152] Large packet buffer size minus one. The number of eight-byte words (minus
-                                                                 one) between the start of a buffer from [LPB_AURA] and the last word that
-                                                                 NIX may write into that buffer. Must be greater than or equal to
-                                                                 [SPB_SIZEM1] when [SPB_ENA] is set.
-
-                                                                 See [SPB_AURA]. */
-		u64 first_skip:7;	     /**< [170:164] First buffer start offset. The number of eight-byte words from the
-                                                                 [SPB_AURA] or first [LPB_AURA] buffer pointer to the first packet data byte
-                                                                 stored in the buffer. Must not be greater than [LPB_SIZEM1], and when
-                                                                 [SPB_ENA] is set not greater than [SPB_SIZEM1].
-
-                                                                 When [SSO_ENA] and [ENA_WQWD] are both set, must satisfy the following
-                                                                 to ensure that the WQE does not overlap with packet data:
-                                                                 _ wqe_size = (NIX_AF_LF()_CFG[XQE_SIZE] == NIX_XQESZ_E::W64) ? 64 : 16.
-                                                                 _ [FIRST_SKIP] \>= wqe_size + 16*[WQE_SKIP]. */
-		u64 reserved_171:1;
-		u64 later_skip:6;	     /**< [177:172] Later buffer start offset. The number of eight-byte words from the
-                                                                 [LPB_AURA] buffer pointer (other than the packet's first buffer)
-                                                                 the first byte stored in the buffer. Must not be greater than
-                                                                 [LPB_SIZEM1]. */
-		u64 xqe_imm_size:6;	/**< [183:178] WQE/CQE immediate size. Must not be greater than 32, and must be 0 when
-                                                                 NIX_AF_LF()_CFG[XQE_SIZE] = NIX_XQESZ_E::W16.
-
-                                                                 When nonzero, the maximum number of starting eight-byte words of immediate
-                                                                 packet data written with NIX_RX_IMM_S in the receive descriptor (CQE or
-                                                                 WQE), excluding any alignment padding before the immediate data (see
-                                                                 NIX_AF_LF()_RX_CFG[DIS_APAD] and NIX_RX_IMM_S[APAD]).
-
-                                                                 See also [XQE_HDR_SPLIT]. Remaining packet data (if any), or all packet
-                                                                 data if [XQE_IMM_COPY] is set, is written to one or more buffers from
-                                                                 [SPB_AURA] or [LPB_AURA].
-
-                                                                 When zero, packet data is not written in the WQE/CQE; all packet data is
-                                                                 written to buffers from [SPB_AURA] or [LPB_AURA].
-
-                                                                 See pseudocode in [SPB_AURA]. */
-		u64 reserved_184_189:6;
-		u64 xqe_imm_copy:1;	/**< [190:190] WQE/CQE immediate data copy. When set, all packet data is written to one or
-                                                                 more buffers from [SPB_AURA] or [LPB_AURA], and initial data bytes,
-                                                                 including initial data bytes written to the WQE/CQE, if any. See also
-                                                                 [XQE_IMM_SIZE] and [XQE_HDR_SPLIT]. */
-		u64 xqe_hdr_split:1;	/**< [191:191] WQE/CQE header split.
-
-                                                                 0 = The first 8*[XQE_IMM_SIZE] bytes (or all bytes if the packet is smaller) are
-                                                                 written to the WQE/CQE irrespective of the parsed header size.
-
-                                                                 1 = Only parsed header bytes (first NIX_RX_PARSE_S[EOH_PTR] bytes of packet) may
-                                                                 be written to the WQE/CQE. The actual number of header bytes written to WQE/CQE
-                                                                 is the smaller of NIX_RX_PARSE_S[EOH_PTR] or 8*[XQE_IMM_SIZE]. */
-		u64 reserved_315_319:5;
-		u64 qint_idx:7;	     /**< [314:308] Queue interrupt index. Select the QINT within LF (index {a} of
-                                                                 NIX_LF_QINT()*) which receives [RQ_INT] events.
-
-                                                                 Internal:
-                                                                 QINT update message is generated on an interrupt update event or when [ENA]
-                                                                 changes. Message op code (INCR/DECR/NOP) is based on current and next
-                                                                 interrupt states:
-                                                                 _ [ENA] && |([RQ_INT] & [RQ_INT_ENA]) */
-		u64 rq_int_ena:8;	     /**< [307:300] RQ interrupt enables. Bits enumerated by NIX_RQINT_E. */
-		u64 rq_int:8;	     /**< [299:292] RQ interrupts. Bits enumerated by NIX_RQINT_E. */
-		u64 reserved_288_291:4;
-		u64 lpb_pool_pass:8;	/**< [287:280] [LPB_AURA]'s average pool level pass threshold for RED.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-		u64 lpb_pool_drop:8;	/**< [279:272] [LPB_AURA]'s average pool level drop threshold for RED.
-
-                                                                 Must be less than or equal to [LPB_POOL_PASS]. Software can set
-                                                                 [LPB_POOL_DROP] = [LPB_POOL_PASS] = 0 to disable this level check in the RQ
-                                                                 RED algorithm.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-		u64 lpb_aura_pass:8;	/**< [271:264] [LPB_AURA]'s average aura level pass threshold for RED.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-		u64 lpb_aura_drop:8;	/**< [263:256] [LPB_AURA]'s average aura level drop threshold for RED.
-
-                                                                 Must be less than or equal to [LPB_AURA_PASS]. Software can set
-                                                                 [LPB_AURA_DROP] = [LPB_AURA_PASS] = 0 to disable this level check in the RQ
-                                                                 RED algorithm.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-#else /* Word 4 - Little Endian */
-u64 lpb_aura_drop:8;			/**< [263:256] [LPB_AURA]'s average aura level drop threshold for RED.
-
-                                                                 Must be less than or equal to [LPB_AURA_PASS]. Software can set
-                                                                 [LPB_AURA_DROP] = [LPB_AURA_PASS] = 0 to disable this level check in the RQ
-                                                                 RED algorithm.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-u64 lpb_aura_pass:8;			/**< [271:264] [LPB_AURA]'s average aura level pass threshold for RED.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-u64 lpb_pool_drop:8;			/**< [279:272] [LPB_AURA]'s average pool level drop threshold for RED.
-
-                                                                 Must be less than or equal to [LPB_POOL_PASS]. Software can set
-                                                                 [LPB_POOL_DROP] = [LPB_POOL_PASS] = 0 to disable this level check in the RQ
-                                                                 RED algorithm.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-u64 lpb_pool_pass:8;			/**< [287:280] [LPB_AURA]'s average pool level pass threshold for RED.
-
-                                                                 See RQ RED algorithm pseudocode in [XQE_DROP]. */
-u64 reserved_288_291:4;
-u64 rq_int:8;			     /**< [299:292] RQ interrupts. Bits enumerated by NIX_RQINT_E. */
-u64 rq_int_ena:8;			     /**< [307:300] RQ interrupt enables. Bits enumerated by NIX_RQINT_E. */
-u64 qint_idx:7;			     /**< [314:308] Queue interrupt index. Select the QINT within LF (index {a} of
-                                                                 NIX_LF_QINT()*) which receives [RQ_INT] events.
-
-                                                                 Internal:
-                                                                 QINT update message is generated on an interrupt update event or when [ENA]
-                                                                 changes. Message op code (INCR/DECR/NOP) is based on current and next
-                                                                 interrupt states:
-                                                                 _ [ENA] && |([RQ_INT] & [RQ_INT_ENA]) */
-u64 reserved_315_319:5;
-u64 ltag:24;			     /**< [343:320] Lower WQE/CQE tag bits for a non-IPSEC receive packet, conditionally
-                                                                 selected by [FLOW_TAGW].
-
-                                                                 Pseudocode:
-                                                                 \<pre\>
-                                                                 rq_tag\<31:24\> = (NIX_RX_PARSE_S[ERRLEV] == 0 && NIX_RX_PARSE_S[ERRCODE] == 0)
-                                                                      ? [GOOD_UTAG] : [BAD_UTAG];
-                                                                 rq_tag\<23:0\> = [LTAG];
-                                                                 flow_tag_mask\<31:0\> = (1 \<\< [FLOW_TAGW]) - 1;
-                                                                 xqe_type = [SSO_ENA] ? NIX_WQE_HDR_S[WQE_TYPE] ? NIX_CQE_HDR_S[CQE_TYPE];
-
-                                                                 if ((xqe_type == NIX_XQE_TYPE_E::RX)
-                                                                     || (xqe_type == NIX_XQE_TYPE_E::RX_IPSECS))
-                                                                 {
-                                                                    // flow_tag\<31:0\> computation is defined in NIX_LF_RX_SECRET()
-                                                                    tag\<31:0\> = (~flow_tag_mask & rq_tag) | (flow_tag_mask & flow_tag);
-                                                                    if ([SSO_ENA]) NIX_WQE_HDR_S[TAG] = tag;
-                                                                    else           NIX_CQE_HDR_S[TAG] = tag;
-                                                                 }
-                                                                 else { // NIX_XQE_TYPE_E::RX_IPSECH or IPSECD, only valid when [SSO_ENA]==1
-                                                                    // SA_index computation is defined in NIX_AF_LF()_RX_IPSEC_CFG1[SA_IDX_W]
-                                                                    NIX_WQE_HDR_S[TAG] = SA_index | (NIX_AF_LF()_RX_IPSEC_CFG1[TAG_CONST] \<\< 8);
-                                                                 }
-                                                                 \</pre\> */
-u64 good_utag:8;			     /**< [351:344] Upper WQE/CQE tag bits for a non-IPSEC packet received without error,
-                                                                 conditionally selected by [FLOW_TAGW].
-                                                                 See pseudocode in [LTAG]. */
-u64 bad_utag:8;			     /**< [359:352] Upper WQE/CQE tag bits for a non-IPSEC packet received with error,
-                                                                 conditionally selected by [FLOW_TAGW].
-                                                                 See pseudocode in [LTAG]. */
-u64 flow_tagw:6;			     /**< [365:360] Flow tag width. Number of lower bits of WQE/CQE tag taken from packet's
-                                                                 flow_tag (see NIX_LF_RX_SECRET()). When greater than or equal to 32, the
-                                                                 WQE/CQE tag equals flow_tag.
-                                                                 See pseudocode in [LTAG]. */
-u64 reserved_366_383:18;
-u64 octs:48;			     /**< [431:384] Number of nondropped octets received (good and bad). Includes any
-                                                                 timestamps, RX headers, Vtag bytes stripped by
-                                                                 NIX_AF_LF()_RX_VTAG_TYPE()[STRIP], and frame minimum size pad bytes.
-                                                                 Excludes FCS stripped by CGX. */
-u64 reserved_432_447:16;
-u64 pkts:48;			     /**< [495:448] Number of nondropped packets received (good and bad). */
-u64 reserved_496_511:16;
-u64 drop_octs:48;			     /**< [559:512] Number of octets dropped. See also [OCTS]. */
-u64 reserved_560_575:16;
-u64 drop_pkts:48;			     /**< [623:576] Number of packets dropped. */
-u64 reserved_624_639:16;
-u64 re_pkts:48;			     /**< [687:640] Number of nondropped packets with receive errors (NIX_RX_PARSE_S[ERRLEV] =
-                                                                 NPC_ERRLEV_E::RE). */
-u64 reserved_688_703:16;
-u64 reserved_704_767:64;
-u64 reserved_768_831:64;
-u64 reserved_832_895:64;
-u64 reserved_896_959:64;
-u64 reserved_960_1023:64;
-}
-
-s;
-	/* struct cavm_nix_rq_ctx_s_s cn; */
-};
-
-/**
- * Structure nix_rsse_hw_s
- *
- * INTERNAL: NIX Receive Side Scaling Entry Structure
- */
-union cavm_nix_rsse_hw_s {
-	uint32_t u;
-	struct cavm_nix_rsse_hw_s_s {
-		uint32_t rq:20;		     /**< [ 19:  0] See NIX_RSSE_S[RQ]. */
-		uint32_t reserved_20_31:12;
-	} s;
-	/* struct cavm_nix_rsse_hw_s_s cn; */
-};
-
-/**
- * Structure nix_rsse_s
- *
- * NIX Receive Side Scaling Entry Structure
- * This structure specifies the format of each hardware entry in the NIX RSS
- * tables in NDC/LLC/DRAM. See NIX_AF_LF()_RSS_BASE and NIX_AF_LF()_RSS_GRP().
- * Software uses the same structure format to read and write an RSS table entry
- * with the NIX admin queue.
- */
-union cavm_nix_rsse_s {
-	uint32_t u;
-	struct cavm_nix_rsse_s_s {
-		uint32_t rq:20;		     /**< [ 19:  0] Receive queue index within LF to which the packet is directed. */
-		uint32_t reserved_20_31:12;
-	} s;
-	/* struct cavm_nix_rsse_s_s cn; */
-};
-
-/**
- * Structure nix_rx_action_s
- *
- * NIX Receive Action Structure
- * This structure defines the format of NPC_RESULT_S[ACTION] for a receive packet.
- */
-union cavm_nix_rx_action_s {
-	u64 u;
-	struct cavm_nix_rx_action_s_s {
-		u64 op:4;		     /**< [  3:  0] Action op code enumerated by NIX_RX_ACTIONOP_E. */
-		u64 pf_func:16;	     /**< [ 19:  4] PF and function to which the packet is directed if unicast.
-                                                                 Format specified by RVU_PF_FUNC_S. Not meaningful when
-                                                                 [OP] = NIX_RX_ACTIONOP_E::MCAST or NIX_RX_ACTIONOP_E::MIRROR. */
-		u64 index:20;	     /**< [ 39: 20] Receive queue or table index in NIX. The index type
-                                                                 is selected as follows:
-                                                                 _ if [OP] = NIX_RX_ACTIONOP_E::UCAST or NIX_RX_ACTIONOP_E::UCAST_IPSEC, RQ
-                                                                 index within [PF_FUNC].
-                                                                 _ if [OP] = NIX_RX_ACTIONOP_E::RSS, RSS group index within [PF_FUNC].
-                                                                 _ if [OP] = NIX_RX_ACTIONOP_E::MCAST, index of first NIX_RX_MCE_S of the
-                                                                 multicast replication list in the NIX RX multicast/mirror table.
-                                                                 _ if [OP] = NIX_RX_ACTIONOP_E::MIRROR, index of first NIX_RX_MCE_S of the
-                                                                 mirror replication list in the NIX RX multicast/mirror table.
-                                                                 _ otherwise, not used. */
-		u64 match_id:16;	     /**< [ 55: 40] Software defined match identifier. */
-		u64 flow_key_alg:5;	/**< [ 60: 56] Flow key algorithm. Index {a} (ALG) of NIX_AF_RX_FLOW_KEY_ALG()_FIELD(). */
-		u64 reserved_61_63:3;
-	} s;
-	/* struct cavm_nix_rx_action_s_s cn; */
-};
-
-/**
- * Structure nix_rx_imm_s
- *
- * NIX Receive Immediate Subdescriptor Structure
- * The receive immediate subdescriptor indicates that bytes immediately following this
- * NIX_RX_IMM_S (after skipping [APAD] bytes) were saved from the received packet. The
- * next subdescriptor following this NIX_RX_IMM_S (when one exists) will follow the
- * immediate bytes, after rounding up the address to a multiple of 16 bytes.
- */
-union cavm_nix_rx_imm_s {
-	u64 u;
-	struct cavm_nix_rx_imm_s_s {
-		u64 size:16;	     /**< [ 15:  0] Size of immediate data (in bytes) that immediately follows this 64-bit
-                                                                 structure. [SIZE] will be between 1 and 256 bytes. The next subdescriptor
-                                                                 follows [APAD]+[SIZE] bytes later in the descriptor, rounded up to the next
-                                                                 16-byte aligned address. */
-		u64 apad:3;	     /**< [ 18: 16] Alignment pad. Number of bytes to skip following this 64-bit structure before
-                                                                 the first byte of packet data. See pseudocode in NIX_AF_LF()_RX_CFG[DIS_APAD]. */
-		u64 reserved_19_59:41;
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates immediate. Enumerated by NIX_SUBDC_E::IMM. */
-	} s;
-	/* struct cavm_nix_rx_imm_s_s cn; */
-};
-
-/**
- * Structure nix_rx_mce_hw_s
- *
- * INTERNAL: NIX Receive Multicast/Mirror Entry Structure
- */
-union cavm_nix_rx_mce_hw_s {
-	u64 u;
-	struct cavm_nix_rx_mce_hw_s_s {
-		u64 op:2;		     /**< [  1:  0] See NIX_RX_MCE_S[OP]. */
-		u64 reserved_2:1;
-		u64 eol:1;		     /**< [  3:  3] See NIX_RX_MCE_S[EOL]. */
-		u64 index:20;	     /**< [ 23:  4] See NIX_RX_MCE_S[INDEX]. */
-		u64 reserved_24_31:8;
-		u64 pf_func:16;	     /**< [ 47: 32] See NIX_RX_MCE_S[PF_FUNC]. */
-		u64 next:16;	     /**< [ 63: 48] See NIX_RX_MCE_S[NEXT]. */
-	} s;
-	/* struct cavm_nix_rx_mce_hw_s_s cn; */
-};
-
-/**
- * Structure nix_rx_mce_s
- *
- * NIX Receive Multicast/Mirror Entry Structure
- * This structure specifies the format of entries in the NIX receive
- * multicast/mirror table maintained by hardware in NDC/LLC/DRAM. See
- * NIX_AF_RX_MCAST_BASE and NIX_AF_RX_MCAST_CFG. Note the table may contain both
- * multicast and mirror replication lists.
- * Software uses the same structure format to read and write a multicast/mirror
- * table entry with the NIX admin queue.
- */
-union cavm_nix_rx_mce_s {
-	u64 u;
-	struct cavm_nix_rx_mce_s_s {
-		u64 op:2;		     /**< [  1:  0] Destination type within [PF_FUNC]; enumerated by NIX_RX_MCOP_E. */
-		u64 reserved_2:1;
-		u64 eol:1;		     /**< [  3:  3] End of multicast/mirror replication list. */
-		u64 index:20;	     /**< [ 23:  4] Receive queue or RSS index within [PF_FUNC] to which the packet is directed. The
-                                                                 index type is selected as follows:
-                                                                 _ if [OP] = NIX_RX_MCOP_E::RQ, RQ index within [PF_FUNC].
-                                                                 _ if [OP] = NIX_RX_MCOP_E::RSS, RSS group index within [PF_FUNC]. */
-		u64 reserved_24_31:8;
-		u64 pf_func:16;	     /**< [ 47: 32] PF and function to which the packet is directed. Format specified by RVU_PF_FUNC_S. */
-		u64 next:16;	     /**< [ 63: 48] Index of next NIX_RX_MCE_S structure in the multicast/mirror replication
-                                                                 list. Valid when [EOL] is clear. */
-	} s;
-	/* struct cavm_nix_rx_mce_s_s cn; */
-};
-
-/**
- * Structure nix_rx_parse_s
- *
- * NIX Receive Parse Structure
- * This structure contains the receive packet parse result. It immediately follows
- * NIX_CQE_HDR_S in a receive CQE, or NIX_WQE_HDR_S in a receive WQE.
- * Stored in memory as little-endian unless NIX_AF_LF()_CFG[BE] is set.
- *
- * Header layers are always 2-byte aligned, so all header pointers in this
- * structure ([EOH_PTR], [LAPTR] through [LHPTR], [VTAG*_PTR]) are even.
- */
-union cavm_nix_rx_parse_s {
-	u64 u[7];
-	struct cavm_nix_rx_parse_s_s {
-		u64 chan:12;	     /**< [ 11:  0] The logical channel that the packet arrived from, enumerated by NIX_CHAN_E. */
-		u64 desc_sizem1:5;	     /**< [ 16: 12] Number of 128-bit words minus one in receive descriptor following NIX_RX_PARSE_S,
-                                                                 i.e. size (minus one) of all NIX_RX_IMM_S, NIX_RX_SG_S and associated immediate
-                                                                 data and IOVAs in the descriptor. */
-		u64 imm_copy:1;	     /**< [ 17: 17] The immediate data following NIX_RX_IMM_S is a copy of data appearing the
-                                                                 the segment buffers due to NIX_RQ_CTX_S[XQE_IMM_COPY] being set. */
-		u64 express:1;	     /**< [ 18: 18] Express packet.
-                                                                 0 = Normal (potentially preemptable) packet.
-                                                                 1 = Express packet. */
-		u64 wqwd:1;	     /**< [ 19: 19] WQE with data. Valid when NIX_RX_PARSE_S is included in a WQE, always clear in
-                                                                 a CQE. Value from NIX_RQ_CTX_S[ENA_WQWD]. When set, indicates that the
-                                                                 packet data starts in the same buffer as the WQE, i.e. the first NIX_IOVA_S
-                                                                 of the first NIX_RX_SG_S in the receive descriptor points to an address
-                                                                 within the WQE's buffer. */
-		u64 errlev:4;	     /**< [ 23: 20] Normally zero, but when errors are detected contains the lowest protocol layer
-                                                                 containing an error, and [ERRCODE] will indicate the precise error
-                                                                 reason. Enumerated by NPC_ERRLEV_E. */
-		u64 errcode:8;	     /**< [ 31: 24] When zero, indicates no error. When nonzero, contains opcode identifying
-                                                                 the error reason, [ERRLEV] specifies the lowest protocol layer containing
-                                                                 the eror, and software should ignore all parse information for layers
-                                                                 higher than [ERRLEV], e.g. ignore [LF*], [LG*] and [LH*] when [ERRCODE] is
-                                                                 nonzero and [ERRLEV]=NPC_ERRLEV_E::LE.
-
-                                                                 Values defined as follows:
-                                                                 * When [ERRLEV] = NPC_ERRLEV_E::RE, [ERRCODE] values are enumerated by
-                                                                 NIX_RE_OPCODE_E.
-                                                                 * When [ERRLEV] = NPC_ERRLEV_E::NIX, [ERRCODE] values are enumerated by
-                                                                 NIX_RX_PERRCODE_E.
-                                                                 * For all other [ERRLEV] values, [ERRCODE] values are software defined in
-                                                                 NPC. */
-		u64 latype:4;	     /**< [ 35: 32] Software defined layer A type from NPC_RESULT_S[LA[LTYPE]]. */
-		u64 lbtype:4;	     /**< [ 39: 36] Software defined layer B type from NPC_RESULT_S[LB[LTYPE]]. */
-		u64 lctype:4;	     /**< [ 43: 40] Software defined layer C type from NPC_RESULT_S[LC[LTYPE]]. */
-		u64 ldtype:4;	     /**< [ 47: 44] Software defined layer D type from NPC_RESULT_S[LD[LTYPE]]. */
-		u64 letype:4;	     /**< [ 51: 48] Software defined layer E type from NPC_RESULT_S[LE[LTYPE]]. */
-		u64 lftype:4;	     /**< [ 55: 52] Software defined layer F type from NPC_RESULT_S[LF[LTYPE]]. */
-		u64 lgtype:4;	     /**< [ 59: 56] Software defined layer G type from NPC_RESULT_S[LG[LTYPE]]. */
-		u64 lhtype:4;	     /**< [ 63: 60] Software defined layer H type from NPC_RESULT_S[LH[LTYPE]]. */
-		u64 pkt_lenm1:16;	     /**< [ 79: 64] Packet length in bytes minus one. Vtag bytes stripped by
-                                                                 NIX_AF_LF()_RX_VTAG_TYPE()[STRIP] are not included. */
-		u64 l2m:1;		     /**< [ 80: 80] Outer L2 multicast. See NPC_RESULT_S[L2M]. */
-		u64 l2b:1;		     /**< [ 81: 81] Outer L2 broadcast. See NPC_RESULT_S[L2B]. */
-		u64 l3m:1;		     /**< [ 82: 82] Outer IP multicast. See NPC_RESULT_S[L3M]. */
-		u64 l3b:1;		     /**< [ 83: 83] Outer IP broadcast. See NPC_RESULT_S[L3B]. */
-		u64 vtag0_valid:1;	     /**< [ 84: 84] Vtag 0 valid. Set when NPC_RESULT_S[NIX_RX_VTAG_ACTION_S[VTAG0_VALID]] and
-                                                                 corresponding NIX_AF_LF()_RX_VTAG_TYPE()[CAPTURE] are set. */
-		u64 vtag0_gone:1;	     /**< [ 85: 85] Vtag 0 gone. Valid when [VTAG0_VALID] is set. Indicates Vtag 0 was stripped from
-                                                                 the packet data. Set when corresponding
-                                                                 NIX_AF_LF()_RX_VTAG_TYPE()[CAPTURE,STRIP] are set. */
-		u64 vtag1_valid:1;	     /**< [ 86: 86] Vtag 1 valid. See [VTAG0_VALID]. */
-		u64 vtag1_gone:1;	     /**< [ 87: 87] Vtag 1 gone. See [VTAG0_GONE]. */
-		u64 pkind:6;	     /**< [ 93: 88] Port kind supplied by CGX or LBK for received packet. */
-		u64 reserved_94_95:2;
-		u64 vtag0_tci:16;	     /**< [111: 96] Vtag 0 tag control information. First two bytes of Vtag's TCI field from the
-                                                                 packet header.
-                                                                 Valid when [VTAG0_VALID] is set. */
-		u64 vtag1_tci:16;	     /**< [127:112] Vtag 1 tag control information. See [VTAG0_TCI]. */
-		u64 laflags:8;	     /**< [135:128] Software defined layer A flags from NPC_RESULT_S[LA[FLAGS]]. */
-		u64 lbflags:8;	     /**< [143:136] Software defined layer B flags from NPC_RESULT_S[LB[FLAGS]]. */
-		u64 lcflags:8;	     /**< [151:144] Software defined layer C flags from NPC_RESULT_S[LC[FLAGS]]. */
-		u64 ldflags:8;	     /**< [159:152] Software defined layer D flags from NPC_RESULT_S[LD[FLAGS]]. */
-		u64 leflags:8;	     /**< [167:160] Software defined layer E flags from NPC_RESULT_S[LE[FLAGS]]. */
-		u64 lfflags:8;	     /**< [175:168] Software defined layer F flags from NPC_RESULT_S[LF[FLAGS]]. */
-		u64 lgflags:8;	     /**< [183:176] Software defined layer G flags from NPC_RESULT_S[LG[FLAGS]]. */
-		u64 lhflags:8;	     /**< [191:184] Software defined layer H flags from NPC_RESULT_S[LH[FLAGS]]. */
-		u64 eoh_ptr:8;	     /**< [199:192] End of header pointer. Byte offset from packet start to first byte after
-                                                                 the last parsed header layer. */
-		u64 wqe_aura:20;	     /**< [219:200] WQE aura. Valid when NIX_RX_PARSE_S is included in a WQE. Not valid when
-                                                                 included in a CQE. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] from which this
-                                                                 WQE buffer was allocated. */
-		u64 pb_aura:20;	     /**< [239:220] Packet buffer aura. Valid when the receive descriptor contains at least one
-                                                                 NIX_RX_SG_S. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] from which the
-                                                                 packet buffer pointers in NIX_RX_SG_S are allocated. */
-		u64 match_id:16;	     /**< [255:240] Software defined match identifier from NIX_RX_ACTION_S[MATCH_ID]. */
-		u64 laptr:8;	     /**< [263:256] Layer A pointer. Byte offset from packet start to first byte of layer A. */
-		u64 lbptr:8;	     /**< [271:264] Layer B pointer. Byte offset from packet start to first byte of layer B. */
-		u64 lcptr:8;	     /**< [279:272] Layer C pointer. Byte offset from packet start to first byte of layer C. */
-		u64 ldptr:8;	     /**< [287:280] Layer D pointer. Byte offset from packet start to first byte of layer D. */
-		u64 leptr:8;	     /**< [295:288] Layer E pointer. Byte offset from packet start to first byte of layer E. */
-		u64 lfptr:8;	     /**< [303:296] Layer F pointer. Byte offset from packet start to first byte of layer F. */
-		u64 lgptr:8;	     /**< [311:304] Layer G pointer. Byte offset from packet start to first byte of layer G. */
-		u64 lhptr:8;	     /**< [319:312] Layer H pointer. Byte offset from packet start to first byte of layer H. */
-		u64 vtag0_ptr:8;	     /**< [327:320] Vtag 0 pointer. Byte offset from packet start to first byte of Vtag 0.
-                                                                 Valid when [VTAG0_VALID] is set. */
-		u64 vtag1_ptr:8;	     /**< [335:328] Vtag 1 pointer. See [VTAG0_PTR]. */
-		u64 flow_key_alg:5;	/**< [340:336] Flow key algorithm used to generate NIX_CQE_HDR_S[TAG]. Index {a}
-                                                                 (ALG) of NIX_AF_RX_FLOW_KEY_ALG()_FIELD(). */
-		u64 reserved_341_383:43;
-		u64 reserved_384_447:64;
-	} s;
-	/* struct cavm_nix_rx_parse_s_s cn; */
-};
-
-/**
- * Structure nix_rx_sg_s
- *
- * NIX Receive Scatter/Gather Subdescriptor Structure
- * The receive scatter/gather subdescriptor specifies one to three segments of packet data bytes.
- * There may be multiple NIX_RX_SG_Ss in each NIX receive descriptor.
- *
- * NIX_RX_SG_S is immediately followed by one NIX_IOVA_S word when [SEGS] = 1,
- * three NIX_IOVA_S words when [SEGS] \>= 2. Each NIX_IOVA_S word specifies the
- * LF IOVA of first packet data byte in the corresponding segment; first NIX_IOVA_S
- * word for segment 1, second word for segment 2, third word for segment 3. Note
- * the third word is present when [SEGS] \>= 2 but only valid when [SEGS] = 3.
- */
-union cavm_nix_rx_sg_s {
-	u64 u;
-	struct cavm_nix_rx_sg_s_s {
-		u64 seg1_size:16;	     /**< [ 15:  0] Size of segment 1 in bytes. */
-		u64 seg2_size:16;	     /**< [ 31: 16] Size of segment 2 in bytes. Valid when [SEGS] \>= 2. */
-		u64 seg3_size:16;	     /**< [ 47: 32] Size of segment 3 in bytes. Valid when [SEGS] = 3. */
-		u64 segs:2;	     /**< [ 49: 48] Number of valid segments. Must be nonzero. */
-		u64 reserved_50_59:10;
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates scatter/gather. Enumerated by NIX_SUBDC_E::SG. */
-	} s;
-	/* struct cavm_nix_rx_sg_s_s cn; */
-};
-
-/**
- * Structure nix_rx_vtag_action_s
- *
- * NIX Receive Vtag Action Structure
- * This structure defines the format of NPC_RESULT_S[VTAG_ACTION] for a receive packet.
- * It specifies up to two Vtags (e.g. C-VLAN/S-VLAN tags, 802.1BR E-TAG) for optional
- * capture and/or stripping.
- */
-union cavm_nix_rx_vtag_action_s {
-	u64 u;
-	struct cavm_nix_rx_vtag_action_s_s {
-		u64 vtag0_relptr:8;	/**< [  7:  0] Vtag 0 relative pointer. Byte offset from start of selected layer to first
-                                                                 tag 0 byte. Must be even. For example, if [VTAG0_LID] = NPC_LID_E::LB, then
-                                                                 the byte offset from packet start to the first tag 0 byte is
-                                                                 NPC_RESULT_S[LB[LPTR]] + [VTAG0_RELPTR]. */
-		u64 vtag0_lid:3;	     /**< [ 10:  8] Vtag 0 layer ID enumerated by NPC_LID_E. */
-		u64 reserved_11:1;
-		u64 vtag0_type:3;	     /**< [ 14: 12] Vtag 0 type. Index to NIX_AF_LF()_RX_VTAG_TYPE() entry for the receive
-                                                                 packet's VF/PF. The selected entry specifies the tag size and optional tag
-                                                                 strip/capture actions.
-
-                                                                 The VF/PF is specified by NIX_RX_ACTION_S[PF_FUNC] when
-                                                                 NIX_RX_ACTION_S[OP] != NIX_RX_ACTIONOP_E::MCAST or
-                                                                 NIX_RX_ACTIONOP_E::MIRROR, and by the NIX RX multicast/mirror replication
-                                                                 list entries otherwise. */
-		u64 vtag0_valid:1;	     /**< [ 15: 15] Vtag 0 valid. Remaining [VTAG0_*] fields are valid when set. */
-		u64 reserved_16_31:16;
-		u64 vtag1_relptr:8;	/**< [ 39: 32] Vtag 1 relative pointer. See [VTAG0_RELPTR]. */
-		u64 vtag1_lid:3;	     /**< [ 42: 40] Vtag 1 layer ID enumerated by NPC_LID_E. */
-		u64 reserved_43:1;
-		u64 vtag1_type:3;	     /**< [ 46: 44] Vtag 1 type. See [VTAG0_TYPE]. */
-		u64 vtag1_valid:1;	     /**< [ 47: 47] Vtag 1 valid. Remaining [VTAG1_*] fields are valid when set. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nix_rx_vtag_action_s_s cn; */
-};
-
-/**
- * Structure nix_send_comp_s
- *
- * NIX Send Completion Structure
- * This structure immediately follows NIX_CQE_HDR_S in a send completion CQE.
- */
-union cavm_nix_send_comp_s {
-	u64 u;
-	struct cavm_nix_send_comp_s_s {
-		u64 status:8;	     /**< [  7:  0] Send completion status enumerated by NIX_SEND_STATUS_E. */
-		u64 sqe_id:16;	     /**< [ 23:  8] SQE identifier from NIX_SEND_HDR_S[SQE_ID]. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nix_send_comp_s_s cn; */
-};
-
-/**
- * Structure nix_send_crc_s
- *
- * NIX Send CRC Subdescriptor Structure
- * The send CRC subdescriptor specifies a CRC calculation be performed during
- * transmission.
- * Ignored when present in a send descriptor with NIX_SEND_EXT_S[LSO] set.
- * There may be up to two NIX_SEND_CRC_Ss per send descriptor.
- *
- * NIX_SEND_CRC_S constraints:
- * * When present, NIX_SEND_CRC_S subdescriptors must precede all NIX_SEND_SG_S,
- * NIX_SEND_IMM_S and NIX_SEND_MEM_S subdescriptors in the send descriptor.
- * * NIX_SEND_CRC_S subdescriptors must follow the same order as their checksum
- * and insert regions in the packet, i.e. the checksum and insert regions of a
- * NIX_SEND_CRC_S must come after the checksum and insert regions of a preceding
- * NIX_SEND_CRC_S. There must be no overlap between any NIX_SEND_CRC_S checksum
- * and insert regions.
- * * If either NIX_SEND_HDR_S[OL4TYPE,IL4TYPE] = NIX_SENDL4TYPE_E::SCTP_CKSUM, the
- * SCTP checksum region and NIX_SEND_CRC_S insert region must not overlap, and
- * likewise the NIX_SEND_CRC_S checksum region and SCTP insert region must not
- * overlap.
- * * If either NIX_SEND_HDR_S[OL3TYPE,IL3TYPE] = NIX_SENDL3TYPE_E::IP4_CKSUM, the
- * IPv4 header checksum region and NIX_SEND_CRC_S insert region must not overlap.
- * * Any checksums inserted by NIX_SEND_HDR_S[OL3TYPE,OL4TYPE,IL3TYPE,IL4TYPE]
- * must be outside of the NIX_SEND_CRC_S checksum and insert regions.
- *
- * Hardware adjusts [START], [SIZE] and [INSERT] as needed to account for any VLAN
- * inserted by NIX_SEND_EXT_S[VLAN*] or Vtag inserted by NIX_TX_VTAG_ACTION_S.
- */
-union cavm_nix_send_crc_s {
-	u64 u[2];
-	struct cavm_nix_send_crc_s_s {
-		u64 size:16;	     /**< [ 15:  0] Length of checksum region, must not be zero. The region is contiguous in packet bytes
-                                                                 [START] through [START]+[SIZE]-1. Note that these covered packet bytes need not be
-                                                                 contiguous in LLC/DRAM -- they can straddle any number of NIX_SEND_SG_S subdescriptors. */
-		u64 start:16;	     /**< [ 31: 16] Byte position relative to the first packet byte at which to start the
-                                                                 checksum. Must be even when [ALG] = NIX_SENDCRCALG_E::ONES16. */
-		u64 insert:16;	     /**< [ 47: 32] Byte position relative to the first packet byte at which to insert the first byte of the
-                                                                 calculated CRC. NIX does not allocate bytes as it inserts the CRC result into the packet,
-                                                                 it overwrites four pre-supplied packet bytes using NIX_SEND_SG_S or NIX_SEND_IMM_S.
-                                                                 The insertion point may not be within the start/size region of this NIX_SEND_CRC_S or
-                                                                 another NIX_SEND_CRC_S. */
-		u64 reserved_48_57:10;
-		u64 alg:2;		     /**< [ 59: 58] CRC algorithm enumerated by NIX_SENDCRCALG_E. */
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates send CRC. Enumerated by NIX_SUBDC_E::CRC. */
-		u64 iv:32;		     /**< [ 95: 64] Initial value of the checksum. If [ALG] = ONES16, then only bits \<15:0\> in
-                                                                 big-endian format are valid. */
-		u64 reserved_96_127:32;
-	} s;
-	/* struct cavm_nix_send_crc_s_s cn; */
-};
-
-/**
- * Structure nix_send_ext_s
- *
- * NIX Send Extended Header Subdescriptor Structure
- * The send extended header specifies LSO, VLAN insertion, timestamp and/or
- * scheduling services on the packet. If present, it must immediately follow
- * NIX_SEND_HDR_S. All fields are assumed to be zero when this subdescriptor is not
- * present.
- */
-union cavm_nix_send_ext_s {
-	u64 u[2];
-	struct cavm_nix_send_ext_s_s {
-		u64 lso_mps:14;	     /**< [ 13:  0] When [LSO] set, maximum payload size in bytes per packet (e.g. maximum
-                                                                 TCP segment size). Must be not less than 16.
-
-                                                                 The maximum LSO packet size is [LSO_SB] + [LSO_MPS], plus optional VLAN
-                                                                 bytes inserted by [VLAN*] and Vtag bytes inserted by
-                                                                 NIX_TX_VTAG_ACTION_S. This must not exceed NIX_AF_SMQ()_CFG[MAXLEN].
-
-                                                                 The number of LSO segments is (NIX_SEND_HDR_S[TOTAL]-[LSO_SB])/[LSO_MPS]
-                                                                 rounded up to the nearest integer, and should be less than or equal to 256.
-                                                                 Otherwise, NIX will terminate the LSO send operation after 256 segments. */
-		u64 lso:1;		     /**< [ 14: 14] Large send offload. Ignored and treated as clear when
-                                                                 NIX_AF_LSO_CFG[ENABLE] is clear. When set along with
-                                                                 NIX_AF_LSO_CFG[ENABLE], the send descriptor is for one or more
-                                                                 packets of a TCP flow, and the related [LSO_*] fields are valid. */
-		u64 tstmp:1;	     /**< [ 15: 15] PTP timestamp. Ignored unless a NIX_SEND_MEM_S is present in the send
-                                                                 descriptor with NIX_SEND_MEM_S[ALG] = NIX_SENDMEMALG_E::SETTSTMP. When set,
-                                                                 hardware writes the packet's timestamp (MIO_PTP_CLOCK_HI) to LF IOVA
-                                                                 NIX_SEND_MEM_S[ADDR] when the targeted CGX LMAC transmits the packet. See
-                                                                 also NIX_SENDMEMALG_E::SETTSTMP.
-
-                                                                 If NIX_SQ_CTX_S[CQ_ENA] and software wishes to receive a CQE on timestamp
-                                                                 completion, it must set NIX_SEND_HDR_S[PNC] = 1 and NIX_SEND_MEM_S[WMEM] =
-                                                                 1.
-
-                                                                 If NIX_SQ_CTX_S[SSO_ENA] and software wishes to add work to SSO on
-                                                                 timestamp completion, it must set NIX_SEND_MEM_S[WMEM] = 1 and include
-                                                                 NIX_SEND_WORK_S in the descriptor. */
-		u64 lso_sb:8;	     /**< [ 23: 16] Start bytes when [LSO] set. Location of the start byte of the TCP message
-                                                                 payload, i.e. the size of the headers preceding the payload, excluding
-                                                                 optional VLAN bytes inserted by [VLAN*] and Vtag bytes
-                                                                 inserted by NIX_TX_VTAG_ACTION_S.
-
-                                                                 Must be nonzero and less than NIX_SEND_HDR_S[TOTAL], else the send
-                                                                 descriptor is treated as non-LSO. */
-		u64 lso_format:5;	     /**< [ 28: 24] Large send offload format. Valid when [LSO] is set and selects index {a}
-                                                                 (FORMAT) of NIX_AF_LSO_FORMAT()_FIELD(). */
-		u64 reserved_29_31:3;
-		u64 shp_chg:9;	     /**< [ 40: 32] Two's complement signed packet size adjustment. The packet size used for
-                                                                 shaper {a} (PIR_ACCUM and CIR_ACCUM) and DWRR scheduler {a} (RR_COUNT)
-                                                                 calculations at level {b} is:
-
-                                                                 _  (NIX_AF_{b}{a}_SHAPE[LENGTH_DISABLE] ? 0 : (NIX_AF_{b}{a}_MD*[LENGTH] + [SHP_CHG]))
-                                                                        + NIX_AF_{b}{a}_SHAPE[ADJUST]
-
-                                                                 where {b} = TL1, TL2, TL3, TL4, or MDQ and {a} selects one of the shapers
-                                                                 at the level selected by {b}.
-
-                                                                 [SHP_CHG] values -255 .. 255 are allowed. [SHP_CHG] value 0x100 (i.e. -256)
-                                                                 is reserved and must never be used.
-
-                                                                 [SHP_CHG] becomes NIX_AF_{b}m_MD*[ADJUST].
-
-                                                                 When [LSO] is set, hardware applies [SHP_CHG] to each LSO segment. */
-		u64 shp_dis:1;	     /**< [ 41: 41] Disables the shaper update and internal coloring algorithms used as
-                                                                 the packet traverses MDQ through TL2 shapers. [SHP_DIS]
-                                                                 has no effect on the L1 rate limiters.
-
-                                                                 When [SHP_DIS] is 0 enabled CIR and PIR counters are used and adjusted
-                                                                 per mode as the packet traverses through an enabled shaper. The
-                                                                 internal color of a packet can be any of NIX_COLORRESULT_E::GREEN,
-                                                                 NIX_COLORRESULT_E::YELLOW, NIX_COLORRESULT_E::RED_SEND, or
-                                                                 NIX_COLORRESULT_E::RED_DROP after a shaper, depending on the shaper state
-                                                                 and configuration.
-
-                                                                 When [SHP_DIS] is 1 there is no packet coloring. No shaper can change
-                                                                 the packet from its initial GREEN color. Neither the CIR nor PIR
-                                                                 counters are used nor adjusted in any shaper as this packet traverses.
-                                                                 Similar behavior to when both NIX_AF_TL*()_CIR[ENABLE] and
-                                                                 NIX_AF_TL*()_PIR[ENABLE] are clear in all traversed shapers.
-
-                                                                 See NIX_AF_TL*()_MD_DEBUG*[PIR_DIS,CIR_DIS]. When [SHP_DIS] is set,
-                                                                 NIX_AF_TL*()_MD_DEBUG*[PIR_DIS,CIR_DIS] are both set. When [SHP_DIS] is
-                                                                 clear, NIX_AF_TL*()_MD_DEBUG*[PIR_DIS,CIR_DIS] are both cleared and
-                                                                 NIX_AF_TL*()_SHAPE[YELLOW_DISABLE,RED_DISABLE] determines the packet
-                                                                 coloring of the shaper.
-
-                                                                 When [LSO] is set, hardware applies [SHP_DIS] to each LSO segment. */
-		u64 shp_ra:2;	     /**< [ 43: 42] Red algorithm. Enumerated by NIX_REDALG_E. Specifies handling of a packet that
-                                                                 traverses a RED MDQ through TL2 shaper. (A shaper is in RED state when
-                                                                 NIX_AF_TL*()_SHAPE_STATE[COLOR]=0x2.) Has no effect when the packet traverses no
-                                                                 shapers that are in the RED state. When [SHP_RA]!=STD, [SHP_RA] overrides the
-                                                                 NIX_AF_TL*()_SHAPE[RED_ALGO] settings in all MDQ through TL2 shapers traversed
-                                                                 by the packet. [SHP_RA] has no effect on the TL1 rate limiters. See
-                                                                 NIX_AF_TL*()_MD_DEBUG*[RED_ALGO_OVERRIDE].
-
-                                                                 When [LSO] is set in the descriptor, hardware applies [SHP_RA] to each LSO
-                                                                 segment. */
-		u64 markptr:8;	     /**< [ 51: 44] Mark pointer. When [MARK_EN] is set, byte offset from packet start to byte
-                                                                 to use for packet shaper marking. [MARKFORM] indirectly determines how this
-                                                                 offset is used, including whether and how an L2 or L3 header is marked. See
-                                                                 also [MARK_EN]. */
-		u64 markform:7;	     /**< [ 58: 52] Mark Format. When [MARK_EN] is set, the NIX_AF_MARK_FORMAT()_CTL register
-                                                                 which specifies how NIX will mark NIX_COLORRESULT_E::YELLOW and
-                                                                 NIX_COLORRESULT_E::RED_SEND packets. [MARKFORM] must be less than the size
-                                                                 of the NIX_AF_MARK_FORMAT()_CTL array. See also [MARK_EN]. */
-		u64 mark_en:1;	     /**< [ 59: 59] Enable for packet shaper marking. When one, NIX_COLORRESULT_E::YELLOW and
-                                                                 NIX_COLORRESULT_E::RED_SEND packets will be marked as specified by
-                                                                 [MARKFORM] and [MARKPTR].
-
-                                                                 When [LSO] and [MARK_EN] are both set in the descriptor, NIX marks each LSO
-                                                                 segment independently, using [MARKPTR] and [MARKFORM] for every LSO
-                                                                 segment. */
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates send extended header. Enumerated by NIX_SUBDC_E::EXT. */
-		u64 vlan0_ins_ptr:8;	/**< [ 71: 64] VLAN 0 insert pointer. Byte offset from packet start to first inserted VLAN byte when
-                                                                 [VLAN0_INS_ENA] is set. Must be even. */
-		u64 vlan0_ins_tci:16;	/**< [ 87: 72] VLAN 0 insert tag control information. See [VLAN0_INS_ENA]. */
-		u64 vlan1_ins_ptr:8;	/**< [ 95: 88] VLAN 1 insert pointer. Byte offset from packet start to first inserted VLAN byte when
-                                                                 [VLAN1_INS_ENA] is set. Must be even. */
-		u64 vlan1_ins_tci:16;	/**< [111: 96] VLAN 1 insert tag control information. See [VLAN1_INS_ENA]. */
-		u64 vlan0_ins_ena:1;	/**< [112:112] VLAN 0 insert enable. If set, NIX inserts a VLAN tag at byte offset
-                                                                 [VLAN0_INS_PTR] from the start of packet. The inserted VLAN tag consists of:
-                                                                 * 16-bit Ethertype given by NIX_AF_LF()_TX_CFG[VLAN0_INS_ETYPE], followed by
-                                                                 * 16-bit tag control information given by [VLAN0_INS_TCI].
-
-                                                                 Up to two VLAN tags may be inserted in a packet due to [VLAN0_INS_ENA] and
-                                                                 [VLAN1_INS_ENA]. If two VLAN tags are inserted:
-                                                                 * [VLAN0_INS_PTR] must be less than or equal to [VLAN1_INS_PTR].
-                                                                 * Hardware inserts VLAN 0 first and adjusts [VLAN1_INS_PTR] accordingly.
-                                                                 Thus, if the two pointers are equal in the descriptor, hardware inserts
-                                                                 VLAN 1 immediately after VLAN 0 in the packet.
-
-                                                                 A VLAN must not be inserted within an outer or inner L3/L4 header, but may be
-                                                                 inserted within an outer L4 payload.
-
-                                                                 The packet header is parsed by NPC after VLAN insertion. Note that the
-                                                                 resulting NIX_TX_VTAG_ACTION_S[VTAG0_OP,VTAG1_OP] may replace or insert
-                                                                 additional header bytes. Thus, Vtag may replace bytes that were inserted by
-                                                                 [VLAN0_INS_*,VLAN1_INS_*]. */
-		u64 vlan1_ins_ena:1;	/**< [113:113] VLAN 1 insert enable. See [VLAN0_INS_ENA]. */
-		u64 reserved_114_127:14;
-	} s;
-	/* struct cavm_nix_send_ext_s_s cn; */
-};
-
-/**
- * Structure nix_send_hdr_s
- *
- * NIX Send Header Subdescriptor Structure
- * The send header is the first subdescriptor of every send descriptor.
- */
-union cavm_nix_send_hdr_s {
-	u64 u[2];
-	struct cavm_nix_send_hdr_s_s {
-		u64 total:18;	     /**< [ 17:  0] Total byte count to send, excluding optional VLAN bytes inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] and Vtag bytes inserted by NIX_TX_VTAG_ACTION_S.
-
-                                                                 For a non-LSO descriptor, total number of bytes, including any inserted
-                                                                 VLAN and/or Vtag bytes, must not exceed NIX_AF_SMQ()_CFG[MAXLEN].
-
-                                                                 For a LSO send descriptor (NIX_SEND_EXT_S[LSO] is set),
-                                                                 specifies the total LSO payload size plus the size of the LSO header,
-                                                                 excluding any inserted VLAN and/or Vtag bytes. In other words, the total
-                                                                 LSO data payload size is [TOTAL] - NIX_SEND_EXT_S[LSO_SB].
-
-                                                                 [TOTAL] does not include any of the outside FCS bytes that CGX may append
-                                                                 to the packet(s). Hardware zero pads the packet when [TOTAL] is larger than
-                                                                 the sum of all NIX_SEND_SG_S[SEG_SIZE*]s and NIX_SEND_IMM_S[SIZE]s in the
-                                                                 descriptor. In addition, hardware zero pads the packet when
-                                                                 NIX_AF_SMQ()_CFG[MINLEN] is larger than the sum of [TOTAL] and any inserted
-                                                                 VLAN and Vtag bytes. */
-		u64 reserved_18:1;
-		u64 df:1;		     /**< [ 19: 19] Don't free. If set, by default NIX will not free the surrounding buffer of
-                                                                 a packet segment from NIX_SEND_SG_S. If clear, by default NIX will free the
-                                                                 buffer. See NIX_SEND_SG_S[I*]. */
-		u64 aura:20;	     /**< [ 39: 20] Aura number. NPA aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] to which buffers are
-                                                                 optionally freed for packet segments from NIX_SEND_SG_S. See [DF] and
-                                                                 NIX_SEND_SG_S[I*]. */
-		u64 sizem1:3;	     /**< [ 42: 40] Number of 128-bit words in the SQE minus one. */
-		u64 pnc:1;		     /**< [ 43: 43] Post normal completion. If set along with NIX_SQ_CTX_S[CQ_ENA], a CQE is
-                                                                 created with NIX_CQE_HDR_S[CQE_TYPE] = NIX_XQE_TYPE_E::SEND when the send
-                                                                 descriptor's operation completes. If NIX_SEND_EXT_S[LSO] is set, a CQE is
-                                                                 created when the send operation completes for the last LSO segment.
-
-                                                                 If clear, no CQE is added on send completion.
-
-                                                                 This bit is ignored when NIX_SQ_CTX_S[CQ_ENA] is clear.
-
-                                                                 NIX will not add a CQE for this send descriptor until after it has
-                                                                 completed all LLC/DRAM fetches that service all prior NIX_SEND_SG_S
-                                                                 subdescriptors, and it has fetched all subdescriptors in the send
-                                                                 descriptor. If NIX_SEND_MEM_S[WMEM]=1, NIX also will not post the CQE until
-                                                                 all NIX_SEND_MEM_S subdescriptors in the descriptor complete and commit. */
-		u64 sq:20;		     /**< [ 63: 44] Send queue within LF. Valid in the first NIX_SEND_HDR_S of an LMT store to
-                                                                 NIX_LF_OP_SEND(). If multiple SQEs are enqueued by the LMT store,
-                                                                 ignored in all NIX_SEND_HDR_S other than the first one.
-
-                                                                 Internal:
-                                                                 Included in LMTST, removed by hardware. */
-		u64 ol3ptr:8;	     /**< [ 71: 64] Outer Layer 3 pointer. Byte offset from packet start to first byte of outer
-                                                                 L3 header, if present, before any VLAN or Vtag insertion. Must be even.
-                                                                 Hardware adjusts the pointer as needed to account for any VLAN inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] or Vtag inserted by NIX_TX_VTAG_ACTION_S at or before
-                                                                 this byte offset.
-
-                                                                 Must be valid when used by a selected checksum or LSO algorithm,
-                                                                 specifically when any of the following is true:
-                                                                 * [OL3TYPE] = NIX_SENDL3TYPE_E::IP4_CKSUM.
-                                                                 * [OL4TYPE] = NIX_SENDL4TYPE_E::TCP_CKSUM or NIX_SENDL4TYPE_E::UDP_CKSUM
-                                                                 (due to IPv4/IPv6 pseudo-header included in the TCP/UDP checksum).
-                                                                 * NIX_SEND_EXT_S[LSO] is set in the descriptor and the LSO
-                                                                 format selected by NIX_SEND_EXT_S[LSO_FORMAT] modifies at least one field
-                                                                 in this layer
-                                                                 (corresponding NIX_AF_LSO_FORMAT()_FIELD()[ALG] != NIX_LSOALG_E::NOP and
-                                                                 NIX_AF_LSO_FORMAT()_FIELD()[LAYER] = NIX_TXLAYER_E::OL3). */
-		u64 ol4ptr:8;	     /**< [ 79: 72] Outer Layer 4 pointer. Byte offset from packet start to first byte of
-                                                                 outer L4 header, if present, before an VLAN or Vtag insertion. Must be even.
-                                                                 Hardware adjusts the pointer as needed to account for any VLAN inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] or Vtag inserted by NIX_TX_VTAG_ACTION_S at or before
-                                                                 this byte offset.
-
-                                                                 Must be valid when used by a selected checksum or LSO algorithm,
-                                                                 specifically when any of the following is true:
-                                                                 * [OL3TYPE] = NIX_SENDL3TYPE_E::IP4_CKSUM
-                                                                 ([OL4PTR points to end of IPv4 header).
-                                                                 * [OL4TYPE] = NIX_SENDL4TYPE_E::TCP_CKSUM or NIX_SENDL4TYPE_E::UDP_CKSUM
-                                                                 * NIX_SEND_EXT_S[LSO] is set in the descriptor and the LSO
-                                                                 format selected by NIX_SEND_EXT_S[LSO_FORMAT] modifies at least one field
-                                                                 in this layer
-                                                                 (corresponding NIX_AF_LSO_FORMAT()_FIELD()[ALG] != NIX_LSOALG_E::NOP and
-                                                                 NIX_AF_LSO_FORMAT()_FIELD()[LAYER] = NIX_TXLAYER_E::OL4). */
-		u64 il3ptr:8;	     /**< [ 87: 80] Inner Layer 3 pointer. Byte offset from packet start to first byte of inner
-                                                                 L3 header, if present, before any VLAN or Vtag insertion. Must be even.
-                                                                 Hardware adjusts the pointer as needed to account for any VLAN inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] or Vtag inserted by NIX_TX_VTAG_ACTION_S at or before
-                                                                 this byte offset.
-
-                                                                 Must be valid when used by a selected checksum or LSO algorithm. See
-                                                                 [OL3PTR] for equivalent outer L3 conditions. */
-		u64 il4ptr:8;	     /**< [ 95: 88] Inner Layer 4 pointer. Byte offset from packet start to first byte of inner
-                                                                 L4 header, if present, before any VLAN or Vtag insertion. Must be even.
-                                                                 Hardware adjusts the pointer as needed to account for any VLAN inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] or Vtag inserted by NIX_TX_VTAG_ACTION_S at or before
-                                                                 this byte offset.
-
-                                                                 Must be valid when used by a selected checksum or LSO algorithm. See
-                                                                 [OL4PTR] for equivalent outer L4 conditions. */
-		u64 ol3type:4;	     /**< [ 99: 96] Outer Layer 3 type enumerated by NIX_SENDL3TYPE_E. */
-		u64 ol4type:4;	     /**< [103:100] Outer Layer 4 type enumerated by NIX_SENDL4TYPE_E. If checksum generation
-                                                                 is specified, hardware includes all packet data following the outer layer 4
-                                                                 header in the checksum calculation, excluding pad bytes added due to
-                                                                 NIX_AF_SMQ()_CFG[MINLEN]. Hardware does not use IP or UDP length fields in
-                                                                 the packet to determine the layer 4 checksum region.
-
-                                                                 When [OL4TYPE] = NIX_SENDL4TYPE_E::SCTP_CKSUM, [IL3TYPE] and [IL4TYPE] must
-                                                                 not specify checksum generation. */
-		u64 il3type:4;	     /**< [107:104] Inner Layer 3 type enumerated by NIX_SENDL3TYPE_E. */
-		u64 il4type:4;	     /**< [111:108] Inner Layer 4 type enumerated by NIX_SENDL4TYPE_E. If checksum generation
-                                                                 is specified, hardware includes all packet data following the inner layer 4
-                                                                 header in the checksum calculation, excluding pad bytes added due to
-                                                                 NIX_AF_SMQ()_CFG[MINLEN]. Hardware does not use IP or UDP length fields in
-                                                                 the packet to determine the layer 4 checksum region. */
-		u64 sqe_id:16;	     /**< [127:112] Software defined SQE identifier copied to NIX_SEND_COMP_S[SQE_ID]. */
-	} s;
-	/* struct cavm_nix_send_hdr_s_s cn; */
-};
-
-/**
- * Structure nix_send_imm_s
- *
- * NIX Send Immediate Subdescriptor Structure
- * The send immediate subdescriptor requests that bytes immediately following this
- * NIX_SEND_IMM_S (after skipping [APAD] bytes) are to be included in the packet data.
- * The next subdescriptor following this NIX_SEND_IMM_S (when one exists) will
- * follow the immediate bytes, after rounding up the address to a multiple of 16 bytes.
- *
- * There may be multiple NIX_SEND_IMM_S in one NIX send descriptor. A
- * NIX_SEND_IMM_S is ignored in a NIX send descriptor if the sum of all prior
- * NIX_SEND_SG_S[SEG*_SIZE]s and NIX_SEND_IMM_S[SIZE]s meets or exceeds
- * NIX_SEND_HDR_S[TOTAL].
- *
- * When NIX_SEND_EXT_S[LSO] is set in the descriptor, all NIX_SEND_IMM_S
- * bytes must be included in the first NIX_SEND_EXT_S[LSO_SB] bytes of the
- * source packet.
- */
-union cavm_nix_send_imm_s {
-	u64 u;
-	struct cavm_nix_send_imm_s_s {
-		u64 size:16;	     /**< [ 15:  0] Size of immediate data (in bytes) that follows this 64-bit structure after
-                                                                 skipping [APAD] bytes. The next subdescriptor follows [APAD]+[SIZE] bytes
-                                                                 later in the descriptor, rounded up to the next 16-byte aligned address.
-                                                                 [SIZE] must be greater than 0, and [APAD]+[SIZE] must be less than or equal
-                                                                 to 264 bytes. */
-		u64 apad:3;	     /**< [ 18: 16] Alignment pad. Number of bytes to skip following this 64-bit structure before
-                                                                 the first byte to be included in the packet data. */
-		u64 reserved_19_59:41;
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates immediate. Enumerated by NIX_SUBDC_E::IMM. */
-	} s;
-	/* struct cavm_nix_send_imm_s_s cn; */
-};
-
-/**
- * Structure nix_send_jump_s
- *
- * NIX Send Jump Subdescriptor Structure
- * The send jump subdescriptor selects a new address for fetching the remaining
- * subdescriptors of a send descriptor. This allows software to create a send
- * descriptor longer than SQE size selected by NIX_SQ_CTX_S[MAX_SQE_SIZE].
- *
- * There can be only one NIX_SEND_JUMP_S subdescriptor in a send descriptor. If
- * present, it must immediately follow NIX_SEND_HDR_S if NIX_SEND_EXT_S is not
- * present, else it must immediately follow NIX_SEND_EXT_S. In either case, it
- * must terminate the SQE enqueued by software.
- */
-union cavm_nix_send_jump_s {
-	u64 u[2];
-	struct cavm_nix_send_jump_s_s {
-		u64 sizem1:7;	     /**< [  6:  0] Number of 16-byte subdescriptor words (minus one) in the subdescriptor list that [ADDR]
-                                                                 points to. */
-		u64 reserved_7_13:7;
-		u64 ld_type:2;	     /**< [ 15: 14] Specifies load transaction type to use for reading post-jump
-                                                                 subdescriptors. Enumerated by NIX_SENDLDTYPE_E. */
-		u64 aura:20;	     /**< [ 35: 16] Aura number. See [F]. */
-		u64 reserved_36_58:23;
-		u64 f:1;		     /**< [ 59: 59] Free.
-                                                                 0 = Hardware will not free the buffer indicated by [ADDR].
-                                                                 1 = Hardware will free the buffer indicated by [ADDR] to NPA after it has read all
-                                                                 subdescriptors from it.
-
-                                                                 NIX sends [ADDR] to NPA as part of the buffer free when [F] is set. Either an NPA
-                                                                 naturally-aligned pool or opaque pool may be appropriate. Refer to the NPA chapter. */
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates send jump. Enumerated by NIX_SUBDC_E::JUMP. */
-		u64 addr:64;	     /**< [127: 64] LF IOVA of the first byte of the next subdescriptor. See NIX_IOVA_S[ADDR]. Bits
-                                                                 \<3:0\> are ignored; address must be 16-byte aligned.
-
-                                                                 If NIX_AF_LF()_CFG[BE] is set for this LF (VF/PF), [ADDR] points to big-endian
-                                                                 instructions, otherwise little-endian. */
-	} s;
-	/* struct cavm_nix_send_jump_s_s cn; */
-};
-
-/**
- * Structure nix_send_mem_s
- *
- * NIX Send Memory Subdescriptor Structure
- * The send memory subdescriptor atomically sets, increments or decrements a memory location.
- *
- * NIX_SEND_MEM_S subdescriptors must follow all NIX_SEND_SG_S and NIX_SEND_IMM_S
- * subdescriptors in the NIX send descriptor. NIX will not initiate the memory
- * update for this subdescriptor until after it has completed all LLC/DRAM fetches
- * that service all prior NIX_SEND_SG_S subdescriptors. The memory update is
- * executed once, even if the packet is replicated due to NIX_TX_ACTION_S[OP] =
- * NIX_TX_ACTIONOP_E::MCAST.
- *
- * Performance is best if a memory decrement by one is used rather than any other memory
- * set/increment/decrement. (Less internal bus bandwidth is used with memory decrements by one.)
- *
- * When NIX_SEND_EXT_S[LSO] is set in the descriptor, NIX executes the
- * memory update only while processing the last LSO segment, after
- * processing prior segments.
- */
-union cavm_nix_send_mem_s {
-	u64 u[2];
-	struct cavm_nix_send_mem_s_s {
-		u64 offset:16;	     /**< [ 15:  0] Adder offset. Constant value to add or subtract or set. If the count being
-                                                                 modified is to represent the true packet size, then the offset may
-                                                                 represent the pad and FCS appended to the packet.
-
-                                                                 Internal:
-                                                                 Note IOB hardware has a special encoding for atomic decrement,
-                                                                 therefore a change of minus one is twice as IOB bandwidth efficient as adding/subtracting
-                                                                 other values or setting. */
-		u64 reserved_16_52:37;
-		u64 wmem:1;	     /**< [ 53: 53] Wait for memory.
-                                                                 0 = The memory operation may complete after the CQE is posted and/or add work is
-                                                                 initiated, and potentially after software has begun servicing the
-                                                                 work/completion.
-                                                                 1 = NIX will wait for this NIX_SEND_MEM_S requested memory operation to
-                                                                 complete and commit before adding a send completion CQE for the send
-                                                                 descriptor if NIX_SEND_HDR_S[PNC] is set, and before initiating SSO add
-                                                                 work for any NIX_SEND_WORK_S in the descriptor. This may have reduced
-                                                                 performance over not waiting. */
-		u64 dsz:2;		     /**< [ 55: 54] Memory data size. The size of the word in memory, enumerated by NIX_SENDMEMDSZ_E. */
-		u64 alg:4;		     /**< [ 59: 56] Adder algorithm. How to modify the memory location, for example by setting or atomically
-                                                                 incrementing. Enumerated by NIX_SENDMEMALG_E.
-
-                                                                 Internal:
-                                                                 NCB command type is selected as follows:
-                                                                 \<pre\>
-                                                                 switch ([ALG]) {
-                                                                    case NIX_SENDMEMALG_E::SET :
-                                                                    case NIX_SENDMEMALG_E::SETTSTMP :
-                                                                    case NIX_SENDMEMALG_E::SETRSLT :
-                                                                       cmd_type = RSTP;
-
-                                                                    case NIX_SENDMEMALG_E::ADD :
-                                                                    case NIX_SENDMEMALG_E::ADDLEN :
-                                                                    case NIX_SENDMEMALG_E::SUBLEN :
-                                                                    case NIX_SENDMEMALG_E::ADDMBUF :
-                                                                    case NIX_SENDMEMALG_E::SUBMBUF :
-                                                                       switch ([DSZ]) {
-                                                                          case NIX_SENDMEMDSZ_E::B8 :
-                                                                          case NIX_SENDMEMDSZ_E::B16 :
-                                                                             unpredictable();
-                                                                          case NIX_SENDMEMDSZ_E::B32 :
-                                                                             cmd_type = SAA32;
-                                                                          case NIX_SENDMEMDSZ_E::B64 :
-                                                                             cmd_type = SAA64;
-                                                                       }
-
-                                                                    NIX_SENDMEMALG_E::SUB :
-                                                                       switch ([DSZ]) {
-                                                                          case NIX_SENDMEMDSZ_E::B8 :
-                                                                          case NIX_SENDMEMDSZ_E::B16 :
-                                                                             unpredictable();
-                                                                          case NIX_SENDMEMDSZ_E::B32 :
-                                                                             cmd_type = ([OFFSET] == 1) ? SAAM132 : SAA32;
-                                                                          case NIX_SENDMEMDSZ_E::B64 :
-                                                                             cmd_type = ([OFFSET] == 1) ? SAAM164 : SAA64;
-                                                                       }
-
-                                                                    default:
-                                                                       unpredictable();
-                                                                 }
-                                                                 \</pre\> */
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates send memory. Enumerated by NIX_SUBDC_E::MEM. */
-		u64 addr:64;	     /**< [127: 64] LF IOVA of the LLC/DRAM address to be modified.
-                                                                 [ADDR] must be naturally aligned to the size specified in [DSZ].
-                                                                 Bits \<63:53\> are ignored by hardware; software should use a sign-extended
-                                                                 bit \<52\> for forward compatibility.
-                                                                 If NIX_AF_LF()_CFG[BE] is set for this LF (VF/PF), [ADDR] is a big-endian byte
-                                                                 pointer. Otherwise, [ADDR] is a little-endian byte pointer. */
-	} s;
-	/* struct cavm_nix_send_mem_s_s cn; */
-};
-
-/**
- * Structure nix_send_sg_s
- *
- * NIX Send Scatter/Gather Subdescriptor Structure
- * The send scatter/gather subdescriptor requests one to three segments of packet
- * data bytes to be transmitted. There may be multiple NIX_SEND_SG_Ss in each NIX send descriptor.
- *
- * NIX_SEND_SG_S is immediately followed by one NIX_IOVA_S word when [SEGS] = 1,
- * three NIX_IOVA_S words when [SEGS] \>= 2. Each NIX_IOVA_S word specifies the
- * LF IOVA of first packet data byte in the corresponding segment; first NIX_IOVA_S
- * word for segment 1, second word for segment 2, third word for segment 3. Note
- * the third word is present when [SEGS] \>= 2 but only valid when [SEGS] = 3.
- *
- * If the sum of all prior NIX_SEND_SG_S[SEG*_SIZE]s and NIX_SEND_IMM_S[SIZE]s
- * meets or exceeds NIX_SEND_HDR_S[TOTAL], this subdescriptor will not contribute
- * any packet data but may free buffers to NPA (see [I1]).
- */
-union cavm_nix_send_sg_s {
-	u64 u;
-	struct cavm_nix_send_sg_s_s {
-		u64 seg1_size:16;	     /**< [ 15:  0] Size of segment 1 in bytes. */
-		u64 seg2_size:16;	     /**< [ 31: 16] Size of segment 2 in bytes. Valid when [SEGS] \>= 2. */
-		u64 seg3_size:16;	     /**< [ 47: 32] Size of segment 3 in bytes. Valid when [SEGS] = 3. */
-		u64 segs:2;	     /**< [ 49: 48] Number of valid segments. Must be nonzero. */
-		u64 reserved_50_54:5;
-		u64 i1:1;		     /**< [ 55: 55] Invert segment 1 free. NIX frees buffer surrounding segment 1 when:
-
-                                                                 _  (NIX_SEND_HDR_S[DF] == [I1]).
-
-                                                                 NIX frees the buffer to NIX_SEND_HDR_S[AURA]. The buffer is freed even if
-                                                                 the segment does not contribute any packet data (e.g. when [SEG1_SIZE] is
-                                                                 zero or when NIX_SEND_HDR_S[TOTAL] has already been met or exceeded).
-
-                                                                 NIX naturally aligns the segment's NIV_IOVA_S to 128 bytes before sending
-                                                                 it to NPA as part of the buffer free. An NPA naturally-aligned pool is
-                                                                 recommended, though opaque pool mode may also be possible. Refer to the NPA
-                                                                 chapter. */
-		u64 i2:1;		     /**< [ 56: 56] Invert segment 2 free. NIX frees buffer surrounding segment 2 when:
-
-                                                                 _  ([SEGS] \>= 2) && (NIX_SEND_HDR_S[DF] == [I2]).
-
-                                                                 See also [I1]. */
-		u64 i3:1;		     /**< [ 57: 57] Invert segment 3 free. NIX frees buffer surrounding segment 3 when:
-
-                                                                 _  ([SEGS] == 3) && (NIX_SEND_HDR_S[DF] == [I3]).
-
-                                                                 See also [I1]. */
-		u64 ld_type:2;	     /**< [ 59: 58] Specifies load transaction type to use for reading segment bytes. Enumerated by
-                                                                 NIX_SENDLDTYPE_E. */
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates scatter/gather. Enumerated by NIX_SUBDC_E::SG. */
-	} s;
-	/* struct cavm_nix_send_sg_s_s cn; */
-};
-
-/**
- * Structure nix_send_work_s
- *
- * NIX Send Work Subdescriptor Structure
- * This subdescriptor adds work to the SSO. At most one NIX_SEND_WORK_S subdescriptor
- * can exist in the NIX send descriptor. If a NIX_SEND_WORK_S exists in the
- * descriptor, it must be the last subdescriptor. NIX will not initiate the work add
- * for this subdescriptor until after (1) it has completed all LLC/DRAM fetches that
- * service all prior NIX_SEND_SG_S subdescriptors, (2) it has
- * fetched all subdescriptors in the descriptor, and (3) all NIX_SEND_MEM_S[WMEM]=1
- * LLC/DRAM updates have completed.
- *
- * Provided the path of descriptors from the SQ through NIX to an output FIFO is
- * unmodified between the descriptors (as should normally be the case, but it is
- * possible for software to change the path), NIX also (1) will submit
- * the SSO add works from all descriptors in the SQ in order, and
- * (2) will not submit an SSO work add until after all prior descriptors
- * in the SQ have completed their NIX_SEND_SG_S
- * processing, and (3) will not submit an SSO work add until after
- * it has fetched all subdescriptors from prior descriptors in the SQ.
- *
- * When NIX_SEND_EXT_S[LSO] is set in the descriptor, NIX executes the
- * NIX_SEND_WORK_S work add only while processing the last LSO segment, after
- * processing prior segments.
- *
- * Hardware ignores NIX_SEND_WORK_S when NIX_SQ_CTX_S[SSO_ENA] is clear.
- */
-union cavm_nix_send_work_s {
-	u64 u[2];
-	struct cavm_nix_send_work_s_s {
-		u64 tag:32;	     /**< [ 31:  0] The SSO tag to use when NIX submits work to SSO. */
-		u64 tt:2;		     /**< [ 33: 32] SSO tag type. The SSO tag type number to add work with. */
-		u64 grp:10;	     /**< [ 43: 34] SSO group. The SSO group number to add work to. Note the upper two bits
-                                                                 correspond to a node number. */
-		u64 reserved_44_59:16;
-		u64 subdc:4;	     /**< [ 63: 60] Subdescriptor code. Indicates send work. Enumerated by NIX_SUBDC_E::WORK. */
-		u64 addr:64;	     /**< [127: 64] LF IOVA of the work-queue entry to be submitted to the SSO. See NIX_IOVA_S[ADDR].
-                                                                 Bits \<2:0\> are ignored; address must be eight-byte aligned. */
-	} s;
-	/* struct cavm_nix_send_work_s_s cn; */
-};
-
-/**
- * Structure nix_sq_ctx_hw_s
- *
- * NIX SQ Context Hardware Structure
- * This structure contains context state maintained by hardware for each SQ in
- * NDC/LLC/DRAM.
- * Software uses the equivalent NIX_SQ_CTX_S structure format to read and write an
- * SQ context with the NIX admin queue.
- * Always stored in byte invariant little-endian format (LE8).
- */
-union cavm_nix_sq_ctx_hw_s {
-	u64 u[16];
-	struct cavm_nix_sq_ctx_hw_s_s {
-		u64 gbl_ena:1;	     /**< [  0:  0] See NIX_SQ_CTX_S[ENA]. */
-		u64 gbl_substream:20;	/**< [ 20:  1] See NIX_SQ_CTX_S[SUBSTREAM]. */
-		u64 gbl_max_sqe_size:2;	/**< [ 22: 21] See NIX_SQ_CTX_S[MAX_SQE_SIZE]. */
-		u64 gbl_sqe_way_mask:16;/**< [ 38: 23] See NIX_SQ_CTX_S[SQE_WAY_MASK]. */
-		u64 gbl_sqb_aura:20;	/**< [ 58: 39] See NIX_SQ_CTX_S[SQB_AURA]. This is the last entry for the enqueue engine requests. */
-		u64 gbl_rsvd1:5;	     /**< [ 63: 59] Reserved. */
-		u64 gbl_cq_id:20;	     /**< [ 83: 64] See NIX_SQ_CTX_S[CQ]. */
-		u64 gbl_cq_ena:1;	     /**< [ 84: 84] See NIX_SQ_CTX_S[CQ_ENA]. */
-		u64 qint_idx:7;	     /**< [ 91: 85] See NIX_SQ_CTX_S[QINT_IDX]. */
-		u64 sq_int:8;	     /**< [ 99: 92] See NIX_SQ_CTX_S[SQ_INT]. */
-		u64 sq_int_ena:8;	     /**< [107:100] See NIX_SQ_CTX_S[SQ_INT_ENA]. */
-		u64 xoff:1;	     /**< [108:108] See NIX_SQ_CTX_S[XOFF]. */
-		u64 send_lso_segnum:8;	/**< [116:109] See NIX_SQ_CTX_S[SEND_LSO_SEGNUM] - NA. */
-		u64 gbl_rsvd:11;	     /**< [127:117] Reserved. */
-		u64 sqb_enqueue_count:16;
-					     /**< [143:128] Used in combination with [SQB_DEQUEUE_COUNT] to respond back to Software
-                                                                 for AQ reads corresponding to NIX_SQ_CTX_S[SQB_COUNT] =
-                                                                 [SQB_ENQUEUE_COUNT] - [SQB_DEQUEUE_COUNT]. */
-		u64 sqe_stype:2;	     /**< [145:144] See NIX_SQ_CTX_S[SQE_STYPE]. */
-		u64 tail_offset:6;	     /**< [151:146] See NIX_SQ_CTX_S[TAIL_OFFSET]. */
-		u64 lmt_dis:1;		/**< [152:152] See NIX_SQ_CTX_S[LMT_DIS]. */
-		u64 smq_rr_quantum:24;	/**< [176:153] See NIX_SQ_CTX_S[SMQ_RR_QUANTUM] */
-		u64 dnq_rsvd1:15;	/**< [191:177] Reserved */
-		u64 tail_sqb:64;	     /**< [255:192] See NIX_SQ_CTX_S[TAIL_SQB]. */
-		u64 next_sqb:64;	     /**< [319:256] See NIX_SQ_CTX_S[NEXT_SQB]. */
-		u64 mnq_dis:1;	     /**< [320:320] See NIX_SQ_CTX_S[MNQ_DIS]. */
-		u64 smq:10;	     /**< [330:321] See NIX_SQ_CTX_S[SMQ]. */
-		u64 smq_pend:1;	     /**< [331:331] See NIX_SQ_CTX_S[SMQ_PEND]. */
-		u64 smq_next_sq:20;	/**< [351:332] See NIX_SQ_CTX_S[SMQ_NEXT_SQ]. */
-		u64 smq_next_sq_vld:1;	/**< [352:352] See NIX_SQ_CTX_S[SMQ_NEXT_SQ] is valid. */
-		u64 scm1_rsvd2:31;	     /**< [383:353] Reserved. */
-		u64 smenq_sqb:64;	     /**< [447:384] See NIX_SQ_CTX_S[SMENQ_SQB]. */
-		u64 smenq_offset:6;	/**< [453:448] See NIX_SQ_CTX_S[SMENQ_OFFSET]. */
-		u64 cq_limit:8;		/**< [461:454] See NIX_SQ_CTX_S[CQ_LIMIT]. */
-		u64 smq_rr_count:25;	/**< [486:462] See NIX_SQ_CTX_S[SMQ_RR_COUNT]. */
-		u64 scm_lso_rem:18;	/**< [504:487] Reserved. */
-		u64 scm_dq_rsvd0:7;	/**< [511:505] Reserved. */
-		u64 smq_lso_segnum:8;	/**< [519:512] See NIX_SQ_CTX_S[SMQ_LSO_SEGNUM]. */
-		u64 vfi_lso_total:18;	/**< [537:520] Used for VF-Isolation. See NIX_SEND_HDR_S[TOTAL]. */
-		u64 vfi_lso_sizem1:3;	/**< [540:538] Used for VF-Isolation. See NIX_SEND_HDR_S[SIZEM1]. */
-		u64 vfi_lso_sb:8;	     /**< [548:541] Used for VF-Isolation. See NIX_SEND_EXT_S[LSO_SB]. */
-		u64 vfi_lso_mps:14;	/**< [562:549] Used for VF-Isolation. See NIX_SEND_EXT_S[LSO_MPS]. */
-		u64 vfi_lso_vlan0_ins_ena:1;
-					     /**< [563:563] Used for VF-Isolation. See NIX_SEND_EXT_S[VLAN0_INS_ENA]. */
-		u64 vfi_lso_vlan1_ins_ena:1;
-					     /**< [564:564] Used for VF-Isolation. See NIX_SEND_EXT_S[VLAN1_INS_ENA]. */
-		u64 vfi_lso_vld:1;	     /**< [565:565] Used for VF-Isolation. See NIX_SEND_EXT_S[LSO]. */
-		u64 smenq_next_sqb_vld:1;    /**< [566:566] See NIX_SQ_CTX_S[SMENQ_NEXT_SQB_VLD]. */
-		u64 scm_dq_rsvd1:9;
-		&			 /**< [575:567] Reserved. */
-		 u64 smenq_next_sqb:64;	     /**< [639:576] See NIX_SQ_CTX_S[SMENQ_NEXT_SQB]. */
-		u64 head_sqb:64;	     /**< [703:640] See NIX_SQ_CTX_S[HEAD_SQB]. */
-		u64 head_offset:6;	     /**< [709:704] See NIX_SQ_CTX_S[HEAD_OFFSET]. */
-		u64 sqb_dequeue_count:16;
-					     /**< [725:710] See [SQB_ENQUEUE_COUNT]. */
-		u64 default_chan:12;	/**< [737:726] See NIX_SQ_CTX_S[DEFAULT_CHAN]. */
-		u64 sdp_mcast:1;	     /**< [738:738] See NIX_SQ_CTX_S[SDP_MCAST]. */
-		u64 sso_ena:1;	     /**< [739:739] See NIX_SQ_CTX_S[SSO_ENA]. */
-		u64 dse_rsvd1:28;	     /**< [767:740] Reserved. */
-		u64 seb_rsvd1:64;	     /**< [831:768] Reserved. */
-		u64 drop_pkts:48;	     /**< [879:832] See NIX_SQ_CTX_S[DROP_PKTS]. */
-		u64 drop_octs_lsw:16;	/**< [895:880] See NIX_SQ_CTX_S[DROP_OCTS]. */
-		u64 drop_octs_msw:32;	/**< [927:896] See NIX_SQ_CTX_S[DROP_OCTS]. */
-		u64 pkts_lsw:32;	     /**< [959:928] See NIX_SQ_CTX_S[PKTS]. */
-		u64 pkts_msw:16;	     /**< [975:960] See NIX_SQ_CTX_S[PKTS]. */
-		u64 octs:48;	     /**< [1023:976] See NIX_SQ_CTX_S[OCTS]. */
-	} s;
-	/* struct cavm_nix_sq_ctx_hw_s_s cn; */
-};
-
-/**
- * Structure nix_sq_ctx_s
- *
- * NIX Send Queue Context Structure
- * This structure specifies the format used by software with the NIX admin queue
- * to read and write a send queue's NIX_SQ_CTX_HW_S structure maintained by
- * hardware in NDC/LLC/DRAM.
- *
- * The SQ statistics ([OCTS], [PKTS], [DROP_OCTS], [DROP_PKTS]) do not account for
- * packet replication due to NIX_TX_ACTION_S[OP] = NIX_TX_ACTIONOP_E::MCAST.
- */
-union cavm_nix_sq_ctx_s {
-	u64 u[16];
-	struct cavm_nix_sq_ctx_s_s {
-		u64 ena:1;		     /**< [  0:  0] SQ enable. */
-		u64 cq_ena:1;	     /**< [  1:  1] Completion queue enable.
-                                                                 0 = NIX_SEND_HDR_S[PNC] is ignored and a packet from this SQ will never generate
-                                                                 a CQE.
-                                                                 1 = A packet with NIX_SEND_HDR_S[PNC] will add a send completion CQE to [CQ]. */
-		u64 max_sqe_size:2;	/**< [  3:  2] Selects maximum SQE size for this SQ. Enumerated by NIX_MAXSQESZ_E.
-                                                                 Internal:
-                                                                 Hardware allocates this size for each SQE stored in an SQB. */
-		u64 substream:20;	     /**< [ 23:  4] Substream ID of IOVAs specified by NIX_SEND_SG_S, NIX_SEND_MEM_S, etc.
-                                                                 When zero, no substream ID is used. */
-		u64 sdp_mcast:1;	     /**< [ 24: 24] SDP multicast. Valid if the SQ sends packets to SDP (corresponding
-                                                                 NIX_AF_TL4()_SDP_LINK_CFG[ENA] is set):
-                                                                 0 = SQ sends SDP unicast packets.
-                                                                 1 = SQ sends SDP multicast packets. */
-		u64 lmt_dis:1;	     /**< [ 25: 25] LMT store disable. Hardware sets this bit along with
-                                                                 [SQ_INT]\<NIX_SQINT_E::LMT_ERR\> when an LMT store to NIX_LF_OP_SEND()
-                                                                 for this SQ has an error. See also NIX_LF_SQ_OP_ERR_DBG. When set,
-                                                                 hardware drops LMT stores targeting this SQ. */
-		u64 mnq_dis:1;	     /**< [ 26: 26] Meta-descriptor enqueue disable. Hardware sets this bit along with
-                                                                 [SQ_INT]\<NIX_SQINT_E::MNQ_ERR\> when an error is detected while enqueuing a
-                                                                 meta-descriptor to [SMQ] from this SQ. When set, hardware stops enqueuing to
-                                                                 [SMQ] from this SQ. */
-		u64 reserved_27_35:9;
-		u64 cq:20;		     /**< [ 55: 36] Completion queue for this SQ. Valid when [CQ_ENA] is set. */
-		u64 cq_limit:8;	     /**< [ 63: 56] Threshold level for suppressing packet send, in units of 1/256th of CQ
-                                                                 level.  0xff represents an empty CQ ring, 0x0 represents a full ring.
-                                                                 Packets will not be sent from the SQ if the available space in the
-                                                                 associated CQ (see shifted_CNT in NIX_CQ_CTX_S[AVG_CON]) is less than the
-                                                                 [CQ_LIMIT] value. */
-		u64 smq:10;	     /**< [ 73: 64] Send meta-descriptor queue for this SQ. Must be less than 512. */
-		u64 xoff:1;	     /**< [ 74: 74] Transmit off. When set, the SQ will not push meta descriptors to the
-                                                                 associated SMQ. Software can read, set and clear this bit with
-                                                                 NIX_LF_SQ_OP_INT[XOFF]. */
-		u64 sso_ena:1;	     /**< [ 75: 75] SSO add work enable.
-                                                                 0 = The SQ never adds work to SSO, and NIX_SEND_WORK_S is ignored when present
-                                                                 in a send descriptor.
-                                                                 1 = A packets with NIX_SEND_WORK_S will add work to SSO. */
-		u64 smq_rr_quantum:24;	/**< [ 99: 76] Round-robin (DWRR) quantum for packets pushed from this SQ to the
-                                                                 associated SMQ (24-bit unsigned integer). Specifies the amount of packet
-                                                                 data bytes to push to SMQ in a round.
-
-                                                                 The minimum value is the MTU. The recommended value for equal weight
-                                                                 arbitration is the larger of the MTU or:
-
-                                                                 _ NIX_AF_SMQ()_CFG[RR_MINLEN] * NIX_AF_SQ_CONST[SMQ_DEPTH]. */
-		u64 default_chan:12;	/**< [111:100] Default channel enumerated by NIX_CHAN_E.
-
-                                                                 If the SQ transmits to CGX and/or LBK (corresponding
-                                                                 NIX_AF_TL4()_SDP_LINK_CFG[ENA] is clear), this is the channel to which a
-                                                                 packet is transmitted when NIX_TX_ACTION_S[OP] =
-                                                                 NIX_TX_ACTIONOP_E::UCAST_DEFAULT in the NPC result.
-
-                                                                 If the SQ transmits to SDP (corresponding NIX_AF_TL4()_SDP_LINK_CFG[ENA] is
-                                                                 set), this is the SDP channel to which packets are transmitted when
-                                                                 [SDP_MCAST] is clear, and the SDP multicast index when [SDP_MCAST] is set. */
-		u64 sqb_count:16;	     /**< [127:112] Number of SQBs currently in use. Includes the SQBs at [HEAD_SQB] and
-                                                                 [TAIL_SQB], and any linked SQBs in between. Excludes the SQB at [NEXT_SQB]. */
-		u64 sqe_way_mask:16;	/**< [143:128] Way partitioning mask for allocating SQB data in NDC (1 means do not use).
-                                                                 All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 reserved_144_171:28;
-		u64 sq_int:8;	     /**< [179:172] SQ interrupts. Bits enumerated by NIX_SQINT_E, which also defines when
-                                                                 hardware sets each bit. Software can read, set or clear these bits with
-                                                                 NIX_LF_SQ_OP_INT. */
-		u64 sq_int_ena:8;	     /**< [187:180] SQ interrupt enables. Bits enumerated by NIX_SQINT_E. Software can read,
-                                                                 set or clear these bits with NIX_LF_SQ_OP_INT. */
-		u64 sqe_stype:2;	     /**< [189:188] Selects the style of write and read for accessing SQB data in LLC/DRAM.
-                                                                 Enumerated by NIX_STYPE_E.
-                                                                 Must be NIX_STYPE_E::STP when NIX_SQ_CTX_S[MAX_SQE_SIZE] =
-                                                                 NIX_MAXSQESZ_E::W8. */
-		u64 smq_pend:1;	     /**< [190:190] When set, indicates that this SQ has pending SQEs to be parsed and pushed to the associated SMQ. */
-		u64 reserved_191:1;
-		u64 reserved_192_223:32;
-		u64 send_lso_segnum:8;	/**< [231:224] Next LSO segment number to send. */
-		u64 smq_lso_segnum:8;	/**< [239:232] Next LSO segment number to enqueue to PSE. */
-		u64 qint_idx:7;	     /**< [246:240] Queue interrupt index. Select the QINT within LF (index {a} of
-                                                                 NIX_LF_QINT()*) which receives [SQ_INT] events.
-
-                                                                 Internal:
-                                                                 See QINT message generation note in NIX_RQ_CTX_S[QINT_IDX]. */
-		u64 reserved_247_255:9;
-		u64 next_sqb:64;	     /**< [319:256] IOVA of next SQB. A NULL value when valid indicates allocation of next SQB
-                                                                 from [SQB_AURA] failed. */
-		u64 tail_sqb:64;	     /**< [383:320] IOVA of tail SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 smenq_sqb:64;	     /**< [447:384] IOVA of SMQ enqueue SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 head_sqb:64;	     /**< [511:448] IOVA of head SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 tail_offset:6;	     /**< [517:512] Offset of next SQE to be enqueued in [TAIL_SQB]. */
-		u64 smenq_offset:6;	/**< [523:518] Offset of next SQE to bve pushed to SMQ in [SMENQ_SQB]. */
-		u64 head_offset:6;	     /**< [529:524] Offset of head SQE in [HEAD_SQB]. */
-		u64 reserved_530_539:10;
-		u64 sqb_aura:20;	     /**< [559:540] SQB aura. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] used for SQE buffer
-                                                                 allocations and frees for this SQ. The selected aura must correspond to a
-                                                                 pool where the buffers (after any NPA_POOL_S[BUF_OFFSET]) are at least of
-                                                                 size NIX_AF_SQ_CONST[SQB_SIZE] (4KB). */
-		u64 reserved_560_575:16;
-		u64 smq_rr_count:25;	/**< [600:576] Round-robin (DWRR) deficit counter for packets pushed from this SQ to the associated SMQ.
-                                                                 A 25-bit two's complement signed integer count. */
-		u64 smenq_next_sqb_vld:1;  /**< [601:601] IOVA of SMQ enqueue [NEXT_SQB] is valid. */
-		u64 smq_next_sq:20;	/**< [621:602] Next SQ within the LF to process in SMQ parse link list. Valid when
-                                                                 [SMQ_PEND] is set and the SQ is not at the tail of the SMQ's link list. */
-		u64 reserved_622_639:18;
-		u64 octs:48;	     /**< [687:640] Number of octets transmitted. Includes frame minimum size pad bytes due to
-                                                                 NIX_AF_SMQ()_CFG[MINLEN], and excludes FCS bytes. Also includes any VLAN
-                                                                 bytes inserted by NIX_SEND_EXT_S[VLAN*] and/or Vtag bytes inserted by
-                                                                 NIX_TX_VTAG_ACTION_S. */
-		u64 reserved_688_703:16;
-		u64 pkts:48;	     /**< [751:704] Number of packets successfully transmitted. */
-		u64 reserved_752_767:16;
-		u64 reserved_768_831:64;
-		u64 smenq_next_sqb:64;	     /**< [895:832] IOVA of the next SMQ enqueue SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 drop_octs:48;	     /**< [943:896] Number of dropped octets. See also NIX_STAT_LF_TX_E::TX_DROP. */
-		u64 reserved_944_959:16;
-		u64 drop_pkts:48;	     /**< [1007:960] Number of dropped packets. See also NIX_STAT_LF_TX_E::TX_DROP. */
-		u64 reserved_1008_1023:16;
-	} s;
-	struct cavm_nix_sq_ctx_s_cn {
-		u64 ena:1;		     /**< [  0:  0] SQ enable. */
-		u64 cq_ena:1;	     /**< [  1:  1] Completion queue enable.
-                                                                 0 = NIX_SEND_HDR_S[PNC] is ignored and a packet from this SQ will never generate
-                                                                 a CQE.
-                                                                 1 = A packet with NIX_SEND_HDR_S[PNC] will add a send completion CQE to [CQ]. */
-		u64 max_sqe_size:2;	/**< [  3:  2] Selects maximum SQE size for this SQ. Enumerated by NIX_MAXSQESZ_E.
-                                                                 Internal:
-                                                                 Hardware allocates this size for each SQE stored in an SQB. */
-		u64 substream:20;	     /**< [ 23:  4] Substream ID of IOVAs specified by NIX_SEND_SG_S, NIX_SEND_MEM_S, etc.
-                                                                 When zero, no substream ID is used. */
-		u64 sdp_mcast:1;	     /**< [ 24: 24] SDP multicast. Valid if the SQ sends packets to SDP (corresponding
-                                                                 NIX_AF_TL4()_SDP_LINK_CFG[ENA] is set):
-                                                                 0 = SQ sends SDP unicast packets.
-                                                                 1 = SQ sends SDP multicast packets. */
-		u64 lmt_dis:1;	     /**< [ 25: 25] LMT store disable. Hardware sets this bit along with
-                                                                 [SQ_INT]\<NIX_SQINT_E::LMT_ERR\> when an LMT store to NIX_LF_OP_SEND()
-                                                                 for this SQ has an error. See also NIX_LF_SQ_OP_ERR_DBG. When set,
-                                                                 hardware drops LMT stores targeting this SQ. */
-		u64 mnq_dis:1;	     /**< [ 26: 26] Meta-descriptor enqueue disable. Hardware sets this bit along with
-                                                                 [SQ_INT]\<NIX_SQINT_E::MNQ_ERR\> when an error is detected while enqueuing a
-                                                                 meta-descriptor to [SMQ] from this SQ. When set, hardware stops enqueuing to
-                                                                 [SMQ] from this SQ. */
-		u64 reserved_27:1;
-		u64 reserved_28_35:8;
-		u64 cq:20;		     /**< [ 55: 36] Completion queue for this SQ. Valid when [CQ_ENA] is set. */
-		u64 cq_limit:8;	     /**< [ 63: 56] Threshold level for suppressing packet send, in units of 1/256th of CQ
-                                                                 level.  0xff represents an empty CQ ring, 0x0 represents a full ring.
-                                                                 Packets will not be sent from the SQ if the available space in the
-                                                                 associated CQ (see shifted_CNT in NIX_CQ_CTX_S[AVG_CON]) is less than the
-                                                                 [CQ_LIMIT] value. */
-		u64 smq:10;	     /**< [ 73: 64] Send meta-descriptor queue for this SQ. Must be less than 512. */
-		u64 xoff:1;	     /**< [ 74: 74] Transmit off. When set, the SQ will not push meta descriptors to the
-                                                                 associated SMQ. Software can read, set and clear this bit with
-                                                                 NIX_LF_SQ_OP_INT[XOFF]. */
-		u64 sso_ena:1;	     /**< [ 75: 75] SSO add work enable.
-                                                                 0 = The SQ never adds work to SSO, and NIX_SEND_WORK_S is ignored when present
-                                                                 in a send descriptor.
-                                                                 1 = A packets with NIX_SEND_WORK_S will add work to SSO. */
-		u64 smq_rr_quantum:24;	/**< [ 99: 76] Round-robin (DWRR) quantum for packets pushed from this SQ to the
-                                                                 associated SMQ (24-bit unsigned integer). Specifies the amount of packet
-                                                                 data bytes to push to SMQ in a round.
-
-                                                                 The minimum value is the MTU. The recommended value for equal weight
-                                                                 arbitration is the larger of the MTU or:
-
-                                                                 _ NIX_AF_SMQ()_CFG[RR_MINLEN] * NIX_AF_SQ_CONST[SMQ_DEPTH]. */
-		u64 default_chan:12;	/**< [111:100] Default channel enumerated by NIX_CHAN_E.
-
-                                                                 If the SQ transmits to CGX and/or LBK (corresponding
-                                                                 NIX_AF_TL4()_SDP_LINK_CFG[ENA] is clear), this is the channel to which a
-                                                                 packet is transmitted when NIX_TX_ACTION_S[OP] =
-                                                                 NIX_TX_ACTIONOP_E::UCAST_DEFAULT in the NPC result.
-
-                                                                 If the SQ transmits to SDP (corresponding NIX_AF_TL4()_SDP_LINK_CFG[ENA] is
-                                                                 set), this is the SDP channel to which packets are transmitted when
-                                                                 [SDP_MCAST] is clear, and the SDP multicast index when [SDP_MCAST] is set. */
-		u64 sqb_count:16;	     /**< [127:112] Number of SQBs currently in use. Includes the SQBs at [HEAD_SQB] and
-                                                                 [TAIL_SQB], and any linked SQBs in between. Excludes the SQB at [NEXT_SQB]. */
-		u64 sqe_way_mask:16;	/**< [143:128] Way partitioning mask for allocating SQB data in NDC (1 means do not use).
-                                                                 All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 reserved_144_171:28;
-		u64 sq_int:8;	     /**< [179:172] SQ interrupts. Bits enumerated by NIX_SQINT_E, which also defines when
-                                                                 hardware sets each bit. Software can read, set or clear these bits with
-                                                                 NIX_LF_SQ_OP_INT. */
-		u64 sq_int_ena:8;	     /**< [187:180] SQ interrupt enables. Bits enumerated by NIX_SQINT_E. Software can read,
-                                                                 set or clear these bits with NIX_LF_SQ_OP_INT. */
-		u64 sqe_stype:2;	     /**< [189:188] Selects the style of write and read for accessing SQB data in LLC/DRAM.
-                                                                 Enumerated by NIX_STYPE_E.
-                                                                 Must be NIX_STYPE_E::STP when NIX_SQ_CTX_S[MAX_SQE_SIZE] =
-                                                                 NIX_MAXSQESZ_E::W8. */
-		u64 smq_pend:1;	     /**< [190:190] When set, indicates that this SQ has pending SQEs to be parsed and pushed to the associated SMQ. */
-		u64 reserved_191:1;
-		u64 reserved_192_223:32;
-		u64 send_lso_segnum:8;	/**< [231:224] Next LSO segment number to send. */
-		u64 smq_lso_segnum:8;	/**< [239:232] Next LSO segment number to enqueue to PSE. */
-		u64 qint_idx:7;	     /**< [246:240] Queue interrupt index. Select the QINT within LF (index {a} of
-                                                                 NIX_LF_QINT()*) which receives [SQ_INT] events.
-
-                                                                 Internal:
-                                                                 See QINT message generation note in NIX_RQ_CTX_S[QINT_IDX]. */
-		u64 reserved_247_255:9;
-		u64 next_sqb:64;	     /**< [319:256] IOVA of next SQB. A NULL value when valid indicates allocation of next SQB
-                                                                 from [SQB_AURA] failed. */
-		u64 tail_sqb:64;	     /**< [383:320] IOVA of tail SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 smenq_sqb:64;	     /**< [447:384] IOVA of SMQ enqueue SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 head_sqb:64;	     /**< [511:448] IOVA of head SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 tail_offset:6;	     /**< [517:512] Offset of next SQE to be enqueued in [TAIL_SQB]. */
-		u64 smenq_offset:6;	/**< [523:518] Offset of next SQE to bve pushed to SMQ in [SMENQ_SQB]. */
-		u64 head_offset:6;	     /**< [529:524] Offset of head SQE in [HEAD_SQB]. */
-		u64 reserved_530_539:10;
-		u64 sqb_aura:20;	     /**< [559:540] SQB aura. Aura within NIX_AF_LF()_CFG[NPA_PF_FUNC] used for SQE buffer
-                                                                 allocations and frees for this SQ. The selected aura must correspond to a
-                                                                 pool where the buffers (after any NPA_POOL_S[BUF_OFFSET]) are at least of
-                                                                 size NIX_AF_SQ_CONST[SQB_SIZE] (4KB). */
-		u64 reserved_560_575:16;
-		u64 smq_rr_count:25;	/**< [600:576] Round-robin (DWRR) deficit counter for packets pushed from this SQ to the associated SMQ.
-                                                                 A 25-bit two's complement signed integer count. */
-		u64 smenq_next_sqb_vld:1;  /**< [601:601] IOVA of SMQ enqueue [NEXT_SQB] is valid. */
-
-		u64 smq_next_sq:20;	/**< [621:602] Next SQ within the LF to process in SMQ parse link list. Valid when
-                                                                 [SMQ_PEND] is set and the SQ is not at the tail of the SMQ's link list. */
-		u64 reserved_622_639:18;
-		u64 octs:48;	     /**< [687:640] Number of octets transmitted. Includes frame minimum size pad bytes due to
-                                                                 NIX_AF_SMQ()_CFG[MINLEN], and excludes FCS bytes. Also includes any VLAN
-                                                                 bytes inserted by NIX_SEND_EXT_S[VLAN*] and/or Vtag bytes inserted by
-                                                                 NIX_TX_VTAG_ACTION_S. */
-		u64 reserved_688_703:16;
-		u64 pkts:48;	     /**< [751:704] Number of packets successfully transmitted. */
-		u64 reserved_752_767:16;
-		u64 reserved_768_831:64;
-		u64 smenq_next_sqb:64; /**< [895:832] IOVA of the next SMQ enqueue SQB. Valid when [SQB_COUNT] is nonzero. */
-		u64 drop_octs:48;	     /**< [943:896] Number of dropped octets. See also NIX_STAT_LF_TX_E::TX_DROP. */
-		u64 reserved_944_959:16;
-		u64 drop_pkts:48;	     /**< [1007:960] Number of dropped packets. See also NIX_STAT_LF_TX_E::TX_DROP. */
-		u64 reserved_1008_1023:16;
-	} cn;
-};
-
-/**
- * Structure nix_tx_action_s
- *
- * NIX Transmit Action Structure
- * This structure defines the format of NPC_RESULT_S[ACTION] for a transmit packet.
- */
-union cavm_nix_tx_action_s {
-	u64 u;
-	struct cavm_nix_tx_action_s_s {
-		u64 op:4;		     /**< [  3:  0] Action op code enumerated by NIX_TX_ACTIONOP_E. */
-		u64 reserved_4_11:8;
-		u64 index:20;	     /**< [ 31: 12] Transmit channel or table index in NIX. The index type is selected as
-                                                                 follows:
-                                                                 _ if [OP] = NIX_TX_ACTIONOP_E::UCAST_CHAN, transmit channel.
-                                                                 _ if [OP] = NIX_TX_ACTIONOP_E::MCAST, pointer to start of multicast
-                                                                 replication list in the NIX TX multicast table.
-                                                                 _ otherwise, not used. */
-		u64 match_id:16;	     /**< [ 47: 32] Software defined match identifier. Used only when NPC_RESULT_S is captured
-                                                                 in NIX_AF_TX_NPC_CAPTURE_RESP(). */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nix_tx_action_s_s cn; */
-};
-
-/**
- * Structure nix_tx_vtag_action_s
- *
- * NIX Transmit Vtag Action Structure
- * This structure defines the format of NPC_RESULT_S[VTAG_ACTION] for a transmit
- * packet. It specifies the optional insertion or replacement of up to two Vtags
- * (e.g. C-VLAN/S-VLAN tags, 802.1BR E-TAG).
- *
- * If two Vtags are specified:
- * * The Vtag 0 byte offset from packet start (see [VTAG0_RELPTR]) must be less
- * than or equal to the Vtag 1 byte offset.
- * * Hardware executes the Vtag 0 action first, Vtag 1 action second.
- * * If Vtag 0 is inserted, hardware adjusts the Vtag 1 byte offset accordingly.
- * Thus, if the two offsets are equal in the structure, hardware inserts Vtag 1
- * immediately after Vtag 0 in the packet.
- *
- * A Vtag must not be inserted or replaced within an outer or inner L3/L4 header,
- * but may be inserted or replaced within an outer L4 payload.
- */
-union cavm_nix_tx_vtag_action_s {
-	u64 u;
-	struct cavm_nix_tx_vtag_action_s_s {
-		u64 vtag0_relptr:8;	/**< [  7:  0] Vtag 0 relative pointer. Byte offset from start of selected layer to first
-                                                                 tag 0 byte. Must be even.
-
-                                                                 Note the layer pointers in NPC_RESULT_S are offset by 8 bytes to
-                                                                 account for NIX_INST_HDR_S, which precedes the packet header supplied to
-                                                                 NPC but is not included in the transmitted packet.
-                                                                 For example, if [VTAG0_LID] = NPC_LID_E::LB, then the byte offset from
-                                                                 packet start (excluding NIX_INST_HDR_S) to the first tag 0 byte is
-                                                                 NPC_RESULT_S[LB[LPTR]] - 8 + [VTAG0_RELPTR]. */
-		u64 vtag0_lid:3;	     /**< [ 10:  8] Vtag 0 layer ID enumerated by NPC_LID_E. */
-		u64 reserved_11:1;
-		u64 vtag0_op:2;	     /**< [ 13: 12] Vtag 0 operation enumerated by NIX_TX_VTAGOP_E. */
-		u64 reserved_14_15:2;
-		u64 vtag0_def:10;	     /**< [ 25: 16] Vtag 0 definition. Index to NIX_AF_TX_VTAG_DEF()_CTL/DATA entry that
-                                                                 defines the tag size and data to insert or replace. */
-		u64 reserved_26_31:6;
-		u64 vtag1_relptr:8;	/**< [ 39: 32] Vtag 1 relative pointer. See [VTAG0_RELPTR]. */
-		u64 vtag1_lid:3;	     /**< [ 42: 40] Vtag 1 layer ID enumerated by NPC_LID_E. */
-		u64 reserved_43:1;
-		u64 vtag1_op:2;	     /**< [ 45: 44] Vtag 1 operation enumerated by NIX_TX_VTAGOP_E. */
-		u64 reserved_46_47:2;
-		u64 vtag1_def:10;	     /**< [ 57: 48] Vtag 1 definition. Index to NIX_AF_TX_VTAG_DEF()_CTL/DATA entry that
-                                                                 defines the tag size and data to insert or replace. */
-		u64 reserved_58_63:6;
-	} s;
-	/* struct cavm_nix_tx_vtag_action_s_s cn; */
-};
-
-/**
- * Structure nix_wqe_hdr_s
- *
- * NIX Work Queue Entry Header Structure
- * This 64-bit structure defines the first word of every receive WQE generated by
- * NIX. It is immediately followed by NIX_RX_PARSE_S.
- * Stored in memory as little-endian unless NIX_AF_LF()_CFG[BE] is set.
- */
-union cavm_nix_wqe_hdr_s {
-	u64 u;
-	struct cavm_nix_wqe_hdr_s_s {
-		u64 tag:32;	     /**< [ 31:  0] The initial tag for the work-queue entry.
-                                                                 See pseudocode in NIX_RQ_CTX_S[LTAG]. */
-		u64 tt:2;		     /**< [ 33: 32] The initial tag type for the packet's SSO add work from
-                                                                 NIX_RQ_CTX_S[SSO_TT]. Enumerated by SSO_TT_E. */
-		u64 grp:10;	     /**< [ 43: 34] The SSO guest-group number used for the packet's add work from
-                                                                 NIX_RQ_CTX_S[SSO_GRP]. [GRP]\<9:8\> is always zero. */
-		u64 node:2;	     /**< [ 45: 44] Node number on which the packet was received or transmitted.
-                                                                 Internal:
-                                                                 This is needed by software; do not remove on single-node parts. */
-		u64 q:14;		     /**< [ 59: 46] Lower 14 bits of RQ or SQ within VF/PF. */
-		u64 wqe_type:4;	     /**< [ 63: 60] WQE type enumerated by NIX_XQE_TYPE_E. */
-	} s;
-	/* struct cavm_nix_wqe_hdr_s_s cn; */
-};
-
-/* Registers */
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_cfg
- *
- * NIX AF Admin Queue Configuration Register
- */
-union cavm_nixx_af_aq_cfg {
-	u64 u;
-	struct cavm_nixx_af_aq_cfg_s {
-		u64 qsize:4;		     /**< [  3:  0](R/W) Specifies AQ ring size in entries of 16 bytes:
-                                                                 0x0 = 16 entries.
-                                                                 0x1 = 64 entries.
-                                                                 0x2 = 256 entries.
-                                                                 0x3 = 1K entries.
-                                                                 0x4 = 4K entries.
-                                                                 0x5 = 16K entries.
-                                                                 0x6 = 64K entries.
-                                                                 0x7 = 256K entries.
-                                                                 0x8 = 1M entries.
-                                                                 0x9-0xF = Reserved.
-
-                                                                 Note that the usable size of the ring is the specified size minus 1 (HEAD==TAIL always
-                                                                 means empty). */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_aq_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_status
- *
- * NIX AF General Status Register
- */
-union cavm_nixx_af_status {
-	u64 u;
-	struct cavm_nixx_af_status_s {
-		u64 blk_busy:10;		     /**< [  9:  0](RO/H) If nonzero, block is not ready for configuration.
-                                                                 Internal:
-                                                                 Each bit corresponds to a subblock:
-                                                                 \<9\> = Reserved.
-                                                                 \<8\> = Reserved.
-                                                                 \<7\> = TBD.
-                                                                 \<6\> = TBD.
-                                                                 \<5\> = TBD.
-                                                                 \<4\> = TBD.
-                                                                 \<3\> = CQM.
-                                                                 \<2\> = PSE.
-                                                                 \<1\> = SEB.
-                                                                 \<0\> = SQM. */
-		u64 calibrate_done:1;	     /**< [ 10: 10](RO/H) Calibrate cycle is complete. */
-		u64 reserved_11_15:5;
-		u64 calibrate_status:5;	     /**< [ 20: 16](RO/H) X2P device calibration state.
-                                                                 0 = Device inactive.
-                                                                 1 = Device ready.
-
-                                                                 Internal:
-                                                                 a "Device Inactive" status means that the X2P agent did not respond to the calibration
-                                                                 cycle.
-                                                                 This is most likely caused because the X2P agents (CGX, LBK, etc) was in reset during the
-                                                                 calibration cycle. */
-		u64 reserved_21_63:43;
-	} s;
-	/* struct cavm_nixx_af_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_ndc_cfg
- *
- * NIX AF General Configuration Register
- */
-union cavm_nixx_af_ndc_cfg {
-	u64 u;
-	struct cavm_nixx_af_ndc_cfg_s {
-		u64 ndc_ign_pois:1;	/**< [  0:  0](R/W) Ignore poison responses from the NDC. */
-		u64 byp_sq:1;		/**< [  1:  1](R/W) Force all NIX_SQ_CTX_HW_S transactions to bypass NDC. */
-		u64 byp_sqb:1;		/**< [  2:  2](R/W) Force all SQB transactions to bypass NDC. */
-		u64 byp_cqs:1;		/**< [  3:  3](R/W) Force all NIX_CQ_CTX_S transactions to bypass NDC. */
-		u64 byp_cints:1;	/**< [  4:  4](R/W) Force all NIX_CINT_HW_S transactions to bypass NDC. */
-		u64 byp_dyno:1;		/**< [  5:  5](R/W) Force all RX IPSEC DYNO transactions to bypass NDC. */
-		u64 byp_mce:1;		/**< [  6:  6](R/W) Force all NIX_RX_MCE_S transactions to bypass NDC. */
-		u64 byp_rqc:1;		/**< [  7:  7](R/W) Force all NIX_RQ_CTX_HW_S transactions to bypass NDC. */
-		u64 byp_rsse:1;		/**< [  8:  8](R/W) Force all NIX_RSSE_S transactions to bypass NDC. */
-		u64 byp_mc_data:1;	/**< [  9:  9](R/W) Force all RX multicast packet data transactions to bypass NDC. */
-		u64 byp_mc_wqe:1;	/**< [ 10: 10](R/W) Force all RX multicast WQE transactions to bypass NDC. */
-		u64 byp_mr_data:1;	/**< [ 11: 11](R/W) Force all RX mirror packet data transactions to bypass NDC. */
-		u64 byp_mr_wqe:1;	/**< [ 12: 12](R/W) Force all RX mirror WQE transactions to bypass NDC. */
-		u64 byp_qints:1;	/**< [ 13: 13](R/W) Force all NIX_QINT_HW_S transactions to bypass NDC. */
-		u64 reserved_14_63:50;
-	} s;
-	/* struct cavm_nixx_af_ndc_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_const
- *
- * NIX AF Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_const {
-	u64 u;
-	struct cavm_nixx_af_const_s {
-		u64 cgx_lmac_channels:8;	     /**< [  7:  0](RO) Number of channels per CGX link/LMAC. */
-		u64 cgx_lmacs:4;		     /**< [ 11:  8](RO) Number of LMACs (links) per CGX. */
-		u64 num_cgx:4;		     /**< [ 15: 12](RO) Number of CGX interfaces enumerated in NIX_LINK_E. */
-		u64 lbk_channels:8;	     /**< [ 23: 16](RO) Number of channels per LBK interface/link. */
-		u64 lbk_to_nix0:6;		     /**< [ 29: 24](RO/H) Link number for transmitting loopback packets to NIX(0).
-                                                                 Value is NIX_LINK_E::LBK(0) for NIX(0) to NIX(0) loopback. */
-		u64 lbk_to_nix1:6;		     /**< [ 35: 30](RO/H) Reserved. */
-		u64 lbk_from_nix0:6;	     /**< [ 41: 36](RO/H) Link number that receives loopback packets transmitted by NIX(0).
-                                                                 Value is NIX_LINK_E::LBK(0) for NIX(0) to NIX(0) loopback. */
-		u64 lbk_from_nix1:6;	     /**< [ 47: 42](RO/H) Reserved. */
-		u64 links:8;		     /**< [ 55: 48](RO) Number of links enumerated by NIX_LINK_E, including the internal
-                                                                 RX multicast/mirror replay interface, NIX_LINK_E::MC. */
-		u64 reserved_56_63:8;
-	} s;
-	/* struct cavm_nixx_af_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_const1
- *
- * NIX AF Constants 1 Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_const1 {
-	u64 u;
-	struct cavm_nixx_af_const1_s {
-		u64 sdp_channels:12;	     /**< [ 11:  0](RO) Number of channels per SDP interface/link. */
-		u64 rx_bpids:12;		     /**< [ 23: 12](RO) Number of receive backpressure IDs. */
-		u64 lf_tx_stats:8;		     /**< [ 31: 24](RO) Number of per-LF transmit statistics counters enumerated by NIX_STAT_LF_TX_E. */
-		u64 lf_rx_stats:8;		     /**< [ 39: 32](RO) Number of per-LF receive statistics counters enumerated by NIX_STAT_LF_RX_E. */
-		u64 lso_format_fields:8;	     /**< [ 47: 40](RO) Number of packets fields per LSO format, each selected by FIELD index of
-                                                                 NIX_AF_LSO_FORMAT()_FIELD() registers. */
-		u64 lso_formats:8;		     /**< [ 55: 48](RO) Number of LSO formats, each selected by FORMAT index of
-                                                                 NIX_AF_LSO_FORMAT()_FIELD() registers. */
-		u64 reserved_56_63:8;
-	} s;
-	/* struct cavm_nixx_af_const1_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_const2
- *
- * NIX AF Constants 2 Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_const2 {
-	u64 u;
-	struct cavm_nixx_af_const2_s {
-		u64 lfs:12;		     /**< [ 11:  0](RO) Number of Local Functions. */
-		u64 qints:12;		     /**< [ 23: 12](RO) Number of queue interrupts per LF. */
-		u64 cints:12;		     /**< [ 35: 24](RO) Number of completion interrupts per LF. */
-		u64 reserved_36_63:28;
-	} s;
-	/* struct cavm_nixx_af_const2_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_const3
- *
- * NIX AF Constants 2 Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_const3 {
-	u64 u;
-	struct cavm_nixx_af_const3_s {
-		u64 sq_ctx_log2bytes:4;	     /**< [  3:  0](RO) SQ context size as log2(bytes). Size of each NIX_SQ_CTX_HW_S structure in a
-                                                                 local function's SQ context table NDC/LLC/DRAM. See NIX_AF_LF()_SQS_BASE
-                                                                 and NIX_AF_LF()_SQS_CFG. */
-		u64 rq_ctx_log2bytes:4;	     /**< [  7:  4](RO) RQ context size as log2(bytes). Size of each NIX_RQ_CTX_S structure in a
-                                                                 local function's RQ context table NDC/LLC/DRAM. See NIX_AF_LF()_RQS_BASE
-                                                                 and NIX_AF_LF()_RQS_CFG. */
-		u64 cq_ctx_log2bytes:4;	     /**< [ 11:  8](RO) CQ context size as log2(bytes). Size of each NIX_CQ_CTX_S structure in a
-                                                                 local function's CQ context table NDC/LLC/DRAM. See NIX_AF_LF()_CQS_BASE
-                                                                 and NIX_AF_LF()_CQS_CFG. */
-		u64 rsse_log2bytes:4;	     /**< [ 15: 12](RO) RSS entry size as log2(bytes). Size of each NIX_RSSE_S structure in a
-                                                                 local function's RSS table NDC/LLC/DRAM. See NIX_AF_LF()_RSS_BASE
-                                                                 and NIX_AF_LF()_RSS_CFG. */
-		u64 mce_log2bytes:4;	     /**< [ 19: 16](RO) Receive multicast/mirror entry size as log2(bytes). Size of each
-                                                                 NIX_RX_MCE_S structure in the AF multicast/mirror table NDC/LLC/DRAM. See
-                                                                 NIX_AF_RX_MCAST_BASE and NIX_AF_RX_MCAST_CFG. */
-		u64 qint_log2bytes:4;	     /**< [ 23: 20](RO) Queue interrupt context size as log2(bytes). Size of each NIX_QINT_HW_S
-                                                                 structure in a local function's queue interrupt context table NDC/LLC/DRAM.
-                                                                 See NIX_AF_LF()_QINTS_BASE and NIX_AF_LF()_QINTS_CFG. */
-		u64 cint_log2bytes:4;	     /**< [ 27: 24](RO) Completion interrupt context size as log2(bytes). Size of each
-                                                                 NIX_CINT_HW_S structure in a local function's completion interrupt context
-                                                                 table NDC/LLC/DRAM. See NIX_AF_LF()_CINTS_BASE and NIX_AF_LF()_CINTS_CFG. */
-		u64 dyno_log2bytes:4;	     /**< [ 31: 28](RO) IPSEC dynamic ordering counter size as log2(bytes). Size of each entry in a
-                                                                 local function's dynamic ordering (DYNO) counter table in NDC/LLC/DRAM. See
-                                                                 NIX_AF_LF()_RX_IPSEC_DYNO_BASE and NIX_AF_LF()_RX_IPSEC_DYNO_CFG. */
-		u64 dyno_array_log2counters:4;	/**< [ 35: 32](RO) IPSEC dynamic ordering counter array size as log2(counters). Size of
-                                                                 counter array accessed by the NIX admin queue when NIX_AQ_INST_S[CTYPE] =
-                                                                 NIX_AQ_CTYPE_E::DYNO. The size of the array in bytes is
-                                                                 1 \<\< ([DYNO_ARRAY_LOG2COUNTERS] + [DYNO_LOG2BYTES]). */
-		u64 reserved_36_63:28;
-	} s;
-	/* struct cavm_nixx_af_const3_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_sq_const
- *
- * NIX AF SQ Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_sq_const {
-	u64 u;
-	struct cavm_nixx_af_sq_const_s {
-		u64 queues_per_lf:24;	     /**< [ 23:  0](RO) Maximum number of send queues per LF. */
-		u64 smq_depth:10;		     /**< [ 33: 24](RO) Depth of each SMQ (number of meta descriptors). */
-		u64 sqb_size:16;		     /**< [ 49: 34](RO) Number of bytes in each hardware-allocated SQE buffer (SQB) in NDC/LLC/DRAM. */
-		u64 reserved_50_63:14;
-	} s;
-	/* struct cavm_nixx_af_sq_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_cq_const
- *
- * NIX AF CQ Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_cq_const {
-	u64 u;
-	struct cavm_nixx_af_cq_const_s {
-		u64 queues_per_lf:24;	     /**< [ 23:  0](RO) Maximum number of completion queues per LF. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_cq_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rq_const
- *
- * NIX AF RQ Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_rq_const {
-	u64 u;
-	struct cavm_nixx_af_rq_const_s {
-		u64 queues_per_lf:24;	     /**< [ 23:  0](RO) Maximum number of receive queues per LF. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_rq_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_pse_const
- *
- * NIX AF PSE Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_pse_const {
-	u64 u;
-	struct cavm_nixx_af_pse_const_s {
-		u64 levels:4;		     /**< [  3:  0](RO) Number of hierarchical transmit shaping levels. */
-		u64 reserved_4_7:4;
-		u64 mark_formats:8;	     /**< [ 15:  8](RO) Number of NIX_AF_MARK_FORMAT()_CTL registers. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_pse_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1_const
- *
- * NIX AF Transmit Level 1 Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_tl1_const {
-	u64 u;
-	struct cavm_nixx_af_tl1_const_s {
-		u64 count:16;		     /**< [ 15:  0](RO) Number of transmit level 1 shaping queues. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_tl1_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2_const
- *
- * NIX AF Transmit Level 2 Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_tl2_const {
-	u64 u;
-	struct cavm_nixx_af_tl2_const_s {
-		u64 count:16;		     /**< [ 15:  0](RO) Number of transmit level 2 shaping queues. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_tl2_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3_const
- *
- * NIX AF Transmit Level 3 Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_tl3_const {
-	u64 u;
-	struct cavm_nixx_af_tl3_const_s {
-		u64 count:16;		     /**< [ 15:  0](RO) Number of transmit level 3 shaping queues. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_tl3_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4_const
- *
- * NIX AF Transmit Level 4 Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_tl4_const {
-	u64 u;
-	struct cavm_nixx_af_tl4_const_s {
-		u64 count:16;		     /**< [ 15:  0](RO) Number of transmit level 4 shaping queues. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_tl4_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq_const
- *
- * NIX AF Meta Descriptor Queue Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_mdq_const {
-	u64 u;
-	struct cavm_nixx_af_mdq_const_s {
-		u64 count:16;		     /**< [ 15:  0](RO) Number of meta descriptor queues and SMQs. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_mdq_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mc_mirror_const
- *
- * NIX AF Multicast/Mirror Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_nixx_af_mc_mirror_const {
-	u64 u;
-	struct cavm_nixx_af_mc_mirror_const_s {
-		u64 buf_size:16;		     /**< [ 15:  0](RO) Size in bytes of multicast/mirror buffers in NDC/LLC/DRAM. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_mc_mirror_const_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lso_cfg
- *
- * NIX AF Large Send Offload Configuration Register
- */
-union cavm_nixx_af_lso_cfg {
-	u64 u;
-	struct cavm_nixx_af_lso_cfg_s {
-		u64 tcp_lsf:16;		     /**< [ 15:  0](R/W) TCP last segment flags mask. Same as [TCP_FSF] but used for the last
-                                                                 packet/segment of an LSO descriptor. */
-		u64 tcp_msf:16;		     /**< [ 31: 16](R/W) TCP middle segment flags mask. Same as [TCP_FSF] but used for LSO
-                                                                 packets/segments other than the first and last segments of an LSO
-                                                                 descriptor. */
-		u64 tcp_fsf:16;		     /**< [ 47: 32](R/W) TCP first segment flags mask. Used for the first packet/segment of an LSO
-                                                                 descriptor when NIX_AF_LSO_FORMAT()_FIELD()[ALG] = NIX_LSOALG_E::TCP_FLAGS.
-                                                                 The selected 16-bit field, typically consisting of the TCP data offset and
-                                                                 TCP flags, is modified as follows:
-
-                                                                 _ FIELD_new = (FIELD_original) AND [TCP_FSF].
-
-                                                                 The upper four bits are typically 0xF in order to keep the original TCP data
-                                                                 offset value.
-
-                                                                 If the LSO descriptor only sends one packet/segment, the selected 16-bit
-                                                                 field is modified as follows:
-                                                                 _ FIELD_new = (FIELD_original) AND ([TCP_FSF] OR [TCP_LSF]). */
-		u64 reserved_48_62:14;
-		u64 enable:1;		     /**< [ 63: 63](R/W) Large send offload enable. When clear, NIX ignores NIX_SEND_EXT_S[LSO] and treats
-                                                                 all send descriptors as non-LSO. */
-	} s;
-	/* struct cavm_nixx_af_lso_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_bar2_alias#
- *
- * INTERNAL: NIX Admin Function  BAR2 Alias Registers
- *
- * These registers alias to the NIX BAR2 registers for the PF and function
- * selected by NIX_AF_BAR2_SEL[PF_FUNC].
- *
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_nixx_af_bar2_aliasx {
-	u64 u;
-	struct cavm_nixx_af_bar2_aliasx_s {
-		u64 data:64; /**< [ 63:  0](R/W/H) Aliased register data. */
-	} s;
-	/* struct cavm_nixx_af_bar2_aliasx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_bar2_sel
- *
- * INTERNAL: NIX Admin Function BAR2 Select Register
- *
- * This register configures BAR2 accesses from the NIX_AF_BAR2_ALIAS() registers in BAR0.
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_nixx_af_bar2_sel {
-	u64 u;
-	struct cavm_nixx_af_bar2_sel_s {
-		u64 alias_pf_func:16;		/**< [ 15:  0](R/W) PF and function whose BAR2 registers may be accessed from the AF BAR2 alias
-                                                                 registers. Format specified by RVU_PF_FUNC_S. */
-		u64 alias_ena:1;		/**< [ 16: 16](R/W) Enable BAR2 register accesses from the AF BAR2 alias registers in BAR0. */
-		u64 reserved_17_63:47;
-	} s;
-	/* struct cavm_nixx_af_bar2_sel_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_blk_rst
- *
- * NIX AF Block Reset Register
- */
-union cavm_nixx_af_blk_rst {
-	u64 u;
-	struct cavm_nixx_af_blk_rst_s {
-		u64 rst:1;			     /**< [  0:  0](WO/H) Write one to reset the block, except for privileged AF registers in PF BAR0
-                                                                 (block_PRIV_*). Software must ensure that all block activity is quiesced before
-                                                                 writing 1. */
-		u64 reserved_1_62:62;
-		u64 busy:1;		     /**< [ 63: 63](RO/H) When one, the block is busy completing reset. No access except the reading of
-                                                                 this bit should occur to the block until this is clear. */
-	} s;
-	/* struct cavm_nixx_af_blk_rst_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_cfg
- *
- * NIX AF General Configuration Register
- */
-union cavm_nixx_af_cfg {
-	u64 u;
-	struct cavm_nixx_af_cfg_s {
-		u64 force_cond_clk_en:1;/**< [  0:  0](R/W) Force the conditional clocks active within the block. For diagnostic use only. */
-		u64 af_be:1;		/**< [  1:  1](R/W) Admin function big-endian select. Specifies endianness of all admin queue
-                                                                 instructions, results and associated structures stored in LLC/DRAM:
-
-                                                                 0 = Little-endian. All AF software data structures are in byte invariant
-                                                                 little-endian format (LE8) with the following ordering within each 64-bit
-                                                                 word: \<7:0\> at byte address 0, \<15:8\> at address 1, ..., \<63:56\> at address
-                                                                 0x7.
-
-                                                                 1 = Big-endian. All AF software data structures are in byte invariant
-                                                                 big-endian format (BE8) with the following ordering within each 64-bit
-                                                                 word: \<63:56\> at byte address 0, \<55:48\> at address 1, ..., \<7:0\> at
-                                                                 address 0x7.
-
-                                                                 The affected data structures are:
-                                                                 * NIX_AQ_INST_S.
-                                                                 * NIX_AQ_RES_S.
-                                                                 * Context read/write data following NIX_AQ_RES_S. */
-		u64 calibrate_x2p:1;	/**< [  2:  2](R/W) Calibrate X2P bus. Writing this bit from zero to one starts a calibration cycle.
-                                                                 Software may then monitor the NIX_AF_STATUS[CALIBRATE_DONE] bit for completion,
-                                                                 and clear this bit. */
-		u64 force_intf_clk_en:1;/**< [  3:  3](R/W) Force the conditional clocks on interface signals between blocks. For diagnostic use only. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_tstmp_cfg
- *
- * NIX AF Transmit Timestamp Configuration Register
- */
-union cavm_nixx_af_tx_tstmp_cfg {
-	u64 u;
-	struct cavm_nixx_af_tx_tstmp_cfg_s {
-		u64 tstmp_wd_period:4;	     /**< [  3:  0](R/W) Watchdog timeout count for send timestamp capture. See
-                                                                 NIX_SEND_EXT_S[TSTMP] and NIX_SENDMEMALG_E::SETTSTMP.
-
-                                                                 The timeout period is 4*(2^[TSTMP_WD_PERIOD]) timer ticks, where each tick
-                                                                 is 128 cycles of the 100 MHz reference clock: 0 = 4 ticks, 1 = 8 ticks, ...
-                                                                 15 = 131072 ticks. */
-		u64 reserved_4_7:4;
-		u64 express:16;		     /**< [ 23:  8](R/W) One bit per CGX LMAC, enumerated by NIX_LINK_E::CGX()_LMAC(). When a bit is
-                                                                 set, only express packets to the LMAC are allowed to request PTP
-                                                                 timestamps. When a bit is clear, only normal packets to the LMAC are
-                                                                 allowed to request PTP timestamps. See NIX_SENDMEMALG_E::SETTSTMP. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tx_tstmp_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_cfg
- *
- * NIX AF Receive Configuration Register
- */
-union cavm_nixx_af_rx_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_cfg_s {
-		u64 cbp_ena:1;		     /**< [  0:  0](R/W) Channel backpressure enable. Software should set this bit before any
-                                                                 NIX_AF_RX_CHAN()_CFG[BP_ENA] is set, and must not clear it unless all
-                                                                 NIX_AF_RX_CHAN()_CFG[BP_ENA] are clear for at least 10 microseconds.
-
-                                                                 Internal:
-                                                                 Enables sending of X2P backpressure. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_avg_delay
- *
- * NIX AF Queue Average Delay Register
- */
-union cavm_nixx_af_avg_delay {
-	u64 u;
-	struct cavm_nixx_af_avg_delay_s {
-		u64 avg_dly:19;		     /**< [ 18:  0](R/W) Average-queue-size delay. [AVG_DLY]+1 is the number of microseconds per
-                                                                 timer tick for calculating the moving average for each CQ level. Note the
-                                                                 minimum of one microsecond implies that at 100 M packets/sec, approximately
-                                                                 100 packets may arrive between average calculations.
-
-                                                                 Larger [AVG_DLY] causes the moving averages of all CQ levels to track
-                                                                 changes in the actual free space more slowly. Larger NIX_CQ_CTX_S[AVG_CON])
-                                                                 values causes a specific CQ to track more slowly, but only affects an
-                                                                 individual level, rather than all. */
-		u64 reserved_19_23:5;
-		u64 avg_timer:16;		     /**< [ 39: 24](R/W/H) Running counter that is incremented every [AVG_DLY]+1 microseconds. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_avg_delay_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_cint_delay
- *
- * NIX AF Completion Interrupt Delay Register
- */
-union cavm_nixx_af_cint_delay {
-	u64 u;
-	struct cavm_nixx_af_cint_delay_s {
-		u64 cint_dly:10;		     /**< [  9:  0](R/W) Completion interrupt timer delay. ([CINT_DLY]+1)*100 is the number
-                                                                 of nanoseconds per timer tick for completion interrupts. */
-		u64 reserved_10_15:6;
-		u64 cint_timer:16;		     /**< [ 31: 16](R/W/H) Completion interrupt timer clock. Running counter that is
-                                                                 incremented every ([CINT_DLY]+1)*100 nanoseconds. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_cint_delay_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mcast_base
- *
- * NIX AF Receive Multicast/Mirror Table Base Address Register
- * This register specifies the base AF IOVA of the receive multicast/mirror
- * table in NDC/LLC/DRAM. The table consists of 1 << (NIX_AF_RX_MCAST_CFG[SIZE]+8)
- * contiguous NIX_RX_MCE_S structures. The size of each structure is
- * 1 << NIX_AF_CONST3[MCE_LOG2BYTES] bytes.
- *
- * The table contains multicast/mirror replication lists. Each list consists of
- * linked entries with NIX_RX_MCE_S[EOL] = 1 in the last entry. All lists
- * must reside within the table size specified by NIX_AF_RX_MCAST_CFG[SIZE]. A
- * mirror replication list will typically consist of two entries, but that is not
- * checked or enforced by hardware.
- *
- * A receive packet is multicast when the action returned by NPC has
- * NIX_RX_ACTION_S[OP] = NIX_RX_ACTIONOP_E::MCAST.
- * A receive packet is mirrored when the action returned by NPC has
- * NIX_RX_ACTION_S[OP] = NIX_RX_ACTIONOP_E::MIRROR.
- * In both cases, NIX_RX_ACTION_S[INDEX] specifies the index of the replication
- * list's first NIX_RX_MCE_S in the table, and a linked entry with
- * NIX_RX_MCE_S[EOL] = 1 indicates the end of list.
- *
- * If a mirrored flow is part of a multicast replication list, software should
- * include the two mirror entries in that list.
- *
- * Internal:
- * A multicast list may have multiple entries for the same LF (e.g. for future
- * RoCE/IB multicast).
- */
-union cavm_nixx_af_rx_mcast_base {
-	u64 u;
-	struct cavm_nixx_af_rx_mcast_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_rx_mcast_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mcast_cfg
- *
- * NIX AF Receive Multicast/Mirror Table Configuration Register
- * See NIX_AF_RX_MCAST_BASE.
- */
-union cavm_nixx_af_rx_mcast_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_mcast_cfg_s {
-		u64 size:4;		     /**< [  3:  0](R/W) Specifies table size in NIX_RX_MCE_S entries of eight bytes:
-                                                                 0x0 = 256 entries.
-                                                                 0x1 = 512 entries.
-                                                                 0x2 = 1K entries.
-                                                                 0x3 = 2K entries.
-                                                                 0x4 = 4K entries.
-                                                                 0x5 = 8K entries.
-                                                                 0x6 = 16K entries.
-                                                                 0x7 = 32K entries.
-                                                                 0x8 = 64K entries.
-                                                                 0x9-0xF = Reserved. */
-		u64 max_list_lenm1:8;	     /**< [ 11:  4](R/W) Maximum list length minus 1. If a multicast or mirror replication list exceeds this
-                                                                 length (e.g. due to a loop in the NIX_RX_MCE_S link list), hardware
-                                                                 terminates the list and sets NIX_AF_ERR_INT[RX_MCE_LIST_ERR]. */
-		u64 reserved_12_19:8;
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating NIX_RX_MCE_S structures in NDC (1
-                                                                 means do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of read for accessing NIX_RX_MCE_S structures in
-                                                                 LLC/DRAM:
-                                                                 0 = NIX_RX_MCE_S reads will not allocate into the LLC.
-                                                                 1 = NIX_RX_MCE_S reads are allocated into the LLC.
-
-                                                                 NIX_RX_MCE_S writes that are not allocated in NDC will always allocate into
-                                                                 LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_rx_mcast_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mcast_buf_base
- *
- * NIX AF Receive Multicast Buffer Base Address Register
- * This register specifies the base AF IOVA of the receive multicast
- * buffers in NDC/LLC/DRAM. These buffers are used to temporarily store packets
- * whose action returned by NPC has NIX_RX_ACTION_S[OP] =
- * NIX_RX_ACTIONOP_E::MCAST. The number of buffers is configured by
- * NIX_AF_RX_MCAST_BUF_CFG[SIZE].
- *
- * If the number of free buffers is insufficient for a received multicast packet,
- * hardware tail drops the packet and sets NIX_AF_GEN_INT[RX_MCAST_DROP].
- *
- * Hardware prioritizes the processing of RX mirror packets over RX multicast
- * packets.
- */
-union cavm_nixx_af_rx_mcast_buf_base {
-	u64 u;
-	struct cavm_nixx_af_rx_mcast_buf_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of buffer in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_rx_mcast_buf_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mcast_buf_cfg
- *
- * NIX AF Receive Multicast Buffer Configuration Register
- * See NIX_AF_RX_MCAST_BUF_BASE.
- */
-union cavm_nixx_af_rx_mcast_buf_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_mcast_buf_cfg_s {
-		u64 size:4;		     /**< [  3:  0](R/W) Total number of buffers of size NIX_AF_MC_MIRROR_CONST[BUF_SIZE]:
-                                                                 0x0 = 8 buffers.
-                                                                 0x1 = 16 buffers.
-                                                                 0x2 = 32 buffers.
-                                                                 0x3 = 64 buffers.
-                                                                 0x4 = 128 buffers.
-                                                                 0x5 = 256 buffers.
-                                                                 0x6 = 512 buffers.
-                                                                 0x7 = 1024 buffers.
-                                                                 0x8 = 2048 buffers.
-                                                                 0x9-0xF = Reserved. */
-		u64 way_mask:16;		     /**< [ 19:  4](R/W) Way partitioning mask for allocating buffer data in NDC (1 means do not
-                                                                 use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 20: 20](R/W) Selects the style of write and read to the LLC.
-                                                                 0 = Writes and reads of buffer data will not allocate into the LLC.
-                                                                 1 = Writes and reads of buffer data are allocated into the LLC. */
-		u64 reserved_21_23:3;
-		u64 npc_replay_pkind:6;	     /**< [ 29: 24](R/W) Packet kind used on NPC request interface for all replayed copies of a
-                                                                 multicasted packet. The NIX_RX_PARSE_S[PKIND] field for the replayed copies will
-                                                                 be the original ingress PKIND. */
-		u64 reserved_30_31:2;
-		u64 free_buf_level:11;	     /**< [ 42: 32](RO/H) Free buffer level. Number of available free buffers (out of the total
-                                                                 [SIZE]). */
-		u64 reserved_43_62:20;
-		u64 ena:1;			     /**< [ 63: 63](R/W) Multicast buffer enable.
-                                                                 0 = All new incoming MC packets will get discarded. Software should
-                                                                 wait until all MC packets in flight are played out before re-enabling [ENA].
-                                                                 1 = The temporary memory defined in NIX_AF_RX_MCAST_BUF_CFG[SIZE] is
-                                                                 divided into equal size buffers as defined by NIX_AF_MC_MIRROR_CONST[BUF_SIZE]. */
-	} s;
-	/* struct cavm_nixx_af_rx_mcast_buf_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mirror_buf_base
- *
- * NIX AF Receive Mirror Buffer Base Address Register
- * This register specifies the base AF IOVA of the receive mirror buffers
- * in NDC/LLC/DRAM. These buffers are used to temporarily store packets whose
- * action returned by NPC has NIX_RX_ACTION_S[OP] = NIX_RX_ACTIONOP_E::MIRROR. The
- * number of buffers is configured by NIX_AF_RX_MIRROR_BUF_CFG[SIZE].
- *
- * If the number of free buffers is insufficient for a received multicast packet,
- * hardware tail drops the packet and sets NIX_AF_GEN_INT[RX_MIRROR_DROP].
- *
- * Hardware prioritizes the processing of RX mirror packets over RX multicast
- * packets.
- */
-union cavm_nixx_af_rx_mirror_buf_base {
-	u64 u;
-	struct cavm_nixx_af_rx_mirror_buf_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of buffer in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_rx_mirror_buf_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_mirror_buf_cfg
- *
- * NIX AF Receive Mirror Buffer Configuration Register
- * See NIX_AF_RX_MIRROR_BUF_BASE.
- */
-union cavm_nixx_af_rx_mirror_buf_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_mirror_buf_cfg_s {
-		u64 size:4;		     /**< [  3:  0](R/W) Total number of buffers of size NIX_AF_MC_MIRROR_CONST[BUF_SIZE]:
-                                                                 0x0 = 8 buffers.
-                                                                 0x1 = 16 buffers.
-                                                                 0x2 = 32 buffers.
-                                                                 0x3 = 64 buffers.
-                                                                 0x4 = 128 buffers.
-                                                                 0x5 = 256 buffers.
-                                                                 0x6 = 512 buffers.
-                                                                 0x7 = 1024 buffers.
-                                                                 0x8 = 2048 buffers.
-                                                                 0x9-0xF = Reserved. */
-		u64 way_mask:16;		     /**< [ 19:  4](R/W) Way partitioning mask for allocating buffer data in NDC (1 means do not
-                                                                 use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 20: 20](R/W) Selects the style of write and read to the LLC.
-                                                                 0 = Writes and reads of buffer data will not allocate into the LLC.
-                                                                 1 = Writes and reads of buffer data are allocated into the LLC. */
-		u64 reserved_21_23:3;
-		u64 npc_replay_pkind:6;	     /**< [ 29: 24](R/W) Packet kind used on NPC request interface for all replayed copies of a
-                                                                 multicasted packet. The NIX_RX_PARSE_S[PKIND] field for the replayed copies will
-                                                                 be the original ingress PKIND. */
-		u64 reserved_30_31:2;
-		u64 free_buf_level:11;	     /**< [ 42: 32](RO/H) Free buffer level. Number of available free buffers (out of the total
-                                                                 [SIZE]). */
-		u64 reserved_43_62:20;
-		u64 ena:1;			     /**< [ 63: 63](R/W) Multicast buffer enable.
-                                                                 0 = All new incoming MC packets will get discarded. Software should
-                                                                 wait until all MC packets in flight are played out before re-enabling [ENA].
-                                                                 1 = The temporary memory defined in NIX_AF_RX_MCAST_BUF_CFG[SIZE] is
-                                                                 divided into equal size buffers as defined by NIX_AF_MC_MIRROR_CONST[BUF_SIZE]. */
-	} s;
-	/* struct cavm_nixx_af_rx_mirror_buf_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf_rst
- *
- * NIX Admin Function LF Reset Register
- */
-union cavm_nixx_af_lf_rst {
-	u64 u;
-	struct cavm_nixx_af_lf_rst_s {
-		u64 lf:8;			     /**< [  7:  0](R/W) Local function that is reset when [EXEC] is set. */
-		u64 reserved_8_11:4;
-		u64 exec:1;		     /**< [ 12: 12](R/W1S/H) Execute LF reset. When software writes a one to set this bit, hardware
-                                                                 resets the local function selected by [LF]. Hardware clears this bit when
-                                                                 done.
-
-                                                                 Internal:
-                                                                 This comment applies to all blocks that refer to this register:
-
-                                                                 This should preferrably reset all registers/state associated with the LF, including
-                                                                 any BLK_LF_* and BLK_AF_LF()_* registers. It would also be nice to reset any per-LF
-                                                                 bits in other registers but its OK to have exceptions as long as the AF software has
-                                                                 another way to reset them, e.g. by writing to the bits. Such additional steps
-                                                                 expected from software should be documented in the HRM, e.g. in section 19.11.5
-                                                                 "VF Function Level Reset". */
-		u64 reserved_13_63:51;
-	} s;
-	/* struct cavm_nixx_af_lf_rst_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_gen_int
- *
- * NIX AF General Interrupt Register
- */
-union cavm_nixx_af_gen_int {
-	u64 u;
-	struct cavm_nixx_af_gen_int_s {
-		u64 rx_mcast_drop:1;	     /**< [  0:  0](R/W1C/H) Receive multicast packet dropped due to insufficient space in the RX
-                                                                 multicast buffer specified by NIX_AF_RX_MCAST_BUF_BASE and
-                                                                 NIX_AF_RX_MCAST_BUF_CFG. */
-		u64 rx_mirror_drop:1;	     /**< [  1:  1](R/W1C/H) Receive mirror packet dropped due to insufficient space in the RX mirror
-                                                                 buffer specified by NIX_AF_RX_MIRROR_BUF_BASE and NIX_AF_RX_MIRROR_BUF_CFG. */
-		u64 reserved_2:1;
-		u64 tl1_drain:1;		     /**< [  3:  3](R/W1C/H) Set when a NIX_AF_MDQ()_SW_XOFF[DRAIN,DRAIN_IRQ] or
-                                                                 NIX_AF_TL*()_SW_XOFF[DRAIN,DRAIN_IRQ] command reaches the TL1 level. */
-		u64 smq_flush_done:1;	     /**< [  4:  4](R/W1C/H) SMQ flush done. Set when an SMQ flush operation initiated by
-                                                                 NIX_AF_SMQ()_CFG[FLUSH] is complete. */
-		u64 reserved_5_63:59;
-	} s;
-	/* struct cavm_nixx_af_gen_int_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_gen_int_w1s
- *
- * NIX AF General Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_af_gen_int_w1s {
-	u64 u;
-	struct cavm_nixx_af_gen_int_w1s_s {
-		u64 rx_mcast_drop:1;	     /**< [  0:  0](R/W1S/H) Reads or sets NIX_AF_GEN_INT[RX_MCAST_DROP]. */
-		u64 rx_mirror_drop:1;	     /**< [  1:  1](R/W1S/H) Reads or sets NIX_AF_GEN_INT[RX_MIRROR_DROP]. */
-		u64 reserved_2:1;
-		u64 tl1_drain:1;		     /**< [  3:  3](R/W1S/H) Reads or sets NIX_AF_GEN_INT[TL1_DRAIN]. */
-		u64 smq_flush_done:1;	     /**< [  4:  4](R/W1S/H) Reads or sets NIX_AF_GEN_INT[SMQ_FLUSH_DONE]. */
-		u64 reserved_5_63:59;
-	} s;
-	/* struct cavm_nixx_af_gen_int_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_gen_int_ena_w1s
- *
- * NIX AF General Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_af_gen_int_ena_w1s {
-	u64 u;
-	struct cavm_nixx_af_gen_int_ena_w1s_s {
-		u64 rx_mcast_drop:1;	     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_AF_GEN_INT[RX_MCAST_DROP]. */
-		u64 rx_mirror_drop:1;	     /**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_AF_GEN_INT[RX_MIRROR_DROP]. */
-		u64 reserved_2:1;
-		u64 tl1_drain:1;		     /**< [  3:  3](R/W1S/H) Reads or sets enable for NIX_AF_GEN_INT[TL1_DRAIN]. */
-		u64 smq_flush_done:1;	     /**< [  4:  4](R/W1S/H) Reads or sets enable for NIX_AF_GEN_INT[SMQ_FLUSH_DONE]. */
-		u64 reserved_5_63:59;
-	} s;
-	/* struct cavm_nixx_af_gen_int_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_gen_int_ena_w1c
- *
- * NIX AF General Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_af_gen_int_ena_w1c {
-	u64 u;
-	struct cavm_nixx_af_gen_int_ena_w1c_s {
-		u64 rx_mcast_drop:1;	     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_AF_GEN_INT[RX_MCAST_DROP]. */
-		u64 rx_mirror_drop:1;	     /**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_AF_GEN_INT[RX_MIRROR_DROP]. */
-		u64 reserved_2:1;
-		u64 tl1_drain:1;		     /**< [  3:  3](R/W1C/H) Reads or clears enable for NIX_AF_GEN_INT[TL1_DRAIN]. */
-		u64 smq_flush_done:1;	     /**< [  4:  4](R/W1C/H) Reads or clears enable for NIX_AF_GEN_INT[SMQ_FLUSH_DONE]. */
-		u64 reserved_5_63:59;
-	} s;
-	/* struct cavm_nixx_af_gen_int_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_err_int
- *
- * NIX Admin Function Error Interrupt Register
- */
-union cavm_nixx_af_err_int {
-	u64 u;
-	struct cavm_nixx_af_err_int_s {
-		u64 rx_mcast_data_fault:1;	     /**< [  0:  0](R/W1C/H) Memory fault on packet data or WQE write to a multicast buffer. */
-		u64 rx_mirror_data_fault:1;	/**< [  1:  1](R/W1C/H) Memory fault on packet data or WQE write to a mirror buffer. */
-		u64 rx_mcast_wqe_fault:1;	     /**< [  2:  2](R/W1C/H) Memory fault on WQE read from a mirror buffer. */
-		u64 rx_mirror_wqe_fault:1;	     /**< [  3:  3](R/W1C/H) Memory fault on WQE read from a multicast buffer. */
-		u64 rx_mce_fault:1;	     /**< [  4:  4](R/W1C/H) Memory fault on NIX_RX_MCE_S read. */
-		u64 rx_mce_list_err:1;	     /**< [  5:  5](R/W1C/H) Receive multicast/mirror replication list error. One of the following (may
-                                                                 not be exhaustive):
-                                                                 * The length of a multicast or mirror replication list exceeds
-                                                                 NIX_AF_RX_MCAST_CFG[MAX_LIST_LENM1]+1.
-                                                                 * Invalid opcode in NIX_RX_MCE_S[OP].
-                                                                 * NIX_RX_MCE_S[NEXT] pointer outside of table size specified by
-                                                                 NIX_AF_RX_MCAST_CFG[SIZE]. */
-		u64 reserved_6_11:6;
-		u64 aq_door_err:1;		     /**< [ 12: 12](R/W1C/H) AQ doorbell error. See NIX_AF_AQ_DOOR[COUNT]. Hardware also sets
-                                                                 NIX_AF_AQ_STATUS[AQ_ERR]. */
-		u64 aq_res_fault:1;	     /**< [ 13: 13](R/W1C/H) Memory fault on NIX_AQ_RES_S write, or on read/write data following
-                                                                 NIX_AQ_RES_S. Hardware also sets NIX_AF_AQ_STATUS[AQ_ERR]. */
-		u64 aq_inst_fault:1;	     /**< [ 14: 14](R/W1C/H) Memory fault on NIX_AQ_INST_S read. Hardware also sets
-                                                                 NIX_AF_AQ_STATUS[AQ_ERR]. */
-		u64 reserved_15_63:49;
-	} s;
-	/* struct cavm_nixx_af_err_int_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_err_int_w1s
- *
- * NIX Admin Function Error Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_af_err_int_w1s {
-	u64 u;
-	struct cavm_nixx_af_err_int_w1s_s {
-		u64 rx_mcast_data_fault:1;	     /**< [  0:  0](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MCAST_DATA_FAULT]. */
-		u64 rx_mirror_data_fault:1;	/**< [  1:  1](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MIRROR_DATA_FAULT]. */
-		u64 rx_mcast_wqe_fault:1;	     /**< [  2:  2](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MCAST_WQE_FAULT]. */
-		u64 rx_mirror_wqe_fault:1;	     /**< [  3:  3](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MIRROR_WQE_FAULT]. */
-		u64 rx_mce_fault:1;	     /**< [  4:  4](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MCE_FAULT]. */
-		u64 rx_mce_list_err:1;	     /**< [  5:  5](R/W1S/H) Reads or sets NIX_AF_ERR_INT[RX_MCE_LIST_ERR]. */
-		u64 reserved_6_11:6;
-		u64 aq_door_err:1;		     /**< [ 12: 12](R/W1S/H) Reads or sets NIX_AF_ERR_INT[AQ_DOOR_ERR]. */
-		u64 aq_res_fault:1;	     /**< [ 13: 13](R/W1S/H) Reads or sets NIX_AF_ERR_INT[AQ_RES_FAULT]. */
-		u64 aq_inst_fault:1;	     /**< [ 14: 14](R/W1S/H) Reads or sets NIX_AF_ERR_INT[AQ_INST_FAULT]. */
-		u64 reserved_15_63:49;
-	} s;
-	/* struct cavm_nixx_af_err_int_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_err_int_ena_w1s
- *
- * NIX Admin Function Error Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_af_err_int_ena_w1s {
-	u64 u;
-	struct cavm_nixx_af_err_int_ena_w1s_s {
-		u64 rx_mcast_data_fault:1;	     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MCAST_DATA_FAULT]. */
-		u64 rx_mirror_data_fault:1;	/**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MIRROR_DATA_FAULT]. */
-		u64 rx_mcast_wqe_fault:1;	     /**< [  2:  2](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MCAST_WQE_FAULT]. */
-		u64 rx_mirror_wqe_fault:1;	     /**< [  3:  3](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MIRROR_WQE_FAULT]. */
-		u64 rx_mce_fault:1;	     /**< [  4:  4](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MCE_FAULT]. */
-		u64 rx_mce_list_err:1;	     /**< [  5:  5](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[RX_MCE_LIST_ERR]. */
-		u64 reserved_6_11:6;
-		u64 aq_door_err:1;		     /**< [ 12: 12](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[AQ_DOOR_ERR]. */
-		u64 aq_res_fault:1;	     /**< [ 13: 13](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[AQ_RES_FAULT]. */
-		u64 aq_inst_fault:1;	     /**< [ 14: 14](R/W1S/H) Reads or sets enable for NIX_AF_ERR_INT[AQ_INST_FAULT]. */
-		u64 reserved_15_63:49;
-	} s;
-	/* struct cavm_nixx_af_err_int_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_err_int_ena_w1c
- *
- * NIX Admin Function Error Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_af_err_int_ena_w1c {
-	u64 u;
-	struct cavm_nixx_af_err_int_ena_w1c_s {
-		u64 rx_mcast_data_fault:1;	     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MCAST_DATA_FAULT]. */
-		u64 rx_mirror_data_fault:1;	/**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MIRROR_DATA_FAULT]. */
-		u64 rx_mcast_wqe_fault:1;	     /**< [  2:  2](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MCAST_WQE_FAULT]. */
-		u64 rx_mirror_wqe_fault:1;	     /**< [  3:  3](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MIRROR_WQE_FAULT]. */
-		u64 rx_mce_fault:1;	     /**< [  4:  4](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MCE_FAULT]. */
-		u64 rx_mce_list_err:1;	     /**< [  5:  5](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[RX_MCE_LIST_ERR]. */
-		u64 reserved_6_11:6;
-		u64 aq_door_err:1;		     /**< [ 12: 12](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[AQ_DOOR_ERR]. */
-		u64 aq_res_fault:1;	     /**< [ 13: 13](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[AQ_RES_FAULT]. */
-		u64 aq_inst_fault:1;	     /**< [ 14: 14](R/W1C/H) Reads or clears enable for NIX_AF_ERR_INT[AQ_INST_FAULT]. */
-		u64 reserved_15_63:49;
-	} s;
-	/* struct cavm_nixx_af_err_int_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_ras
- *
- * NIX AF RAS Interrupt Register
- * This register is intended for delivery of RAS events to the SCP, so should be
- * ignored by OS drivers.
- */
-union cavm_nixx_af_ras {
-	u64 u;
-	struct cavm_nixx_af_ras_s {
-		u64 rx_mce_poison:1;	     /**< [  0:  0](R/W1C/H) Poisoned data returned on NIX_RX_MCE_S read. */
-		u64 rx_mcast_wqe_poison:1;	     /**< [  1:  1](R/W1C/H) Poisoned data returned on WQE read from a multicast buffer. */
-		u64 rx_mirror_wqe_poison:1;	/**< [  2:  2](R/W1C/H) Poisoned data returned on WQE read from a mirror buffer. */
-		u64 rx_mcast_data_poison:1;	/**< [  3:  3](R/W1C/H) Poisoned data returned on packet data read from a multicast buffer. */
-		u64 rx_mirror_data_poison:1;	/**< [  4:  4](R/W1C/H) Poisoned data returned on packet data read from a mirror buffer. */
-		u64 reserved_5_31:27;
-		u64 aq_ctx_poison:1;	     /**< [ 32: 32](R/W1C/H) Poisoned data returned on read of hardware context data selected by
-                                                                 NIX_AQ_INST_S[LF,CTYPE,CINDEX]. If NIX_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware
-                                                                 also returns NIX_AQ_RES_S[COMPCODE] = NIX_AQ_COMP_E::CTX_POISON. */
-		u64 aq_res_poison:1;	     /**< [ 33: 33](R/W1C/H) Poisoned read data returned following NIX_AQ_RES_S. If
-                                                                 NIX_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware also sets
-                                                                 NIX_AF_AQ_STATUS[AQ_ERR]. */
-		u64 aq_inst_poison:1;	     /**< [ 34: 34](R/W1C/H) Poisoned data returned on NIX_AQ_INST_S read. If
-                                                                 NIX_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware also sets
-                                                                 NIX_AF_AQ_STATUS[AQ_ERR]. */
-		u64 reserved_35_63:29;
-	} s;
-	/* struct cavm_nixx_af_ras_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_ras_w1s
- *
- * NIX AF RAS Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_af_ras_w1s {
-	u64 u;
-	struct cavm_nixx_af_ras_w1s_s {
-		u64 rx_mce_poison:1;	     /**< [  0:  0](R/W1S/H) Reads or sets NIX_AF_RAS[RX_MCE_POISON]. */
-		u64 rx_mcast_wqe_poison:1;	     /**< [  1:  1](R/W1S/H) Reads or sets NIX_AF_RAS[RX_MCAST_WQE_POISON]. */
-		u64 rx_mirror_wqe_poison:1;	/**< [  2:  2](R/W1S/H) Reads or sets NIX_AF_RAS[RX_MIRROR_WQE_POISON]. */
-		u64 rx_mcast_data_poison:1;	/**< [  3:  3](R/W1S/H) Reads or sets NIX_AF_RAS[RX_MCAST_DATA_POISON]. */
-		u64 rx_mirror_data_poison:1;	/**< [  4:  4](R/W1S/H) Reads or sets NIX_AF_RAS[RX_MIRROR_DATA_POISON]. */
-		u64 reserved_5_31:27;
-		u64 aq_ctx_poison:1;	     /**< [ 32: 32](R/W1S/H) Reads or sets NIX_AF_RAS[AQ_CTX_POISON]. */
-		u64 aq_res_poison:1;	     /**< [ 33: 33](R/W1S/H) Reads or sets NIX_AF_RAS[AQ_RES_POISON]. */
-		u64 aq_inst_poison:1;	     /**< [ 34: 34](R/W1S/H) Reads or sets NIX_AF_RAS[AQ_INST_POISON]. */
-		u64 reserved_35_63:29;
-	} s;
-	/* struct cavm_nixx_af_ras_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras_ena_w1s
- *
- * NIX LF RAS Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_lf_ras_ena_w1s {
-	u64 u;
-	struct cavm_nixx_lf_ras_ena_w1s_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SQB_POISON]. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SQ_CTX_POISON]. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1S/H) Reads or sets enable for NIX_LF_RAS[RQ_CTX_POISON]. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1S/H) Reads or sets enable for NIX_LF_RAS[CQ_CTX_POISON]. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1S/H) Reads or sets enable for NIX_LF_RAS[RSSE_POISON]. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1S/H) Reads or sets enable for NIX_LF_RAS[IPSEC_DYNO_POISON]. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SEND_JUMP_POISON]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SEND_SG_POISON]. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1S/H) Reads or sets enable for NIX_LF_RAS[QINT_POISON]. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1S/H) Reads or sets enable for NIX_LF_RAS[CINT_POISON]. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras_ena_w1c
- *
- * NIX LF RAS Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_lf_ras_ena_w1c {
-	u64 u;
-	struct cavm_nixx_lf_ras_ena_w1c_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SQB_POISON]. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SQ_CTX_POISON]. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1C/H) Reads or clears enable for NIX_LF_RAS[RQ_CTX_POISON]. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1C/H) Reads or clears enable for NIX_LF_RAS[CQ_CTX_POISON]. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1C/H) Reads or clears enable for NIX_LF_RAS[RSSE_POISON]. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1C/H) Reads or clears enable for NIX_LF_RAS[IPSEC_DYNO_POISON]. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SEND_JUMP_POISON]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SEND_SG_POISON]. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1C/H) Reads or clears enable for NIX_LF_RAS[QINT_POISON]. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1C/H) Reads or clears enable for NIX_LF_RAS[CINT_POISON]. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rvu_int
- *
- * NIX AF RVU Interrupt Register
- * This register contains RVU error interrupt summary bits.
- */
-union cavm_nixx_af_rvu_int {
-	u64 u;
-	struct cavm_nixx_af_rvu_int_s {
-		u64 unmapped_slot:1;	     /**< [  0:  0](R/W1C/H) Unmapped slot. Received an IO request to a VF/PF slot in BAR2 that is not
-                                                                 reverse mapped to an LF. See NIX_PRIV_LF()_CFG and NIX_AF_RVU_LF_CFG_DEBUG. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rvu_int_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rvu_int_w1s
- *
- * NIX AF RVU Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_af_rvu_int_w1s {
-	u64 u;
-	struct cavm_nixx_af_rvu_int_w1s_s {
-		u64 unmapped_slot:1;	     /**< [  0:  0](R/W1S/H) Reads or sets NIX_AF_RVU_INT[UNMAPPED_SLOT]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rvu_int_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rvu_int_ena_w1s
- *
- * NIX AF RVU Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_af_rvu_int_ena_w1s {
-	u64 u;
-	struct cavm_nixx_af_rvu_int_ena_w1s_s {
-		u64 unmapped_slot:1;	     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_AF_RVU_INT[UNMAPPED_SLOT]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rvu_int_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rvu_int_ena_w1c
- *
- * NIX AF RVU Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_af_rvu_int_ena_w1c {
-	u64 u;
-	struct cavm_nixx_af_rvu_int_ena_w1c_s {
-		u64 unmapped_slot:1;	     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_AF_RVU_INT[UNMAPPED_SLOT]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rvu_int_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tcp_timer
- *
- * NIX TCP Timer Register
- */
-union cavm_nixx_af_tcp_timer {
-	u64 u;
-	struct cavm_nixx_af_tcp_timer_s {
-		u64 dur_counter:16;	     /**< [ 15:  0](R/W/H) Periodic counter that wraps around every [DURATION]*100 nanoseconds.
-                                                                 Enabled when [ENA] is set. */
-		u64 lf_counter:8;		     /**< [ 23: 16](RO/H) LF Counter. Updated when [DUR_COUNTER] wraps around to select the next LF
-                                                                 for which a timer event is generated. Cycles through values 0 through
-                                                                 NIX_AF_CONST2[LFS]-1. */
-		u64 reserved_24_31:8;
-		u64 duration:16;		     /**< [ 47: 32](R/W) Duration of the TCP timer as a multiple of 100 nanoseconds. */
-		u64 reserved_48_62:15;
-		u64 ena:1;			     /**< [ 63: 63](R/W) TCP timer enable. When clear, [LF_COUNTER] and [DUR_COUNTER] are forced to
-                                                                 0 and timer events will not be posted. */
-	} s;
-	/* struct cavm_nixx_af_tcp_timer_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_ol2
- *
- * NIX AF Receive Outer L2 Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer L2/Ethernet
- * header. Typically the same as NPC_PCK_DEF_OL2.
- */
-union cavm_nixx_af_rx_def_ol2 {
-	u64 u;
-	struct cavm_nixx_af_rx_def_ol2_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_ol2_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_oip4
- *
- * NIX AF Receive Outer IPv4 Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer IPv4 L3 header.
- * Typically the same as NPC_PCK_DEF_OIP4.
- */
-union cavm_nixx_af_rx_def_oip4 {
-	u64 u;
-	struct cavm_nixx_af_rx_def_oip4_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_oip4_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_iip4
- *
- * NIX AF Receive Inner IPv4 Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an inner IPv4 header.
- * Typically the same as NPC_PCK_DEF_IIP4.
- */
-union cavm_nixx_af_rx_def_iip4 {
-	u64 u;
-	struct cavm_nixx_af_rx_def_iip4_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_iip4_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_oip6
- *
- * NIX AF Receive Outer IPv6 Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer IPv6 header.
- * Typically the same as NPC_PCK_DEF_OIP6.
- */
-union cavm_nixx_af_rx_def_oip6 {
-	u64 u;
-	struct cavm_nixx_af_rx_def_oip6_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_oip6_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_iip6
- *
- * NIX AF Receive Inner IPv6 Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an inner IPv6 header.
- */
-union cavm_nixx_af_rx_def_iip6 {
-	u64 u;
-	struct cavm_nixx_af_rx_def_iip6_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_iip6_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_otcp
- *
- * NIX AF Receive Outer TCP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer TCP header.
- */
-union cavm_nixx_af_rx_def_otcp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_otcp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_otcp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_itcp
- *
- * NIX AF Receive Inner TCP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an inner TCP header.
- */
-union cavm_nixx_af_rx_def_itcp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_itcp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_itcp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_oudp
- *
- * NIX AF Receive Outer UDP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer UDP header.
- */
-union cavm_nixx_af_rx_def_oudp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_oudp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_oudp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_iudp
- *
- * NIX AF Receive Inner UDP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an inner UDP header.
- */
-union cavm_nixx_af_rx_def_iudp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_iudp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_iudp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_osctp
- *
- * NIX AF Receive Outer SCTP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an outer SCTP header.
- */
-union cavm_nixx_af_rx_def_osctp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_osctp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_osctp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_isctp
- *
- * NIX AF Receive Inner SCTP Header Definition Register
- * Defines layer information in NPC_RESULT_S to identify an inner SCTP header.
- */
-union cavm_nixx_af_rx_def_isctp {
-	u64 u;
-	struct cavm_nixx_af_rx_def_isctp_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LH as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_af_rx_def_isctp_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_def_ipsec#
- *
- * NIX AF Receive IPSEC Header Definition Registers
- * These two registers define layer information in NPC_RESULT_S to identify an
- * IPSEC header for up to two IPSEC packet formats. The two formats are typically
- * IPSEC ESP (RFC 4303) and UDP-encapsulated IPSEC ESP (RFC 3948).
- */
-union cavm_nixx_af_rx_def_ipsecx {
-	u64 u;
-	struct cavm_nixx_af_rx_def_ipsecx_s {
-		u64 ltype_mask:4;		     /**< [  3:  0](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;		     /**< [  7:  4](R/W) Layer type match value. Hardware detects a layer match when:
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LG as selected by [LID]. */
-		u64 lid:3;			     /**< [ 10:  8](R/W) Layer ID. Enumerated by NPC_LID_E. */
-		u64 reserved_11:1;
-		u64 spi_offset:4;		     /**< [ 15: 12](R/W) SPI offset. Starting byte offset of IPSEC SPI field relative to the start
-                                                                 of the IPSEC header identifies by [LID], [LTYPE_MATCH] and [LTYPE_MASK]. */
-		u64 spi_nz:1;		     /**< [ 16: 16](R/W) SPI non-zero. When set, match only is the IPSEC SPI field in the packet is non-zero. */
-		u64 reserved_17_63:47;
-	} s;
-	/* struct cavm_nixx_af_rx_def_ipsecx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_ipsec_gen_cfg
- *
- * NIX AF Receive IPSEC General Configuration Register
- * This register specifie the values of certain fields in CPT instructions
- * (CPT_INST_S) generated by NIX for IPSEC hardware fast-path packets.
- */
-union cavm_nixx_af_rx_ipsec_gen_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_ipsec_gen_cfg_s {
-		u64 param2:16;		     /**< [ 15:  0](R/W) CPT_INST_S[PARAM2] value. */
-		u64 param1:16;		     /**< [ 31: 16](R/W) CPT_INST_S[PARAM1] value. */
-		u64 opcode:16;		     /**< [ 47: 32](R/W) CPT_INST_S[OPCODE] value. */
-		u64 egrp:3;		     /**< [ 50: 48](R/W) CPT_INST_S[EGRP] value. */
-		u64 reserved_51_63:13;
-	} s;
-	/* struct cavm_nixx_af_rx_ipsec_gen_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_cpt#_inst_qsel
- *
- * NIX AF Receive CPT Instruction Queue Select Register
- * Selects the CPT queue to which instructions (CPT_INST_S) are sent.
- * Internal:
- * NIX sends CPT_INST_S to the CPT_LF_NQ() physical address for [PF_FUNC] and [SLOT]:
- * \<pre\>
- * // CPT_LF_NQ() physical address:
- * chip_pa_defs::io_rvu2a_t cpt_addr;
- * cpt_addr = RVU_BAR_E::RVU_PF()_FUNC()_BAR2(pf, func);
- * cpt_addr.block = RVU_BLOCK_ADDR_E::CPT()({a}); // {a} = CPT index
- * cpt_addr.slot = [SLOT];
- * cpt_addr.offset = `CPT_LF_NQX__BASE;
- *
- * // NDC/NCBI command:
- * ncbi_cmd.paddr = 1; // Physical address
- * ncbi_cmd.addr = cpt_addr;
- * \</pre\>
- */
-union cavm_nixx_af_rx_cptx_inst_qsel {
-	u64 u;
-	struct cavm_nixx_af_rx_cptx_inst_qsel_s {
-		u64 slot:8;		     /**< [  7:  0](R/W) CPT queue's slot within [PF_FUNC]; */
-		u64 pf_func:16;		     /**< [ 23:  8](R/W) RVU PF and function of the CPT queue. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_rx_cptx_inst_qsel_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_cfg
- *
- * NIX AF Admin Queue Configuration Register
- */
-union cavm_nixx_af_aq_cfg {
-	u64 u;
-	struct cavm_nixx_af_aq_cfg_s {
-		u64 qsize:4;		     /**< [  3:  0](R/W) Specifies AQ ring size in entries of 16 bytes:
-                                                                 0x0 = 16 entries.
-                                                                 0x1 = 64 entries.
-                                                                 0x2 = 256 entries.
-                                                                 0x3 = 1K entries.
-                                                                 0x4 = 4K entries.
-                                                                 0x5 = 16K entries.
-                                                                 0x6 = 64K entries.
-                                                                 0x7 = 256K entries.
-                                                                 0x8 = 1M entries.
-                                                                 0x9-0xF = Reserved.
-
-                                                                 Note that the usable size of the ring is the specified size minus 1 (HEAD==TAIL always
-                                                                 means empty). */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_aq_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_base
- *
- * NIX AF Admin Queue Base Address Register
- */
-union cavm_nixx_af_aq_base {
-	u64 u;
-	struct cavm_nixx_af_aq_base_s {
-		u64 reserved_0_6:7;
-		u64 base_addr:46;		     /**< [ 52:  7](R/W) AF IOVA\<52:7\> of AQ ring in LLC/DRAM. IOVA bits \<6:0\> are always zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_aq_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_status
- *
- * NIX AF Admin Queue Status Register
- */
-union cavm_nixx_af_aq_status {
-	u64 u;
-	struct cavm_nixx_af_aq_status_s {
-		u64 reserved_0_3:4;
-		u64 head_ptr:20;		     /**< [ 23:  4](R/W/H) Head pointer \<24:4\> of AQ ring relative to NIX_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the head pointer when it pops an entry
-                                                                 from the AQ. */
-		u64 reserved_24_35:12;
-		u64 tail_ptr:20;		     /**< [ 55: 36](R/W/H) Tail pointer \<24:4\> of AQ ring relative to NIX_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the tail pointer when software writes to
-                                                                 NIX_AF_AQ_DOOR. */
-		u64 reserved_56_61:6;
-		u64 aq_busy:1;		     /**< [ 62: 62](RO/H) This bit is set when an AQ command is currently being processed. */
-		u64 aq_err:1;		     /**< [ 63: 63](R/W1C/H) AQ error. See NIX_AF_ERR_INT[AQ_INST_FAULT,AQ_RES_FAULT,AQ_DOOR_ERR] and
-                                                                 NIX_AF_RAS[AQ_INST_POISON,AQ_RES_POISON].
-                                                                 When set, hardware stops reading instructions from the AQ ring. Software
-                                                                 clears the error by writing a one back. */
-	} s;
-	struct cavm_nixx_af_aq_status_cn {
-		u64 reserved_0_3:4;
-		u64 head_ptr:20;		     /**< [ 23:  4](R/W/H) Head pointer \<24:4\> of AQ ring relative to NIX_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the head pointer when it pops an entry
-                                                                 from the AQ. */
-		u64 reserved_24_31:8;
-		u64 reserved_32_35:4;
-		u64 tail_ptr:20;		     /**< [ 55: 36](R/W/H) Tail pointer \<24:4\> of AQ ring relative to NIX_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the tail pointer when software writes to
-                                                                 NIX_AF_AQ_DOOR. */
-		u64 reserved_56_61:6;
-		u64 aq_busy:1;		     /**< [ 62: 62](RO/H) This bit is set when an AQ command is currently being processed. */
-		u64 aq_err:1;		     /**< [ 63: 63](R/W1C/H) AQ error. See NIX_AF_ERR_INT[AQ_INST_FAULT,AQ_RES_FAULT,AQ_DOOR_ERR] and
-                                                                 NIX_AF_RAS[AQ_INST_POISON,AQ_RES_POISON].
-                                                                 When set, hardware stops reading instructions from the AQ ring. Software
-                                                                 clears the error by writing a one back. */
-	} cn;
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_door
- *
- * NIX AF Admin Queue Doorbell Register
- * Software writes to this register to enqueue entries to AQ.
- */
-union cavm_nixx_af_aq_door {
-	u64 u;
-	struct cavm_nixx_af_aq_door_s {
-		u64 count:16;		     /**< [ 15:  0](WO) Number of enqueued 16-byte entries. Hardware advances
-                                                                 NIX_AF_AQ_STATUS[TAIL_PTR] by this value.
-
-                                                                 A doorbell write that would overflow the AQ ring is suppressed and sets
-                                                                 NIX_AF_AQ_STATUS[AQ_ERR] and NIX_AF_ERR_INT[AQ_DOOR_ERR]. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_aq_door_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_wait
- *
- * NIX AF Admin Queue Done Interrupt Coalescing Wait Register
- * Specifies the queue interrupt coalescing settings.
- */
-union cavm_nixx_af_aq_done_wait {
-	u64 u;
-	struct cavm_nixx_af_aq_done_wait_s {
-		u64 num_wait:20;		     /**< [ 19:  0](R/W) Number of messages hold-off. When NIX_AF_AQ_DONE[DONE] \>= [NUM_WAIT] then
-                                                                 interrupt coalescing ends; see NIX_AF_AQ_DONE[DONE]. If 0x0, same behavior as
-                                                                 0x1. */
-		u64 reserved_20_31:12;
-		u64 time_wait:16;		     /**< [ 47: 32](R/W) Time hold-off in microseconds. When NIX_AF_AQ_DONE[DONE] = 0, or
-                                                                 NIX_AF_AQ_DONE_ACK is written, the interrupt coalescing timer
-                                                                 (NIX_AF_AQ_DONE_TIMER[COUNT]) is cleared. The timer increments every
-                                                                 microsecond, and interrupt coalescing ends when timer reaches [TIME_WAIT];
-                                                                 see NIX_AF_AQ_DONE[DONE]. If 0x0, time coalescing is disabled. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_aq_done_wait_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done
- *
- * NIX AF Admin Queue Done Count Register
- */
-union cavm_nixx_af_aq_done {
-	u64 u;
-	struct cavm_nixx_af_aq_done_s {
-		u64 done:20;		     /**< [ 19:  0](R/W/H) Done count. When NIX_AQ_INST_S[DONEINT] set and that instruction completes,
-                                                                 NIX_AF_AQ_DONE[DONE] is incremented. Write to this field are for diagnostic use only;
-                                                                 instead software writes NIX_AF_AQ_DONE_ACK with the number of decrements for this field.
-
-                                                                 Interrupts are sent as follows:
-
-                                                                 * When NIX_AF_AQ_DONE[DONE] = 0, then no results are pending, the interrupt
-                                                                 coalescing timer (NIX_AF_AQ_DONE_TIMER[COUNT]) is held to zero, and an
-                                                                 interrupt is not sent.
-
-                                                                 * When NIX_AF_AQ_DONE[DONE] != 0, then NIX_AF_AQ_DONE_TIMER[COUNT]
-                                                                 counts every microsecond. If the counter is \>= NIX_AF_AQ_DONE_WAIT[TIME_WAIT],
-                                                                 or NIX_AF_AQ_DONE[DONE] \>= NIX_AF_AQ_DONE_WAIT[NUM_WAIT], i.e. enough time
-                                                                 has passed or enough results have arrived, then the interrupt is sent.
-                                                                 Otherwise, it is not sent due to coalescing.
-
-                                                                 * When NIX_AF_AQ_DONE_ACK is written (or NIX_AF_AQ_DONE is written but this
-                                                                 is not typical), NIX_AF_AQ_DONE_TIMER[COUNT] restarts. Note after
-                                                                 decrementing this interrupt equation is recomputed, for example if
-                                                                 NIX_AF_AQ_DONE[DONE] \>= NIX_AF_AQ_DONE_WAIT[NUM_WAIT] and because the timer
-                                                                 is zero, the interrupt will be resent immediately. (This covers the race
-                                                                 case between software acknowledging an interrupt and a result returning.)
-
-                                                                 * When NIX_AF_AQ_DONE_ENA_W1S[DONE] = 0, interrupts are not sent, but the
-                                                                 counting described above still occurs.
-
-                                                                 AQ instructions complete in order.
-
-                                                                 Software is responsible for making sure [DONE] does not overflow; for example by
-                                                                 insuring there are not more than 2^20-1 instructions in flight that may request
-                                                                 interrupts. */
-		u64 reserved_20_63:44;
-	} s;
-	/* struct cavm_nixx_af_aq_done_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_ack
- *
- * NIX AF Admin Queue Done Count Ack Register
- * This register is written by software to acknowledge interrupts.
- */
-union cavm_nixx_af_aq_done_ack {
-	u64 u;
-	struct cavm_nixx_af_aq_done_ack_s {
-		u64 done_ack:20;		     /**< [ 19:  0](R/W/H) Number of decrements to NIX_AF_AQ_DONE[DONE]. Reads NIX_AF_AQ_DONE[DONE].
-
-                                                                 Written by software to acknowledge interrupts. If NIX_AF_AQ_DONE[DONE] is still
-                                                                 nonzero the interrupt will be resent if the conditions described in
-                                                                 NIX_AF_AQ_DONE[DONE] are satisfied.
-
-                                                                 Internal:
-                                                                 If [DONE_ACK] write value is greater than NIX_AF_AQ_DONE[DONE], hardware
-                                                                 resets NIX_AF_AQ_DONE[DONE] to zero. */
-		u64 reserved_20_63:44;
-	} s;
-	/* struct cavm_nixx_af_aq_done_ack_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_int
- *
- * INTERNAL: NIX AF Admin Queue Done Interrupt Register
- */
-union cavm_nixx_af_aq_done_int {
-	u64 u;
-	struct cavm_nixx_af_aq_done_int_s {
-		u64 done:1;		     /**< [  0:  0](RO/H) Done interrupt. See NIX_AF_AQ_DONE[DONE]. Note this bit is read-only, to acknowledge
-                                                                 interrupts use NIX_AF_AQ_DONE_ACK. To test interrupts, write nonzero to
-                                                                 NIX_AF_AQ_DONE[DONE]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_aq_done_int_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_int_w1s
- *
- * INTERNAL: NIX AF Admin Queue Done Interrupt Set Register
- */
-union cavm_nixx_af_aq_done_int_w1s {
-	u64 u;
-	struct cavm_nixx_af_aq_done_int_w1s_s {
-		u64 done:1;		     /**< [  0:  0](RO/H) Done interrupt. See NIX_AF_AQ_DONE[DONE]. Note this bit is read-only, to acknowledge
-                                                                 interrupts use NIX_AF_AQ_DONE_ACK. To test interrupts, write nonzero to
-                                                                 NIX_AF_AQ_DONE[DONE]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_aq_done_int_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_timer
- *
- * NIX AF Admin Queue Done Interrupt Timer Register
- */
-union cavm_nixx_af_aq_done_timer {
-	u64 u;
-	struct cavm_nixx_af_aq_done_timer_s {
-		u64 count:16; /**< [ 15:  0](R/W/H) Timer count. Hardware counter that increments every microsecond when
-                                                                 interrupt coalescing is active; coalescing ends when the counter reaches
-                                                                 NIX_AF_AQ_DONE_WAIT[TIME_WAIT]. Writes to this field are for diagnostic use
-                                                                 only. See also NIX_AF_AQ_DONE[DONE]. */
-		u64 reserved_16_63:48;
-	} s;
-	/* struct cavm_nixx_af_aq_done_timer_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_ena_w1s
- *
- * NIX AF Admin Queue Done Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_af_aq_done_ena_w1s {
-	u64 u;
-	struct cavm_nixx_af_aq_done_ena_w1s_s {
-		u64 done:1;		     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_AF_AQ_DONE_INT[DONE]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_aq_done_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_aq_done_ena_w1c
- *
- * NIX AF Admin Queue Done Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_af_aq_done_ena_w1c {
-	u64 u;
-	struct cavm_nixx_af_aq_done_ena_w1c_s {
-		u64 done:1;		     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_AF_AQ_DONE_INT[DONE]. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_aq_done_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_link#_sl#_spkt_cnt
- *
- * INTERNAL: NIX Receive Software Sync Link Packet Count Registers
- *
- * For diagnostic use only for debug of NIX_AF_RX_SW_SYNC[ENA] function. LINK
- * index is enumerated by NIX_LINK_E. SL index is zero for non-express packets,
- * one for express packets. For the internal NIX_LINK_E::MC, SL index is zero for
- * multicast replay, one for mirror replay.
- */
-union cavm_nixx_af_rx_linkx_slx_spkt_cnt {
-	u64 u;
-	struct cavm_nixx_af_rx_linkx_slx_spkt_cnt_s {
-		u64 in_cnt:20;		     /**< [ 19:  0](RO/H) Running count at input of machine. */
-		u64 reserved_20_31:12;
-		u64 out_cnt:20;		     /**< [ 51: 32](RO/H) Running count at output of machine. */
-		u64 reserved_52_63:12;
-	} s;
-	/* struct cavm_nixx_af_rx_linkx_slx_spkt_cnt_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_link#_cfg
- *
- * NIX AF Receive Link Configuration Registers
- * Index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_rx_linkx_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_linkx_cfg_s {
-		u64 minlen:16;		     /**< [ 15:  0](R/W) Byte count for min-sized frame check on packets received from this link,
-                                                                 excluding FCS potentially stripped outside NIX by CGX.
-                                                                 See NIX_RE_OPCODE_E::UNDERSIZE. Zero disables the check.
-                                                                 See [MAXLEN] for packet bytes that may be included or excluded in the
-                                                                 specified length. */
-		u64 maxlen:16;		     /**< [ 31: 16](R/W) Byte count for max-sized frame check on packets received from this link.
-                                                                 See NIX_RE_OPCODE_E::OVERSIZE. This length must include any any Vtags
-                                                                 which may be stripped and optional timestamp inserted by CGX. FCS bytes
-                                                                 stripped by CGX are not included. Must not exceed 9212 bytes (9216 minus 4
-                                                                 byte FCS) for CGX and LBK links. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_rx_linkx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_sw_sync
- *
- * NIX AF Receive Software Sync Register
- */
-union cavm_nixx_af_rx_sw_sync {
-	u64 u;
-	struct cavm_nixx_af_rx_sw_sync_s {
-		u64 ena:1;			     /**< [  0:  0](R/W1S/H) Sync enable. Software sets this bit to kick off a sync cycle on the RX path.
-                                                                 Hardware resets this bit to indicated the sync cycle is complete.
-                                                                 This sync insures that all packets that were in flight are flushed out to memory.
-                                                                 This can be used to assist in the tearing down of an active RQ. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_rx_sw_sync_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_link#_wrr_cfg
- *
- * NIX AF Receive Link Weighted Round Robin Configuration Registers
- * Index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_rx_linkx_wrr_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_linkx_wrr_cfg_s {
-		u64 weight:8;		     /**< [  7:  0](R/W) Link's round robin weight for receiving packet data in 16-byte transfer
-                                                                 units. Zero disables packed receive from the link.
-                                                                 When the maximum aggregate data rate from all links exceeds the NIX
-                                                                 data rate, software should program link weights proportional to the
-                                                                 links speeds or based on desired link priorities.
-
-                                                                 Internal:
-                                                                 Link's weight in the X2P grant arbiter. */
-		u64 reserved_8_63:56;
-	} s;
-	/* struct cavm_nixx_af_rx_linkx_wrr_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_seb_eco
- *
- * INTERNAL: SEB AF ECO Register
- *
- * Internal:
- * TODO - When CSI ECO register is added, switch this one to inherit from it.
- */
-union cavm_nixx_af_seb_eco {
-	u64 u;
-	struct cavm_nixx_af_seb_eco_s {
-		u64 eco_rw:32;		     /**< [ 31:  0](R/W) Reserved for ECO usage. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_seb_eco_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_norm_tx_fifo_status
- *
- * NIX AF Normal Transmit FIFO Status Register
- * Status of FIFO which transmits normal (potentially preemptable) packets to CGX and LBK.
- */
-union cavm_nixx_af_norm_tx_fifo_status {
-	u64 u;
-	struct cavm_nixx_af_norm_tx_fifo_status_s {
-		u64 count:12;		     /**< [ 11:  0](RO/H) Number of 128-bit entries in the TX FIFO. */
-		u64 reserved_12_63:52;
-	} s;
-	/* struct cavm_nixx_af_norm_tx_fifo_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_expr_tx_fifo_status
- *
- * NIX AF Express Transmit FIFO Status Register
- * Status of FIFO which transmits express packets to CGX and LBK.
- */
-union cavm_nixx_af_expr_tx_fifo_status {
-	u64 u;
-	struct cavm_nixx_af_expr_tx_fifo_status_s {
-		u64 count:12;		     /**< [ 11:  0](RO/H) Number of 128-bit entries in the TX FIFO. */
-		u64 reserved_12_63:52;
-	} s;
-	/* struct cavm_nixx_af_expr_tx_fifo_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_sdp_tx_fifo_status
- *
- * NIX AF SDP Transmit FIFO Status Register
- * Status of FIFO which transmits packets to SDP.
- */
-union cavm_nixx_af_sdp_tx_fifo_status {
-	u64 u;
-	struct cavm_nixx_af_sdp_tx_fifo_status_s {
-		u64 count:12;		     /**< [ 11:  0](RO/H) Number of 128-bit entries in the TX FIFO. */
-		u64 reserved_12_63:52;
-	} s;
-	/* struct cavm_nixx_af_sdp_tx_fifo_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_npc_capture_config
- *
- * NIX AF Transmit NPC Response Capture Configuration Register
- * Configures the NPC response capture logic for transmit packets. When enabled,
- * allows NPC responses for selected packets to be captured in
- * NIX_AF_TX_NPC_CAPTURE_INFO and NIX_AF_TX_NPC_CAPTURE_RESP().
- */
-union cavm_nixx_af_tx_npc_capture_config {
-	u64 u;
-	struct cavm_nixx_af_tx_npc_capture_config_s {
-		u64 en:1;			     /**< [  0:  0](R/W) Enable for NPC response capturing. When one, NPC response capturing will be
-                                                                 performed. When 0, NPC responses will not be captured. */
-		u64 continuous:1;		     /**< [  1:  1](R/W) Enable for continuous mode of NPC response capturing. When one, the NPC response
-                                                                 for any matching packet will be captured. When 0, only the first matching
-                                                                 packet will be captured. */
-		u64 lso_segnum_en:1;	     /**< [  2:  2](R/W) Enable for LSO segment number  matching, to trigger an NPC response capture.
-                                                                 When one, an NPC response will be captured for a packet whose LSO segment number
-                                                                 matches [LSO_SEGNUM]. */
-		u64 sqe_id_en:1;		     /**< [  3:  3](R/W) Enable for SQE ID matching, to trigger an NPC response capture. When one, an NPC
-                                                                 response will be captured for a packet whose SQE ID matches [SQE_ID]. */
-		u64 sq_id_en:1;		     /**< [  4:  4](R/W) Enable for SQ matching, to trigger an NPC response capture. When one, an NPC
-                                                                 response will be captured for a packet whose SQ matches [LF_ID]. */
-		u64 lf_id_en:1;		     /**< [  5:  5](R/W) Enable for LF matching, to trigger an NPC response capture. When one, an NPC
-                                                                 response will be captured for a packet whose LF matches [LF_ID]. */
-		u64 reserved_6_11:6;
-		u64 lso_segnum:8;		     /**< [ 19: 12](R/W) LSO segment number to be matched, when enabled by [LSO_SEGNUM_EN], to trigger
-                                                                 an NPC response capture. */
-		u64 sqe_id:16;		     /**< [ 35: 20](R/W) SQE to be matched, when enabled by [SQE_ID_EN], to trigger an NPC response capture. */
-		u64 sq_id:20;		     /**< [ 55: 36](R/W) SQ to be matched, when enabled by [SQ_ID_EN], to trigger an NPC response capture. */
-		u64 lf_id:8;		     /**< [ 63: 56](R/W) LF to be matched, when enabled by [LF_ID_EN], to trigger an NPC response capture. */
-	} s;
-	/* struct cavm_nixx_af_tx_npc_capture_config_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_npc_capture_info
- *
- * NIX AF Transmit NPC Response Capture Information Register
- * This register contains captured NPC response information for a transmit packet.
- * See NIX_AF_TX_NPC_CAPTURE_CONFIG.
- */
-union cavm_nixx_af_tx_npc_capture_info {
-	u64 u;
-	struct cavm_nixx_af_tx_npc_capture_info_s {
-		u64 vld:1;			     /**< [  0:  0](R/W/H) When set, indicates a valid NPC response has been captured in this register
-                                                                 and in NIX_AF_TX_NPC_CAPTURE_RESP(). */
-		u64 reserved_1_11:11;
-		u64 lso_segnum:8;		     /**< [ 19: 12](R/W/H) LSO segment number corresponding to the captured packet. */
-		u64 sqe_id:16;		     /**< [ 35: 20](R/W/H) SQE ID corresponding to the captured packet. */
-		u64 sq_id:20;		     /**< [ 55: 36](R/W/H) SQ ID corresponding to the captured packet. */
-		u64 lf_id:8;		     /**< [ 63: 56](R/W/H) LF ID corresponding to the captured packet. */
-	} s;
-	/* struct cavm_nixx_af_tx_npc_capture_info_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_smq#_cfg
- *
- * NIX AF SQM PSE Queue Configuration Registers
- */
-union cavm_nixx_af_smqx_cfg {
-	u64 u;
-	struct cavm_nixx_af_smqx_cfg_s {
-		u64 minlen:7;		/**< [  6:  0](R/W) Minimum packet length in bytes, excluding FCS potentially appended outside
-                                                                 NIX by CGX. Packets smaller than the minimum length from this SMQ,
-                                                                 including optional VLAN bytes inserted by NIX_SEND_EXT_S[VLAN*] and Vtag
-                                                                 bytes inserted by NIX_TX_VTAG_ACTION_S, are padded with zeros. Software
-                                                                 should program this to match the minimum length for all links that this SMQ
-                                                                 can transmit to.
-
-                                                                 Must be greater than 16. The default value ensures the pre-FCS packet is at
-                                                                 least 60 bytes. */
-		u64 desc_shp_ctl_dis:1;	/**< [  7:  7](R/W) Descriptor shaper control disable for packets transmitted by this SMQ.
-                                                                 0 = NIX_SEND_EXT_S[SHP_RA,SHP_DIS,SHP_CHG] values are used when present in
-                                                                 the descriptor.
-                                                                 1 = NIX_SEND_EXT_S[SHP_RA,SHP_DIS,SHP_CHG] values in the send descriptor,
-                                                                 are ignored and treated as 0. */
-		u64 maxlen:16;		/**< [ 23:  8](R/W) Maximum packet length in bytes, including optional VLAN bytes inserted by
-                                                                 NIX_SEND_EXT_S[VLAN*] and Vtag bytes inserted by NIX_TX_VTAG_ACTION_S,
-                                                                 but excluding FCS potentially appended outside NIX by CGX.
-
-                                                                 Must not be less than [MINLEN].
-                                                                 Must not exceed 9212 (9216 minus four byte FCS) if the SMQ transmits to
-                                                                 CGX and LBK. May be set to a larger value (up to 65535 bytes) if the SMQ
-                                                                 transmits to SDP (corresponding NIX_AF_TL4()_SDP_LINK_CFG[ENA] is set).
-
-                                                                 Software should set a value that does not exceed the MTU of any link to
-                                                                 which the SMQ can transmit. */
-		u64 lf:7;		/**< [ 30: 24](R/W) Local function with SQs that may feed this SMQ. Software must ensure NIX_SQ_CTX_S[SMQ]
-                                                                 does not point to this SMQ for any SQ outside of this LF. */
-		u64 reserved_31_35:5;
-		u64 max_vtag_ins:3;	/**< [ 38: 36](R/W) Maximum Vtag insertion size as a as a multiple of four bytes. Must be less
-                                                                 than or equal to four (16 bytes), and must be large enough to account for the
-                                                                 maximum number of bytes inserted by NIX_TX_VTAG_ACTION_S for any packet
-                                                                 sent through this SMQ.
-
-                                                                 Internal:
-                                                                 SQM computes allowed maximum Vtag insertion bytes (ok_vtag_max) such that
-                                                                 the computed packet size does not exceed [MAXLEN], including VLAN bytes
-                                                                 inserted by NIX_SEND_EXT_S[VLAN*]. SEB enforces ok_vtag_max when inserting
-                                                                 Vtag bytes based on NIX_TX_VTAG_ACTION_S. */
-		u64 rr_minlen:9;	/**< [ 47: 39](R/W) Round-robin minimum packet length. When less than or equal to [MINLEN],
-                                                                 NIX will always use the packet length for round-robin (DWRR) arbitration
-                                                                 between SQs.  Otherwise, for packets shorter than this value, NIX will use
-                                                                 [RR_MINLEN] as the length for round-robin arbitration only; this does not
-                                                                 affect the actual packet length or the length used for DWRR arbitration at
-                                                                 the MDQ and TL4-TL1 levels. Increasing [RR_MINLEN] reduces NDC/LLC/DRAM
-                                                                 bandwidth utilization when sending small packets.
-
-                                                                 Internal:
-                                                                 Reset value optimized for line rate @100MPPS:
-                                                                 _ 128 \> (100Gbps/8)*1000/100MPPS - 20(IFG+pre) = 108. */
-		u64 express:1;		/**< [ 48: 48](R/W) Express.
-                                                                 0 = The SMQ transmits normal packets.
-                                                                 1 = The SMQ transmits express packets.
-
-                                                                 Must have the same value as the corresponding
-                                                                 NIX_AF_TL3_TL2()_CFG[EXPRESS]. Hardware prioritizes enqueue to express SMQs
-                                                                 over normal SMQs. */
-		u64 flush:1;		/**< [ 49: 49](R/W1S/H) Software can write a one to set this bit and initiate an SMQ flush.
-                                                                 When set, hardware flushes all meta-descriptors/packets from this SMQ
-                                                                 through PSE and the send data path. Hardware clears this bit and sets
-                                                                 NIX_AF_GEN_INT[SMQ_FLUSH_DONE] when the flush operation is complete,
-
-                                                                 [ENQ_XOFF] must be set whenever this bit is set.
-
-                                                                 Must not be set when a DRAIN command is active
-                                                                 (NIX_AF_MDQ()_SW_XOFF[DRAIN,DRAIN_IRQ] or
-                                                                 NIX_AF_TL*()_SW_XOFF[DRAIN,DRAIN_IRQ] command has been issued and resulting
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] is not set).
-
-                                                                 The SMQ flush operation may stall if the downstream TL3/TL2 queue is
-                                                                 backpressured from CGX/LBK or the downstream TL4 queue is backpressured
-                                                                 from SDP. If the backpressure does not go away, software may need to
-                                                                 disable it at the destination link(s), e.g. by clearing
-                                                                 CGX()_SMU()_RX_FRM_CTL[CTL_BCK] to disable physical backpressure from a
-                                                                 10G+ CGX LMAC. */
-		u64 enq_xoff:1;		/**< [ 50: 50](R/W) Enqueue transmit off. When set, hardware will not enqueue meta-descriptorrs
-                                                                 to the SMQ. */
-		u64 pri_thr:6;		/**< [ 56: 51](R/W) SMQ enqueue priority threshold. When NIX_AF_SMQ()_STATUS[LEVEL] is less
-                                                                 than or equal to this value, high priority is given for enqueuing of MDs to
-                                                                 this SMQ. */
-		u64 reserved_57_63:7;
-	} s;
-	/* struct cavm_nixx_af_smqx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_smq#_head
- *
- * NIX AF SQM SMQ Head Register
- * These registers track the head of the SMQ linked list.
- */
-union cavm_nixx_af_smqx_head {
-	u64 u;
-	struct cavm_nixx_af_smqx_head_s {
-		u64 sq_idx:20;		/**< [ 19:  0](RO/H) SQ index. */
-		u64 valid:1;		/**< [ 20: 20](RO/H) Valid. */
-		u64 reserved_21_63:43;
-	} s;
-	/* struct cavm_nixx_af_smqx_head_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_smq#_nxt_head
- *
- * NIX AF SQM SMQ Next Head Register
- * These registers track the next head of the SMQ linked list.
- */
-union cavm_nixx_af_smqx_nxt_head {
-	u64 u;
-	struct cavm_nixx_af_smqx_nxt_head_s {
-		u64 sq_idx:20;		/**< [ 19:  0](RO/H) SQ index. */
-		u64 valid:1;		/**< [ 20: 20](RO/H) Valid. */
-		u64 reserved_21_63:43;
-	} s;
-	/* struct cavm_nixx_af_smqx_nxt_head_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_smq#_status
- *
- * NIX AF SQM SMQ Status Register
- * These registers track the status of the SMQ fifo.
- */
-union cavm_nixx_af_smqx_status {
-	u64 u;
-	struct cavm_nixx_af_smqx_status_s {
-		u64 level:7;			/**< [  6:  0](RO/H) Number of meta descriptors in the SMQ. */
-		u64 reserved_7_63:57;
-	} s;
-	/* struct cavm_nixx_af_smqx_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_smq#_tail
- *
- * NIX AF SQM SMQ Head Register
- * These registers track the tail of SMQ linked list.
- */
-union cavm_nixx_af_smqx_tail {
-	u64 u;
-	struct cavm_nixx_af_smqx_tail_s {
-		u64 sq_idx:20;		/**< [ 19:  0](RO/H) SQ index. */
-		u64 valid:1;		/**< [ 20: 20](RO/H) Valid. */
-		u64 reserved_21_63:43;
-	} s;
-	/* struct cavm_nixx_af_smqx_tail_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3_tl2#_link#_cfg
- *
- * NIX AF Transmit Level 3/2 Link Configuration Registers
- * These registers specify the links and associated channels that a given TL3 or
- * TL2 queue (depending on NIX_AF_PSE_CHANNEL_LEVEL[BP_LEVEL]) can transmit on.
- * Each TL3/TL2 queue can be enabled to transmit on and be backpressured by one or
- * more links and associated channels.
- */
-union cavm_nixx_af_tl3_tl2x_linkx_cfg {
-	u64 u;
-	struct cavm_nixx_af_tl3_tl2x_linkx_cfg_s {
-		u64 relchan:8;		     /**< [  7:  0](R/W) Relative channel number within this link. See [ENA]. */
-		u64 reserved_8_11:4;
-		u64 ena:1;			     /**< [ 12: 12](R/W) Enable. When set, the TL3/TL2 queue can transmit on relative channel number
-                                                                 [RELCHAN] of this link, and will respond to backpressure from link credits
-                                                                 (NIX_AF_TX_LINK()_NORM_CREDIT, NIX_AF_TX_LINK()_EXPR_CREDIT). If
-                                                                 [BP_ENA] is set, the queue also responds to channel backpressure. */
-		u64 bp_ena:1;		     /**< [ 13: 13](R/W) Backpressure enable. When set, the TL3/TL2 queue responds to backpressure
-                                                                 from (NIX_AF_TX_LINK()_HW_XOFF/_SW_XOFF[CHAN_XOFF]\<[RELCHAN]\>). */
-		u64 reserved_14_63:50;
-	} s;
-	/* struct cavm_nixx_af_tl3_tl2x_linkx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_pse_shaper_cfg
- *
- * NIX AF PSE Shaper Configuration Register
- */
-union cavm_nixx_af_pse_shaper_cfg {
-	u64 u;
-	struct cavm_nixx_af_pse_shaper_cfg_s {
-		u64 red_send_as_yellow:1;	     /**< [  0:  0](R/W) Red send as yellow. Configures the way packets colored
-                                                                 NIX_COLORRESULT_E::RED_SEND are handled by the TL4 through TL2 shapers when
-                                                                 operating in [COLOR_AWARE] mode. Normally packets colored
-                                                                 NIX_COLORRESULT_E::RED_DROP do not decrement the PIR in TL4 through TL2
-                                                                 shapers while packets colored YELLOW do. (Neither
-                                                                 NIX_COLORRESULT_E::RED_DROP nor YELLOW packets decrement the CIR in TL4
-                                                                 through TL2 shapers.)  Packets colored NIX_COLORRESULT_E::RED_SEND are
-                                                                 treated as either NIX_COLORRESULT_E::RED_DROP or YELLOW in the TL4 through
-                                                                 TL2 shapers as follows:
-                                                                 0 = Treat NIX_COLORRESULT_E::RED_SEND as NIX_COLORRESULT_E::RED_DROP.
-                                                                 1 = Treat NIX_COLORRESULT_E::RED_SEND as YELLOW.
-
-                                                                 In the TL1 shapers, NIX_COLORRESULT_E::RED_DROP packets do not decrement
-                                                                 the CIR, while YELLOW do. NIX_COLORRESULT_E::RED_SEND packets are always
-                                                                 treated the same as YELLOW is in the TL1 shapers, irrespective of
-                                                                 [RED_SEND_AS_YELLOW]. */
-		u64 color_aware:1;		     /**< [  1:  1](R/W) Color aware. Selects whether or not the PSE shapers take into account
-                                                                 the color of the incoming packet.
-                                                                 0 = Color blind.
-                                                                 1 = Color aware. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_nixx_af_pse_shaper_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mark_format#_ctl
- *
- * NIX AF Packet Marking Format Registers
- * Describes packet marking calculations for YELLOW and for
- * NIX_COLORRESULT_E::RED_SEND packets. NIX_SEND_EXT_S[MARKFORM] selects the CSR
- * used for the packet descriptor.
- *
- * All the packet marking offset calculations assume big-endian bits within a byte.
- *
- * For example, if NIX_SEND_EXT_S[MARKPTR] is 3 and [OFFSET] is 5 and the packet is YELLOW,
- * the NIX marking hardware would do this:
- *
- * _  byte[3]\<2:0\> |=   [Y_VAL]\<3:1\>
- * _  byte[3]\<2:0\> &= ~[Y_MASK]\<3:1\>
- * _  byte[4]\<7\>   |=   [Y_VAL]\<0\>
- * _  byte[4]\<7\>   &= ~[Y_MASK]\<0\>
- *
- * where byte[3] is the third byte in the packet, and byte[4] the fourth.
- *
- * For another example, if NIX_SEND_EXT_S[MARKPTR] is 3 and [OFFSET] is 0 and the
- * packet is NIX_COLORRESULT_E::RED_SEND,
- *
- * _   byte[3]\<7:4\> |=   [R_VAL]\<3:0\>
- * _   byte[3]\<7:4\> &= ~[R_MASK]\<3:0\>
- */
-union cavm_nixx_af_mark_formatx_ctl {
-	u64 u;
-	struct cavm_nixx_af_mark_formatx_ctl_s {
-		u64 r_val:4;		     /**< [  3:  0](R/W) Red mark value. Corresponding bits in packet's data are set when marking a
-                                                                 NIX_COLORRESULT_E::RED_SEND packet. [R_MASK] & [R_VAL] must be zero. */
-		u64 r_mask:4;		     /**< [  7:  4](R/W) Red mark mask. Corresponding bits in packet's data are cleared when marking
-                                                                 a NIX_COLORRESULT_E::RED_SEND packet. [R_MASK] & [R_VAL] must be zero. */
-		u64 y_val:4;		     /**< [ 11:  8](R/W) Yellow mark value. Corresponding bits in packet's data are set when marking a YELLOW
-                                                                 packet. [Y_MASK] & [Y_VAL] must be zero. */
-		u64 y_mask:4;		     /**< [ 15: 12](R/W) Yellow mark mask. Corresponding bits in packet's data are cleared when marking a YELLOW
-                                                                 packet. [Y_MASK] & [Y_VAL] must be zero. */
-		u64 offset:3;		     /**< [ 18: 16](R/W) Packet marking starts NIX_SEND_EXT_S[MARKPTR]*8 + [OFFSET] bits into the packet.
-                                                                 All processing with [Y_MASK,Y_VAL,R_MASK,R_VAL] starts at this offset. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_mark_formatx_ctl_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_link#_norm_credit
- *
- * NIX AF Transmit Link Normal Credit Registers
- * These registers track credits per link for normal (potentially preemptable)
- * packets sent to CGX and LBK. Link index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_tx_linkx_norm_credit {
-	u64 u;
-	struct cavm_nixx_af_tx_linkx_norm_credit_s {
-		u64 reserved_0:1;
-		u64 cc_enable:1;		     /**< [  1:  1](R/W) Credit enable. Enables [CC_UNIT_CNT] and [CC_PACKET_CNT] link credit processing. */
-		u64 cc_packet_cnt:10;	     /**< [ 11:  2](R/W/H) Link-credit packet count. This value, plus 1, represents the maximum outstanding
-                                                                 packet count for this link. Note that this 10-bit field represents a two's
-                                                                 complement signed value that decrements towards zero as credits are used.
-                                                                 Packets are not allowed to flow
-                                                                 when the count is less than zero. As such the most significant bit should normally be
-                                                                 programmed as zero (positive count). This gives a maximum value for this field of 2^9 - 1. */
-		u64 cc_unit_cnt:20;	     /**< [ 31: 12](R/W/H) Link-credit unit count. This value, plus 1 MTU, represents the maximum outstanding
-                                                                 credit units for this link. A credit unit is 16 bytes. Note that this
-                                                                 20-bit field represents a two's complement signed value that decrements
-                                                                 towards zero as credits are used.
-                                                                 Packets are not allowed to flow when the count is less than zero. As such, the most
-                                                                 significant bit should normally be programmed as zero (positive count). This gives a
-                                                                 maximum value for this field of 2^19 - 1.
-
-                                                                 In order to prevent blocking between CGX LMACs, [CC_ENABLE] should be set to 1 and
-                                                                 [CC_UNIT_CNT] should be less than
-
-                                                                 _     ((LMAC TX buffer size in CGX) - (MTU excluding FCS))/16
-
-                                                                 The LMAC TX buffer size is defined by CGX()_CMR_TX_LMACS[LMACS]. For example, if
-                                                                 CGX()_CMR_TX_LMACS[LMACS]=0x4 (16 KB per LMAC) and the LMAC's MTU excluding FCS
-                                                                 is 9212 bytes (9216 minus 4 byte FCS), then [CC_UNIT_CNT] should be \< (16384 - 9212)/16 =
-                                                                 448.
-
-                                                                 The recommended configuration for LBK is [CC_ENABLE] = 1 and
-                                                                 [CC_UNIT_CNT] = (10 * Max_LBK_Data_Rate),
-                                                                 e.g. [CC_UNIT_CNT] = 1000 for 100 Gbps max LBK data rate.
-
-                                                                 Internal:
-                                                                 LBK value is sized for specified data rate with 1200ns round trip latency,
-                                                                 e.g. for 100 Gbps:
-
-                                                                 _ Minimum LBK in-flight data = 100*1200/128b = 938 credit units.
-
-                                                                 Note: maximum LBK in-fligh data = initial_value + MTU. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_tx_linkx_norm_credit_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_link#_expr_credit
- *
- * NIX AF Transmit Link Express Credit Registers
- * These registers track credits per link for express packets that may potentially
- * preempt normal packets. Link index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_tx_linkx_expr_credit {
-	u64 u;
-	struct cavm_nixx_af_tx_linkx_expr_credit_s {
-		u64 reserved_0:1;
-		u64 cc_enable:1;		     /**< [  1:  1](R/W) Credit enable. Enables [CC_UNIT_CNT] and [CC_PACKET_CNT] link credit processing. */
-		u64 cc_packet_cnt:10;	     /**< [ 11:  2](R/W/H) Link-credit packet count. This value, plus 1, represents the maximum outstanding
-                                                                 packet count for this link. Note that this 10-bit field represents a two's
-                                                                 complement signed value that decrements towards zero as credits are used.
-                                                                 Packets are not allowed to flow
-                                                                 when the count is less than zero. As such the most significant bit should normally be
-                                                                 programmed as zero (positive count). This gives a maximum value for this field of 2^9 - 1. */
-		u64 cc_unit_cnt:20;	     /**< [ 31: 12](R/W/H) Link-credit unit count. This value, plus 1 MTU, represents the maximum outstanding
-                                                                 credit units for this link. A credit unit is 16 bytes. Note that this
-                                                                 20-bit field represents a two's complement signed value that decrements
-                                                                 towards zero as credits are used.
-                                                                 Packets are not allowed to flow when the count is less than zero. As such, the most
-                                                                 significant bit should normally be programmed as zero (positive count). This gives a
-                                                                 maximum value for this field of 2^19 - 1.
-
-                                                                 In order to prevent blocking between CGX LMACs, [CC_ENABLE] should be set to 1 and
-                                                                 [CC_UNIT_CNT] should be less than
-
-                                                                 _     ((LMAC TX buffer size in CGX) - (MTU excluding FCS))/16
-
-                                                                 The LMAC TX buffer size is defined by CGX()_CMR_TX_LMACS[LMACS]. For example, if
-                                                                 CGX()_CMR_TX_LMACS[LMACS]=0x4 (16 KB per LMAC) and the LMAC's MTU excluding FCS
-                                                                 is 9212 bytes (9216 minus 4 byte FCS), then [CC_UNIT_CNT] should be \< (16384 - 9212)/16 =
-                                                                 448.
-
-                                                                 The recommended configuration for LBK is [CC_ENABLE] = 1 and
-                                                                 [CC_UNIT_CNT] = (10 * Max_LBK_Data_Rate),
-                                                                 e.g. [CC_UNIT_CNT] = 1000 for 100 Gbps max LBK data rate.
-
-                                                                 Internal:
-                                                                 LBK value is sized for specified data rate with 1200ns round trip latency,
-                                                                 e.g. for 100 Gbps:
-
-                                                                 _ Minimum LBK in-flight data = 100*1200/128b = 938 credit units.
-
-                                                                 Note: maximum LBK in-fligh data = initial_value + MTU. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_tx_linkx_expr_credit_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_link#_sw_xoff
- *
- * NIX AF Transmit Link Software Controlled XOFF Registers
- * Link index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_tx_linkx_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tx_linkx_sw_xoff_s {
-		u64 chan_xoff:64;		     /**< [ 63:  0](R/W) Channel software controlled XOFF. One bit per channel on this link. When a bit is set,
-                                                                 packets will not be transmitted on the associated channel. */
-	} s;
-	/* struct cavm_nixx_af_tx_linkx_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_link#_hw_xoff
- *
- * NIX AF Transmit Link Hardware Controlled XOFF Registers
- * Link index enumerated by NIX_LINK_E.
- */
-union cavm_nixx_af_tx_linkx_hw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tx_linkx_hw_xoff_s {
-		u64 chan_xoff:64;	     /**< [ 63:  0](RO/H) Channel hardware XOFF status. One bit per channel on this link. When a bit is set,
-                                                                 indicates that the transmit channel is being backpressured (XOFF) by the link. */
-	} s;
-	/* struct cavm_nixx_af_tx_linkx_hw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_sdp_link_credit
- *
- * NIX AF Transmit Link SDP Credit Register
- * This register tracks SDP link credits.
- */
-union cavm_nixx_af_sdp_link_credit {
-	u64 u;
-	struct cavm_nixx_af_sdp_link_credit_s {
-		u64 reserved_0:1;
-		u64 cc_enable:1;		     /**< [  1:  1](R/W) Credit enable. Enables [CC_UNIT_CNT] and [CC_PACKET_CNT] link credit
-                                                                 processing. Must be one when SDP is used. */
-		u64 cc_packet_cnt:10;	     /**< [ 11:  2](R/W/H) See NIX_AF_TX_LINK()_NORM_CREDIT[CC_PACKET_CNT]. Must be less than to 512.
-                                                                 Internal:
-                                                                 Limited by the 512 PSE packet IDs for SDP. */
-		u64 cc_unit_cnt:20;	     /**< [ 31: 12](R/W/H) See NIX_AF_TX_LINK()_NORM_CREDIT[CC_UNIT_CNT].
-
-                                                                 The recommended configuration for SDP is
-                                                                 [CC_UNIT_CNT] = (10 * Max_SDP_Data_Rate),
-                                                                 e.g. [CC_UNIT_CNT] = 500 for 50 Gbps max SDP data rate. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_sdp_link_credit_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_sdp_sw_xoff#
- *
- * NIX AF SDP Transmit Link Software Controlled XOFF Registers
- */
-union cavm_nixx_af_sdp_sw_xoffx {
-	u64 u;
-	struct cavm_nixx_af_sdp_sw_xoffx_s {
-		u64 chan_xoff:64;		     /**< [ 63:  0](R/W) Channel software controlled XOFF.
-                                                                 One bit per SDP channel (NIX_AF_SDP_HW_XOFF({n})[CHAN_XOFF]\<{m}\> for
-                                                                 NIX_CHAN_E::SDP_CH(64*{n}+{m}).
-                                                                 When a bit is set, packets will not be transmitted on the associated
-                                                                 channel. */
-	} s;
-	/* struct cavm_nixx_af_sdp_sw_xoffx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_sdp_hw_xoff#
- *
- * NIX AF SDP Transmit Link Hardware Controlled XOFF Registers
- * .
- */
-union cavm_nixx_af_sdp_hw_xoffx {
-	u64 u;
-	struct cavm_nixx_af_sdp_hw_xoffx_s {
-		u64 chan_xoff:64;		     /**< [ 63:  0](RO/H) Channel hardware XOFF status.
-                                                                 One bit per SDP channel (NIX_AF_SDP_HW_XOFF({n})[CHAN_XOFF]\<{m}\> for
-                                                                 NIX_CHAN_E::SDP_CH(64*{n}+{m}).
-                                                                 When a bit is set, indicates that the transmit channel is being
-                                                                 backpressured (XOFF) by the link. */
-	} s;
-	/* struct cavm_nixx_af_sdp_hw_xoffx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_bp_status
- *
- * NIX AF Transmit Level 4 Backpressure Status Registers
- */
-union cavm_nixx_af_tl4x_bp_status {
-	u64 u;
-	struct cavm_nixx_af_tl4x_bp_status_s {
-		u64 hw_xoff:1;		     /**< [  0:  0](RO/H) Hardware XOFF status. Set if NIX_AF_TL4()_SDP_LINK_CFG[BP_ENA] and the SDP
-                                                                 channel selected by NIX_AF_TL4()_SDP_LINK_CFG[RELCHAN] is backpressure with
-                                                                 XOFF, or if the SDP link is backpressured by NIX_AF_SDP_LINK_CREDIT. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_tl4x_bp_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_sdp_link_cfg
- *
- * NIX AF Transmit Level 4 Link Configuration Registers
- * These registers specify the which TL4 queues transmit to and are optionally
- * backpressured by SDP.
- */
-union cavm_nixx_af_tl4x_sdp_link_cfg {
-	u64 u;
-	struct cavm_nixx_af_tl4x_sdp_link_cfg_s {
-		u64 relchan:8;		     /**< [  7:  0](R/W) Relative channel number. When [BP_ENA] is set, this is the
-                                                                 NIX_CHAN_E::SDP_CH() index of the SDP channel that may backpressure the TL4
-                                                                 queue. */
-		u64 reserved_8_11:4;
-		u64 ena:1;			     /**< [ 12: 12](R/W) Enable.
-                                                                 0 = The TL4 queue will not transmit to SDP and may transmit to CGX and/or LBK.
-                                                                 1 = The TL4 queue may only transmit to SDP and will respond to backpressure from
-                                                                 NIX_AF_SDP_LINK_CREDIT. If [BP_ENA] is set, the queue also responds to channel
-                                                                 backpressure. */
-		u64 bp_ena:1;		     /**< [ 13: 13](R/W) Backpressure enable. When set, the TL4 queue responds to backpressure from
-                                                                 (NIX_AF_SDP_HW_XOFF()/_SW_XOFF()[CHAN_XOFF]\<[RELCHAN]\>). */
-		u64 reserved_14_63:50;
-	} s;
-	/* struct cavm_nixx_af_tl4x_sdp_link_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_schedule
- *
- * NIX AF Transmit Level 1 Scheduling Control Register
- */
-union cavm_nixx_af_tl1x_schedule {
-	u64 u;
-	struct cavm_nixx_af_tl1x_schedule_s {
-		u64 rr_quantum:24;		     /**< [ 23:  0](R/W) Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
-                                                                 integer).
-
-                                                                 Typically [RR_QUANTUM] should be at or near the MTU or more (to limit or prevent
-                                                                 negative accumulations of the deficit count).
-
-                                                                 Transmit limiter 1 packet meta descriptor are active in the scheduler when the rate limiter
-                                                                 has not been exceeded. The position of the child in the TL1 array is always the position in
-                                                                 the circle (i.e. no linked list, used by packet queue arbiter). PSE moves the current head
-                                                                 of the circle on quantum expiration or when the head cannot follow with an active packet.
-
-                                                                 Packet queue arbiter takes a snap shot of TL1 active packet meta descriptor and performs
-                                                                 round robin arbitration. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tl1x_schedule_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_shape
- *
- * NIX AF Transmit Level 1 Shaping Control Register
- */
-union cavm_nixx_af_tl1x_shape {
-	u64 u;
-	struct cavm_nixx_af_tl1x_shape_s {
-		u64 adjust:9;		     /**< [  8:  0](R/W) NIX_AF_TL2()_SHAPE[ADJUST]. */
-		u64 reserved_9_23:15;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) NIX_AF_TL2()_SHAPE[LENGTH_DISABLE]. */
-		u64 reserved_25_63:39;
-	} s;
-	struct cavm_nixx_af_tl1x_shape_cn {
-		u64 adjust:9;		     /**< [  8:  0](R/W) NIX_AF_TL2()_SHAPE[ADJUST]. */
-		u64 reserved_9_17:9;
-		u64 reserved_18_23:6;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) NIX_AF_TL2()_SHAPE[LENGTH_DISABLE]. */
-		u64 reserved_25_63:39;
-	} cn;
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_cir
- *
- * NIX AF Transmit Level 1 Committed Information Rate Register
- */
-union cavm_nixx_af_tl1x_cir {
-	u64 u;
-	struct cavm_nixx_af_tl1x_cir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl1x_cir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_shape_state
- *
- * NIX AF Transmit Level 1 Shape State Register
- * This register must not be written during normal operation.
- */
-union cavm_nixx_af_tl1x_shape_state {
-	u64 u;
-	struct cavm_nixx_af_tl1x_shape_state_s {
-		u64 cir_accum:26;		     /**< [ 25:  0](R/W/H) Committed information rate accumulator. Debug access to the live CIR accumulator. */
-		u64 reserved_26_51:26;
-		u64 color:1;		     /**< [ 52: 52](R/W/H) Shaper connection status. Debug access to the live shaper state.
-                                                                 0 = Connected - shaper is connected.
-                                                                 1 = Pruned - shaper is disconnected. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_tl1x_shape_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_sw_xoff
- *
- * NIX AF Transmit Level 1 Software Controlled XOFF Registers
- */
-union cavm_nixx_af_tl1x_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tl1x_sw_xoff_s {
-		u64 xoff:1;		     /**< [  0:  0](R/W) XOFF. Stops meta flow out of the MDQ/TL* shaping queue. When [XOFF] is set,
-                                                                 the corresponding meta descriptor in the MDQ/TL* shaping queue cannot be
-                                                                 transferred to the next level. */
-		u64 drain:1;		     /**< [  1:  1](WO) Drain. This control activates a drain path through the PSE that starts at this queue
-                                                                 and ends at the TL1 level. The drain path is prioritized over other paths through PSE
-                                                                 and can be used in combination with [DRAIN_IRQ]. [DRAIN] need never be set for the
-                                                                 TL1 level, but is useful at all other levels, including the TL4 and MDQ levels.
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] should be clear prior to initiating a [DRAIN]=1 write to
-                                                                 this CSR.
-
-                                                                 After [DRAIN] is set for a shaping queue, it should not be set again, for
-                                                                 this or any other shaping queue, until NIX_AF_GEN_INT[TL1_DRAIN] is set.
-
-                                                                 [DRAIN] must not be set for any shaping queue when an SMQ FLUSH command is
-                                                                 active (any NIX_AF_SMQ()_CFG[FLUSH] is set).
-
-                                                                 DRAIN has no effect unless [XOFF] is also set. Only one drain command is
-                                                                 allowed to be active at a time. */
-		u64 reserved_2:1;
-		u64 drain_irq:1;		     /**< [  3:  3](WO) Drain IRQ. Enables setting of NIX_AF_GEN_INT[TL1_DRAIN] when the drain
-                                                                 operation has completed.
-                                                                 [DRAIN_IRQ] should be set whenever [DRAIN] is, and must not be set when [DRAIN] isn't
-                                                                 set. [DRAIN_IRQ] has no effect unless [DRAIN] and [XOFF] are also set. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_tl1x_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_topology
- *
- * NIX AF Transmit Level 1 Topology Registers
- */
-union cavm_nixx_af_tl1x_topology {
-	u64 u;
-	struct cavm_nixx_af_tl1x_topology_s {
-		u64 reserved_0:1;
-		u64 rr_prio:4;		     /**< [  4:  1](R/W) Round-robin priority. The priority assigned to the round-robin scheduler. A
-                                                                 higher-level queue is a child queue of this shaper when its
-                                                                 NIX_AF_TL*()_PARENT/NIX_AF_MDQ()_PARENT
-                                                                 selects this shaper, and it further is a round robin child queue when its
-                                                                 NIX_AF_TL*()_SCHEDULE[PRIO] equals [RR_PRIO]. All round-robin queues
-                                                                 attached to this shaper must have the same priority. But the number of
-                                                                 round-robin child queues attached (at this priority) is limited only by the
-                                                                 number of higher-level queues. When this shaper is not used, we recommend
-                                                                 [RR_PRIO] be zero.
-
-                                                                 When a shaper is used, [RR_PRIO] should be 0xF when there are no priorities
-                                                                 with more than one child queue (i.e. when there are no round-robin child
-                                                                 queues), and should otherwise be a legal priority (values 0-9). */
-		u64 reserved_5_31:27;
-		u64 prio_anchor:8;		     /**< [ 39: 32](R/W) Priority anchor. The base index positioning the static priority child
-                                                                 queues of this shaper. A higher-level queue is a child queue of this shaper
-                                                                 when its NIX_AF_TL*()_PARENT/NIX_AF_MDQ()_PARENT selects this shaper, and
-                                                                 it further is a static priority child queue when its
-                                                                 NIX_AF_TL*()_SCHEDULE[PRIO] does not equal [RR_PRIO]. A static priority
-                                                                 child queue with priority PRIO must be located at n=[PRIO_ANCHOR]+PRIO,
-                                                                 where PRIO=NIX_AF_TL*(n)_SCHEDULE[PRIO]. There can be at most one static
-                                                                 priority child queue at each priority. When there are no static priority
-                                                                 child queues attached at any priority, or if this shaper isn't used, the
-                                                                 hardware does not use [PRIO_ANCHOR]. In this case, we recommend
-                                                                 [PRIO_ANCHOR] be zero. Note that there are 10 available priorities, 0
-                                                                 through 9, with priority 0 being the highest and priority 9 being the
-                                                                 lowest. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl1x_topology_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_green
- *
- * INTERNAL: NIX Transmit Level 1 Green State Debug Register
- */
-union cavm_nixx_af_tl1x_green {
-	u64 u;
-	struct cavm_nixx_af_tl1x_green_s {
-		u64 tail:8;		     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;		     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_19:2;
-		u64 active_vec:20;		     /**< [ 39: 20](R/W/H) Active vector. A 20-bit vector, two bits per each of the 10 supported priorities.
-                                                                 For the non-RR_PRIO priorities, the two bits encode whether the child is active
-                                                                 GREEN, active YELLOW, active RED_SEND/RED_DROP, or inactive. At RR_PRIO, one
-                                                                 bit is set if the GREEN DWRR child list is not empty, and the other is set if the
-                                                                 YELLOW DWRR child list is not empty. For internal use only. */
-		u64 rr_active:1;		     /**< [ 40: 40](R/W/H) Round-robin red active. Set when the RED_SEND/RED_DROP DWRR child list is not empty.
-                                                                 For internal use only. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl1x_green_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_yellow
- *
- * INTERNAL: NIX Transmit Level 1 Yellow State Debug Register
- */
-union cavm_nixx_af_tl1x_yellow {
-	u64 u;
-	struct cavm_nixx_af_tl1x_yellow_s {
-		u64 tail:8;		     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;		     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_63:46;
-	} s;
-	/* struct cavm_nixx_af_tl1x_yellow_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_red
- *
- * INTERNAL: NIX Transmit Level 1 Red State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL1()_YELLOW.
- */
-union cavm_nixx_af_tl1x_red {
-	u64 u;
-	struct cavm_nixx_af_tl1x_red_s {
-		u64 tail:8;		     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;		     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_63:46;
-	} s;
-	/* struct cavm_nixx_af_tl1x_red_s cn; */
-};
-
-union cavm_nixx_af_tl1x_dropped_packets {
-	u64 u;
-	struct cavm_nixx_af_tl1x_dropped_packets_s {
-		u64 count:40;		     /**< [ 39:  0](R/W/H) Count. The running count of packets. Note that this count wraps. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl1x_dropped_packets_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_dropped_bytes
- *
- * NIX AF Transmit Level 1 Dropped Bytes Registers
- * This register has the same bit fields as NIX_AF_TL1()_GREEN_BYTES.
- */
-union cavm_nixx_af_tl1x_dropped_bytes {
-	u64 u;
-	struct cavm_nixx_af_tl1x_dropped_bytes_s {
-		u64 count:48;		     /**< [ 47:  0](R/W/H) Count. The running count of bytes. Note that this count wraps. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_tl1x_dropped_bytes_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_red_packets
- *
- * NIX AF Transmit Level 1 Red Sent Packets Registers
- * This register has the same bit fields as NIX_AF_TL1()_GREEN_PACKETS.
- */
-union cavm_nixx_af_tl1x_red_packets {
-	u64 u;
-	struct cavm_nixx_af_tl1x_red_packets_s {
-		u64 count:40;		     /**< [ 39:  0](R/W/H) Count. The running count of packets. Note that this count wraps. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl1x_red_packets_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_red_bytes
- *
- * NIX AF Transmit Level 1 Red Sent Bytes Registers
- * This register has the same bit fields as NIX_AF_TL1()_GREEN_BYTES.
- */
-union cavm_nixx_af_tl1x_red_bytes {
-	u64 u;
-	struct cavm_nixx_af_tl1x_red_bytes_s {
-		u64 count:48;		     /**< [ 47:  0](R/W/H) Count. The running count of bytes. Note that this count wraps. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_tl1x_red_bytes_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_yellow_packets
- *
- * NIX AF Transmit Level 1 Yellow Sent Packets Registers
- * This register has the same bit fields as NIX_AF_TL1()_GREEN_PACKETS.
- */
-union cavm_nixx_af_tl1x_yellow_packets {
-	u64 u;
-	struct cavm_nixx_af_tl1x_yellow_packets_s {
-		u64 count:40;		     /**< [ 39:  0](R/W/H) Count. The running count of packets. Note that this count wraps. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl1x_yellow_packets_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_yellow_bytes
- *
- * NIX AF Transmit Level 1 Yellow Sent Bytes Registers
- * This register has the same bit fields as NIX_AF_TL1()_GREEN_BYTES.
- */
-union cavm_nixx_af_tl1x_yellow_bytes {
-	u64 u;
-	struct cavm_nixx_af_tl1x_yellow_bytes_s {
-		u64 count:48;		     /**< [ 47:  0](R/W/H) Count. The running count of bytes. Note that this count wraps. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_tl1x_yellow_bytes_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_green_packets
- *
- * NIX AF Transmit Level 1 Green Sent Packets Registers
- */
-union cavm_nixx_af_tl1x_green_packets {
-	u64 u;
-	struct cavm_nixx_af_tl1x_green_packets_s {
-		u64 count:40;		     /**< [ 39:  0](R/W/H) Count. The running count of packets. Note that this count wraps. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl1x_green_packets_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl1#_green_bytes
- *
- * NIX AF Transmit Level 1 Green Sent Bytes Registers
- */
-union cavm_nixx_af_tl1x_green_bytes {
-	u64 u;
-	struct cavm_nixx_af_tl1x_green_bytes_s {
-		u64 count:48;		     /**< [ 47:  0](R/W/H) Count. The running count of bytes. Note that this count wraps. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_tl1x_green_bytes_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_schedule
- *
- * NIX AF Transmit Level 2 Scheduling Control Registers
- */
-union cavm_nixx_af_tl2x_schedule {
-	u64 u;
-	struct cavm_nixx_af_tl2x_schedule_s {
-		u64 rr_quantum:24;		     /**< [ 23:  0](R/W) Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
-                                                                 integer). The packet size used in all DWRR (RR_COUNT) calculations is:
-
-                                                                 _  (NIX_nm_SHAPE[LENGTH_DISABLE] ? 0 : (NIX_nm_MD*[LENGTH] + NIX_nm_MD*[ADJUST]))
-                                                                    + NIX_nm_SHAPE[ADJUST]
-
-                                                                 where nm corresponds to this NIX_nm_SCHEDULE CSR.
-
-                                                                 Typically [RR_QUANTUM] should be at or near the MTU or more (to limit or prevent
-                                                                 negative accumulations of the deficit count). */
-		u64 prio:4;		     /**< [ 27: 24](R/W) Priority. The priority used for this shaping queue in the (lower-level)
-                                                                 parent's scheduling algorithm. When this shaping queue is not used, we
-                                                                 recommend setting [PRIO] to zero. The legal [PRIO] values are zero to nine
-                                                                 when the shaping queue is used. In addition to priority, [PRIO] determines
-                                                                 whether the shaping queue is a static queue or not: If [PRIO] equals the
-                                                                 parent's NIX_AF_TL*()_TOPOLOGY[RR_PRIO], then this is a round-robin child
-                                                                 queue into the shaper at the next level. */
-		u64 reserved_28_63:36;
-	} s;
-	/* struct cavm_nixx_af_tl2x_schedule_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_shape
- *
- * NIX AF Transmit Level 2 Shaping Control Registers
- */
-union cavm_nixx_af_tl2x_shape {
-	u64 u;
-	struct cavm_nixx_af_tl2x_shape_s {
-		u64 adjust:9;		     /**< [  8:  0](R/W) Shaping and scheduling calculation adjustment. This nine-bit two's
-                                                                 complement signed value allows -255 .. 255 bytes to be added to the packet
-                                                                 length for rate limiting and scheduling calculations. Constraints:
-                                                                 * Must be positive when [LENGTH_DISABLE] is set
-                                                                 * May be negative When [LENGTH_DISABLE] is clear, but must be greater than
-                                                                 - NIX_AF_SMQ()_CFG[MINLEN].
-                                                                 * Must not be 0x100. */
-		u64 red_algo:2;		     /**< [ 10:  9](R/W) Shaper red state algorithm when not specified by the NIX SEND. Used by hardware
-                                                                 only when the shaper is in RED state. (A shaper is in RED state when
-                                                                 NIX_AF_TL*()_SHAPE_STATE[PIR_ACCUM] is negative.) When NIX_SEND_EXT_S[SHP_RA]!=STD (!=0) for a
-                                                                 packet, this [RED_ALGO] is not used, and NIX_SEND_EXT_S[SHP_RA] instead defines
-                                                                 the shaper red state algorithm used for the packet. The
-                                                                 encoding for the [RED_ALGO]/NIX_SEND_EXT_S[SHP_RA] that is used:
-                                                                 0x0 = STALL. See 0x2.
-                                                                 0x1 = SEND. Send packets while the shaper is in RED state. When the shaper is
-                                                                       in RED state, packets that traverse the shaper will be downgraded to
-                                                                       NIX_COLORRESULT_E::RED_SEND.  (if not already
-                                                                       NIX_COLORRESULT_E::RED_SEND or NIX_COLORRESULT_E::RED_DROP) unless
-                                                                       [RED_DISABLE] is set or NIX_SEND_EXT_S[SHP_DIS] for the packet is
-                                                                       set. See also NIX_REDALG_E::SEND.
-                                                                 0x2 = STALL. Stall packets while the shaper is in RED state until the shaper is
-                                                                       YELLOW or GREEN state. Packets that traverse the shaper are never
-                                                                       downgraded to the RED state in this mode.
-                                                                       See also NIX_REDALG_E::STALL.
-                                                                 0x3 = DISCARD. Continually discard packets while the shaper is in RED state.
-                                                                       When the shaper is in RED state, all packets that traverse the shaper
-                                                                       will be downgraded to NIX_COLORRESULT_E::RED_DROP (if not already
-                                                                       NIX_COLORRESULT_E::RED_DROP), unless [RED_DISABLE] is set or
-                                                                       NIX_SEND_EXT_S[SHP_DIS] for the packet is set.
-                                                                       NIX_COLORRESULT_E::RED_DROP packets traverse all subsequent
-                                                                       schedulers/shapers (all the way through L1), but do so as quickly as
-                                                                       possible without affecting any RR_COUNT, CIR_ACCUM, or PIR_ACCUM
-                                                                       state, and are then discarded by NIX. See also NIX_REDALG_E::DISCARD. */
-		u64 red_disable:1;		     /**< [ 11: 11](R/W) Disable red transitions. Disables green-to-red and yellow-to-red packet
-                                                                 color marking transitions when set. Not used by hardware when
-                                                                 [RED_ALGO]/NIX_SEND_EXT_S[SHP_RA]=0x2/STALLi nor when corresponding
-                                                                 NIX_AF_TL*()_PIR[ENABLE]/NIX_AF_MDQ()_PIR[ENABLE] is clear. */
-		u64 yellow_disable:1;	     /**< [ 12: 12](R/W) Disable yellow transitions. Disables green-to-yellow packet color marking
-                                                                 transitions when set. Not used by hardware when corresponding
-                                                                 NIX_AF_TL*()_CIR[ENABLE]/NIX_AF_MDQ()_CIR[ENABLE] is clear. */
-		u64 reserved_13_23:11;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) Length disable. Disables the use of packet lengths in DWRR scheduling
-                                                                 and shaping calculations such that only the value of [ADJUST] is used. */
-		u64 schedule_list:2;	     /**< [ 26: 25](R/W) Shaper scheduling list. Restricts shaper scheduling to specific lists.
-                                                                   0x0 = Normal (selected for nearly all scheduling/shaping applications).
-                                                                   0x1 = Green-only.
-                                                                   0x2 = Yellow-only.
-                                                                   0x3 = Red-only. */
-		u64 reserved_27_63:37;
-	} s;
-	/* struct cavm_nixx_af_tl2x_shape_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_cir
- *
- * NIX AF Transmit Level 2 Committed Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl2x_cir {
-	u64 u;
-	struct cavm_nixx_af_tl2x_cir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl2x_cir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_pir
- *
- * NIX AF Transmit Level 2 Peak Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl2x_pir {
-	u64 u;
-	struct cavm_nixx_af_tl2x_pir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl2x_pir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_sched_state
- *
- * NIX AF Transmit Level 2 Scheduling Control State Registers
- */
-union cavm_nixx_af_tl2x_sched_state {
-	u64 u;
-	struct cavm_nixx_af_tl2x_sched_state_s {
-		u64 rr_count:25;		     /**< [ 24:  0](R/W/H) Round-robin (DWRR) deficit counter. A 25-bit two's complement signed
-                                                                 integer count. For diagnostic use. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_tl2x_sched_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_shape_state
- *
- * NIX AF Transmit Level 2 Shape State Registers
- * This register must not be written during normal operation.
- */
-union cavm_nixx_af_tl2x_shape_state {
-	u64 u;
-	struct cavm_nixx_af_tl2x_shape_state_s {
-		u64 cir_accum:26;		     /**< [ 25:  0](R/W/H) Committed information rate accumulator. Debug access to the live CIR accumulator. */
-		u64 pir_accum:26;		     /**< [ 51: 26](R/W/H) Peak information rate accumulator. Debug access to the live PIR accumulator. */
-		u64 color:2;		     /**< [ 53: 52](R/W/H) Shaper connection status. Debug access to the live shaper state.
-                                                                 0x0 = Green - shaper is connected into the green list.
-                                                                 0x1 = Yellow - shaper is connected into the yellow list.
-                                                                 0x2 = Red - shaper is connected into the red list.
-                                                                 0x3 = Pruned - shaper is disconnected. */
-		u64 reserved_54_63:10;
-	} s;
-	/* struct cavm_nixx_af_tl2x_shape_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_pointers
- *
- * INTERNAL: NIX Transmit Level 2 Linked List Pointers Debug Register
- */
-union cavm_nixx_af_tl2x_pointers {
-	u64 u;
-	struct cavm_nixx_af_tl2x_pointers_s {
-		u64 next:8;		     /**< [  7:  0](R/W/H) Next pointer. The linked-list next pointer. */
-		u64 reserved_8_15:8;
-		u64 prev:8;		     /**< [ 23: 16](R/W/H) Previous pointer. The linked-list previous pointer. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tl2x_pointers_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_sw_xoff
- *
- * NIX AF Transmit Level 2 Software Controlled XOFF Registers
- * This register has the same bit fields as NIX_AF_TL1()_SW_XOFF.
- */
-union cavm_nixx_af_tl2x_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tl2x_sw_xoff_s {
-		u64 xoff:1;		     /**< [  0:  0](R/W) XOFF. Stops meta flow out of the MDQ/TL* shaping queue. When [XOFF] is set,
-                                                                 the corresponding meta descriptor in the MDQ/TL* shaping queue cannot be
-                                                                 transferred to the next level. */
-		u64 drain:1;		     /**< [  1:  1](WO) Drain. This control activates a drain path through the PSE that starts at this queue
-                                                                 and ends at the TL1 level. The drain path is prioritized over other paths through PSE
-                                                                 and can be used in combination with [DRAIN_IRQ]. [DRAIN] need never be set for the
-                                                                 TL1 level, but is useful at all other levels, including the TL4 and MDQ levels.
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] should be clear prior to initiating a [DRAIN]=1 write to
-                                                                 this CSR.
-
-                                                                 After [DRAIN] is set for a shaping queue, it should not be set again, for
-                                                                 this or any other shaping queue, until NIX_AF_GEN_INT[TL1_DRAIN] is set.
-
-                                                                 [DRAIN] must not be set for any shaping queue when an SMQ FLUSH command is
-                                                                 active (any NIX_AF_SMQ()_CFG[FLUSH] is set).
-
-                                                                 DRAIN has no effect unless [XOFF] is also set. Only one drain command is
-                                                                 allowed to be active at a time. */
-		u64 reserved_2:1;
-		u64 drain_irq:1;		     /**< [  3:  3](WO) Drain IRQ. Enables setting of NIX_AF_GEN_INT[TL1_DRAIN] when the drain
-                                                                 operation has completed.
-                                                                 [DRAIN_IRQ] should be set whenever [DRAIN] is, and must not be set when [DRAIN] isn't
-                                                                 set. [DRAIN_IRQ] has no effect unless [DRAIN] and [XOFF] are also set. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_tl2x_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_topology
- *
- * NIX AF Transmit Level 2 Topology Registers
- */
-union cavm_nixx_af_tl2x_topology {
-	u64 u;
-	struct cavm_nixx_af_tl2x_topology_s {
-		u64 reserved_0:1;
-		u64 rr_prio:4;		     /**< [  4:  1](R/W) See NIX_AF_TL1()_TOPOLOGY[RR_PRIO]. */
-		u64 reserved_5_31:27;
-		u64 prio_anchor:8;		     /**< [ 39: 32](R/W) See NIX_AF_TL1()_TOPOLOGY[PRIO_ANCHOR]. */
-		u64 reserved_40_63:24;
-	} s;
-	/* struct cavm_nixx_af_tl2x_topology_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_parent
- *
- * NIX AF Transmit Level 2 Parent Registers
- */
-union cavm_nixx_af_tl2x_parent {
-	u64 u;
-	struct cavm_nixx_af_tl2x_parent_s {
-		u64 reserved_0_15:16;
-		u64 parent:5;		     /**< [ 20: 16](R/W) Parent queue index. The index of the shaping element at the next lower hierarchical level
-                                                                 that accepts this shaping element's outputs. Refer to the NIX_AF_TL*()_TOPOLOGY
-                                                                 [PRIO_ANCHOR,RR_PRIO] descriptions for constraints on which child queues can attach to
-                                                                 which shapers at the next lower level. When this shaper is unused, we recommend that
-                                                                 [PARENT] be zero. */
-		u64 reserved_21_63:43;
-	} s;
-	/* struct cavm_nixx_af_tl2x_parent_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_green
- *
- * INTERNAL: NIX Transmit Level 2 Green State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL1()_GREEN.
- */
-union cavm_nixx_af_tl2x_green {
-	u64 u;
-	struct cavm_nixx_af_tl2x_green_s {
-		u64 tail:8;		     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;		     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_19:2;
-		u64 active_vec:20;		     /**< [ 39: 20](R/W/H) Active vector. A 20-bit vector, two bits per each of the 10 supported priorities.
-                                                                 For the non-RR_PRIO priorities, the two bits encode whether the child is active
-                                                                 GREEN, active YELLOW, active RED_SEND/RED_DROP, or inactive. At RR_PRIO, one
-                                                                 bit is set if the GREEN DWRR child list is not empty, and the other is set if the
-                                                                 YELLOW DWRR child list is not empty. For internal use only. */
-		u64 rr_active:1;		     /**< [ 40: 40](R/W/H) Round-robin red active. Set when the RED_SEND/RED_DROP DWRR child list is not empty.
-                                                                 For internal use only. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl2x_green_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_yellow
- *
- * INTERNAL: NIX Transmit Level 2 Yellow State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL1()_YELLOW.
- */
-union cavm_nixx_af_tl2x_yellow {
-	u64 u;
-	struct cavm_nixx_af_tl2x_yellow_s {
-		u64 tail:8;		     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;		     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_63:46;
-	} s;
-	/* struct cavm_nixx_af_tl2x_yellow_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl2#_red
- *
- * INTERNAL: NIX Transmit Level 2 Red State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL1()_RED.
- */
-union cavm_nixx_af_tl2x_red {
-	u64 u;
-	struct cavm_nixx_af_tl2x_red_s {
-		u64 tail:8;	     /**< [  7:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_8_9:2;
-		u64 head:8;	     /**< [ 17: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_18_63:46;
-	} s;
-	/* struct cavm_nixx_af_tl2x_red_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_schedule
- *
- * NIX AF Transmit Level 3 Scheduling Control Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHEDULE.
- */
-union cavm_nixx_af_tl3x_schedule {
-	u64 u;
-	struct cavm_nixx_af_tl3x_schedule_s {
-		u64 rr_quantum:24;		     /**< [ 23:  0](R/W) Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
-                                                                 integer). The packet size used in all DWRR (RR_COUNT) calculations is:
-
-                                                                 _  (NIX_nm_SHAPE[LENGTH_DISABLE] ? 0 : (NIX_nm_MD*[LENGTH] + NIX_nm_MD*[ADJUST]))
-                                                                    + NIX_nm_SHAPE[ADJUST]
-
-                                                                 where nm corresponds to this NIX_nm_SCHEDULE CSR.
-
-                                                                 Typically [RR_QUANTUM] should be at or near the MTU or more (to limit or prevent
-                                                                 negative accumulations of the deficit count). */
-		u64 prio:4;		     /**< [ 27: 24](R/W) Priority. The priority used for this shaping queue in the (lower-level)
-                                                                 parent's scheduling algorithm. When this shaping queue is not used, we
-                                                                 recommend setting [PRIO] to zero. The legal [PRIO] values are zero to nine
-                                                                 when the shaping queue is used. In addition to priority, [PRIO] determines
-                                                                 whether the shaping queue is a static queue or not: If [PRIO] equals the
-                                                                 parent's NIX_AF_TL*()_TOPOLOGY[RR_PRIO], then this is a round-robin child
-                                                                 queue into the shaper at the next level. */
-		u64 reserved_28_63:36;
-	} s;
-	/* struct cavm_nixx_af_tl3x_schedule_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_shape
- *
- * NIX AF Transmit Level 3 Shaping Control Registers
- */
-union cavm_nixx_af_tl3x_shape {
-	u64 u;
-	struct cavm_nixx_af_tl3x_shape_s {
-		u64 adjust:9;		     /**< [  8:  0](R/W) See NIX_AF_TL2()_SHAPE[ADJUST]. */
-		u64 red_algo:2;		     /**< [ 10:  9](R/W) See NIX_AF_TL2()_SHAPE[RED_ALGO]. */
-		u64 red_disable:1;		     /**< [ 11: 11](R/W) See NIX_AF_TL2()_SHAPE[RED_DISABLE]. */
-		u64 yellow_disable:1;	     /**< [ 12: 12](R/W) See NIX_AF_TL2()_SHAPE[YELLOW_DISABLE]. */
-		u64 reserved_13_23:11;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) Length disable. Disables the use of packet lengths in DWRR scheduling
-                                                                 and shaping calculations such that only the value of [ADJUST] is used. */
-		u64 schedule_list:2;	     /**< [ 26: 25](R/W) Shaper scheduling list. Restricts shaper scheduling to specific lists.
-                                                                   0x0 = Normal (selected for nearly all scheduling/shaping applications).
-                                                                   0x1 = Green-only.
-                                                                   0x2 = Yellow-only.
-                                                                   0x3 = Red-only. */
-		u64 reserved_27_63:37;
-	} s;
-	/* struct cavm_nixx_af_tl3x_shape_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_cir
- *
- * NIX AF Transmit Level 3 Committed Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl3x_cir {
-	u64 u;
-	struct cavm_nixx_af_tl3x_cir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl3x_cir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_pir
- *
- * NIX AF Transmit Level 3 Peak Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl3x_pir {
-	u64 u;
-	struct cavm_nixx_af_tl3x_pir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl3x_pir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_sched_state
- *
- * NIX AF Transmit Level 3 Scheduling Control State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHED_STATE.
- */
-union cavm_nixx_af_tl3x_sched_state {
-	u64 u;
-	struct cavm_nixx_af_tl3x_sched_state_s {
-		u64 rr_count:25;		     /**< [ 24:  0](R/W/H) Round-robin (DWRR) deficit counter. A 25-bit two's complement signed
-                                                                 integer count. For diagnostic use. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_tl3x_sched_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_shape_state
- *
- * NIX AF Transmit Level 3 Shaping State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SHAPE_STATE.
- * This register must not be written during normal operation.
- */
-union cavm_nixx_af_tl3x_shape_state {
-	u64 u;
-	struct cavm_nixx_af_tl3x_shape_state_s {
-		u64 cir_accum:26;		     /**< [ 25:  0](R/W/H) Committed information rate accumulator. Debug access to the live CIR accumulator. */
-		u64 pir_accum:26;		     /**< [ 51: 26](R/W/H) Peak information rate accumulator. Debug access to the live PIR accumulator. */
-		u64 color:2;		     /**< [ 53: 52](R/W/H) Shaper connection status. Debug access to the live shaper state.
-                                                                 0x0 = Green - shaper is connected into the green list.
-                                                                 0x1 = Yellow - shaper is connected into the yellow list.
-                                                                 0x2 = Red - shaper is connected into the red list.
-                                                                 0x3 = Pruned - shaper is disconnected. */
-		u64 reserved_54_63:10;
-	} s;
-	/* struct cavm_nixx_af_tl3x_shape_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_pointers
- *
- * INTERNAL: NIX Transmit Level 3 Linked List Pointers Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL2()_POINTERS.
- */
-union cavm_nixx_af_tl3x_pointers {
-	u64 u;
-	struct cavm_nixx_af_tl3x_pointers_s {
-		u64 next:8;		     /**< [  7:  0](R/W/H) Next pointer. The linked-list next pointer. */
-		u64 reserved_8_15:8;
-		u64 prev:8;		     /**< [ 23: 16](R/W/H) Previous pointer. The linked-list previous pointer. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tl3x_pointers_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_sw_xoff
- *
- * NIX AF Transmit Level 3 Software Controlled XOFF Registers
- * This register has the same bit fields as NIX_AF_TL1()_SW_XOFF
- */
-union cavm_nixx_af_tl3x_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tl3x_sw_xoff_s {
-		u64 xoff:1;		     /**< [  0:  0](R/W) XOFF. Stops meta flow out of the MDQ/TL* shaping queue. When [XOFF] is set,
-                                                                 the corresponding meta descriptor in the MDQ/TL* shaping queue cannot be
-                                                                 transferred to the next level. */
-		u64 drain:1;		     /**< [  1:  1](WO) Drain. This control activates a drain path through the PSE that starts at this queue
-                                                                 and ends at the TL1 level. The drain path is prioritized over other paths through PSE
-                                                                 and can be used in combination with [DRAIN_IRQ]. [DRAIN] need never be set for the
-                                                                 TL1 level, but is useful at all other levels, including the TL4 and MDQ levels.
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] should be clear prior to initiating a [DRAIN]=1 write to
-                                                                 this CSR.
-
-                                                                 After [DRAIN] is set for a shaping queue, it should not be set again, for
-                                                                 this or any other shaping queue, until NIX_AF_GEN_INT[TL1_DRAIN] is set.
-
-                                                                 [DRAIN] must not be set for any shaping queue when an SMQ FLUSH command is
-                                                                 active (any NIX_AF_SMQ()_CFG[FLUSH] is set).
-
-                                                                 DRAIN has no effect unless [XOFF] is also set. Only one drain command is
-                                                                 allowed to be active at a time. */
-		u64 reserved_2:1;
-		u64 drain_irq:1;		     /**< [  3:  3](WO) Drain IRQ. Enables setting of NIX_AF_GEN_INT[TL1_DRAIN] when the drain
-                                                                 operation has completed.
-                                                                 [DRAIN_IRQ] should be set whenever [DRAIN] is, and must not be set when [DRAIN] isn't
-                                                                 set. [DRAIN_IRQ] has no effect unless [DRAIN] and [XOFF] are also set. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_tl3x_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_topology
- *
- * NIX AF Transmit Level 3 Topology Registers
- */
-union cavm_nixx_af_tl3x_topology {
-	u64 u;
-	struct cavm_nixx_af_tl3x_topology_s {
-		u64 reserved_0:1;
-		u64 rr_prio:4;		     /**< [  4:  1](R/W) See NIX_AF_TL1()_TOPOLOGY[RR_PRIO]. */
-		u64 reserved_5_31:27;
-		u64 prio_anchor:9;		     /**< [ 40: 32](R/W) See NIX_AF_TL1()_TOPOLOGY[PRIO_ANCHOR]. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl3x_topology_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_parent
- *
- * NIX AF Transmit Level 3 Parent Registers
- */
-union cavm_nixx_af_tl3x_parent {
-	u64 u;
-	struct cavm_nixx_af_tl3x_parent_s {
-		u64 reserved_0_15:16;
-		u64 parent:8;		     /**< [ 23: 16](R/W) See NIX_AF_TL2()_PARENT[PARENT]. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tl3x_parent_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_green
- *
- * INTERNAL: NIX Transmit Level 3 Green State Debug Register
- */
-union cavm_nixx_af_tl3x_green {
-	u64 u;
-	struct cavm_nixx_af_tl3x_green_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19:1;
-		u64 active_vec:20;		     /**< [ 39: 20](R/W/H) Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
-                                                                 scheduling queue are active. For internal use only. */
-		u64 rr_active:1;		     /**< [ 40: 40](R/W/H) Round-robin red active. Indicates that the round-robin input is mapped to RED. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl3x_green_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_yellow
- *
- * INTERNAL: NIX Transmit Level 3 Yellow State Debug Register
- */
-union cavm_nixx_af_tl3x_yellow {
-	u64 u;
-	struct cavm_nixx_af_tl3x_yellow_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_tl3x_yellow_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3#_red
- *
- * INTERNAL: NIX Transmit Level 3 Red State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL3()_YELLOW.
- */
-union cavm_nixx_af_tl3x_red {
-	u64 u;
-	struct cavm_nixx_af_tl3x_red_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_tl3x_red_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_schedule
- *
- * NIX AF Transmit Level 4 Scheduling Control Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHEDULE.
- */
-union cavm_nixx_af_tl4x_schedule {
-	u64 u;
-	struct cavm_nixx_af_tl4x_schedule_s {
-		u64 rr_quantum:24;		     /**< [ 23:  0](R/W) Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
-                                                                 integer). The packet size used in all DWRR (RR_COUNT) calculations is:
-
-                                                                 _  (NIX_nm_SHAPE[LENGTH_DISABLE] ? 0 : (NIX_nm_MD*[LENGTH] + NIX_nm_MD*[ADJUST]))
-                                                                    + NIX_nm_SHAPE[ADJUST]
-
-                                                                 where nm corresponds to this NIX_nm_SCHEDULE CSR.
-
-                                                                 Typically [RR_QUANTUM] should be at or near the MTU or more (to limit or prevent
-                                                                 negative accumulations of the deficit count). */
-		u64 prio:4;		     /**< [ 27: 24](R/W) Priority. The priority used for this shaping queue in the (lower-level)
-                                                                 parent's scheduling algorithm. When this shaping queue is not used, we
-                                                                 recommend setting [PRIO] to zero. The legal [PRIO] values are zero to nine
-                                                                 when the shaping queue is used. In addition to priority, [PRIO] determines
-                                                                 whether the shaping queue is a static queue or not: If [PRIO] equals the
-                                                                 parent's NIX_AF_TL*()_TOPOLOGY[RR_PRIO], then this is a round-robin child
-                                                                 queue into the shaper at the next level. */
-		u64 reserved_28_63:36;
-	} s;
-	/* struct cavm_nixx_af_tl4x_schedule_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_shape
- *
- * NIX AF Transmit Level 4 Shaping Control Registers
- * This register has the same bit fields as NIX_AF_TL2()_SHAPE.
- */
-union cavm_nixx_af_tl4x_shape {
-	u64 u;
-	struct cavm_nixx_af_tl4x_shape_s {
-		u64 adjust:9;		     /**< [  8:  0](R/W) See NIX_AF_TL2()_SHAPE[ADJUST]. */
-		u64 red_algo:2;		     /**< [ 10:  9](R/W) See NIX_AF_TL2()_SHAPE[RED_ALGO]. */
-		u64 red_disable:1;		     /**< [ 11: 11](R/W) See NIX_AF_TL2()_SHAPE[RED_DISABLE]. */
-		u64 yellow_disable:1;	     /**< [ 12: 12](R/W) See NIX_AF_TL2()_SHAPE[YELLOW_DISABLE]. */
-		u64 reserved_13_23:11;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) Length disable. Disables the use of packet lengths in DWRR scheduling
-                                                                 and shaping calculations such that only the value of [ADJUST] is used. */
-		u64 schedule_list:2;	     /**< [ 26: 25](R/W) Shaper scheduling list. Restricts shaper scheduling to specific lists.
-                                                                   0x0 = Normal (selected for nearly all scheduling/shaping applications).
-                                                                   0x1 = Green-only.
-                                                                   0x2 = Yellow-only.
-                                                                   0x3 = Red-only. */
-		u64 reserved_27_63:37;
-	} s;
-	/* struct cavm_nixx_af_tl4x_shape_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_cir
- *
- * NIX AF Transmit Level 4 Committed Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl4x_cir {
-	u64 u;
-	struct cavm_nixx_af_tl4x_cir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl4x_cir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_pir
- *
- * NIX AF Transmit Level 4 Peak Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_tl4x_pir {
-	u64 u;
-	struct cavm_nixx_af_tl4x_pir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl4x_pir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_sched_state
- *
- * NIX AF Transmit Level 4 Scheduling Control State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHED_STATE.
- */
-union cavm_nixx_af_tl4x_sched_state {
-	u64 u;
-	struct cavm_nixx_af_tl4x_sched_state_s {
-		u64 rr_count:25;		     /**< [ 24:  0](R/W/H) Round-robin (DWRR) deficit counter. A 25-bit two's complement signed
-                                                                 integer count. For diagnostic use. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_tl4x_sched_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_shape_state
- *
- * NIX AF Transmit Level 4 Shaping State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SHAPE_STATE.
- * This register must not be written during normal operation.
- */
-union cavm_nixx_af_tl4x_shape_state {
-	u64 u;
-	struct cavm_nixx_af_tl4x_shape_state_s {
-		u64 cir_accum:26;		     /**< [ 25:  0](R/W/H) Committed information rate accumulator. Debug access to the live CIR accumulator. */
-		u64 pir_accum:26;		     /**< [ 51: 26](R/W/H) Peak information rate accumulator. Debug access to the live PIR accumulator. */
-		u64 color:2;		     /**< [ 53: 52](R/W/H) Shaper connection status. Debug access to the live shaper state.
-                                                                 0x0 = Green - shaper is connected into the green list.
-                                                                 0x1 = Yellow - shaper is connected into the yellow list.
-                                                                 0x2 = Red - shaper is connected into the red list.
-                                                                 0x3 = Pruned - shaper is disconnected. */
-		u64 reserved_54_63:10;
-	} s;
-	/* struct cavm_nixx_af_tl4x_shape_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_pointers
- *
- * INTERNAL: NIX Transmit Level 4 Linked List Pointers Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL2()_POINTERS.
- */
-union cavm_nixx_af_tl4x_pointers {
-	u64 u;
-	struct cavm_nixx_af_tl4x_pointers_s {
-		u64 next:9;		     /**< [  8:  0](R/W/H) See NIX_AF_TL2()_POINTERS[NEXT]. */
-		u64 reserved_9_15:7;
-		u64 prev:9;		     /**< [ 24: 16](R/W/H) See NIX_AF_TL2()_POINTERS[PREV]. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_tl4x_pointers_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_sw_xoff
- *
- * NIX AF Transmit Level 4 Software Controlled XOFF Registers
- * This register has the same bit fields as NIX_AF_TL1()_SW_XOFF
- */
-union cavm_nixx_af_tl4x_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_tl4x_sw_xoff_s {
-		u64 xoff:1;		     /**< [  0:  0](R/W) XOFF. Stops meta flow out of the MDQ/TL* shaping queue. When [XOFF] is set,
-                                                                 the corresponding meta descriptor in the MDQ/TL* shaping queue cannot be
-                                                                 transferred to the next level. */
-		u64 drain:1;		     /**< [  1:  1](WO) Drain. This control activates a drain path through the PSE that starts at this queue
-                                                                 and ends at the TL1 level. The drain path is prioritized over other paths through PSE
-                                                                 and can be used in combination with [DRAIN_IRQ]. [DRAIN] need never be set for the
-                                                                 TL1 level, but is useful at all other levels, including the TL4 and MDQ levels.
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] should be clear prior to initiating a [DRAIN]=1 write to
-                                                                 this CSR.
-
-                                                                 After [DRAIN] is set for a shaping queue, it should not be set again, for
-                                                                 this or any other shaping queue, until NIX_AF_GEN_INT[TL1_DRAIN] is set.
-
-                                                                 [DRAIN] must not be set for any shaping queue when an SMQ FLUSH command is
-                                                                 active (any NIX_AF_SMQ()_CFG[FLUSH] is set).
-
-                                                                 DRAIN has no effect unless [XOFF] is also set. Only one drain command is
-                                                                 allowed to be active at a time. */
-		u64 reserved_2:1;
-		u64 drain_irq:1;		     /**< [  3:  3](WO) Drain IRQ. Enables setting of NIX_AF_GEN_INT[TL1_DRAIN] when the drain
-                                                                 operation has completed.
-                                                                 [DRAIN_IRQ] should be set whenever [DRAIN] is, and must not be set when [DRAIN] isn't
-                                                                 set. [DRAIN_IRQ] has no effect unless [DRAIN] and [XOFF] are also set. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_tl4x_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_topology
- *
- * NIX AF Transmit Level 4 Topology Registers
- */
-union cavm_nixx_af_tl4x_topology {
-	u64 u;
-	struct cavm_nixx_af_tl4x_topology_s {
-		u64 reserved_0:1;
-		u64 rr_prio:4;		     /**< [  4:  1](R/W) See NIX_AF_TL1()_TOPOLOGY[RR_PRIO]. */
-		u64 reserved_5_31:27;
-		u64 prio_anchor:9;		     /**< [ 40: 32](R/W) See NIX_AF_TL1()_TOPOLOGY[PRIO_ANCHOR]. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl4x_topology_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_parent
- *
- * NIX AF Transmit Level 4 Parent Registers
- */
-union cavm_nixx_af_tl4x_parent {
-	u64 u;
-	struct cavm_nixx_af_tl4x_parent_s {
-		u64 reserved_0_15:16;
-		u64 parent:8;		     /**< [ 23: 16](R/W) See NIX_AF_TL2()_PARENT[PARENT]. */
-		u64 reserved_24_63:40;
-	} s;
-	/* struct cavm_nixx_af_tl4x_parent_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_green
- *
- * INTERNAL: NIX Transmit Level 4 Green State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL3()_GREEN.
- */
-union cavm_nixx_af_tl4x_green {
-	u64 u;
-	struct cavm_nixx_af_tl4x_green_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19:1;
-		u64 active_vec:20;		     /**< [ 39: 20](R/W/H) Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
-                                                                 scheduling queue are active. For internal use only. */
-		u64 rr_active:1;		     /**< [ 40: 40](R/W/H) Round-robin red active. Indicates that the round-robin input is mapped to RED. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_tl4x_green_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_yellow
- *
- * INTERNAL: NIX Transmit Level 4 Yellow State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL3()_YELLOW
- */
-union cavm_nixx_af_tl4x_yellow {
-	u64 u;
-	struct cavm_nixx_af_tl4x_yellow_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_tl4x_yellow_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl4#_red
- *
- * INTERNAL: NIX Transmit Level 4 Red State Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL3()_YELLOW.
- */
-union cavm_nixx_af_tl4x_red {
-	u64 u;
-	struct cavm_nixx_af_tl4x_red_s {
-		u64 tail:9;		     /**< [  8:  0](R/W/H) Tail pointer. The index of round-robin linked-list tail. For internal use only. */
-		u64 reserved_9:1;
-		u64 head:9;		     /**< [ 18: 10](R/W/H) Head pointer. The index of round-robin linked-list head. For internal use only. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_tl4x_red_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_sched_state
- *
- * NIX AF Meta Descriptor Queue Scheduling Control State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHED_STATE.
- */
-union cavm_nixx_af_mdqx_sched_state {
-	u64 u;
-	struct cavm_nixx_af_mdqx_sched_state_s {
-		u64 rr_count:25;		     /**< [ 24:  0](R/W/H) Round-robin (DWRR) deficit counter. A 25-bit two's complement signed
-                                                                 integer count. For diagnostic use. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_mdqx_sched_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_shape
- *
- * NIX AF Meta Descriptor Queue Shaping Control Registers
- * This register has the same bit fields as NIX_AF_TL3()_SHAPE.
- */
-union cavm_nixx_af_mdqx_shape {
-	u64 u;
-	struct cavm_nixx_af_mdqx_shape_s {
-		u64 adjust:9;		     /**< [  8:  0](R/W) See NIX_AF_TL2()_SHAPE[ADJUST]. */
-		u64 red_algo:2;		     /**< [ 10:  9](R/W) See NIX_AF_TL2()_SHAPE[RED_ALGO]. */
-		u64 red_disable:1;		     /**< [ 11: 11](R/W) See NIX_AF_TL2()_SHAPE[RED_DISABLE]. */
-		u64 yellow_disable:1;	     /**< [ 12: 12](R/W) See NIX_AF_TL2()_SHAPE[YELLOW_DISABLE]. */
-		u64 reserved_13_23:11;
-		u64 length_disable:1;	     /**< [ 24: 24](R/W) Length disable. Disables the use of packet lengths in DWRR scheduling
-                                                                 and shaping calculations such that only the value of [ADJUST] is used. */
-		u64 schedule_list:2;	     /**< [ 26: 25](R/W) Shaper scheduling list. Restricts shaper scheduling to specific lists.
-                                                                   0x0 = Normal (selected for nearly all scheduling/shaping applications).
-                                                                   0x1 = Green-only.
-                                                                   0x2 = Yellow-only.
-                                                                   0x3 = Red-only. */
-		u64 reserved_27_63:37;
-	} s;
-	/* struct cavm_nixx_af_mdqx_shape_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_cir
- *
- * NIX AF Meta Descriptor Queue Committed Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_mdqx_cir {
-	u64 u;
-	struct cavm_nixx_af_mdqx_cir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_mdqx_cir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_pir
- *
- * NIX AF Meta Descriptor Queue Peak Information Rate Registers
- * This register has the same bit fields as NIX_AF_TL1()_CIR.
- */
-union cavm_nixx_af_mdqx_pir {
-	u64 u;
-	struct cavm_nixx_af_mdqx_pir_s {
-		u64 enable:1;		     /**< [  0:  0](R/W) Enable. Enables CIR shaping. */
-		u64 rate_mantissa:8;	     /**< [  8:  1](R/W) Rate mantissa. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_exponent:4;	     /**< [ 12:  9](R/W) Rate exponent. See [RATE_DIVIDER_EXPONENT]. */
-		u64 rate_divider_exponent:4;	/**< [ 16: 13](R/W) Rate divider exponent. This base-2 exponent is used to divide the
-                                                                 data rate by specifying the number of time-wheel turns required before the
-                                                                 rate accumulator is increased.
-
-                                                                 The supported range for [RATE_DIVIDER_EXPONENT] is 0 to 12. Programmed
-                                                                 values greater than 12 are treated as 12.
-
-                                                                 The data rate in Mbits/sec is computed as follows:
-                                                                 \<pre\>
-                                                                 rate_div_exp = min(12, [RATE_DIVIDER_EXPONENT]);
-                                                                 data_rate = 2 Mbps * (1.[RATE_MANTISSA] \<\< [RATE_EXPONENT]) / (1 \<\< rate_div_exp);
-                                                                 \</pre\>
-
-                                                                 Internal:
-                                                                 Hardware generates a rate divider tick every 400 rst__gbl_100mhz_sclk_edge
-                                                                 pulses, thus 100/400 = 0.25 MBytes/sec = 2 Mbps. This corresponds to a
-                                                                 minimum of 1200 SCLK cycles per tick with SCLK \>= 300 MHz. Each TL2/TL3/TL4/MDQ
-                                                                 samples its rate divider every 860 SCLK cycles and each TL1 samples every
-                                                                 240 SCLK cycles, so the sample rates are  fast enough to keep up with the
-                                                                 divider tick.
-
-                                                                 Max rate = 2 Mbps * ((1 + (255/256)) \<\< 15) = 130 Gbps. */
-		u64 reserved_17_28:12;
-		u64 burst_mantissa:8;	     /**< [ 36: 29](R/W) Burst mantissa. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 burst_exponent:4;	     /**< [ 40: 37](R/W) Burst exponent. The burst limit is 1.[BURST_MANTISSA] \<\< ([BURST_EXPONENT] + 1).
-                                                                 With [BURST_EXPONENT]=0xF and [BURST_MANTISSA]=0xFF, the burst limit is the largest
-                                                                 possible value, which is 130,816 (0x1FF00) bytes. */
-		u64 reserved_41_63:23;
-	} s;
-	/* struct cavm_nixx_af_mdqx_pir_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_sched_state
- *
- * NIX AF Meta Descriptor Queue Scheduling Control State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SCHED_STATE.
- */
-union cavm_nixx_af_mdqx_sched_state {
-	u64 u;
-	struct cavm_nixx_af_mdqx_sched_state_s {
-		u64 rr_count:25;		     /**< [ 24:  0](R/W/H) Round-robin (DWRR) deficit counter. A 25-bit two's complement signed
-                                                                 integer count. For diagnostic use. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_mdqx_sched_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_shape_state
- *
- * NIX AF Meta Descriptor Queue Shaping State Registers
- * This register has the same bit fields as NIX_AF_TL2()_SHAPE_STATE.
- * This register must not be written during normal operation.
- */
-union cavm_nixx_af_mdqx_shape_state {
-	u64 u;
-	struct cavm_nixx_af_mdqx_shape_state_s {
-		u64 cir_accum:26;		     /**< [ 25:  0](R/W/H) Committed information rate accumulator. Debug access to the live CIR accumulator. */
-		u64 pir_accum:26;		     /**< [ 51: 26](R/W/H) Peak information rate accumulator. Debug access to the live PIR accumulator. */
-		u64 color:2;		     /**< [ 53: 52](R/W/H) Shaper connection status. Debug access to the live shaper state.
-                                                                 0x0 = Green - shaper is connected into the green list.
-                                                                 0x1 = Yellow - shaper is connected into the yellow list.
-                                                                 0x2 = Red - shaper is connected into the red list.
-                                                                 0x3 = Pruned - shaper is disconnected. */
-		u64 reserved_54_63:10;
-	} s;
-	/* struct cavm_nixx_af_mdqx_shape_state_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_pointers
- *
- * INTERNAL: NIX AF Meta Descriptor 4 Linked List Pointers Debug Register
- *
- * This register has the same bit fields as NIX_AF_TL4()_POINTERS.
- */
-union cavm_nixx_af_mdqx_pointers {
-	u64 u;
-	struct cavm_nixx_af_mdqx_pointers_s {
-		u64 next:9;		     /**< [  8:  0](R/W/H) See NIX_AF_TL2()_POINTERS[NEXT]. */
-		u64 reserved_9_15:7;
-		u64 prev:9;		     /**< [ 24: 16](R/W/H) See NIX_AF_TL2()_POINTERS[PREV]. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_mdqx_pointers_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_sw_xoff
- *
- * NIX AF Meta Descriptor Controlled XOFF Registers
- * This register has the same bit fields as NIX_AF_TL1()_SW_XOFF
- */
-union cavm_nixx_af_mdqx_sw_xoff {
-	u64 u;
-	struct cavm_nixx_af_mdqx_sw_xoff_s {
-		u64 xoff:1;		     /**< [  0:  0](R/W) XOFF. Stops meta flow out of the MDQ/TL* shaping queue. When [XOFF] is set,
-                                                                 the corresponding meta descriptor in the MDQ/TL* shaping queue cannot be
-                                                                 transferred to the next level. */
-		u64 drain:1;		     /**< [  1:  1](WO) Drain. This control activates a drain path through the PSE that starts at this queue
-                                                                 and ends at the TL1 level. The drain path is prioritized over other paths through PSE
-                                                                 and can be used in combination with [DRAIN_IRQ]. [DRAIN] need never be set for the
-                                                                 TL1 level, but is useful at all other levels, including the TL4 and MDQ levels.
-                                                                 NIX_AF_GEN_INT[TL1_DRAIN] should be clear prior to initiating a [DRAIN]=1 write to
-                                                                 this CSR.
-
-                                                                 After [DRAIN] is set for a shaping queue, it should not be set again, for
-                                                                 this or any other shaping queue, until NIX_AF_GEN_INT[TL1_DRAIN] is set.
-
-                                                                 [DRAIN] must not be set for any shaping queue when an SMQ FLUSH command is
-                                                                 active (any NIX_AF_SMQ()_CFG[FLUSH] is set).
-
-                                                                 DRAIN has no effect unless [XOFF] is also set. Only one drain command is
-                                                                 allowed to be active at a time. */
-		u64 reserved_2:1;
-		u64 drain_irq:1;		     /**< [  3:  3](WO) Drain IRQ. Enables setting of NIX_AF_GEN_INT[TL1_DRAIN] when the drain
-                                                                 operation has completed.
-                                                                 [DRAIN_IRQ] should be set whenever [DRAIN] is, and must not be set when [DRAIN] isn't
-                                                                 set. [DRAIN_IRQ] has no effect unless [DRAIN] and [XOFF] are also set. */
-		u64 reserved_4_63:60;
-	} s;
-	/* struct cavm_nixx_af_mdqx_sw_xoff_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_mdq#_parent
- *
- * NIX AF Meta Descriptor Queue Topology Registers
- */
-union cavm_nixx_af_mdqx_parent {
-	u64 u;
-	struct cavm_nixx_af_mdqx_parent_s {
-		u64 reserved_0_15:16;
-		u64 parent:9;		     /**< [ 24: 16](R/W) See NIX_AF_TL2()_PARENT[PARENT]. */
-		u64 reserved_25_63:39;
-	} s;
-	/* struct cavm_nixx_af_mdqx_parent_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3_tl2#_cfg
- *
- * NIX AF Transmit Level 3/2 Configuration Registers
- */
-union cavm_nixx_af_tl3_tl2x_cfg {
-	u64 u;
-	struct cavm_nixx_af_tl3_tl2x_cfg_s {
-		u64 express:1;		     /**< [  0:  0](R/W) Express.
-                                                                 0 = This level 3 or level 2 shaping queue transmits normal packets
-                                                                 only and uses NIX_AF_TX_LINK()_NORM_CREDIT registers for link credits.
-                                                                 1 = This level 3 or level 2 shaping queue transmits express packets
-                                                                 only and uses NIX_AF_TX_LINK()_EXPR_CREDIT registers for link credits. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_tl3_tl2x_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3_tl2#_bp_status
- *
- * NIX AF Transmit Level 3/2 Backpressure Status Registers
- */
-union cavm_nixx_af_tl3_tl2x_bp_status {
-	u64 u;
-	struct cavm_nixx_af_tl3_tl2x_bp_status_s {
-		u64 hw_xoff:1;		     /**< [  0:  0](RO/H) Hardware XOFF status. Set if any of the channels mapped to this level 3 or level 2 queue
-                                                                 with NIX_AF_TL3_TL2()_LINK()_CFG is backpressured with XOFF, or if any associated link
-                                                                 is backpressured due to lack of credits (see NIX_AF_TX_LINK()_NORM_CREDIT,
-                                                                 NIX_AF_TX_LINK()_EXPR_CREDIT). */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_tl3_tl2x_bp_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tl3_tl2#_link#_cfg
- *
- * NIX AF Transmit Level 3/2 Link Configuration Registers
- * These registers specify the links and associated channels that a given TL3 or
- * TL2 queue (depending on NIX_AF_PSE_CHANNEL_LEVEL[BP_LEVEL]) can transmit on.
- * Each TL3/TL2 queue can be enabled to transmit on and be backpressured by one or
- * more links and associated channels.
- */
-union cavm_nixx_af_tl3_tl2x_linkx_cfg {
-	u64 u;
-	struct cavm_nixx_af_tl3_tl2x_linkx_cfg_s {
-		u64 relchan:8;		     /**< [  7:  0](R/W) Relative channel number within this link. See [ENA]. */
-		u64 reserved_8_11:4;
-		u64 ena:1;			     /**< [ 12: 12](R/W) Enable. When set, the TL3/TL2 queue can transmit on relative channel number
-                                                                 [RELCHAN] of this link, and will respond to backpressure from link credits
-                                                                 (NIX_AF_TX_LINK()_NORM_CREDIT, NIX_AF_TX_LINK()_EXPR_CREDIT). If
-                                                                 [BP_ENA] is set, the queue also responds to channel backpressure. */
-		u64 bp_ena:1;		     /**< [ 13: 13](R/W) Backpressure enable. When set, the TL3/TL2 queue responds to backpressure
-                                                                 from (NIX_AF_TX_LINK()_HW_XOFF/_SW_XOFF[CHAN_XOFF]\<[RELCHAN]\>). */
-		u64 reserved_14_63:50;
-	} s;
-	/* struct cavm_nixx_af_tl3_tl2x_linkx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_flow_key_alg#_field#
- *
- * NIX AF Receive Flow Key Algorithm Field Registers
- * A flow key algorithm defines how the 40-byte FLOW_KEY is formed from the received
- * packet header. FLOW_KEY is formed using up to five header fields (this register's
- * last index) with up to 16 bytes per field.
- *
- * The algorithm (index {a} (ALG) of these registers) is selected by
- * NIX_RX_ACTION_S[FLOW_KEY_ALG] from the packet's NPC_RESULT_S[ACTION].
- *
- * Internal:
- * 40-byte FLOW_KEY is wide enough to support an IPv6 5-tuple that includes a
- * VXLAN/GENEVE/NVGRE tunnel ID, e.g:
- * _ Source IP: 16B.
- * _ Dest IP: 16B.
- * _ Source port: 2B.
- * _ Dest port: 2B.
- * _ Tunnel VNI/VSI: 3B.
- * _ Total: 39B.
- */
-union cavm_nixx_af_rx_flow_key_algx_fieldx {
-	u64 u;
-	struct cavm_nixx_af_rx_flow_key_algx_fieldx_s {
-		u64 key_offset:6;		     /**< [  5:  0](R/W) Key offset. Starting byte offset of field in FLOW_KEY\<319:0\>. Bytes in
-                                                                 FLOW_KEY are enumerated in network byte order as follows:
-                                                                 Byte 0: FLOW_KEY\<319:312\>.
-                                                                 Byte 1: FLOW_KEY\<311:304\>.
-                                                                 ...
-                                                                 Byte 39: FLOW_KEY\<7:0\>.
-
-                                                                 For example, if [KEY_OFFSET] = 5, [BYTESM1] = 3:
-                                                                 _ First header byte is written to FLOW_KEY\<279:272\>.
-                                                                 _ Second header byte is written to FLOW_KEY\<271:264\>.
-                                                                 _ Third header byte is written to FLOW_KEY\<263:256\>. */
-		u64 ln_mask:1;		     /**< [  6:  6](R/W) Last nibble mask. When set, the least significant 4 bits of the last
-                                                                 extracted header byte are written to FLOW_KEY as zeros. */
-		u64 fn_mask:1;		     /**< [  7:  7](R/W) First nibble mask. When set, the most significant 4 bits of the first
-                                                                 extracted header byte are written to FLOW_KEY as zeros. */
-		u64 hdr_offset:8;		     /**< [ 15:  8](R/W) Header offset. Starting byte offset of field relative to the start
-                                                                 of the header layer. For example, when [LID] = NPC_LID_E::LC, the header
-                                                                 layer's NPC_LAYER_INFO_S = NPC_RESULT_S[LC], and the field's first byte is
-                                                                 at the following byte offset from packet start:
-                                                                 _ NPC_LAYER_INFO_S[LPTR] + [HDR_OFFSET].
-
-                                                                 Not used when [SEL_CHAN] is set. */
-		u64 bytesm1:5;		     /**< [ 20: 16](R/W) Field size in bytes minus one. 0x0=1 byte; 0x1=2 bytes, ..., 0xF=16 bytes.
-
-                                                                 Must be 0x1 when [SEL_CHAN] is set. */
-		u64 lid:3;			     /**< [ 23: 21](R/W) Layer ID of packet header. Enumerated by NPC_LID_E. Not used when [SEL_CHAN] is set. */
-		u64 reserved_23:1;
-		u64 ena:1;			     /**< [ 25: 25](R/W) Field extract enable. */
-		u64 sel_chan:1;				/**< [ 26: 26](R/W) Select channel number. When set, {4'h0, NIX_RX_PARSE_S[CHAN]\<11:0\>} is
-                                                                 selected as the field data instead of the packet header data specified by
-                                                                 [LID] and [HDR_OFFSET].
-                                                                 [BYTESM1] must be 0x1 (2 bytes) when this bit is set. */
-		u64 ltype_mask:4;	/**< [ 30: 27](R/W) Layer type mask. See [LTYPE_MATCH]. */
-		u64 ltype_match:4;	/**< [ 34: 31](R/W) Layer type match value. Hardware detects a layer match when
-                                                                 \<pre\>
-                                                                 ([LTYPE_MATCH] & [LTYPE_MASK]) == (NPC_RESULT_S[LX[LTYPE]] & [LTYPE_MASK])
-                                                                 \</pre\>
-
-                                                                 where LX is one of LA, LB, ..., LG as selected by [LID]. */
-		u64 reserved_35_63:29;
-	} s;
-	/* struct cavm_nixx_af_rx_flow_key_algx_fieldx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_mcast#
- *
- * NIX AF Transmit Multicast Registers
- * These registers access transmit multicast table entries used to specify multicast replication
- * lists. Each list consists of linked entries with [EOL] = 1 in the last entry.
- *
- * A transmit packet is multicast when the action returned by NPC has NIX_TX_ACTION_S[OP] =
- * NIX_TX_ACTIONOP_E::MCAST. NIX_TX_ACTION_S[INDEX] points to the start of the multicast
- * replication list, and [EOL] = 1 indicates the end of list.
- */
-union cavm_nixx_af_tx_mcastx {
-	u64 u;
-	struct cavm_nixx_af_tx_mcastx_s {
-		u64 channel:12;		     /**< [ 11:  0](R/W) Transmit channel ID enumerated by NIX_CHAN_E. */
-		u64 eol:1;			     /**< [ 12: 12](R/W) End of multicast replication list. */
-		u64 reserved_13_15:3;
-		u64 next:16;		     /**< [ 31: 16](R/W) Pointer to next NIX_AF_TX_MCAST() register in the multicast replication
-                                                                 list. Valid when [EOL] is clear. */
-		u64 reserved_32_63:32;
-	} s;
-	/* struct cavm_nixx_af_tx_mcastx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_vtag_def#_ctl
- *
- * NIX AF Transmit Vtag Definition Control Registers
- * The transmit Vtag definition table specifies Vtag layers (e.g. VLAN, E-TAG) to
- * optionally insert or replace in the TX packet header. Indexed by
- * NIX_TX_VTAG_ACTION_S[VTAG*_DEF].
- */
-union cavm_nixx_af_tx_vtag_defx_ctl {
-	u64 u;
-	struct cavm_nixx_af_tx_vtag_defx_ctl_s {
-		u64 size:3;		     /**< [  2:  0](R/W) Vtag size enumerated by NIX_VTAGSIZE_E. */
-		u64 reserved_3_63:61;
-	} s;
-	/* struct cavm_nixx_af_tx_vtag_defx_ctl_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_tx_vtag_def#_data
- *
- * NIX AF Transmit Vtag Definition Data Registers
- * See NIX_AF_TX_VTAG_DEF()_CTL.
- */
-union cavm_nixx_af_tx_vtag_defx_data {
-	u64 u;
-	struct cavm_nixx_af_tx_vtag_defx_data_s {
-		u64 data:64;		     /**< [ 63:  0](R/W) Vtag data formatted as follows:
-                                                                 * If NIX_AF_TX_VTAG_DEF()_CTL[SIZE] = NIX_VTAGSIZE_E::T4:
-                                                                   \<63:48\> Ethertype, \<47:32\> TCI, \<31:0\> Reserved.
-                                                                 * If NIX_AF_TX_VTAG_DEF()_CTL[SIZE] = NIX_VTAGSIZE_E::T8:
-                                                                   \<63:48\> Ethertype, \<47:0\> TCI. */
-	} s;
-	/* struct cavm_nixx_af_tx_vtag_defx_data_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_bpid#_status
- *
- * NIX AF Receive Backpressure ID Status Registers
- */
-union cavm_nixx_af_rx_bpidx_status {
-	u64 u;
-	struct cavm_nixx_af_rx_bpidx_status_s {
-		u64 aura_cnt:32;		     /**< [ 31:  0](R/W/H) Backpressure aura count. Number of auras that are backpressuring (XOFF) this BPID.
-
-                                                                 Writes to this field are for diagnostic use only. The write data is a two's
-                                                                 complement signed value added to the aura count. */
-		u64 cq_cnt:32;		     /**< [ 63: 32](R/W/H) Backpressure CQ count. Number of completion queues that are backpressuring (XOFF) this
-                                                                 BPID.
-
-                                                                 Writes to this field are for diagnostic use only. The write data is a two's
-                                                                 complement signed value added to the CQ count. */
-	} s;
-	/* struct cavm_nixx_af_rx_bpidx_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_chan#_cfg
- *
- * NIX AF Receive Channel Configuration Registers
- */
-union cavm_nixx_af_rx_chanx_cfg {
-	u64 u;
-	struct cavm_nixx_af_rx_chanx_cfg_s {
-		u64 bpid:9;		     /**< [  8:  0](R/W/H) BPID used to receive backpressure when [BP_ENA] is set. */
-		u64 reserved_9_15:7;
-		u64 bp_ena:1;		     /**< [ 16: 16](R/W/H) Backpressure enable. When set, the channel receives backpressure from [BPID]. */
-		u64 sw_xoff:1;		     /**< [ 17: 17](R/W/H) Software XOFF. When set, backpressure is forced on the RX channel. */
-		u64 imp:1;			     /**< [ 18: 18](RO/H) Implemented. This register is sparse (only indexes with values in NIX_CHAN_E which are
-                                                                 implemented).
-                                                                 0 = Channel is not implemented.
-                                                                 1 = Channel is implemented.
-
-                                                                 Write to a non-implemented channel is ignored. Reading a non-implemented channel returns
-                                                                 all zero data. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_rx_chanx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_cint_timer#
- *
- * NIX AF Completion Interrupt Timer Registers
- */
-union cavm_nixx_af_cint_timerx {
-	u64 u;
-	struct cavm_nixx_af_cint_timerx_s {
-		u64 expir_time:16;		     /**< [ 15:  0](RO/H) CINT expiration time. Updated as follows when the CINT timer is activated
-                                                                 (see [ACTIVE]):
-                                                                 _ [EXPIR_TIME] = NIX_AF_CINT_DELAY[CINT_TIMER] + NIX_LF_CINT()_WAIT[TIME_WAIT]
-
-                                                                 When [ACTIVE] is set and NIX_AF_CINT_DELAY[CINT_TIMER] crosses
-                                                                 [EXPIR_TIME], hardware sets the associated
-                                                                 NIX_LF_CINT()_INT[INTR] bit and deactivates this CINT timer. */
-		u64 cint:7;		     /**< [ 22: 16](RO/H) Completion interrupt within [LF] associated with this timer. */
-		u64 reserved_23:1;
-		u64 lf:8;			     /**< [ 31: 24](RO/H) Local function associated with this timer. */
-		u64 active:1;		     /**< [ 32: 32](RO/H) This CINT timer is active and the remaining fields in this register
-                                                                 are valid when this bit is set. See also [EXPIR_TIME].
-
-                                                                 A CINT timer is activated when a CINT's NIX_LF_CINT()_CNT[ECOUNT]
-                                                                 increments from zero, and deactivated when the CINT's
-                                                                 NIX_LF_CINT()_INT[INTR] is set or NIX_LF_CINT()_CNT[ECOUNT] goes to zero. A
-                                                                 timer is also activated when software writes a one to clear
-                                                                 NIX_LF_CINT()_INT[INTR] and NIX_LF_CINT()_CNT[ECOUNT] is nonzero.
-
-                                                                 When all CINT timers are active and a new timer needs to be activated, the
-                                                                 least recently activated timer is removed and the associated
-                                                                 NIX_LF_CINT()_INT[INTR] is set. */
-		u64 reserved_33_63:31;
-	} s;
-	/* struct cavm_nixx_af_cint_timerx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lso_format#_field#
- *
- * NIX AF Large Send Offload Format Field Registers
- * These registers specify LSO packet modification formats. Each format may modify
- * up to eight packet fields with the following constraints:
- * * If fewer than eight fields are modified, [ALG] must be NIX_LSOALG_E::NOP in the
- * unused field registers.
- * * Modified fields must be specified in contiguous field registers starting with
- * NIX_AF_LSO_FORMAT()_FIELD(0).
- * * Modified fields cannot overlap.
- * * Multiple fields with the same [LAYER] value must be specified in
- * ascending [OFFSET] order.
- * * Fields in different layers must be specified in ascending [LAYER] order.
- */
-union cavm_nixx_af_lso_formatx_fieldx {
-	u64 u;
-	struct cavm_nixx_af_lso_formatx_fieldx_s {
-		u64 offset:8;		     /**< [  7:  0](R/W) Starting byte offset of the field relative to the first byte of [LAYER] in
-                                                                 the packet header. */
-		u64 layer:2;		     /**< [  9:  8](R/W) Header layer that contains the field, enumerated by NIX_TXLAYER_E. */
-		u64 reserved_10_11:2;
-		u64 sizem1:2;		     /**< [ 13: 12](R/W) Field size in bytes minus one. */
-		u64 reserved_14_15:2;
-		u64 alg:3;			     /**< [ 18: 16](R/W) Field modification algorithm enumerated by NIX_LSOALG_E. The remaining
-                                                                 fields in the register are valid when value is not NIX_LSOALG_E::NOP. */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_lso_formatx_fieldx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_priv_lf#_cfg
- *
- * NIX Privileged Local Function Configuration Registers
- * These registers allow each NIX local function (LF) to be provisioned to a VF/PF
- * for RVU. See also NIX_AF_RVU_LF_CFG_DEBUG.
- *
- * Software should read this register after write to ensure that the LF is mapped to
- * [PF_FUNC] before issuing transactions to the mapped PF and function.
- *
- * [SLOT] must be zero.
- *
- * Internal:
- * Hardware ignores [SLOT] and always assumes 0x0.
- */
-union cavm_nixx_priv_lfx_cfg {
-	u64 u;
-	struct cavm_nixx_priv_lfx_cfg_s {
-		u64 slot:8;		     /**< [  7:  0](R/W) Slot within the VF/PF selected by [PF_FUNC] to which the LF is
-                                                                 provisioned. */
-		u64 pf_func:16;		     /**< [ 23:  8](R/W) RVU VF/PF to which the LF is provisioned. Format defined by RVU_PF_FUNC_S.
-                                                                 Interrupts from the LF are delivered to the selected PF/VF. */
-		u64 reserved_24_62:39;
-		u64 ena:1;			     /**< [ 63: 63](R/W) Enable. When set, the LF is enabled and provisioned to the VF/PF slot
-                                                                 selected by [PF_FUNC] and [SLOT]. When clear, the LF is not provisioned.
-
-                                                                 LF to slot mapping must be 1-to-1. Thus, each enabled LF must be provisioned
-                                                                 to a unique {[PF_FUNC], [SLOT]} combination. */
-	} s;
-	/* struct cavm_nixx_priv_lfx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_sqs_cfg
- *
- * NIX AF Local Function Send Queues Configuration Register
- * This register configures send queues in the LF.
- */
-union cavm_nixx_af_lfx_sqs_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_sqs_cfg_s {
-		u64 max_queuesm1:20;	     /**< [ 19:  0](R/W) Maximum number of queues minus one. */
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating queue context structures in NDC (1
-                                                                 means do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of write and read for accessing queue context structures
-                                                                 in LLC/DRAM:
-                                                                 0 = Writes and reads of context data will not allocate into the LLC.
-                                                                 1 = Writes and reads of context data are allocated into the LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_sqs_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_sqs_base
- *
- * NIX AF Local Function Send Queues Base Address Register
- * This register specifies the base AF IOVA of the LF's SQ context table.
- * The table consists of NIX_AF_LF()_SQS_CFG[MAX_QUEUESM1]+1 contiguous
- * NIX_SQ_CTX_HW_S structures.
- */
-union cavm_nixx_af_lfx_sqs_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_sqs_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_sqs_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rqs_cfg
- *
- * NIX AF Local Function Receive Queues Configuration Register
- * This register configures receive queues in the LF.
- */
-union cavm_nixx_af_lfx_rqs_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_rqs_cfg_s {
-		u64 max_queuesm1:20;	     /**< [ 19:  0](R/W) Maximum number of queues minus one. */
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating queue context structures in NDC (1
-                                                                 means do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of write and read for accessing queue context structures
-                                                                 in LLC/DRAM:
-                                                                 0 = Writes and reads of context data will not allocate into the LLC.
-                                                                 1 = Writes and reads of context data are allocated into the LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_rqs_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rqs_base
- *
- * NIX AF Local Function Receive Queues Base Address Register
- * This register specifies the base AF IOVA of the LF's RQ context table.
- * The table consists of NIX_AF_LF()_RQS_CFG[MAX_QUEUESM1]+1 contiguous
- * NIX_RQ_CTX_S structures.
- */
-union cavm_nixx_af_lfx_rqs_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_rqs_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_rqs_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_cqs_cfg
- *
- * NIX AF Local Function Completion Queues Configuration Register
- * This register configures completion queues in the LF.
- */
-union cavm_nixx_af_lfx_cqs_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_cqs_cfg_s {
-		u64 max_queuesm1:20;	     /**< [ 19:  0](R/W) Maximum number of queues minus one. */
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating queue context structures in NDC (1
-                                                                 means do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of write and read for accessing queue context structures
-                                                                 in LLC/DRAM:
-                                                                 0 = Writes and reads of context data will not allocate into the LLC.
-                                                                 1 = Writes and reads of context data are allocated into the LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_cqs_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_cqs_base
- *
- * NIX AF Local Function Completion Queues Base Address Register
- * This register specifies the base AF IOVA of the LF's CQ context table.
- * The table consists of NIX_AF_LF()_CQS_CFG[MAX_QUEUESM1]+1 contiguous
- * NIX_CQ_CTX_S structures.
- */
-union cavm_nixx_af_lfx_cqs_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_cqs_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_cqs_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_tx_cfg
- *
- * NIX AF Local Function Transmit Configuration Register
- */
-union cavm_nixx_af_lfx_tx_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_tx_cfg_s {
-		u64 vlan0_ins_etype:16;	     /**< [ 15:  0](R/W) VLAN 0 Insert Ethertype. Ethertype of VLAN tag that is inserted when
-                                                                 NIX_SEND_EXT_S[VLAN0_INS_ENA]=1. */
-		u64 vlan1_ins_etype:16;	     /**< [ 31: 16](R/W) VLAN 1 Insert Ethertype. Ethertype of VLAN tag that is inserted when
-                                                                 NIX_SEND_EXT_S[VLAN1_INS_ENA]=1. */
-		u64 send_tstmp_ena:1;	     /**< [ 32: 32](R/W) Send timestamp enable. When set, the LF is allowed to request PTP
-                                                                 timestamps in send packets. See NIX_SEND_EXT_S[TSTMP] and
-                                                                 NIX_SENDMEMALG_E::SETTSTMP. */
-		u64 lock_viol_cqe_ena:1;	     /**< [ 33: 33](R/W) Enable reporting of lockdown violations due to either of the following
-                                                                 conditions:
-                                                                 * [LOCK_ENA] is set and a violation is detected on packet data locked by
-                                                                 NIX_AF_LF()_LOCK().
-                                                                 * NIX_TX_ACTION_S[OP] = NIX_TX_ACTIONOP_E::DROP_VIOL. */
-		u64 lock_ena:1;		     /**< [ 34: 34](R/W) Lockdown enable. When set, NIX_AF_LF()_LOCK() can be used to lock
-                                                                 down one or more bits in packets transmitted by the LF. */
-		u64 reserved_35_63:29;
-	} s;
-	/* struct cavm_nixx_af_lfx_tx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_tx_parse_cfg
- *
- * NIX AF Local Function Transmit Parse Configuration Register
- */
-union cavm_nixx_af_lfx_tx_parse_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_tx_parse_cfg_s {
-		u64 pkind:6;		     /**< [  5:  0](R/W/H) Port kind supplied to NPC to seed the parsing of packets to be transmitted by this LF. */
-		u64 reserved_6_63:58;
-	} s;
-	/* struct cavm_nixx_af_lfx_tx_parse_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_cfg
- *
- * NIX AF Local Function Receive Configuration Register
- */
-union cavm_nixx_af_lfx_rx_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_cfg_s {
-		u64 reserved_0_32:33;
-		u64 lenerr_en:1;		     /**< [ 33: 33](R/W) Outer L2 length error check enable. See NIX_RE_OPCODE_E::OL2_LENMISM. */
-		u64 ip6_udp_opt:1;		     /**< [ 34: 34](R/W) IPv6/UDP checksum is optional. IPv4 allows an optional UDP checksum by
-                                                                 sending the all-0s patterns. IPv6 outlaws this and the spec says to always
-                                                                 check UDP checksum.
-                                                                 0 = Spec compliant, do not allow all-0s IPv6/UDP checksum.
-                                                                 1 = Treat IPv6 as IPv4; the all-0s pattern will cause a UDP checksum pass. */
-		u64 dis_apad:1;		     /**< [ 35: 35](R/W) Disable alignment pad. When set, alignment padding is not added before the packet's
-                                                                 first byte.
-
-                                                                 When clear, enables alignment padding before the packet's first byte is written to
-                                                                 either of the following (or both when NIX_RQ_CTX_S[XQE_IMM_COPY] is set):
-                                                                 * The packet's first buffer (first NIX_RX_SG_S segment in WQE/CQE).
-                                                                   The alignment pad size (APAD) is in this case added to the first segment's
-                                                                   NIX_IOVA_S, i.e.  NIX_IOVA_S\<2:0\> = APAD.
-                                                                 * Immediate data following NIX_RX_IMM_S.
-                                                                   The alignment pad size is in this case captured in NIX_RX_IMM_S[APAD].
-
-                                                                 The padding is calculated by the following algorithm:
-                                                                 \<pre\>
-                                                                 int nix_calc_alignment_pad(
-                                                                       // Layer valids and pointers based on NPC_RESULT_S[LA,..,LH] matching
-                                                                       // NIX_AF_RX_DEF_OIP4/OIP6/IIP6.
-                                                                       bool oip4_valid,
-                                                                       bool oip6_valid,
-                                                                       bool iip6_valid,
-                                                                       int oip4_ptr,
-                                                                       int oip6_ptr,
-                                                                       int iip6_ptr )
-                                                                 {
-                                                                    int APAD;
-                                                                    if ([DIS_APAD])
-                                                                       APAD = 0;
-                                                                    else if (oip6_valid) // Outer IP.ver == 6
-                                                                       APAD = (8 - oip6_ptr) & 0x7;
-                                                                    else if (oip4_valid && iip6_valid) // Inner IP.ver == 6
-                                                                       APAD = (8 - iip6_ptr) & 0x7;
-                                                                    else if (oip4_valid)
-                                                                       APAD = (4 - oip4_ptr) & 0x7;
-                                                                    else
-                                                                       APAD = 0;
-                                                                    return APAD;
-                                                                 }
-                                                                 \</pre\> */
-		u64 csum_il4:1;		     /**< [ 36: 36](R/W) Enable checking of inner L4 TCP/UDP/SCTP checksum. See
-                                                                 NIX_RX_PERRCODE_E::IL4_CHK. */
-		u64 csum_ol4:1;		     /**< [ 37: 37](R/W) Enable checking of outer L4 TCP/UDP/SCTP checksum. See
-                                                                 NIX_RX_PERRCODE_E::OL4_CHK. */
-		u64 len_il4:1;		     /**< [ 38: 38](R/W) Inner L4 UDP length error check enable. See NIX_RX_PERRCODE_E::IL4_LEN. */
-		u64 len_il3:1;		     /**< [ 39: 39](R/W) Inner L3 length error check enable. See NIX_RX_PERRCODE_E::IL3_LEN. */
-		u64 len_ol4:1;		     /**< [ 40: 40](R/W) Outer L4 UDP length error check enable. See NIX_RX_PERRCODE_E::OL4_LEN. */
-		u64 len_ol3:1;		     /**< [ 41: 41](R/W) Outer L3 length error check enable. See NIX_RX_PERRCODE_E::OL3_LEN. */
-		u64 reserved_42_63:22;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rss_cfg
- *
- * NIX AF Local Function Receive Size Scaling Table Configuration Register
- * See NIX_AF_LF()_RSS_BASE and NIX_AF_LF()_RSS_GRP().
- */
-union cavm_nixx_af_lfx_rss_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_rss_cfg_s {
-		u64 size:4;		     /**< [  3:  0](R/W) Specifies table size in NIX_RSSE_S entries of four bytes when [ENA] is set:
-                                                                 0x0 = 256 entries.
-                                                                 0x1 = 512 entries.
-                                                                 0x2 = 1K entries.
-                                                                 0x3 = 2K entries.
-                                                                 0x4-0xF = Reserved. */
-		u64 ena:1;			     /**< [  4:  4](R/W) RSS is enabled for the LF. */
-		u64 reserved_5_19:15;
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating NIX_RSSE_S structures in NDC (1 means
-                                                                 do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of read for accessing NIX_RSSE_S structures in LLC/DRAM:
-                                                                 0 = NIX_RSSE_S reads will not allocate into the LLC.
-                                                                 1 = NIX_RSSE_S reads are allocated into the LLC.
-
-                                                                 NIX_RX_MCE_S writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_rss_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rss_base
- *
- * NIX AF Local Function Receive Size Scaling Table Base Address Register
- * This register specifies the base AF IOVA of the RSS table per LF. The
- * table is present when NIX_AF_LF()_RSS_CFG[ENA] is set and consists of
- * 2^(NIX_AF_LF()_RSS_CFG[SIZE]+8) contiguous NIX_RSSE_S structures, where the
- * size of each structure is 1 \<\< NIX_AF_CONST3[RSSE_LOG2BYTES] bytes.
- * See NIX_AF_LF()_RSS_GRP().
- */
-union cavm_nixx_af_lfx_rss_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_rss_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_rss_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_qints_cfg
- *
- * NIX AF Local Function Queue Interrupts Configuration Registers
- * This register controls access to the LF's queue interrupt context table in
- * NDC/LLC/DRAM. The table consists of NIX_AF_CONST2[QINTS] contiguous NIX_QINT_HW_S
- * structures. The size of each structure is 1 \<\< NIX_AF_CONST3[QINT_LOG2BYTES]
- * bytes.
- */
-union cavm_nixx_af_lfx_qints_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_qints_cfg_s {
-		u64 reserved_0_19:20;
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating context structures in NDC (1 means do
-                                                                 not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style read for accessing context structures in LLC/DRAM:
-                                                                 0 = Context structure reads will not allocate into the LLC.
-                                                                 1 = Context structure reads are allocated into the LLC.
-
-                                                                 Context structure writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_qints_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_qints_base
- *
- * NIX AF Local Function Queue Interrupts Base Address Registers
- * This register specifies the base AF IOVA of LF's queue interrupt context
- * table in NDC/LLC/DRAM. The table consists of NIX_AF_CONST2[QINTS] contiguous
- * NIX_QINT_HW_S structures.
- */
-union cavm_nixx_af_lfx_qints_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_qints_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_qints_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_cints_cfg
- *
- * NIX AF Local Function Completion Interrupts Configuration Registers
- * This register controls access to the LF's completion interrupt context table in
- * NDC/LLC/DRAM. The table consists of NIX_AF_CONST2[CINTS] contiguous NIX_CINT_HW_S
- * structures. The size of each structure is 1 \<\< NIX_AF_CONST3[CINT_LOG2BYTES]
- * bytes.
- */
-union cavm_nixx_af_lfx_cints_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_cints_cfg_s {
-		u64 reserved_0_19:20;
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating context structures in NDC (1 means do
-                                                                 not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style read for accessing context structures in LLC/DRAM:
-                                                                 0 = Context structure reads will not allocate into the LLC.
-                                                                 1 = Context structure reads are allocated into the LLC.
-
-                                                                 Context structure writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_cints_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_cints_base
- *
- * NIX AF Local Function Completion Interrupts Base Address Registers
- * This register specifies the base AF IOVA of LF's completion interrupt
- * context table in NDC/LLC/DRAM. The table consists of NIX_AF_CONST2[CINTS]
- * contiguous NIX_CINT_HW_S structures.
- */
-union cavm_nixx_af_lfx_cints_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_cints_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_cints_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_ipsec_cfg0
- *
- * NIX AF LF Receive IPSEC Configuration Registers
- */
-union cavm_nixx_af_lfx_rx_ipsec_cfg0 {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_ipsec_cfg0_s {
-		u64 lenm1_max:14;		     /**< [ 13:  0](R/W) Maximum length in bytes (minus 1) of a packet that may use the IPSEC
-                                                                 hardware fast-path. */
-		u64 sa_pow2_size:4;	     /**< [ 17: 14](R/W) Power of 2 size of IPSEC SA structure used by CPT:
-                                                                 0x0-0x4 = Reserved.
-                                                                 0x5 = 32 bytes.
-                                                                 0x6 = 64 bytes.
-                                                                 0x7 = 128 bytes.
-                                                                 0x8 = 256 bytes.
-                                                                 0x9 = 512 bytes.
-                                                                 0xA-0xF = Reserved. */
-		u64 reserved_18_39:22;
-		u64 defcpt:1;		     /**< [ 40: 40](RAZ) Default CPT index. Always zero. */
-		u64 hshcpt:1;		     /**< [ 41: 41](RAZ) Hash CPT index. Always zero. */
-		u64 reserved_42_63:22;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_ipsec_cfg0_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_ipsec_cfg1
- *
- * NIX AF LF Receive IPSEC Security Association Configuration Register
- */
-union cavm_nixx_af_lfx_rx_ipsec_cfg1 {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_ipsec_cfg1_s {
-		u64 sa_idx_max:32;		     /**< [ 31:  0](R/W) Maximum SA index recognized by hardware for the LF. See [SA_IDX_W]. */
-		u64 tag_const:24;	/**< [ 55: 32](R/W) Constant value ORed into NIX_WQE_HDR_S[TAG]\<31:8\> for IPSEC fast-path
-                                                                 (non-software) packets (NIX_WQE_HDR_S[WQE_TYPE] = NIX_XQE_TYPE_E::RX_IPSECH
-                                                                 or NIX_XQE_TYPE_E::RX_IPSECD). */
-		u64 tt:2;		/**< [ 57: 56](R/W) SSO tag type to load to NIX_WQE_HDR_S[TT] for IPSEC fast-path
-                                                                 (non-software) packets (NIX_WQE_HDR_S[WQE_TYPE] = NIX_XQE_TYPE_E::RX_IPSECH
-                                                                 or NIX_XQE_TYPE_E::RX_IPSECD). */
-		u64 sa_idx_w:5;		     /**< [ 62: 58](R/W) Security association index width. Number of lower bits from the SPI field
-                                                                 of an IPSEC packet that provide the packet's SA index. The SA index is
-                                                                 computed as follows:
-                                                                 \<pre\>
-                                                                 SPI\<31:0\> = packet's 32-bit IPSEC SPI field; // see NIX_AF_RX_DEF_IPSEC()
-                                                                 SA_index = SPI & ((1 \<\< [SA_IDX_W]) - 1);
-                                                                 \</pre\>
-
-                                                                 If the packet's SA index is greater than [SA_IDX_MAX], the packet uses the
-                                                                 IPSEC software fast-path (NIX_WQE_HDR_S[WQE_TYPE]/NIX_CQE_HDR_S[CQE_TYPE] =
-                                                                 NIX_XQE_TYPE_E::RX_IPSECS). */
-		u64 reserved_63:1;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_ipsec_cfg1_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_ipsec_dyno_cfg
- *
- * NIX AF LF Receive IPSEC Dynamic Ordering Base Address Registers
- */
-union cavm_nixx_af_lfx_rx_ipsec_dyno_cfg {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_ipsec_dyno_cfg_s {
-		u64 dyno_idx_w:4;		     /**< [  3:  0](R/W) Dynamic ordering counter index width. When [DYNO_ENA]==1, specifies the
-                                                                 number of lower bits of an IPSEC packet's SA index used to select the DYNO
-                                                                 counter for the packet. See [DYNO_ENA]. */
-		u64 dyno_ena:1;		     /**< [  4:  4](R/W) Dynamic ordering enable. When set, enables dynamic ordering (DYNO) counters
-                                                                 used to enforce ordering between IPSEC hardware fast-path packets
-                                                                 (NIX_WQE_HDR_S[WQE_TYPE] = NIX_XQE_TYPE_E::RX_IPSECH) and dynamically
-                                                                 prevented packets (NIX_WQE_HDR_S[WQE_TYPE] = NIX_XQE_TYPE_E::RX_IPSECD)
-                                                                 within a given flow.
-
-                                                                 When set, hardware maintains 1 \<\< [DYNO_IDX_W] DYNO counters in
-                                                                 NDC/LLC/DRAM starting at address NIX_AF_LF()_RX_IPSEC_DYNO_BASE, where the
-                                                                 size of each counter is 1 \<\< NIX_AF_CONST3[DYNO_LOG2BYTES] bytes.
-
-                                                                 The DYNO counter index for an IPSEC hardware fast-path or a dynamically
-                                                                 prevented packet is obtained from the lower [DYNO_IDX_W] bits of the
-                                                                 packet's IPSEC SA index. See NIX_AF_LF()_RX_IPSEC_CFG1[SA_IDX_W].
-
-                                                                 Hardware increments the selected DYNO counter by one for each dynamically
-                                                                 prevented packet. Software decrements the counter by writing to
-                                                                 NIX_LF_OP_IPSEC_DYNO_CNT. Hardware suppresses the IPSEC hardware fast-path
-                                                                 when the counter is non-zero. */
-		u64 reserved_5_19:15;
-		u64 way_mask:16;		     /**< [ 35: 20](R/W) Way partitioning mask for allocating NIX_RSSE_S structures in NDC (1 means
-                                                                 do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-		u64 caching:1;		     /**< [ 36: 36](R/W) Selects the style of read for accessing dynamic ordering counters in
-                                                                 LLC/DRAM:
-                                                                 0 = DYNO counter reads will not allocate into the LLC.
-                                                                 1 = DYNO counter reads are allocated into the LLC.
-
-                                                                 DYNO counter writes that are not allocated in NDC will always allocate into
-                                                                 LLC. */
-		u64 reserved_37_63:27;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_ipsec_dyno_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_ipsec_dyno_base
- *
- * NIX AF LF Receive IPSEC Dynamic Ordering Base Address Registers
- * This register specifies the base AF IOVA of LF's dynamic ordering
- * (DYNO) counter table in NDC/LLC/DRAM. The table consists of
- * 1 \<\< (NIX_AF_LF()_RX_IPSEC_DYNO_CFG[DYNO_IDX_W]) counters. The size of each
- * counter is 1 \<\< NIX_AF_CONST3[DYNO_LOG2BYTES] bytes.
- * See NIX_AF_LF()_RX_IPSEC_DYNO_CFG[DYNO_ENA].
- */
-union cavm_nixx_af_lfx_rx_ipsec_dyno_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_ipsec_dyno_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_ipsec_dyno_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_ipsec_sa_base
- *
- * NIX AF LF Receive IPSEC Security Association Base Address Register
- * This register specifies the base IOVA of CPT's IPSEC SA table in LLC/DRAM.
- */
-union cavm_nixx_af_lfx_rx_ipsec_sa_base {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_ipsec_sa_base_s {
-		u64 reserved_0_6:7;
-		u64 addr:46;		     /**< [ 52:  7](R/W) Base AF IOVA of table in NDC/LLC/DRAM. IOVA bits \<6:0\> are always
-                                                                 zero. */
-		u64 reserved_53_63:11;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_ipsec_sa_base_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_tx_status
- *
- * NIX AF LF Transmit Status Register
- */
-union cavm_nixx_af_lfx_tx_status {
-	u64 u;
-	struct cavm_nixx_af_lfx_tx_status_s {
-		u64 sq_ctx_err:1;		     /**< [  0:  0](R/W1C/H) SQ context error. An error was detected on a NIX_SQ_CTX_S read. When set:
-                                                                 * Hardware drops LMT stores to NIX_LF_OP_SEND().
-                                                                 * Hardware stops enqueueing MDs to SMQs assigned to the LF
-                                                                 (NIX_AF_SMQ()_CFG[LF]).
-
-                                                                 Software can clear this bit by writing a one. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_nixx_af_lfx_tx_status_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_vtag_type#
- *
- * NIX AF Local Function Receive Vtag Type Registers
- * These registers specify optional Vtag (e.g. VLAN, E-TAG) actions for received
- * packets. Indexed by NIX_RX_VTAG_ACTION_S[VTAG*_TYPE].
- */
-union cavm_nixx_af_lfx_rx_vtag_typex {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_vtag_typex_s {
-		u64 size:3;		     /**< [  2:  0](R/W) Vtag size enumerated by NIX_VTAGSIZE_E. */
-		u64 reserved_3:1;
-		u64 strip:1;		     /**< [  4:  4](R/W) When set, the Vtag is stripped from the received packet header. Note that the
-                                                                 Vtag is silently stripped if [STRIP] is set and [CAPTURE] is clear. */
-		u64 capture:1;		     /**< [  5:  5](R/W) When set, Vtag's information is captured in NIX_RX_PARSE_S[VTAG*]. */
-		u64 reserved_6_63:58;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_vtag_typex_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_lock#
- *
- * NIX AF Local Function Lockdown Registers
- * Internal:
- * The NIX lockdown depth of 32 bytes is shallow compared to 96 bytes for NIC and meant for outer
- * MAC and/or VLAN (optionally preceded by a small number of skip bytes). NPC's MCAM can be used
- * for deeper protocol-aware lockdown.
- */
-union cavm_nixx_af_lfx_lockx {
-	u64 u;
-	struct cavm_nixx_af_lfx_lockx_s {
-		u64 data:32;		     /**< [ 31:  0](R/W) Lockdown data. If corresponding [BIT_ENA] is set and
-                                                                 NIX_AF_LF()_TX_CFG[LOCK_ENA] is set, outbound packet data must match the
-                                                                 [DATA] bit or the packet will be dropped. Bytes are numbered in little
-                                                                 endian form, with byte 0 the first byte onto the wire:
-                                                                 _ If LOCK(0)[BIT_ENA]\<7:0\> set, LOCK(0)[DATA]\<7:0\> = packet byte 0.
-                                                                 _ If LOCK(0)[BIT_ENA]\<15:8\> set, LOCK(0)[DATA]\<15:8\> = packet byte 1.
-                                                                 _ If LOCK(0)[BIT_ENA]\<23:16\> set, LOCK(0)[DATA]\<23:16\> = packet byte 2.
-                                                                 _ ...
-                                                                 _ If LOCK(1)[BIT_ENA]\<7:0\> set, LOCK(1)[DATA]\<7:0\> = packet byte 4.
-                                                                 _ ...
-                                                                 _ If LOCK(7)[BIT_ENA]\<31:24\> set, LOCK(7)[DATA]\<31:24\> = packet byte 31.
-
-                                                                 Lockdown data is checked after all packet modifications by hardware other
-                                                                 than checksum/CRC updates. These modifications include potential VLAN
-                                                                 insertion, packet shaper marking, LSO modifications and Vtag
-                                                                 insertion/replacement.
-
-                                                                 In addition, if any checksum/CRC bits updated by NIX_SEND_HDR_S[CKL*]
-                                                                 and/or NIX_SEND_CRC_S are locked down, a lockdown violation is detected and
-                                                                 the packet is dropped. */
-		u64 bit_ena:32;		     /**< [ 63: 32](R/W) Lockdown bit enable. Each set bit indicates that the transmitted packet's corresponding
-                                                                 bit number will be compared against [DATA]. */
-	} s;
-	/* struct cavm_nixx_af_lfx_lockx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_tx_stat#
- *
- * NIX AF Local Function Transmit Statistics Registers
- * The last dimension indicates which statistic, and is enumerated by NIX_STAT_LF_TX_E.
- */
-union cavm_nixx_af_lfx_tx_statx {
-	u64 u;
-	struct cavm_nixx_af_lfx_tx_statx_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. See also NIX_LF_TX_STAT() for a read-only alias of this
-                                                                 field. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_lfx_tx_statx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rx_stat#
- *
- * NIX AF Local Function Receive Statistics Registers
- * The last dimension indicates which statistic, and is enumerated by NIX_STAT_LF_RX_E.
- */
-union cavm_nixx_af_lfx_rx_statx {
-	u64 u;
-	struct cavm_nixx_af_lfx_rx_statx_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. See also NIX_LF_RX_STAT() for a read-only alias of this
-                                                                 field. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_lfx_rx_statx_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_lf#_rss_grp#
- *
- * NIX AF Local Function Receive Side Scaling Group Registers
- * A receive packet targets a LF's RSS group when its NIX_RX_ACTION_S[OP] =
- * NIX_RX_ACTIONOP_E::RSS, or its target multicast list has an entry with
- * NIX_RX_MCE_S[OP] = NIX_RX_MCOP_E::RSS. The RSS group index (this register's last
- * index) is NIX_RX_ACTION_S[INDEX] or NIX_RX_MCE_S[INDEX].
- *
- * The RSS computation is as follows:
- * * The packet's flow_tag (see NIX_LF_RX_SECRET()) and RSS group are used to
- * select a NIX_RSSE_S entry in the LF's RSS table (see [SIZEM1]).
- * * NIX_RSSE_S selects the packet's destination RQ.
- */
-union cavm_nixx_af_lfx_rss_grpx {
-	u64 u;
-	struct cavm_nixx_af_lfx_rss_grpx_s {
-		u64 offset:11;		     /**< [ 10:  0](R/W) Offset (number of four-byte NIX_RSSE_S structures) into RSS table from
-                                                                 NIX_AF_LF()_RSS_BASE. See [SIZEM1]. */
-		u64 reserved_11_15:5;
-		u64 sizem1:3;		     /**< [ 18: 16](R/W) Number of RSS adder bits minus one to add in RSS calculation.
-                                                                 0x0 = rss_adder\<0\> included in RSS.
-                                                                 0x1 = rss_adder\<1:0\> included in RSS.
-                                                                 0x2 = rss_adder\<2:0\> included in RSS.
-                                                                 0x3 = rss_adder\<3:0\> included in RSS.
-                                                                 0x4 = rss_adder\<4:0\> included in RSS.
-                                                                 0x5 = rss_adder\<5:0\> included in RSS.
-                                                                 0x6 = rss_adder\<6:0\> included in RSS.
-                                                                 0x7 = rss_adder\<7:0\> included in RSS.
-
-                                                                 where:
-
-                                                                 _ rss_adder\<7:0\> = flow_tag\<7:0\> ^ flow_tag\<15:8\> ^ flow_tag\<23:16\> ^ flow_tag\<31:24\>
-
-                                                                 The AF IOVA of the packet's final NIX_RSSE_S structure is computed as follows:
-                                                                 \<pre\>
-                                                                 rsse_offset = ([OFFSET] + rss_adder[\<[SIZEM1]:0\>]) % (1 \<\< (NIX_AF_LF()_RSS_CFG[SIZE] + 8));
-                                                                 rsse_iova = NIX_AF_LF()_RSS_BASE + 4*rsse_offset;
-                                                                 \</pre\> */
-		u64 reserved_19_63:45;
-	} s;
-	/* struct cavm_nixx_af_lfx_rss_grpx_s cn; */
-};
-
-***Register(RVU_PF_BAR0) nix
-#_af_rx_npc_mc_rcv
-    * *NIX AF Multicast Receive Statistics Register * The counter increments for every
-recieved MC packet marked by the NPC. * /union cavm_nixx_af_rx_npc_mc_rcv {
-	u64 u;
-	struct cavm_nixx_af_rx_npc_mc_rcv_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_rx_npc_mc_rcv_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_npc_mc_drop
- *
- * NIX AF Multicast Drop Statistics Register
- * The counter increments for every dropped MC packet marked by the NPC.
- */
-union cavm_nixx_af_rx_npc_mc_drop {
-	u64 u;
-	struct cavm_nixx_af_rx_npc_mc_drop_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_rx_npc_mc_drop_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_npc_mirror_rcv
- *
- * NIX AF Mirror Receive Statistics Register
- * The counter increments for every recieved MIRROR packet marked by the NPC.
- */
-union cavm_nixx_af_rx_npc_mirror_rcv {
-	u64 u;
-	struct cavm_nixx_af_rx_npc_mirror_rcv_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_rx_npc_mirror_rcv_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) nix#_af_rx_npc_mirror_drop
- *
- * NIX AF Mirror Drop Statistics Register
- * The counter increments for every dropped MIRROR packet marked by the NPC.
- */
-union cavm_nixx_af_rx_npc_mirror_drop {
-	u64 u;
-	struct cavm_nixx_af_rx_npc_mirror_drop_s {
-		u64 stat:48;		     /**< [ 47:  0](R/W/H) Statistic value. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_af_rx_npc_mirror_drop_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_rx_secret#
- *
- * NIX LF Receive Secret Key Registers
- */
-union cavm_nixx_lf_rx_secretx {
-	u64 u;
-	struct cavm_nixx_lf_rx_secretx_s {
-		u64 key:64;		     /**< [ 63:  0](R/W) 64 bits of the 352-bit VF secret key for flow key hashing. Software must set
-                                                                 this to a random secret value shared with the driver.
-
-                                                                 The FLOW_KEY\<319:0\> is generated for the packet as described in
-                                                                 NIX_AF_RX_FLOW_KEY_ALG()_FIELD(). The following hash function computes flow_tag\<31:0\>
-                                                                 from FLOW_KEY:
-                                                                 \<pre\>
-                                                                   uint32_t nix_rx_flow_tag_hash(bit_array\<319:0\> FLOW_KEY) {
-                                                                      uint32_t flow_tag = 0;
-                                                                      bit_array\<351:0\> secret;
-                                                                      secret\<351:288\> = NIX_LF_RX_SECRET(0);
-                                                                      secret\<287:224\> = NIX_LF_RX_SECRET(1);
-                                                                      secret\<223:160\> = NIX_LF_RX_SECRET(2);
-                                                                      secret\<159:96\> = NIX_LF_RX_SECRET(3);
-                                                                      secret\<95:32\> = NIX_LF_RX_SECRET(4);
-                                                                      secret\<31:0\> = NIX_LF_RX_SECRET(5)[KEY]\<63:32\>;
-                                                                      // Note NIX_LF_RX_SECRET(5)[KEY]\<31:0\> bits are unused.
-                                                                      secret_bit = 351;
-                                                                      foreach bit_value (FLOW_KEY) { // MSB processed first
-                                                                         assert(secret_bit\>=31);
-                                                                         if (bit_value) {
-                                                                            flow_tag ^= secret\<secret_bit:(secret_bit-31)\>;
-                                                                         }
-                                                                         secret_bit--;
-                                                                      }
-                                                                      return flow_tag;
-                                                                   }
-                                                                 \</pre\>
-
-                                                                 If bidirectional flows are desired to land on the same queue, a secret key that
-                                                                 provides a symmetric hash can be selected. The hash is symmetric for two fields of
-                                                                 width W starting at MSB positions P1 and P2 in FLOW_KEY\<319:0\> if the secret key
-                                                                 satisfies:
-                                                                 _ secret\<(P1+32):(P1-W+1)\> = secret\<(P2+32):(P2-W+1)\>
-
-                                                                 For example, the hash will be symmetric for source and destination IPv4 addresses at
-                                                                 FLOW_KEY\<87:56\> and FLOW_KEY\<55:24\> when secret\<119:56\> = secret\<87:24\>.
-
-                                                                 For L3/L4 flows (e.g. TCP/UDP/SCTP over IPv4 or IPv6) with 16-bit aligned L3/L4
-                                                                 source/destination fields in FLOW_KEY, a secret key with a repeating 16-bit pattern
-                                                                 will provide a symmetric hash. */
-	} s;
-	/* struct cavm_nixx_lf_rx_secretx_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_gint
- *
- * NIX LF General Interrupt Register
- */
-union cavm_nixx_lf_gint {
-	u64 u;
-	struct cavm_nixx_lf_gint_s {
-		u64 drop:1;		     /**< [  0:  0](R/W1C/H) Packet dropped interrupt. Set when any packet has been dropped. This is intended for
-                                                                 diagnostic use; typical production software will want this interrupt disabled. */
-		u64 tcp_timer:1;		     /**< [  1:  1](R/W1C/H) TCP timer interrupt. Enabled when NIX_AF_TCP_TIMER[ENA] and
-                                                                 NIX_LF_CFG[TCP_TIMER_INT_ENA] are both set. Set every
-                                                                 NIX_AF_TCP_TIMER[DURATION]*256*128 coprocessor cycles when enabled. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_nixx_lf_gint_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_gint_w1s
- *
- * NIX LF General Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_lf_gint_w1s {
-	u64 u;
-	struct cavm_nixx_lf_gint_w1s_s {
-		u64 drop:1;		     /**< [  0:  0](R/W1S/H) Reads or sets NIX_LF_GINT[DROP]. */
-		u64 tcp_timer:1;		     /**< [  1:  1](R/W1S/H) Reads or sets NIX_LF_GINT[TCP_TIMER]. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_nixx_lf_gint_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_gint_ena_w1c
- *
- * NIX LF General Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_lf_gint_ena_w1c {
-	u64 u;
-	struct cavm_nixx_lf_gint_ena_w1c_s {
-		u64 drop:1;		     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_LF_GINT[DROP]. */
-		u64 tcp_timer:1;		     /**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_LF_GINT[TCP_TIMER]. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_nixx_lf_gint_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_gint_ena_w1s
- *
- * NIX LF General Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_lf_gint_ena_w1s {
-	u64 u;
-	struct cavm_nixx_lf_gint_ena_w1s_s {
-		u64 drop:1;		     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_LF_GINT[DROP]. */
-		u64 tcp_timer:1;		     /**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_LF_GINT[TCP_TIMER]. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_nixx_lf_gint_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_err_int
- *
- * NIX LF Error Interrupt Register
- */
-union cavm_nixx_lf_err_int {
-	u64 u;
-	struct cavm_nixx_lf_err_int_s {
-		u64 sqb_fault:1;		     /**< [  0:  0](R/W1C/H) Memory fault on SQB read or write. */
-		u64 sq_ctx_fault:1;	     /**< [  1:  1](R/W1C/H) Memory fault on NIX_SQ_CTX_HW_S read or write. */
-		u64 rq_ctx_fault:1;	     /**< [  2:  2](R/W1C/H) Memory fault on NIX_RQ_CTX_S read on packet receive or NIX_LF_RQ_OP_* access. */
-		u64 cq_ctx_fault:1;	     /**< [  3:  3](R/W1C/H) Memory fault on NIX_CQ_CTX_S read or write. */
-		u64 reserved_4:1;
-		u64 rsse_fault:1;		     /**< [  5:  5](R/W1C/H) Memory fault on NIX_RSSE_S read. */
-		u64 ipsec_dyno_fault:1;	     /**< [  6:  6](R/W1C/H) Memory fault on IPSEC dynamic ordering counter read. See
-                                                                 NIX_AF_LF()_RX_IPSEC_CFG0. */
-		u64 sq_disabled:1;		     /**< [  7:  7](R/W1C/H) LMT store or NIX_LF_SQ_OP_* access to a disabled SQ. NIX_SQ_CTX_S[ENA]
-                                                                 was clear for the selected SQ. */
-		u64 sq_oor:1;		     /**< [  8:  8](R/W1C/H) LMT store or NIX_LF_SQ_OP_* access to out-of-range SQ. The SQ index was
-                                                                 greater than NIX_AF_LF()_SQS_CFG[MAX_QUEUESM1]. */
-		u64 send_jump_fault:1;	     /**< [  9:  9](R/W1C/H) Memory fault on send descriptor read at or beyond NIX_SEND_JUMP_S[ADDR]. */
-		u64 send_sg_fault:1;	     /**< [ 10: 10](R/W1C/H) Memory fault on packet data read for NIX_SEND_SG_S. */
-		u64 rq_disabled:1;		     /**< [ 11: 11](R/W1C/H) Packet receive or NIX_LF_RQ_OP_* access to a disabled RQ;
-                                                                 NIX_RQ_CTX_S[ENA] was clear for selected RQ. See [RQ_OOR] for RQ
-                                                                 selection. */
-		u64 rq_oor:1;		     /**< [ 12: 12](R/W1C/H) Packet receive or NIX_LF_RQ_OP_* access to out-of-range RQ. The
-                                                                 packet's RQ index was greater than NIX_AF_LF()_RQS_CFG[MAX_QUEUESM1]. The RQ
-                                                                 index for a received packet is obtained as follows:
-                                                                 * When NIX_RX_ACTION_S[OP] = NIX_RX_ACTIONOP_E::UCAST or
-                                                                 NIX_RX_ACTIONOP_E::UCAST_IPSEC, RQ = NIX_RX_ACTION_S[INDEX].
-                                                                 * For RSS, NIX_RSSE_S[RQ].
-                                                                 * For multicast or mirror packet with NIX_RX_MCE_S[OP] = NIX_RX_MCOP_E::RQ,
-                                                                 RQ = NIX_RX_MCE_S[INDEX]. */
-		u64 rx_wqe_fault:1;	     /**< [ 13: 13](R/W1C/H) Memory fault on receive packet WQE write to LLC/DRAM. */
-		u64 rss_err:1;		     /**< [ 14: 14](R/W1C/H) RSSE Table entry was disabled or the rsse_offset was larger than the programmed size. */
-		u64 reserved_15_19:5;
-		u64 dyno_err:1;		     /**< [ 20: 20](R/W1C/H) NIX_LF_OP_IPSEC_DYNO_CNT[COUNT] underflow or overflow. */
-		u64 reserved_21_23:3;
-		u64 cq_disabled:1;		     /**< [ 24: 24](R/W1C/H) CQ disabled. NIX_CQ_CTX_S[ENA] was clear for the CQ of a send/receive CQE
-                                                                 write or NIX_LF_CQ_OP_* access. */
-		u64 cq_oor:1;		     /**< [ 25: 25](R/W1C/H) CQ out of range. The CQ index of a send/receive CQE write or
-                                                                 NIX_LF_CQ_OP_* access was greater than
-                                                                 NIX_AF_LF()_CQS_CFG[MAX_QUEUESM1]. */
-		u64 reserved_26_27:2;
-		u64 qint_fault:1;		     /**< [ 28: 28](R/W1C/H) Memory fault on NIX_QINT_HW_S read or write. */
-		u64 cint_fault:1;		     /**< [ 29: 29](R/W1C/H) Memory fault on NIX_CINT_HW_S read or write. */
-		u64 reserved_30_63:34;
-	} s;
-	/* struct cavm_nixx_lf_err_int_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_err_int_w1s
- *
- * NIX LF Error Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_lf_err_int_w1s {
-	u64 u;
-	struct cavm_nixx_lf_err_int_w1s_s {
-		u64 sqb_fault:1;		     /**< [  0:  0](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SQB_FAULT]. */
-		u64 sq_ctx_fault:1;	     /**< [  1:  1](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SQ_CTX_FAULT]. */
-		u64 rq_ctx_fault:1;	     /**< [  2:  2](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RQ_CTX_FAULT]. */
-		u64 cq_ctx_fault:1;	     /**< [  3:  3](R/W1S/H) Reads or sets NIX_LF_ERR_INT[CQ_CTX_FAULT]. */
-		u64 reserved_4:1;
-		u64 rsse_fault:1;		     /**< [  5:  5](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RSSE_FAULT]. */
-		u64 ipsec_dyno_fault:1;	     /**< [  6:  6](R/W1S/H) Reads or sets NIX_LF_ERR_INT[IPSEC_DYNO_FAULT]. */
-		u64 sq_disabled:1;		     /**< [  7:  7](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SQ_DISABLED]. */
-		u64 sq_oor:1;		     /**< [  8:  8](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SQ_OOR]. */
-		u64 send_jump_fault:1;	     /**< [  9:  9](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SEND_JUMP_FAULT]. */
-		u64 send_sg_fault:1;	     /**< [ 10: 10](R/W1S/H) Reads or sets NIX_LF_ERR_INT[SEND_SG_FAULT]. */
-		u64 rq_disabled:1;		     /**< [ 11: 11](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RQ_DISABLED]. */
-		u64 rq_oor:1;		     /**< [ 12: 12](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RQ_OOR]. */
-		u64 rx_wqe_fault:1;	     /**< [ 13: 13](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RX_WQE_FAULT]. */
-		u64 rss_err:1;		     /**< [ 14: 14](R/W1S/H) Reads or sets NIX_LF_ERR_INT[RSS_ERR]. */
-		u64 reserved_15_19:5;
-		u64 dyno_err:1;		     /**< [ 20: 20](R/W1S/H) Reads or sets NIX_LF_ERR_INT[DYNO_ERR]. */
-		u64 reserved_21_23:3;
-		u64 cq_disabled:1;		     /**< [ 24: 24](R/W1S/H) Reads or sets NIX_LF_ERR_INT[CQ_DISABLED]. */
-		u64 cq_oor:1;		     /**< [ 25: 25](R/W1S/H) Reads or sets NIX_LF_ERR_INT[CQ_OOR]. */
-		u64 reserved_26_27:2;
-		u64 qint_fault:1;		     /**< [ 28: 28](R/W1S/H) Reads or sets NIX_LF_ERR_INT[QINT_FAULT]. */
-		u64 cint_fault:1;		     /**< [ 29: 29](R/W1S/H) Reads or sets NIX_LF_ERR_INT[CINT_FAULT]. */
-		u64 reserved_30_63:34;
-	} s;
-	/* struct cavm_nixx_lf_err_int_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_err_int_ena_w1c
- *
- * NIX LF Error Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_lf_err_int_ena_w1c {
-	u64 u;
-	struct cavm_nixx_lf_err_int_ena_w1c_s {
-		u64 sqb_fault:1;		     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SQB_FAULT]. */
-		u64 sq_ctx_fault:1;	     /**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SQ_CTX_FAULT]. */
-		u64 rq_ctx_fault:1;	     /**< [  2:  2](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RQ_CTX_FAULT]. */
-		u64 cq_ctx_fault:1;	     /**< [  3:  3](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[CQ_CTX_FAULT]. */
-		u64 reserved_4:1;
-		u64 rsse_fault:1;		     /**< [  5:  5](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RSSE_FAULT]. */
-		u64 ipsec_dyno_fault:1;	     /**< [  6:  6](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[IPSEC_DYNO_FAULT]. */
-		u64 sq_disabled:1;		     /**< [  7:  7](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SQ_DISABLED]. */
-		u64 sq_oor:1;		     /**< [  8:  8](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SQ_OOR]. */
-		u64 send_jump_fault:1;	     /**< [  9:  9](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SEND_JUMP_FAULT]. */
-		u64 send_sg_fault:1;	     /**< [ 10: 10](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[SEND_SG_FAULT]. */
-		u64 rq_disabled:1;		     /**< [ 11: 11](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RQ_DISABLED]. */
-		u64 rq_oor:1;		     /**< [ 12: 12](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RQ_OOR]. */
-		u64 rx_wqe_fault:1;	     /**< [ 13: 13](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RX_WQE_FAULT]. */
-		u64 rss_err:1;		     /**< [ 14: 14](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[RSS_ERR]. */
-		u64 reserved_15_19:5;
-		u64 dyno_err:1;		     /**< [ 20: 20](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[DYNO_ERR]. */
-		u64 reserved_21_23:3;
-		u64 cq_disabled:1;		     /**< [ 24: 24](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[CQ_DISABLED]. */
-		u64 cq_oor:1;		     /**< [ 25: 25](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[CQ_OOR]. */
-		u64 reserved_26_27:2;
-		u64 qint_fault:1;		     /**< [ 28: 28](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[QINT_FAULT]. */
-		u64 cint_fault:1;		     /**< [ 29: 29](R/W1C/H) Reads or clears enable for NIX_LF_ERR_INT[CINT_FAULT]. */
-		u64 reserved_30_63:34;
-	} s;
-	/* struct cavm_nixx_lf_err_int_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_err_int_ena_w1s
- *
- * NIX LF Error Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_lf_err_int_ena_w1s {
-	u64 u;
-	struct cavm_nixx_lf_err_int_ena_w1s_s {
-		u64 sqb_fault:1;		     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SQB_FAULT]. */
-		u64 sq_ctx_fault:1;	     /**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SQ_CTX_FAULT]. */
-		u64 rq_ctx_fault:1;	     /**< [  2:  2](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RQ_CTX_FAULT]. */
-		u64 cq_ctx_fault:1;	     /**< [  3:  3](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[CQ_CTX_FAULT]. */
-		u64 reserved_4:1;
-		u64 rsse_fault:1;		     /**< [  5:  5](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RSSE_FAULT]. */
-		u64 ipsec_dyno_fault:1;	     /**< [  6:  6](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[IPSEC_DYNO_FAULT]. */
-		u64 sq_disabled:1;		     /**< [  7:  7](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SQ_DISABLED]. */
-		u64 sq_oor:1;		     /**< [  8:  8](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SQ_OOR]. */
-		u64 send_jump_fault:1;	     /**< [  9:  9](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SEND_JUMP_FAULT]. */
-		u64 send_sg_fault:1;	     /**< [ 10: 10](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[SEND_SG_FAULT]. */
-		u64 rq_disabled:1;		     /**< [ 11: 11](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RQ_DISABLED]. */
-		u64 rq_oor:1;		     /**< [ 12: 12](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RQ_OOR]. */
-		u64 rx_wqe_fault:1;	     /**< [ 13: 13](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RX_WQE_FAULT]. */
-		u64 rss_err:1;		     /**< [ 14: 14](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[RSS_ERR]. */
-		u64 reserved_15_19:5;
-		u64 dyno_err:1;		     /**< [ 20: 20](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[DYNO_ERR]. */
-		u64 reserved_21_23:3;
-		u64 cq_disabled:1;		     /**< [ 24: 24](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[CQ_DISABLED]. */
-		u64 cq_oor:1;		     /**< [ 25: 25](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[CQ_OOR]. */
-		u64 reserved_26_27:2;
-		u64 qint_fault:1;		     /**< [ 28: 28](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[QINT_FAULT]. */
-		u64 cint_fault:1;		     /**< [ 29: 29](R/W1S/H) Reads or sets enable for NIX_LF_ERR_INT[CINT_FAULT]. */
-		u64 reserved_30_63:34;
-	} s;
-	/* struct cavm_nixx_lf_err_int_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras
- *
- * NIX LF RAS Interrupt Register
- */
-union cavm_nixx_lf_ras {
-	u64 u;
-	struct cavm_nixx_lf_ras_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1C/H) Poisoned data returned on SQB read. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1C/H) Poisoned data returned on NIX_SQ_CTX_HW_S read. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1C/H) Poisoned data returned on NIX_RQ_CTX_S read. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1C/H) Poisoned data returned on NIX_CQ_CTX_S read. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1C/H) Poisoned data returned on NIX_RSSE_S read. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1C/H) Poisoned data returned on IPSEC dynamic ordering counter read. See
-                                                                 NIX_AF_LF()_RX_IPSEC_CFG0. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1C/H) Poisoned data returned on send descriptor read at or beyond
-                                                                 NIX_SEND_JUMP_S[ADDR]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1C/H) Poisoned data returned on packet data read for NIX_SEND_SG_S. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1C/H) Poisoned data returned on NIX_QINT_HW_S read. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1C/H) Poisoned data returned on NIX_CINT_HW_S read. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras_w1s
- *
- * NIX LF RAS Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_nixx_lf_ras_w1s {
-	u64 u;
-	struct cavm_nixx_lf_ras_w1s_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1S/H) Reads or sets NIX_LF_RAS[SQB_POISON]. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1S/H) Reads or sets NIX_LF_RAS[SQ_CTX_POISON]. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1S/H) Reads or sets NIX_LF_RAS[RQ_CTX_POISON]. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1S/H) Reads or sets NIX_LF_RAS[CQ_CTX_POISON]. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1S/H) Reads or sets NIX_LF_RAS[RSSE_POISON]. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1S/H) Reads or sets NIX_LF_RAS[IPSEC_DYNO_POISON]. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1S/H) Reads or sets NIX_LF_RAS[SEND_JUMP_POISON]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1S/H) Reads or sets NIX_LF_RAS[SEND_SG_POISON]. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1S/H) Reads or sets NIX_LF_RAS[QINT_POISON]. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1S/H) Reads or sets NIX_LF_RAS[CINT_POISON]. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras_ena_w1c
- *
- * NIX LF RAS Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_nixx_lf_ras_ena_w1c {
-	u64 u;
-	struct cavm_nixx_lf_ras_ena_w1c_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SQB_POISON]. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SQ_CTX_POISON]. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1C/H) Reads or clears enable for NIX_LF_RAS[RQ_CTX_POISON]. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1C/H) Reads or clears enable for NIX_LF_RAS[CQ_CTX_POISON]. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1C/H) Reads or clears enable for NIX_LF_RAS[RSSE_POISON]. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1C/H) Reads or clears enable for NIX_LF_RAS[IPSEC_DYNO_POISON]. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SEND_JUMP_POISON]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1C/H) Reads or clears enable for NIX_LF_RAS[SEND_SG_POISON]. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1C/H) Reads or clears enable for NIX_LF_RAS[QINT_POISON]. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1C/H) Reads or clears enable for NIX_LF_RAS[CINT_POISON]. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_ena_w1c_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_ras_ena_w1s
- *
- * NIX LF RAS Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_nixx_lf_ras_ena_w1s {
-	u64 u;
-	struct cavm_nixx_lf_ras_ena_w1s_s {
-		u64 sqb_poison:1;		     /**< [  0:  0](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SQB_POISON]. */
-		u64 sq_ctx_poison:1;	     /**< [  1:  1](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SQ_CTX_POISON]. */
-		u64 rq_ctx_poison:1;	     /**< [  2:  2](R/W1S/H) Reads or sets enable for NIX_LF_RAS[RQ_CTX_POISON]. */
-		u64 cq_ctx_poison:1;	     /**< [  3:  3](R/W1S/H) Reads or sets enable for NIX_LF_RAS[CQ_CTX_POISON]. */
-		u64 reserved_4:1;
-		u64 rsse_poison:1;		     /**< [  5:  5](R/W1S/H) Reads or sets enable for NIX_LF_RAS[RSSE_POISON]. */
-		u64 ipsec_dyno_poison:1;	     /**< [  6:  6](R/W1S/H) Reads or sets enable for NIX_LF_RAS[IPSEC_DYNO_POISON]. */
-		u64 send_jump_poison:1;	     /**< [  7:  7](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SEND_JUMP_POISON]. */
-		u64 send_sg_poison:1;	     /**< [  8:  8](R/W1S/H) Reads or sets enable for NIX_LF_RAS[SEND_SG_POISON]. */
-		u64 qint_poison:1;		     /**< [  9:  9](R/W1S/H) Reads or sets enable for NIX_LF_RAS[QINT_POISON]. */
-		u64 cint_poison:1;		     /**< [ 10: 10](R/W1S/H) Reads or sets enable for NIX_LF_RAS[CINT_POISON]. */
-		u64 reserved_11_63:53;
-	} s;
-	/* struct cavm_nixx_lf_ras_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_sq_op_err_dbg
- *
- * NIX LF SQ Operation Error Debug Register
- * This register captures debug info for an error detected on LMT store to
- * NIX_LF_OP_SEND() or when a NIX_LF_SQ_OP_* register is accessed.
- * Hardware sets [VALID] when the debug info is captured, and subsequent errors
- * are not captured until software clears [VALID] by writing a one to it.
- */
-union cavm_nixx_lf_sq_op_err_dbg {
-	u64 u;
-	struct cavm_nixx_lf_sq_op_err_dbg_s {
-		u64 errcode:8;		     /**< [  7:  0](RO/H) Error code enumerated by NIX_SQOPERR_E. */
-		u64 sq:20;			     /**< [ 27:  8](RO/H) SQ within LF. */
-		u64 sqe_id:16;		     /**< [ 43: 28](RO/H) SQE identifier from NIX_SEND_HDR_S[SQE_ID]. */
-		u64 valid:1;		     /**< [ 44: 44](R/W1C/H) Debug info valid. When set, remaining fields in this register are valid. */
-		u64 reserved_45_63:19;
-	} s;
-	/* struct cavm_nixx_lf_sq_op_err_dbg_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_mnq_err_dbg
- *
- * NIX LF Meta-descriptor Enqueue Error Debug Register
- * This register captures debug info for an error detected during send
- * meta-descriptor enqueue from an SQ to an SMQ.
- * Hardware sets [VALID] when the debug info is captured, and subsequent errors
- * are not captured until software clears [VALID] by writing a one to it.
- */
-union cavm_nixx_lf_mnq_err_dbg {
-	u64 u;
-	struct cavm_nixx_lf_mnq_err_dbg_s {
-		u64 errcode:8;		     /**< [  7:  0](RO/H) Error code enumerated by NIX_MNQERR_E. */
-		u64 sq:20;			     /**< [ 27:  8](RO/H) SQ within LF. */
-		u64 sqe_id:16;		     /**< [ 43: 28](RO/H) SQE identifier from NIX_SEND_HDR_S[SQE_ID]. */
-		u64 valid:1;		     /**< [ 44: 44](R/W1C/H) Debug info valid. When set, remaining fields in this register are valid. */
-		u64 reserved_45_63:19;
-	} s;
-	/* struct cavm_nixx_lf_mnq_err_dbg_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_send_err_dbg
- *
- * NIX LF Send Error Debug Register
- * This register captures debug info an error detected on packet send after a
- * meta-descriptor is granted by PSE.
- * Hardware sets [VALID] when the debug info is captured, and subsequent errors
- * are not captured until software clears [VALID] by writing a one to it.
- */
-union cavm_nixx_lf_send_err_dbg {
-	u64 u;
-	struct cavm_nixx_lf_send_err_dbg_s {
-		u64 errcode:8;		     /**< [  7:  0](RO/H) Error code enumerated by NIX_SEND_STATUS_E. */
-		u64 sq:20;			     /**< [ 27:  8](RO/H) SQ within LF. */
-		u64 sqe_id:16;		     /**< [ 43: 28](RO/H) SQE identifier from NIX_SEND_HDR_S[SQE_ID]. */
-		u64 valid:1;		     /**< [ 44: 44](R/W1C/H) Debug info valid. When set, remaining fields in this register are valid. */
-		u64 reserved_45_63:19;
-	} s;
-	/* struct cavm_nixx_lf_send_err_dbg_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_tx_stat#
- *
- * NIX LF Transmit Statistics Registers
- * The last dimension indicates which statistic, and is enumerated by NIX_STAT_LF_TX_E.
- */
-union cavm_nixx_lf_tx_statx {
-	u64 u;
-	struct cavm_nixx_lf_tx_statx_s {
-		u64 stat:48;		     /**< [ 47:  0](RO/H) Statistic value. See also NIX_AF_LF()_TX_STAT() for a writable alias of this field. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_lf_tx_statx_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_rx_stat#
- *
- * NIX LF Receive Statistics Registers
- * The last dimension indicates which statistic, and is enumerated by NIX_STAT_LF_RX_E.
- */
-union cavm_nixx_lf_rx_statx {
-	u64 u;
-	struct cavm_nixx_lf_rx_statx_s {
-		u64 stat:48;		     /**< [ 47:  0](RO/H) Statistic value. See also NIX_AF_LF()_RX_STAT() for a writable alias of this field. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_nixx_lf_rx_statx_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_op_send#
- *
- * NIX LF Send Operation Registers
- * An LMTST (or large store from CPT) to this address enqueues one or more SQEs to
- * a send queue. NIX_SEND_HDR_S[SQ] in the first SQE selects the send queue.The
- * maximum size of each SQE is specified by NIX_SQ_CTX_S[MAX_SQE_SIZE].
- *
- * A read to this address is RAZ.
- *
- * An RSL access to this address will fault.
- *
- * The endianness of the instruction write data is controlled by NIX_AF_LF()_CFG[BE].
- *
- * When a NIX_SEND_JUMP_S is not present in the SQE, the SQE consists of the
- * entire send descriptor.
- *
- * When a NIX_SEND_JUMP_S is present in the SQE, the SQE must contain exactly the
- * portion of the send descriptor up to and including the NIX_SEND_JUMP_S, and the
- * remainder of the send descriptor must be at LF IOVA NIX_SEND_JUMP_S[ADDR] in
- * LLC/DRAM.
- *
- * Software must ensure that all LLC/DRAM locations that will be referenced by NIX while
- * processing this descriptor, including all packet data and post-jump subdescriptors
- * contain the latest updates before issuing the LMTST. A DMB instruction may be required prior
- * to the LMTST to ensure this. A DMB following the LMTST may be useful if SQ descriptor ordering
- * matters and more than one CPU core is simultaneously enqueueing to the same SQ. For more
- * information on ordering, refer to the HRM "Core Memory Reference Ordering" section in the CPU
- * cores chapter.
- */
-union cavm_nixx_lf_op_sendx {
-	u64 u;
-	struct cavm_nixx_lf_op_sendx_s {
-		u64 data:64;		     /**< [ 63:  0](WO) Data that forms the send descriptor; see register description. */
-	} s;
-	/* struct cavm_nixx_lf_op_sendx_s cn; */
-};
-
-union cavm_nixx_lf_rq_op_int {
-	u64 u;
-	struct cavm_nixx_lf_rq_op_int_s {
-		u64 rq_int:8;		     /**< [  7:  0](R/W/H) Returns NIX_RQ_CTX_S[RQ_INT] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NIX_RQ_CTX_S[RQ_INT] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-		u64 rq_int_ena:8;		     /**< [ 15:  8](R/W/H) Returns NIX_RQ_CTX_S[RQ_INT_ENA] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NIX_RQ_CTX_S[RQ_INT_ENA] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-		u64 reserved_16_41:26;
-		u64 op_err:1;		     /**< [ 42: 42](RO/H) Operation error. Remaining read data fields are not valid. One of the
-                                                                 following (may not be exhaustive):
-                                                                 * Memory fault on NIX_RQ_CTX_S read; also sets NIX_LF_ERR_INT[RQ_CTX_FAULT].
-                                                                 * Poisoned data returned on NIX_RQ_CTX_S read; also sets
-                                                                 NIX_LF_RAS[RQ_CTX_POISON].
-                                                                 * Access to out-of-range RQ ([RQ] \> NIX_AF_LF()_RQS_CFG[MAX_QUEUESM1]);
-                                                                 also sets NIX_LF_ERR_INT[RQ_OOR].
-                                                                 * Disabled RQ (NIX_RQ_CTX_S[ENA] = 0); also sets
-                                                                 NIX_LF_ERR_INT[RQ_DISABLED]. */
-		u64 setop:1;		     /**< [ 43: 43](WO) Set Operation. Valid on a write. Indicates write-one-to-set when set,
-                                                                 write-one-to-clear when clear. */
-		u64 rq:20;			     /**< [ 63: 44](WO) RQ within LF. This field is present on a write, or in the write data
-                                                                 of an atomic load-and-add. */
-	} s;
-	/* struct cavm_nixx_lf_rq_op_int_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_rq_op_octs
- *
- * NIX LF Receive Queue Octets Operation Register
- * A 64-bit atomic load-and-add to this register reads NIX_RQ_CTX_S[OCTS]. The atomic
- * write data has format NIX_OP_Q_WDATA_S and selects the RQ within LF.
- *
- * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_rq_op_octs {
-	u64 u;
-	struct cavm_nixx_lf_rq_op_octs_s {
-		u64 cnt:48;		     /**< [ 47:  0](RO) Count. */
-		u64 reserved_48_62:15;
-		u64 op_err:1;		     /**< [ 63: 63](RO/H) Operation error. See NIX_LF_RQ_OP_INT[OP_ERR]. */
-	} s;
-	/* struct cavm_nixx_lf_rq_op_octs_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_rq_op_pkts
- *
- * NIX LF Receive Queue Packets Operation Register
- * A 64-bit atomic load-and-add to this register reads NIX_RQ_CTX_S[PKTS]. The atomic
- * write data has format NIX_OP_Q_WDATA_S and selects the RQ within LF.
- *
- * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_rq_op_pkts {
-	u64 u;
-	struct cavm_nixx_lf_rq_op_pkts_s {
-		u64 cnt:48;		     /**< [ 47:  0](RO) Count. */
-		u64 reserved_48_62:15;
-		u64 op_err:1;		     /**< [ 63: 63](RO/H) Operation error. See NIX_LF_RQ_OP_INT[OP_ERR]. */
-	} s;
-	/* struct cavm_nixx_lf_rq_op_pkts_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_rq_op_re_pkts
- *
- * NIX LF Receive Queue Errored Packets Operation Register
- * A 64-bit atomic load-and-add to this register reads NIX_RQ_CTX_S[RE_PKTS].
- * The atomic write data has format NIX_OP_Q_WDATA_S and selects the RQ within LF.
- *
- * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_rq_op_re_pkts {
-	u64 u;
-	struct cavm_nixx_lf_rq_op_re_pkts_s {
-		u64 cnt:48;		     /**< [ 47:  0](RO) Count. */
-		u64 reserved_48_62:15;
-		u64 op_err:1;		     /**< [ 63: 63](RO/H) Operation error. See NIX_LF_RQ_OP_INT[OP_ERR]. */
-	} s;
-	/* struct cavm_nixx_lf_rq_op_re_pkts_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_cq_op_int
- *
- * NIX LF Completion Queue Interrupt Operation Register
- * A 64-bit atomic load-and-add to this register reads CQ interrupts and
- * interrupt enables.
- * A write optionally sets or clears interrupts and interrupt enables.
- * A read is RAZ.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_cq_op_int {
-	u64 u;
-	struct cavm_nixx_lf_cq_op_int_s {
-		u64 cq_err_int:8;		     /**< [  7:  0](R/W/H) Returns NIX_CQ_CTX_S[CQ_ERR_INT] on an atomic load-and-add. On a
-                                                                 write, write-one-to-set NIX_CQ_CTX_S[CQ_ERR_INT] if [SETOP] is set,
-                                                                 write-one-to-clear otherwise. */
-		u64 cq_err_int_ena:8;	     /**< [ 15:  8](R/W/H) Returns NIX_CQ_CTX_S[CQ_ERR_INT_ENA] on an atomic load-and-add. On a
-                                                                 write, write-one-to-set NIX_CQ_CTX_S[CQ_ERR_INT_ENA] if [SETOP] is
-                                                                 set, write-one-to-clear otherwise. */
-		u64 reserved_16_41:26;
-		u64 op_err:1;		     /**< [ 42: 42](RO/H) Operation error. Remaining read data fields are not valid. One of the
-                                                                 following (may not be exhaustive):
-                                                                 * Memory fault on NIX_CQ_CTX_S read; also sets NIX_LF_ERR_INT[CQ_CTX_FAULT].
-                                                                 * Poisoned data returned on NIX_CQ_CTX_S read; also sets
-                                                                 NIX_LF_RAS[CQ_CTX_POISON].
-                                                                 * Access to out-of-range CQ ([CQ] \> NIX_AF_LF()_CQS_CFG[MAX_QUEUESM1]);
-                                                                 also sets NIX_LF_ERR_INT[CQ_OOR].
-                                                                 * Disabled CQ (NIX_CQ_CTX_S[ENA] = 0); also sets
-                                                                 NIX_LF_ERR_INT[CQ_DISABLED]. */
-		u64 setop:1;		     /**< [ 43: 43](WO) Set operation. Valid on a write. Indicates write-one-to-set when set,
-                                                                 write-one-to-clear when clear. */
-		u64 cq:20;			     /**< [ 63: 44](WO) CQ within LF. This field is present on a write, or in the write data
-                                                                 of an atomic load-and-add. */
-	} s;
-	/* struct cavm_nixx_lf_cq_op_int_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_cint#_wait
- *
- * NIX LF Completion Interrupt Count Registers
- */
-union cavm_nixx_lf_cintx_wait {
-	u64 u;
-	struct cavm_nixx_lf_cintx_wait_s {
-		u64 ecount_wait:32;		/**< [ 31:  0](R/W/H) Entry count hold-off. See NIX_LF_CINT()_INT[INTR]. */
-		u64 qcount_wait:16;		/**< [ 47: 32](R/W/H) Active queue count hold-off. See NIX_LF_CINT()_INT[INTR]. */
-		u64 time_wait:8;		/**< [ 55: 48](R/W/H) Time hold-off as a multiple of
-                                                                 (NIX_AF_CINT_DELAY[CINT_DLY]+1)*100 nanoseconds. Time to wait
-                                                                 when NIX_LF_CINT()_CNT[ECOUNT] is nonzero before setting
-                                                                 NIX_LF_CINT()_INT[INTR]. */
-		u64 reserved_56_63:8;
-	} s;
-	/* struct cavm_nixx_lf_cintx_wait_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_cq_op_door
- *
- * NIX LF CQ Doorbell Operation Register
- * A write to this register dequeues CQEs from a CQ ring within the LF.
- * A read is RAZ.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_cq_op_door {
-	u64 u;
-	struct cavm_nixx_lf_cq_op_door_s {
-		u64 count:16;		     /**< [ 15:  0](WO) Number of dequeued CQEs. Hardware advances NIX_CQ_CTX_S[HEAD] by this value
-                                                                 if the CQ is enabled. The size of each dequeued CQE is selected by
-                                                                 NIX_AF_LF()_CFG[XQE_SIZE].
-
-                                                                 A doorbell write that would underflow the ring is suppressed and sets
-                                                                 NIX_CQ_CTX_S[CQ_ERR_INT]\<NIX_CQERRINT_E::DOOR_ERR\>. */
-		u64 reserved_16_31:16;
-		u64 cq:20;			     /**< [ 51: 32](WO) CQ within the VF. */
-		u64 reserved_52_63:12;
-	} s;
-	/* struct cavm_nixx_lf_cq_op_door_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) nix#_lf_cq_op_status
- *
- * NIX LF Completion Queue Status Operation Register
- * A 64-bit atomic load-and-add to this register reads NIX_CQ_CTX_S[HEAD,TAIL].
- * The atomic write data has format NIX_OP_Q_WDATA_S and selects the CQ within LF.
- *
- * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
- *
- * An RSL access to this register will fault.
- */
-union cavm_nixx_lf_cq_op_status {
-	u64 u;
-	struct cavm_nixx_lf_cq_op_status_s {
-		u64 tail:20;		     /**< [ 19:  0](RO/H) See NIX_CQ_CTX_S[TAIL]. */
-		u64 head:20;		     /**< [ 39: 20](RO/H) See NIX_CQ_CTX_S[HEAD]. The number of entries in the CQ is:
-                                                                 _ ([TAIL] - [HEAD]) % (1 \<\< (2 * (NIX_CQ_CTX_S[QSIZE] + 2)) */
-		u64 reserved_40_45:6;
-		u64 cq_err:1;		     /**< [ 46: 46](RO/H) See NIX_CQ_CTX_S[CQ_ERR]. */
-		u64 reserved_47_62:16;
-		u64 op_err:1;		     /**< [ 63: 63](RO/H) Operation error. See NIX_LF_CQ_OP_INT[OP_ERR]. */
-	} s;
-	/* struct cavm_nixx_lf_cq_op_status_s cn; */
-};
-
-#endif /* __NIX_REGS_H__ */
diff --git a/drivers/net/cavium/octeontx2/npc.c b/drivers/net/cavium/octeontx2/npc.c
new file mode 100644
index 0000000000..97dcd5f8da
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/npc.c
@@ -0,0 +1,402 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Cavium OcteonTx2 RVU Admin function driver
+ *
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <common.h>
+#include <net.h>
+#include <netdev.h>
+#include <malloc.h>
+#include <dm.h>
+#include <misc.h>
+#include <pci.h>
+#include <memalign.h>
+#include <watchdog.h>
+#include <asm/io.h>
+#include <linux/types.h>
+#include <linux/bitops.h>
+#include <asm/arch/octeontx2.h>
+#include "cavm-csrs-npc.h"
+#include "cavm-csrs-nix.h"
+#include "npc_profile.h"
+#include "nix_af.h"
+#include "nix.h"
+#include "npc.h"
+
+#define RSVD_MCAM_ENTRIES_PER_PF	2 /** Ucast & Bcast */
+#define RSVD_MCAM_ENTRIES_PER_NIXLF	1 /** Ucast for VFs */
+
+static u64 npc_af_reg_read(struct npc_af *npc, u64 offset)
+{
+	return readq(npc->npc_af_base + offset);
+}
+
+static void npc_af_reg_write(struct npc_af *npc, u64 offset, u64 val)
+{
+	writeq(va, npc->npc_af_base + offset);
+}
+
+static inline u64 enable_mask(int count)
+{
+	return ((count < 64) ? ~(BIT_ULL(count) - 1) : (0x00ULL));
+}
+
+
+#define LDATA_EXTRACT_CONFIG(intf, lid, ltype, ld, cfg) \
+	npc_af_reg_write(npc,			\
+		CAVM_NPC_AF_INTFX_LIDX_LTX_LDX_CFG(intf, lid, ltype, ld), cfg)
+
+#define LDATA_FLAGS_CONFIG(intf, ld, flags, cfg)	\
+	npc_af_reg_write(npc,			\
+		CAVM_NPC_AF_INTFX_LDATAX_FLAGSX_CFG(intf, ld, flags), cfg)
+
+static void npc_af_config_layer_info(struct npc_af *npc)
+{
+	union cavm_npc_af_const af_const;
+	union cavm_npc_af_intfx_lidx_ltx_ldx_cfg cfg;
+	int lid_count;
+	int lid, ltype;
+	struct npc_mcam *mcam = &npc->mcam;
+
+	af_const.u = npc_af_reg_read(npc, CAVM_NPC_AF_CONST());
+	lid_count = af_const.s.lids;
+
+	/* First clear any existing config i.e
+	 * disable LDATA and FLAGS extraction.
+	 */
+	for (lid = 0; lid < lid_count; lid++) {
+		for (ltype = 0; ltype < 16; ltype++) {
+			LDATA_EXTRACT_CONFIG(NIX_INTF_RX, lid, ltype, 0, 0ULL);
+			LDATA_EXTRACT_CONFIG(NIX_INTF_RX, lid, ltype, 1, 0ULL);
+			LDATA_EXTRACT_CONFIG(NIX_INTF_TX, lid, ltype, 0, 0ULL);
+			LDATA_EXTRACT_CONFIG(NIX_INTF_TX, lid, ltype, 1, 0ULL);
+
+			LDATA_FLAGS_CONFIG(NIX_INTF_RX, 0, ltype, 0ULL);
+			LDATA_FLAGS_CONFIG(NIX_INTF_RX, 1, ltype, 0ULL);
+			LDATA_FLAGS_CONFIG(NIX_INTF_TX, 0, ltype, 0ULL);
+			LDATA_FLAGS_CONFIG(NIX_INTF_TX, 1, ltype, 0ULL);
+		}
+	}
+
+	/* If we plan to extract Outer IPv4 tuple for TCP/UDP pkts
+	 * then 112bit key is not sufficient
+	 */
+	if (mcam->keysize != NPC_MCAM_KEY_X2)
+		return;
+
+	/* Start placing extracted data/flags from 64bit onwards, for now */
+	/* Extract DMAC from the packet */
+	cfg.u = 0;
+	cfg.s.bytesm1 = 0x05;
+	cfg.s.ena = 1;
+	cfg.s.key_offset = 0x8;
+	LDATA_EXTRACT_CONFIG(NIX_INTF_RX, CAVM_NPC_LID_E_LA, NPC_LT_LA_ETHER, 0, cfg.u);
+}
+
+static void npc_af_config_kpuaction(struct npc_af *npc,
+				    struct npc_kpu_profile_action *kpuaction,
+				    int kpu, int entry, bool pkind)
+{
+	u64 reg;
+	union cavm_npc_af_pkindx_action0 action0;
+	union cavm_npc_af_pkindx_action1 action1;
+
+	action0.u = 0;
+	action1.u = 0;
+	action1.s.errlev = kpuaction->errlev;
+	action1.s.errcode = kpuaction->errcode;
+	action1.s.dp0_offset = kpuaction->dp0_offset;
+	action1.s.dp1_offset = kpuaction->dp1_offset;
+	action1.s.dp2_offset = kpuaction->dp2_offset;
+
+	reg = pkind ? CAVM_NPC_AF_PKINDX_ACTION1(entry) :
+		      CAVM_NPC_AF_KPUX_ENTRYX_ACTION1(kpu, entry);
+	npc_af_reg_write(npc, reg, action1.u);
+
+	action0.s.byp_count = kpuaction->bypass_count;
+	action0.s.capture_ena = kpuaction->cap_ena;
+	action0.s.parse_done = kpuaction->parse_done;
+	action0.s.next_state = kpuaction->next_state;
+	action0.s.capture_lid = kpuaction->lid;
+	action0.s.capture_ltype = kpuaction->ltype;
+	action0.s.capture_flags = kpuaction->flags;
+	action0.s.ptr_advance = kpuaction->ptr_advance;
+	action0.s.var_len_offset = kpuaction->offset;
+	action0.s.var_len_mask = kpuaction->mask;
+	action0.s.var_len_right = kpuaction->right;
+	action0.s.var_len_shift = kpuaction->shift;
+
+	reg = pkind ? CAVM_NPC_AF_PKINDX_ACTION0(entry) :
+		      CAVM_NPC_AF_KPUX_ENTRYX_ACTION0(kpu, entry);
+	npc_af_reg_write(npc, reg, action0.u);
+}
+
+static void npc_af_config_kpucam(struct npc_af *npc,
+				 struct npc_kpu_profile_cam *kpucam,
+				 int kpu, int entry)
+{
+	union cavm_npc_af_kpux_entryx_camx cam0, cam1;
+
+	cam0.u = 0;
+	cam1.u = 0;
+	cam1.s.state = kpucam->state & kpucam->state_mask;
+	cam1.s.dp0_data = kpucam->dp0 & kpucam->dp0_mask;
+	cam1.s.dp1_data = kpucam->dp1 & kpucam->dp1_mask;
+	cam1.s.dp2_data = kpucam->dp2 & kpucam->dp2_mask;
+
+	cam0.s.state = ~kpucam->state & kpucam->state_mask;
+	cam0.s.dp0_data = ~kpucam->dp0 & kpucam->dp0_mask;
+	cam0.s.dp1_data = ~kpucam->dp1 & kpucam->dp1_mask;
+	cam0.s.dp2_data = ~kpucam->dp2 & kpucam->dp2_mask;
+
+	npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRYX_CAMX(kpu, entry, 0),
+			 cam0.u);
+	npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRYX_CAMX(kpu, entry, 1),
+			 cam1.u);
+}
+
+static void npc_af_program_kpu_profile(struct npc_af *npc, int kpu,
+				       struct npc_kpu_profile *profile)
+{
+	int entry, num_entries, max_entries;
+	union cavm_npc_af_const1 af_const1;
+	union cavm_npc_af_kpux_cfg kpu_cfg;
+
+	if (profile->cam_entries != profile->action_entries) {
+		printf("%s: KPU%d: CAM and action entries [%d != %d] not equal\n",
+		       __func__, kpu, profile->cam_entries,
+		       profile->action_entries);
+		return;
+	}
+
+	af_const1.u = npc_af_reg_read(npc, CAVM_NPC_AF_CONST1());
+	max_entries = af_const1.s.kpu_entries;
+
+	/* Program CAM match entries for previous KPU extracted data */
+	num_entries = min_t(int, profile->cam_entries, max_entries);
+	for (entry = 0; entry < num_entries; entry++)
+		npc_af_config_kpucam(npc, &profile->cam[entry], kpu, entry);
+
+	/* Program this KPU's actions */
+	num_entries = min_t(int, profile->action_entries, max_entries);
+	npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRY_DISX(kpu, 0),
+			 enable_mask(num_entries));
+	if (num_entries > 64)
+		npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRY_DISX(kpu, 1),
+				 enable_mask(num_entries - 64));
+
+	/* Enable this KPU */
+	kpu_cfg.u = npc_af_reg_read(CAVM_NPC_AF_KPUX_CFG(kpu));
+	kpu_cfg.s.ena = 1;
+	npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_CFG(kpu), kpu_cfg.u);
+}
+
+static void npc_parser_profile_init(struct npc_af *npc)
+{
+	int num_pkinds, num_kpus, idx;
+	struct npc_pkind *pkind = &npc->pkind;
+	union cavm_npc_af_const af_const;
+
+	af_const.u = npc_af_reg_read(npc, CAVM_NPC_AF_CONST());
+	npc->npc_kpus = af_const.s.kpus;
+
+	/* Disable all KPUs and their entries */
+	for (idx = 0; idx < npc->npc_kpus; idx++) {
+		npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRY_DISX(idx, 0),
+				 ~0ULL);
+		npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_ENTRY_DISX(idx, 1),
+				 ~0ULL);
+		npc_af_reg_write(npc, CAVM_NPC_AF_KPUX_CFG(idx), 0);
+	}
+
+	/* First program IKPU profile (i.e. PKIND configs).
+	 * Check HW max count to avoid configuring junk or writing to
+	 * unsupported CSR addresses.
+	 */
+
+	num_pkinds = ARRAY_SIZE(ikpu_action_entries);
+	num_pkinds = min_t(int, pkind->rsrc.max, num_pkinds);
+
+	for (idx = 0; idx < num_pkinds; idx++)
+		npc_af_config_kpuaction(npc, &ikpu_action_entries[idx],
+					0, idx, true);
+	/* Program KPU CAM and Action profiles */
+	num_kpus = ARRAY_SIZE(npc_kpu_profiles);
+	num_kpus = min_t(int, npc->npc_kpus, num_kpus);
+
+	for (idx = 0; idx < num_kpus; idx++)
+		npc_af_program_kpu_profile(npc, idx, &npc_kpu_profiles[idx]);
+
+	npc_af_config_layer_info(npc);
+}
+
+static int npc_af_mcam_rsrcs_init(struct npc_af *npc)
+{
+	int err, rsvd;
+	struct npc_mcam *mcam = &npc->mcam;
+	union cavm_npc_af_const af_const;
+	union cavm_npc_af_intfx_kex_cfg kex_cfg;
+	struct nix_af_handle *nix = npc->nix_af;
+
+	/* Get HW limits */
+	af_const.u = npc_af_reg_read(npc, CAVM_NPC_AF_CONST());
+	mcam->banks = af_const.s.mcam_banks;
+	mcam->banksize = af_const.s.mcam_bank_depth;
+	mcam->counters = af_const.s.match_stats;
+
+	/* Actual number of MCAM entries vary by entry size */
+	kex_cfg.u = npc_af_reg_read(npc, CAVM_NPC_AF_INTFX_KEX_CFG(0));
+	mcam->total_entries = (mcam->banks / kex_cfg.s.keyw) * mcam->banksize;
+	mcam->keysize = kex_cfg.s.keyw;
+
+	/* Number of banks combined per MCAM entry */
+	switch (kex_cfg.s.keyw) {
+	case CAVM_NPC_MCAMKEYW_E_X4:
+		mcam->banks_per_entry = 4;
+		break;
+	case CAVM_NPC_MCAMKEYW_E_X2:
+		mcam->banks_per_entry = 2;
+		break;
+	default:
+		mcam->banks_per_entry = 1;
+		break;
+	}
+
+	/* Reserve one MCAM entry for each of the NIX LFs to guarantee space
+	 * to install default matching DMAC rule.  Also reserve 2 MCAM entries
+	 * for each PF for default channel based matchingor 'ucast & bcast'
+	 * matching to support UCAST and PROMISC modes of operation for PFs.
+	 * PF0 is excluded.
+	 */
+	rsvd = (npc->block.rsrc.max * RSVD_MCAM_ENTRIES_PER_NIXLF) +
+		((npc->hw->total_pfs - 1) * RSVD_MCAM_ENTRIES_PER_PF);
+	if (mcam->total_entries <= rsvd) {
+		printf("%s: Insufficient NPC MCAM size %d for pkt I/O, exiting\n",
+		       __func__);
+		return -ENOMEM;
+	}
+	mcam->entries = mcam->total_entries - rsvd;
+	mcam->nixlf_offset = mcam->entries;
+	mcam->pf_offset = mcam->nixlf_offset + nix->rsrc.max;
+
+	/* Allocate bitmap for this resource and memory for MCAM entry to
+	 * RVU PFFUNC allocation mapping info.
+	 */
+	mcam->rsrc.max = mcam->entries;
+	err = rvu_alloc_bitmap(&mcam->rsrc);
+	if (err)
+		return err;
+	mcam->pfvf_map = calloc(mcam->rsrc.max, sizeof(u16));
+	if (!mcam->pfvf_map)
+		return -ENOMEM;
+
+	return 0;
+}
+
+int npc_af_init(struct npc_af *npc)
+{
+	int err;
+	u64 keyz = NPC_MCAM_KEY_X2;
+	struct npc_pkind *pkind = &npc->pkind;
+	union cavm_npc_af_const1 af_const1;
+	union cavm_npc_af_pck_def_ol2 pck_ol2;
+	union cavm_nixx_af_rx_def_ol2 rx_def_ol2;
+	union cavm_nixx_af_rx_def_oudp rx_oudp;
+	union cavm_nixx_af_rx_def_otcp rx_otcp;
+	union cavm_nixx_af_rx_def_oip4 rx_oip4;
+	union cavm_npc_af_pck_def_oip4 pck_oip4;
+	union cavm_npc_af_pck_cfg pck_cfg;
+	union cavm_npc_af_intfx_kex_cfg key_cfg;
+
+	af_const1.u = npc_af_reg_read(npc, CAVM_NPC_AF_CONST1());
+	pkind->rsrc.max = af_const1.s.pkinds;
+
+	err = rvu_alloc_bitmap(&pkind->rsrc);
+	if (err)
+		return err;
+
+	pkind->pfchan_map = calloc(pkind->rsrc.max, sizeof(u32));
+	if (!pkind->pfchan_map)
+		return -ENOMEM;
+
+	/* Configure KPU profile */
+	npc_parser_profile_init(npc);
+
+	/* Config outer L2, IP, TCP and UDP's NPC layer info */
+	pck_ol2.u = 0;
+	pck_ol2.s.lid = CAVM_NPC_LID_E_LA;
+	pck_ol2.s.ltype_match = NPC_LT_LA_ETHER;
+	pck_ol2.s.ltype_mask = 0x0f;
+	npc_af_reg_write(npc, CAVM_NPC_AF_PCK_DEF_OL2(), pck_ol2.u);
+	rx_def_ol2.u = 0;
+	rx_def_ol2.s.lid = CAVM_NPC_LID_E_LA;
+	rx_def_ol2.s.ltype_match = NPC_LT_LA_ETHER;
+	rx_def_ol2.s.ltype_mask = 0x0f;
+	nix_af_reg_write(npc->nix_af, CAVM_NIXX_AF_RX_DEF_OL2(), rx_def_ol2.u);
+	rx_oudp.u = 0;
+	rx_oudp.s.lid = CAVM_NPC_LID_E_LD;
+	rx_oudp.s.ltype_match = NPC_LT_LD_UDP;
+	rx_oudp.s.ltype_mask = 0x0f;
+	nix_af_reg_write(npc->nix_af, CAVM_NIXX_AF_RX_DEF_OUDP(), rx_oudp.u);
+	rx_otcp.s.lid = CAVM_NPC_LID_E_LD;
+	rx_otcp.s.ltype_match = NPC_LT_LD_TCP;
+	rx_otcp.s.ltype_mask = 0x0f;
+	nix_af_reg_write(npc->nix_af, CAVM_NIXX_AF_RX_DEF_OTCP(), rx_otcp.u);
+	rx_oip4.u = 0;
+	rx_oip4.s.lid = CAVM_NPC_LID_E_LC;
+	rx_oip4.s.ltype_match = NPC_LT_LC_IP;
+	rx_oip4.s.ltype_mask = 0x0f;
+	nix_af_reg_write(npc->nix_af, CAVM_NIXX_AF_RX_DEF_OIP4(), rx_oip4.u);
+	pck_oip4.u = 0;
+	pck_oip4.s.lid = CAVM_NPC_LID_E_LC;
+	pck_oip4.s.ltype_match = NPC_LT_LC_IP;
+	pck_oip4.s.ltype_mask = 0x0f;
+	npc_af_reg_write(npc, CAVM_NPC_AF_PCK_DEF_OIP4(), pck_oip4.u);
+
+	/* Enable below for Rx packets
+	 * - IPv4 header checksum validation
+	 * - Detect outer L2 broadcast addresses/
+	 */
+	pck_cfg.u = npc_af_reg_read(npc, CAVM_NPC_AF_PCK_CFG());
+	pck_cfg.s.oip4_cksum = 1;
+	pck_cfg.s.l2b = 1;
+	npc_af_reg_write(npc, CAVM_NPC_AF_PCK_CFG(), pck_cfg.u)
+
+	/* Set RX and TX side MCAM search key size.
+	 * Also enable parse key extract nibles such that execpt layer E to H,
+	 * rest of the key is included for MCAM search.
+	 * Layer E-H is excluded since all KPUs are not yet in use.
+	 */
+	key_cfg.u = 0;
+	key_cfg.s.keyw = keyz & 0x3;
+	key_cfg.s.parse_nibble_ena = (1 << 20) - 1;
+	npc_af_reg_write(npc,
+		      CAVM_NPC_AF_INTFX_KEY_CFG(CAVM_NPC_INTF_E_NIXX_RX(0)), key_cfg.u);
+	key_cfg.u = 0;
+	key_cfg.s.keyw = keyz & 0x3;
+	key_cfg.s.parse_nibble_ena = (1 << 20) - 1;
+	npc_af_reg_write(npc,
+		      CAVM_NPC_AF_INTFX_KEY_CFG(CAVM_NPC_INTF_E_NIXX_TX(0)),
+		      key_cfg.u);
+
+	/* Set TX miss action to UCAST_DEFAULT, i.e. transmit the packet on
+	 * NIX LF SQ's default channel
+	 */
+	npc_af_reg_write(npc,
+		      CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_TX(0)),
+		      CAVM_NIX_TX_ACTIONOP_E_UCAST_DEFAULT);
+
+	/* If MCAM lookup doesn't result in a match, drop the received packet */
+	npc_af_reg_write(npc,
+		      CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_RX(0)),
+		      CAVM_NIX_RX_ACTIONOP_E_DROP);
+
+	err = npc_mcam_rsrcs_init(npc);
+
+	return err;
+}
diff --git a/drivers/net/cavium/octeontx2/npc.h b/drivers/net/cavium/octeontx2/npc.h
new file mode 100644
index 0000000000..4c76279125
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/npc.h
@@ -0,0 +1,95 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Cavium OcteonTx2 RVU Admin function driver
+ *
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __NPC_H__
+#define __NPC_H__
+
+#define RSVD_MCAM_ENTRIES_PER_PF	2	/** Ucast and Bcast */
+#define RSVD_MCAM_ENTRIES_PER_NIXLF	1	/** Ucast for VFs */
+
+struct npc_kpu_profile_cam {
+	u8 state;
+	u8 state_mask;
+	u16 dp0;
+	u16 dp0_mask;
+	u16 dp1;
+	u16 dp1_mask;
+	u16 dp2;
+	u16 dp2_mask;
+};
+
+struct npc_kpu_profile_action {
+	u8 errlev;
+	u8 errcode;
+	u8 dp0_offset;
+	u8 dp1_offset;
+	u8 dp2_offset;
+	u8 bypass_count;
+	u8 parse_done;
+	u8 next_state;
+	u8 ptr_advance;
+	u8 cap_ena;
+	u8 lid;
+	u8 ltype;
+	u8 flags;
+	u8 offset;
+	u8 mask;
+	u8 right;
+	u8 shift;
+};
+
+struct npc_kpu_profile {
+	int cam_entries;
+	int action_entries;
+	struct npc_kpu_profile_cam *cam;
+	struct npc_kpu_profile_action *action;
+};
+
+struct npc_pkind {
+	struct rsrc_bmap rsrc;
+	u32	*pfchan_map;
+};
+
+struct npc_mcam {
+	struct rsrc_bmap rsrc;
+	u16	*pfvf_map;
+	u16	total_entries; /* Total number of MCAM entries */
+	u16	entries;  /* Total - reserved for NIX LFs */
+	u8	banks_per_entry;  /* Number of keywords in key */
+	u8	keysize;
+	u8	banks;    /* Number of MCAM banks */
+	u16	banksize; /* Number of MCAM entries in each bank */
+	u16	counters; /* Number of match counters */
+	u16	nixlf_offset;
+	u16	pf_offset;
+};
+
+struct nix_af_handle;
+struct nix_handle;
+struct rvu_hwinfo;
+
+struct npc_af {
+	struct nix_af_handle	*nix_af;
+	struct npc_pkind	pkind;
+	void __iomem		*npc_af_base;
+	u8			npc_kpus;	/** Number of parser units */
+	struct npc_mcam		mcam;
+	struct rvu_block	block;
+	struct rvu_hwinfo	*hw;
+};
+
+struct npc {
+	struct npc_af		*npc_af;
+	void __iomem		*npc_base;
+	struct nix_handle	*nix;
+}
+
+#endif /* __NPC_H__ */
+
diff --git a/drivers/net/cavium/octeontx2/npc_hw.h b/drivers/net/cavium/octeontx2/npc_hw.h
new file mode 100644
index 0000000000..b4c149d7e7
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/npc_hw.h
@@ -0,0 +1,331 @@
+/* This file is auto-generated. Do not edit */
+
+/***********************license start***************
+ * Copyright (c) 2003-2018  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export
+ * control laws, including the U.S. Export Administration Act and its
+ * associated regulations, and may be subject to export or import regulations
+ * in other countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+ * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+ * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+ * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+ * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+ * OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+ * PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT,
+ * QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING
+ * OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+#ifndef __NPC_HW_H__
+#define __NPC_HW_H__
+
+/* Register offsets */
+
+#define CAVM_NPC_AF_CFG                                   (0x0ull)
+#define CAVM_NPC_AF_ACTIVE_PC                             (0x10ull)
+#define CAVM_NPC_AF_CONST                                 (0x20ull)
+#define CAVM_NPC_AF_CONST1                                (0x30ull)
+#define CAVM_NPC_AF_BLK_RST                               (0x40ull)
+#define CAVM_NPC_AF_MCAM_SCRUB_CTL                        (0xa0ull)
+#define CAVM_NPC_AF_KCAM_SCRUB_CTL                        (0xb0ull)
+#define CAVM_NPC_AF_KPUX_CFG(a)                           \
+	(0x500ull | (u64)(a) << 3)
+#define CAVM_NPC_AF_PCK_CFG                               (0x600ull)
+#define CAVM_NPC_AF_PCK_DEF_OL2                           (0x610ull)
+#define CAVM_NPC_AF_PCK_DEF_OIP4                          (0x620ull)
+#define CAVM_NPC_AF_PCK_DEF_OIP6                          (0x630ull)
+#define CAVM_NPC_AF_PCK_DEF_IIP4                          (0x640ull)
+#define CAVM_NPC_AF_KEX_LDATAX_FLAGS_CFG(a)               \
+	(0x800ull | (u64)(a) << 3)
+#define CAVM_NPC_AF_INTFX_KEX_CFG(a)                      \
+	(0x1010ull | (u64)(a) << 8)
+#define CAVM_NPC_AF_PKINDX_ACTION0(a)                     \
+	(0x80000ull | (u64)(a) << 6)
+#define CAVM_NPC_AF_PKINDX_ACTION1(a)                     \
+	(0x80008ull | (u64)(a) << 6)
+#define CAVM_NPC_AF_PKINDX_CPI_DEFX(a, b)                 \
+	(0x80020ull | (u64)(a) << 6 | (u64)(b) << 3)
+#define CAVM_NPC_AF_KPUX_ENTRYX_CAMX(a, b, c)             \
+	(0x100000ull | (u64)(a) << 14 | (u64)(b) << 6 | (u64)(c) << 3)
+#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION0(a, b)             \
+	(0x100020ull | (u64)(a) << 14 | (u64)(b) << 6)
+#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION1(a, b)             \
+	(0x100028ull | (u64)(a) << 14 | (u64)(b) << 6)
+#define CAVM_NPC_AF_KPUX_ENTRY_DISX(a, b)                 \
+	(0x180000ull | (u64)(a) << 6 | (u64)(b) << 3)
+#define CAVM_NPC_AF_CPIX_CFG(a)                           \
+	(0x200000ull | (u64)(a) << 3)
+#define CAVM_NPC_AF_INTFX_LIDX_LTX_LDX_CFG(a, b, c, d)    \
+	(0x900000ull | (u64)(a) << 16 | (u64)(b) << 12 | (u64)(c) << 5 | \
+	(u64)(d) << 3)
+#define CAVM_NPC_AF_INTFX_LDATAX_FLAGSX_CFG(a, b, c)      \
+	(0x980000ull | (u64)(a) << 16 | (u64)(b) << 12 | (u64)(c) << 3)
+#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(a, b, c)       \
+	(0x1000000ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
+#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(a, b, c)         \
+	(0x1000010ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
+#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(a, b, c)         \
+	(0x1000020ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
+#define CAVM_NPC_AF_MCAMEX_BANKX_CFG(a, b)                \
+	(0x1800000ull | (u64)(a) << 8 | (u64)(b) << 4)
+#define CAVM_NPC_AF_MCAMEX_BANKX_STAT_ACT(a, b)           \
+	(0x1880000ull | (u64)(a) << 8 | (u64)(b) << 4)
+#define CAVM_NPC_AF_MATCH_STATX(a)                        \
+	(0x1880008ull | (u64)(a) << 8)
+#define CAVM_NPC_AF_INTFX_MISS_STAT_ACT(a)                \
+	(0x1880040ull + (u64)(a) * 0x8)
+#define CAVM_NPC_AF_MCAMEX_BANKX_ACTION(a, b)             \
+	(0x1900000ull | (u64)(a) << 8 | (u64)(b) << 4)
+#define CAVM_NPC_AF_MCAMEX_BANKX_TAG_ACT(a, b)            \
+	(0x1900008ull | (u64)(a) << 8 | (u64)(b) << 4)
+#define CAVM_NPC_AF_INTFX_MISS_ACT(a)                     \
+	(0x1a00000ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_INTFX_MISS_TAG_ACT(a)                 \
+	(0x1b00008ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_MCAM_BANKX_HITX(a, b)                 \
+	(0x1c80000ull | (u64)(a) << 8 | (u64)(b) << 4)
+#define CAVM_NPC_AF_LKUP_CTL                              (0x2000000ull)
+#define CAVM_NPC_AF_LKUP_DATAX(a)                         \
+	(0x2000200ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_LKUP_RESULTX(a)                       \
+	(0x2000400ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_INTFX_STAT(a)                         \
+	(0x2000800ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_DBG_CTL                               (0x3000000ull)
+#define CAVM_NPC_AF_DBG_STATUS                            (0x3000010ull)
+#define CAVM_NPC_AF_KPUX_DBG(a)                           \
+	(0x3000020ull | (u64)(a) << 8)
+#define CAVM_NPC_AF_IKPU_ERR_CTL                          (0x3000080ull)
+#define CAVM_NPC_AF_KPUX_ERR_CTL(a)                       \
+	(0x30000a0ull | (u64)(a) << 8)
+#define CAVM_NPC_AF_MCAM_DBG                              (0x3001000ull)
+#define CAVM_NPC_AF_DBG_DATAX(a)                          \
+	(0x3001400ull | (u64)(a) << 4)
+#define CAVM_NPC_AF_DBG_RESULTX(a)                        \
+	(0x3001800ull | (u64)(a) << 4)
+
+
+/* Enum offsets */
+
+#define CAVM_NPC_INTF_NIX0_RX    (0x0ull)
+#define CAVM_NPC_INTF_NIX0_TX    (0x1ull)
+
+#define CAVM_NPC_ERRLEV_RE       (0x0ull)
+#define CAVM_NPC_ERRLEV_LA       (0x1ull)
+#define CAVM_NPC_ERRLEV_LB       (0x2ull)
+#define CAVM_NPC_ERRLEV_LC       (0x3ull)
+#define CAVM_NPC_ERRLEV_LD       (0x4ull)
+#define CAVM_NPC_ERRLEV_LE       (0x5ull)
+#define CAVM_NPC_ERRLEV_LF       (0x6ull)
+#define CAVM_NPC_ERRLEV_LG       (0x7ull)
+#define CAVM_NPC_ERRLEV_LH       (0x8ull)
+#define CAVM_NPC_ERRLEV_NIX      (0xfull)
+#define CAVM_NPC_ERRLEV_R9       (0x9ull)
+#define CAVM_NPC_ERRLEV_R10      (0xaull)
+#define CAVM_NPC_ERRLEV_R11      (0xbull)
+#define CAVM_NPC_ERRLEV_R12      (0xcull)
+#define CAVM_NPC_ERRLEV_R13      (0xdull)
+#define CAVM_NPC_ERRLEV_R14      (0xeull)
+
+#define CAVM_NPC_LKUPOP_PKT      (0x0ull)
+#define CAVM_NPC_LKUPOP_KEY      (0x1ull)
+
+#define CAVM_NPC_LID_LA          (0x0ull)
+#define CAVM_NPC_LID_LB          (0x1ull)
+#define CAVM_NPC_LID_LC          (0x2ull)
+#define CAVM_NPC_LID_LD          (0x3ull)
+#define CAVM_NPC_LID_LE          (0x4ull)
+#define CAVM_NPC_LID_LF          (0x5ull)
+#define CAVM_NPC_LID_LG          (0x6ull)
+#define CAVM_NPC_LID_LH          (0x7ull)
+
+#define CAVM_NPC_MCAMKEYW_X1     (0x0ull)
+#define CAVM_NPC_MCAMKEYW_X2     (0x1ull)
+#define CAVM_NPC_MCAMKEYW_X4     (0x2ull)
+
+
+/* Structures definitions */
+
+/**
+ * NPC Layer Parse Information Structure
+ * This structure specifies the format of NPC_RESULT_S[LA,LB,...,LH].
+ */
+union cavm_npc_layer_info_s {
+	u32 u;
+	struct npc_layer_info_s_s {
+	
+		u32 lptr:       8;
+		u32 flags:      8;
+		u32 ltype:      4;
+		u32 rsvd_31_20: 12;
+	} s;
+};
+
+/**
+ * NPC Layer MCAM Search Key Extract Structure
+ * This structure specifies the format of each of the
+ * NPC_PARSE_KEX_S[LA,LB,...,LH] fields. It contains the subset of
+ * NPC_LAYER_INFO_S fields that can be included in the MCAM search key. See
+ * NPC_PARSE_KEX_S and NPC_AF_INTF()_KEX_CFG.
+ */
+union cavm_npc_layer_kex_s {
+	u16 u;
+	struct npc_layer_kex_s_s {
+	
+		u16 flags:      8;
+		u16 ltype:      4;
+		u16 rsvd_15_12: 4;
+	} s;
+};
+
+/**
+ * NPC MCAM Search Key X1 Structure
+ * This structure specifies the MCAM search key format used by an interface
+ * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X1.
+ */
+union cavm_npc_mcam_key_x1_s {
+	u64 u[3];
+	struct npc_mcam_key_x1_s_s {
+		/* Word 0 */
+		u64 intf:               2;
+		u64 rsvd_63_2:          62;
+		u64 kw0;               	/* Word 1 */
+		/* Word 2 */
+		u64 kw1:                48;
+		u64 rsvd_191_176:       16;
+	} s;
+};
+
+/**
+ * NPC MCAM Search Key X2 Structure
+ * This structure specifies the MCAM search key format used by an interface
+ * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X2.
+ */
+union cavm_npc_mcam_key_x2_s {
+	u64 u[5];
+	struct npc_mcam_key_x2_s_s {
+		/* Word 0 */
+		u64 intf:               2;
+		u64 rsvd_63_2:          62;
+		u64 kw0;               	/* Word 1 */
+		u64 kw1;               	/* Word 2 */
+		u64 kw2;               	/* Word 3 */
+		/* Word 4 */
+		u64 kw3:                32;
+		u64 rsvd_319_288:       32;
+	} s;
+};
+
+/**
+ * NPC MCAM Search Key X4 Structure
+ * This structure specifies the MCAM search key format used by an interface
+ * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X4.
+ */
+union cavm_npc_mcam_key_x4_s {
+	u64 u[8];
+	struct npc_mcam_key_x4_s_s {
+		/* Word 0 */
+		u64 intf:       2;
+		u64 rsvd_63_2:  62;
+		u64 kw0;               	/* Word 1 */
+		u64 kw1;               	/* Word 2 */
+		u64 kw2;               	/* Word 3 */
+		u64 kw3;               	/* Word 4 */
+		u64 kw4;               	/* Word 5 */
+		u64 kw5;               	/* Word 6 */
+		u64 kw6;               	/* Word 7 */
+	} s;
+};
+
+/**
+ * NPC Parse Key Extract Structure
+ * This structure contains the subset of NPC_RESULT_S fields that can be
+ * included in the MCAM search key. See NPC_AF_INTF()_KEX_CFG.
+ */
+union cavm_npc_parse_kex_s {
+	u64 u[2];
+	struct npc_parse_kex_s_s {
+		/* Word 0 */
+		u64 chan:               12;
+		u64 errlev:             4;
+		u64 errcode:            8;
+		u64 l2m:                1;
+		u64 l2b:                1;
+		u64 l3m:                1;
+		u64 l3b:                1;
+		u64 la:                 12;
+		u64 lb:                 12;
+		u64 lc:                 12;
+		/* Word 1 */
+		u64 ld:                 12;
+		u64 le:                 12;
+		u64 lf:                 12;
+		u64 lg:                 12;
+		u64 lh:                 12;
+		u64 rsvd_127_124:       4;
+	} s;
+};
+
+/**
+ * NPC Result Structure
+ * This structure contains a packet's parse and flow identification
+ * information.
+ */
+union cavm_npc_result_s {
+	u64 u[6];
+	struct npc_result_s_s {
+		/* Word 0 */
+		u64 intf:               2;
+		u64 pkind:              6;
+		u64 chan:               12;
+		u64 errlev:             4;
+		u64 errcode:            8;
+		u64 l2m:                1;
+		u64 l2b:                1;
+		u64 l3m:                1;
+		u64 l3b:                1;
+		u64 eoh_ptr:            8;
+		u64 rsvd_63_44:         20;
+		u64 action;            	/* Word 1 */
+		u64 vtag_action;       	/* Word 2 */
+		/* Word 3 */
+		u64 la:                 20;
+		u64 lb:                 20;
+		u64 lc:                 20;
+		u64 rsvd_255_252:       4;
+		/* Word 4 */
+		u64 ld:                 20;
+		u64 le:                 20;
+		u64 lf:                 20;
+		u64 rsvd_319_316:       4;
+		/* Word 5 */
+		u64 lg:                 20;
+		u64 lh:                 20;
+		u64 rsvd_383_360:       24;
+	} s;
+};
+
+#endif /* __NPC_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/npc_profile.h b/drivers/net/cavium/octeontx2/npc_profile.h
new file mode 100644
index 0000000000..77e3a31065
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/npc_profile.h
@@ -0,0 +1,3356 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Cavium OcteonTx2 RVU Admin function driver
+ *
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef NPC_PROFILE_H
+#define NPC_PROFILE_H
+
+#define NPC_ETYPE_IP		0x0800
+#define NPC_ETYPE_IP6		0x86dd
+#define NPC_ETYPE_ARP		0x0806
+#define NPC_ETYPE_RARP		0x8035
+#define NPC_ETYPE_MPLSU		0x8847
+#define NPC_ETYPE_MPLSM		0x8848
+#define NPC_ETYPE_ETAG		0x893f
+#define NPC_ETYPE_CTAG		0x8100
+#define NPC_ETYPE_SBTAG		0x88a8
+#define NPC_ETYPE_ITAG		0X88e7
+#define NPC_ETYPE_QINQ		0x9100
+#define NPC_ETYPE_TRANS_ETH_BR	0x6558
+#define NPC_ETYPE_PPP		0x880b
+
+#define NPC_IPNH_HOP		0
+#define NPC_IPNH_ICMP		1
+#define NPC_IPNH_IGMP		2
+#define NPC_IPNH_IP		4
+#define NPC_IPNH_TCP		6
+#define NPC_IPNH_UDP		17
+#define NPC_IPNH_IP6		41
+#define NPC_IPNH_ROUT		43
+#define NPC_IPNH_FRAG		44
+#define NPC_IPNH_GRE		47
+#define NPC_IPNH_ESP		50
+#define NPC_IPNH_AH		51
+#define NPC_IPNH_ICMP6		58
+#define NPC_IPNH_NONH		59
+#define NPC_IPNH_DEST		60
+#define NPC_IPNH_SCTP		132
+
+#define NPC_UDP_PORT_GTPC	2123
+#define NPC_UDP_PORT_GTPU	2152
+#define NPC_UDP_PORT_VXLAN	4789
+#define NPC_UDP_PORT_GENEVE	6081
+
+#define NPC_TCP_PORT_HTTP	80
+#define NPC_TCP_PORT_HTTPS	443
+
+#define NPC_IP_VER_4		0x4000
+#define NPC_IP_VER_6		0x6000
+#define NPC_IP_VER_MASK		0xf000
+#define NPC_IP_HDR_LEN_5	0x0500
+#define NPC_IP_HDR_LEN_MASK	0x0f00
+
+#define NPC_GRE_F_CSUM		(0x1 << 15)
+#define NPC_GRE_F_ROUTE		(0x1 << 14)
+#define NPC_GRE_F_KEY		(0x1 << 13)
+#define NPC_GRE_F_SEQ		(0x1 << 12)
+#define NPC_GRE_F_ACK		(0x1 << 7)
+#define NPC_GRE_FLAG_MASK	(NPC_GRE_F_CSUM | NPC_GRE_F_ROUTE | \
+				 NPC_GRE_F_KEYNPC_GRE_F_SEQNPC_GRE_F_ACK)
+#define NPC_GRE_VER_MASK	0x0003
+#define NPC_GRE_VER_1		0x0001
+
+#define NPC_VXLAN_I		0x0800
+
+#define NPC_GENEVE_F_OAM	(0x1 << 7)
+#define NPC_GENEVE_F_CRI_OPT	(0x1 << 6)
+#define NPC_GTP_PT_GTP		(0x1 << 12)
+#define NPC_GTP_PT_MASK		(0x1 << 12)
+#define NPC_GTP_VER1		(0x1 << 13)
+#define NPC_GTP_VER_MASK	(0x7 << 13)
+#define NPC_GTP_MT_G_PDU	0xff
+#define NPC_GTP_MT_MASK		0xff
+
+#define NPC_TCP_DATA_OFFSET_5		0x5000
+#define NPC_TCP_DATA_OFFSET_MASK	0xf000
+
+enum NPC_ERRLEV_E {
+	NPC_ERRLEV_RE = 0,
+	NPC_ERRLEV_LA = 1,
+	NPC_ERRLEV_LB = 2,
+	NPC_ERRLEV_LC = 3,
+	NPC_ERRLEV_LD = 4,
+	NPC_ERRLEV_LE = 5,
+	NPC_ERRLEV_LF = 6,
+	NPC_ERRLEV_LG = 7,
+	NPC_ERRLEV_LH = 8,
+	NPC_ERRLEV_NIX = 15,
+	NPC_ERRLEV_ENUM_LAST = 16,
+};
+
+enum npc_kpu_err_code {
+	NPC_EC_NOERR = 0, /* has to be zero */
+	NPC_EC_UNK,
+	NPC_EC_L2_K1,
+	NPC_EC_L2_K2,
+	NPC_EC_L2_K3,
+	NPC_EC_L2_K3_ETYPE_UNK,
+	NPC_EC_IP_VER,
+	NPC_EC_IP6_VER,
+	NPC_EC_VXLAN,
+	NPC_EC_NVGRE,
+	NPC_EC_GRE,
+	NPC_EC_GRE_VER1,
+	NPC_EC_L4,
+	NPC_EC_LAST /* has to be the last item */
+};
+
+enum npc_kpu_parser_state {
+	NPC_S_NA = 0,
+	NPC_S_KPU1_ETHER,
+	NPC_S_KPU1_PKI,
+	NPC_S_KPU2_CTAG,
+	NPC_S_KPU2_SBTAG,
+	NPC_S_KPU2_QINQ,
+	NPC_S_KPU2_ETAG,
+	NPC_S_KPU3_CTAG,
+	NPC_S_KPU3_STAG,
+	NPC_S_KPU3_QINQ,
+	NPC_S_KPU4_MPLS,
+	NPC_S_KPU5_IP,
+	NPC_S_KPU5_IP6,
+	NPC_S_KPU5_ARP,
+	NPC_S_KPU5_RARP,
+	NPC_S_KPU6_IP6_EXT,
+	NPC_S_KPU7_IP6_EXT,
+	NPC_S_KPU8_TCP,
+	NPC_S_KPU8_UDP,
+	NPC_S_KPU8_SCTP,
+	NPC_S_KPU8_ICMP,
+	NPC_S_KPU8_IGMP,
+	NPC_S_KPU8_ICMP6,
+	NPC_S_KPU8_GRE,
+	NPC_S_KPU8_ESP,
+	NPC_S_KPU8_AH,
+	NPC_S_KPU9_TU_ETHER,
+	NPC_S_KPU9_TU_PPP,
+	NPC_S_KPU11_TU_IP,
+	NPC_S_KPU11_TU_IP6,
+	NPC_S_KPU11_TU_ARP,
+	NPC_S_KPU12_TU_IP6_EXT,
+	NPC_S_KPU13_TU_IP6_EXT,
+	NPC_S_KPU14_TU_TCP,
+	NPC_S_KPU14_TU_UDP,
+	NPC_S_KPU14_TU_SCTP,
+	NPC_S_KPU14_TU_ICMP,
+	NPC_S_KPU14_TU_IGMP,
+	NPC_S_KPU14_TU_ICMP6,
+	NPC_S_KPU14_TU_ESP,
+	NPC_S_KPU14_TU_AH,
+	NPC_S_KPU15_HTTP_DATA,
+	NPC_S_KPU15_HTTPS_DATA,
+	NPC_S_KPU15_TCP_DATA,
+	NPC_S_KPU15_UDP_DATA,
+	NPC_S_LAST /* has to be the last item */
+};
+
+enum npc_kpu_parser_flag {
+	NPC_F_NA = 0,
+	NPC_F_HAS_PKI,
+	NPC_F_HAS_PKI_HAS_VLAN,
+	NPC_F_HAS_PKI_HAS_ETAG,
+	NPC_F_HAS_PKI_HAS_MPLS,
+	NPC_F_ETYPE_UNK,
+	NPC_F_ETHER_HAS_VLAN,
+	NPC_F_ETHER_HAS_ETAG,
+	NPC_F_ETHER_HAS_MPLS,
+	NPC_F_VLAN_2_TAGS,
+	NPC_F_VLAN_2_TAGS_ETYPE_UNK,
+	NPC_F_VLAN_3_TAGS,
+	NPC_F_VLAN_4_TAGS,
+	NPC_F_QINQ_DBL,
+	NPC_F_BTAG_HAS_CTAG,
+	NPC_F_IP_HAS_OPTIONS,
+	NPC_F_IP_IN_IP,
+	NPC_F_IP_6TO4,
+	NPC_F_IP_UNK_PROTO,
+	NPC_F_IP_IN_IP_HAS_OPTIONS,
+	NPC_F_IP_6TO4_HAS_OPTIONS,
+	NPC_F_IP_UNK_PROTO_HAS_OPTIONS,
+	NPC_F_IP6_HAS_EXT,
+	NPC_F_IP6_TUN_IP6,
+	NPC_F_TCP_HAS_OPTIONS,
+	NPC_F_TCP_HTTP,
+	NPC_F_TCP_HTTPS,
+	NPC_F_TCP_UNK_PORT,
+	NPC_F_TCP_HTTP_HAS_OPTIONS,
+	NPC_F_TCP_HTTPS_HAS_OPTIONS,
+	NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+	NPC_F_UDP_VXLAN_NOVNI,
+	NPC_F_UDP_GTPU_G_PDU,
+	NPC_F_UDP_GTPU_UNK,
+	NPC_F_UDP_UNK_PORT,
+	NPC_F_UDP_GENEVE_OAM,
+	NPC_F_UDP_GENEVE_CRI_OPT,
+	NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+	NPC_F_GRE_HAS_SRE,
+	NPC_F_GRE_HAS_CSUM,
+	NPC_F_GRE_HAS_KEY,
+	NPC_F_GRE_HAS_SEQ,
+	NPC_F_GRE_HAS_CSUM_KEY,
+	NPC_F_GRE_HAS_CSUM_SEQ,
+	NPC_F_GRE_HAS_KEY_SEQ,
+	NPC_F_GRE_HAS_CSUM_KEY_SEQ,
+	NPC_F_GRE_HAS_ROUTE,
+	NPC_F_GRE_UNK_PROTO,
+	NPC_F_GRE_VER1,
+	NPC_F_GRE_VER1_HAS_SEQ,
+	NPC_F_GRE_VER1_HAS_ACK,
+	NPC_F_GRE_VER1_HAS_SEQ_ACK,
+	NPC_F_GRE_VER1_UNK_PROTO,
+	NPC_F_TU_ETHER_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_CTAG,
+	NPC_F_TU_ETHER_HAS_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_STAG_CTAG,
+	NPC_F_TU_ETHER_HAS_STAG_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_STAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_QINQ_CTAG,
+	NPC_F_TU_ETHER_HAS_QINQ_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_QINQ_ETYPE_UNK,
+	NPC_F_LAST /* has to be the last item */
+};
+
+struct npc_kpu_profile_action ikpu_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 1, 0xff,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_cam kpu1_cam_entries[] = {
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_SBTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_QINQ, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_ETAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0000, 0xfc00, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0400, 0xfe00, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_SBTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_QINQ, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_ETAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0010,
+		0x0010, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0010,
+		0x0010, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu2_cam_entries[] = {
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_MPLSU,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_MPLSM,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		NPC_ETYPE_CTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		NPC_ETYPE_SBTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_RARP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_CTAG, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_IP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_IP6, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_ARP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_RARP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_MPLSU, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_MPLSM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		NPC_ETYPE_CTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		NPC_ETYPE_QINQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_IP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_IP6, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_ARP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_RARP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu3_cam_entries[] = {
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu4_cam_entries[] = {
+	{
+		NPC_S_KPU4_MPLS, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu5_cam_entries[] = {
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_TCP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_UDP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_SCTP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ICMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IGMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ESP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_AH, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_GRE, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP6, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_TCP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_UDP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_SCTP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ICMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IGMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ESP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_AH, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_GRE, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP6, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_ARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_RARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_TCP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_UDP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_SCTP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ICMP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ICMP6 << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ESP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_AH << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_GRE << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_IP6 << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, 0x0000, 0x0000, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu6_cam_entries[] = {
+	{
+		NPC_S_KPU6_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu7_cam_entries[] = {
+	{
+		NPC_S_KPU7_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu8_cam_entries[] = {
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTP,
+		0xffff, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTPS,
+		0xffff, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, 0x0000, 0x0000, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, NPC_VXLAN_I,
+		NPC_VXLAN_I, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, 0x0000,
+		0xffff, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		0x0000, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		0x0000, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff, 0x0000,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPC, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPU, 0xffff,
+		NPC_GTP_PT_GTP | NPC_GTP_VER1 | NPC_GTP_MT_G_PDU,
+		NPC_GTP_PT_MASK | NPC_GTP_VER_MASK | NPC_GTP_MT_MASK,
+		0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_SCTP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ICMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_IGMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ICMP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ESP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_AH, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		0x0000, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY | NPC_GRE_F_SEQ,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		0x0000, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY | NPC_GRE_F_SEQ,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, NPC_GRE_F_ROUTE,
+		0x4fff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0000,
+		0x4fff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0000,
+		0x0003, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_VER_1, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_ACK | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ | NPC_GRE_F_ACK | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x2001,
+		0xef7f, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0001,
+		0x0003, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu9_cam_entries[] = {
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_IP,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_IP6,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_ARP,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_PPP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu10_cam_entries[] = {
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu11_cam_entries[] = {
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_TCP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_UDP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_SCTP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ICMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_IGMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ESP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_AH, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_TCP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_UDP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_SCTP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ICMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_IGMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ESP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_AH, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_ARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_TCP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_UDP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_SCTP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ICMP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ICMP6 << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ESP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_AH << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu12_cam_entries[] = {
+	{
+		NPC_S_KPU12_TU_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu13_cam_entries[] = {
+	{
+		NPC_S_KPU13_TU_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu14_cam_entries[] = {
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, 0x0000, 0x0000,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_UDP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_SCTP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ICMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_IGMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ICMP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ESP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_AH, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu15_cam_entries[] = {
+	{
+		NPC_S_KPU15_TCP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_HTTP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_HTTPS_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_UDP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_action kpu1_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		3, 0, NPC_S_KPU5_IP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		3, 0, NPC_S_KPU5_IP6, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_ARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_RARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_CTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 20,
+		0, 0, NPC_S_KPU2_SBTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_QINQ, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		0, 0, NPC_S_KPU2_ETAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_ETAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_8023, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_8023, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		3, 0, NPC_S_KPU5_IP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		3, 0, NPC_S_KPU5_IP6, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_ARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_RARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_CTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 20,
+		0, 0, NPC_S_KPU2_SBTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_QINQ, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		0, 0, NPC_S_KPU2_ETAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_ETAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LA, NPC_EC_L2_K1, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu2_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_3_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_STAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_4_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU3_CTAG, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_BTAG_HAS_CTAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_3_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_QINQ, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_4_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_STAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_STAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_QINQ, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_QINQ, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K2, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu3_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu4_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		0, 0, NPC_S_KPU5_IP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu5_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_IGMP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_ESP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_AH, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_IN_IP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_6TO4, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_IGMP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_ESP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_AH, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_IN_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_6TO4_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_UNK_PROTO_HAS_OPTIONS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_IP_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_ARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_RARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP6, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ESP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_AH, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, NPC_F_IP6_TUN_IP6, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU6_IP6_EXT, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, NPC_F_IP6_HAS_EXT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_IP6_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu6_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu7_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu8_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTP_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTPS_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTPS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_TCP_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTP_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTP_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTPS_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTPS_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_TCP_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_VXLAN, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_VXLAN, NPC_F_UDP_VXLAN_NOVNI,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_VXLAN, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPC, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPU, NPC_F_UDP_GTPU_G_PDU, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPU, NPC_F_UDP_GTPU_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_UDP_DATA, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP, NPC_F_UDP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_SCTP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ICMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_IGMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ICMP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ESP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_AH, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_NVGRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_NVGRE, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 4, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 4, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_ROUTE, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_GRE, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_ACK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_SEQ_ACK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_GRE_VER1, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu9_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_STAG_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_STAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_PPP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LE, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LE, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu10_action_entries[] = {
+	{
+		NPC_ERRLEV_LE, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LE, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu11_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_IGMP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_IGMP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_UNK_PROTO_HAS_OPTIONS,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_IP_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_ARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP6, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 40, 1,
+		NPC_LID_LC, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 40, 1,
+		NPC_LID_LC, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU12_TU_IP6_EXT, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, NPC_F_IP6_HAS_EXT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_IP6_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LF, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu12_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu13_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu14_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTP_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTPS_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTPS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_TCP_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTP_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTP_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTPS_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTPS_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_TCP_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_UDP_DATA, 8, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_UDP, NPC_F_UDP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_SCTP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ICMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_IGMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ICMP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ESP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_AH, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LG, NPC_EC_L4, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LG, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu15_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_TCP_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_HTTP_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_HTTPS_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_UDP_DATA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile npc_kpu_profiles[] = {
+	{
+		ARRAY_SIZE(kpu1_cam_entries),
+		ARRAY_SIZE(kpu1_action_entries),
+		&kpu1_cam_entries[0],
+		&kpu1_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu2_cam_entries),
+		ARRAY_SIZE(kpu2_action_entries),
+		&kpu2_cam_entries[0],
+		&kpu2_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu3_cam_entries),
+		ARRAY_SIZE(kpu3_action_entries),
+		&kpu3_cam_entries[0],
+		&kpu3_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu4_cam_entries),
+		ARRAY_SIZE(kpu4_action_entries),
+		&kpu4_cam_entries[0],
+		&kpu4_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu5_cam_entries),
+		ARRAY_SIZE(kpu5_action_entries),
+		&kpu5_cam_entries[0],
+		&kpu5_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu6_cam_entries),
+		ARRAY_SIZE(kpu6_action_entries),
+		&kpu6_cam_entries[0],
+		&kpu6_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu7_cam_entries),
+		ARRAY_SIZE(kpu7_action_entries),
+		&kpu7_cam_entries[0],
+		&kpu7_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu8_cam_entries),
+		ARRAY_SIZE(kpu8_action_entries),
+		&kpu8_cam_entries[0],
+		&kpu8_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu9_cam_entries),
+		ARRAY_SIZE(kpu9_action_entries),
+		&kpu9_cam_entries[0],
+		&kpu9_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu10_cam_entries),
+		ARRAY_SIZE(kpu10_action_entries),
+		&kpu10_cam_entries[0],
+		&kpu10_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu11_cam_entries),
+		ARRAY_SIZE(kpu11_action_entries),
+		&kpu11_cam_entries[0],
+		&kpu11_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu12_cam_entries),
+		ARRAY_SIZE(kpu12_action_entries),
+		&kpu12_cam_entries[0],
+		&kpu12_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu13_cam_entries),
+		ARRAY_SIZE(kpu13_action_entries),
+		&kpu13_cam_entries[0],
+		&kpu13_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu14_cam_entries),
+		ARRAY_SIZE(kpu14_action_entries),
+		&kpu14_cam_entries[0],
+		&kpu14_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu15_cam_entries),
+		ARRAY_SIZE(kpu15_action_entries),
+		&kpu15_cam_entries[0],
+		&kpu15_action_entries[0],
+	},
+};
+
+#endif /* NPC_PROFILE_H */
diff --git a/drivers/net/cavium/octeontx2/npc_reg.h b/drivers/net/cavium/octeontx2/npc_reg.h
new file mode 100644
index 0000000000..dbfd358e84
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/npc_reg.h
@@ -0,0 +1,632 @@
+
+/* Register definitions */
+
+/**
+ * NPC AF General Configuration Register
+ */
+union cavm_npc_af_cfg {
+	u64 u;
+	struct npc_af_cfg_s {
+		u64 rsvd_1_0:           2;
+		u64 cclk_force:         1;
+		u64 force_intf_clk_en:  1;
+		u64 rsvd_63_4:          60;
+	} s;
+};
+
+/**
+ * NPC Interrupt-Timer Configuration Register
+ */
+union cavm_npc_af_active_pc {
+	u64 u;
+	struct npc_af_active_pc_s {
+		u64 active_pc;                      
+	} s;
+};
+
+/**
+ * NPC AF Constants Register
+ * This register contains constants for software discovery.
+ */
+union cavm_npc_af_const {
+	u64 u;
+	struct npc_af_const_s {
+		u64 intfs:              4;
+		u64 lids:               4;
+		u64 kpus:               5;
+		u64 rsvd_15_13:         3;
+		u64 mcam_bank_width:    10;
+		u64 rsvd_27_26:         2;
+		u64 mcam_bank_depth:    16;
+		u64 mcam_banks:         4;
+		u64 match_stats:        16;
+	} s;
+};
+
+/**
+ * NPC AF Constants 1 Register
+ * This register contains constants for software discovery.
+ */
+union cavm_npc_af_const1 {
+	u64 u;
+	struct npc_af_const1_s {
+		u64 kpu_entries:        12;
+		u64 pkinds:             8;
+		u64 cpi_size:           16;
+		u64 rsvd_63_36:         28;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Scrub Control Register
+ */
+union cavm_npc_af_mcam_scrub_ctl {
+	u64 u;
+	struct npc_af_mcam_scrub_ctl_s {
+		u64 ena:        1;
+		u64 rsvd_7_1:   7;
+		u64 lp_dis:     1;
+		u64 rsvd_15_9:  7;
+		u64 toth:       4;
+		u64 rsvd_63_20: 44;
+	} s;
+};
+
+/**
+ * NPC AF KPU Configuration Registers
+ */
+union cavm_npc_af_kpux_cfg {
+	u64 u;
+	struct npc_af_kpux_cfg_s {
+		u64 ena:        1;
+		u64 rsvd_63_1:  63;
+	} s;
+};
+
+/**
+ * NPC AF Protocol Check Configuration Register
+ */
+union cavm_npc_af_pck_cfg {
+	u64 u;
+	struct npc_af_pck_cfg_s {
+		u64 rsvd_0:             1;
+		u64 iip4_cksum:         1;
+		u64 oip4_cksum:         1;
+		u64 rsvd_3:             1;
+		u64 l3b:                1;
+		u64 l3m:                1;
+		u64 l2b:                1;
+		u64 l2m:                1;
+		u64 rsvd_23_8:          16;
+		u64 iip4_cksum_errcode: 8;
+		u64 oip4_cksum_errcode: 8;
+		u64 rsvd_63_40:         24;
+	} s;
+};
+
+/**
+ * NPC AF Protocol Check Outer L2 Definition Register
+ * Provides layer information used by the protocol checker to identify an
+ * outer L2 header.
+ */
+union cavm_npc_af_pck_def_ol2 {
+	u64 u;
+	struct npc_af_pck_def_ol2_s {
+		u64 ltype_mask:         4;
+		u64 ltype_match:        4;
+		u64 lid:                3;
+		u64 rsvd_63_11:         53;
+	} s;
+};
+
+/**
+ * NPC AF Key Extract Layer Data Flags Configuration Register
+ */
+union cavm_npc_af_kex_ldatax_flags_cfg {
+	u64 u;
+	struct npc_af_kex_ldatax_flags_cfg_s {
+		u64 lid:        3;
+		u64 rsvd_63_3:  61;
+	} s;
+};
+
+/**
+ * NPC AF Interface Key Extract Configuration Registers
+ */
+union cavm_npc_af_intfx_kex_cfg {
+	u64 u;
+	struct npc_af_intfx_kex_cfg_s {
+		u64 parse_nibble_ena:   31;
+		u64 rsvd_31:            1;
+		u64 keyw:               3;
+		u64 rsvd_63_35:         29;
+	} s;
+};
+
+/**
+ * NPC AF Port Kind Channel Parse Index Definition Registers
+ * These registers specify the layer information and algorithm to compute a
+ * packet's channel parse index (CPI), which provides a port to channel adder
+ * for calculating NPC_RESULT_S[CHAN]. There are two CPI definitions per port
+ * kind, allowing the CPI computation to use two possible layer definitions in
+ * the parsed packet, e.g. DiffServ DSCP from either IPv4 or IPv6 header. CPI
+ * pseudocode: <pre> for (i = 0; i < 2; i++) {  cpi_def =
+ * NPC_AF_PKIND()_CPI_DEF(i);  LX = LA, LB, ..., or LH as selected by
+ * cpi_def[LID];   if (cpi_def[VALID]    && ((cpi_def[LTYPE_MATCH] &
+ * cpi_def[LTYPE_MASK])       == (NPC_RESULT_S[LX[LTYPE]] &
+ * cpi_def[LTYPE_MASK]))    && ((cpi_def[FLAGS_MATCH] & cpi_def[FLAGS_MASK])
+ * == (NPC_RESULT_S[LX[FLAGS]] & cpi_def[FLAGS_MASK])))  {    // Found
+ * matching layer    nibble_offset = (2*NPC_RESULT_S[LX[LPTR]]) +
+ * cpi_def[ADD_OFFSET];    add_byte = byte at nibble_offset from start of
+ * packet;    cpi_add = (add_byte & cpi_def[ADD_MASK]) >> cpi_def[ADD_SHIFT];
+ * cpi = cpi_def[CPI_BASE] + cpi_add;    NPC_RESULT_S[CHAN] +=
+ * NPC_AF_CPI(cpi)_CFG[PADD];    break;  } } </pre>
+ */
+union cavm_npc_af_pkindx_cpi_defx {
+	u64 u;
+	struct npc_af_pkindx_cpi_defx_s {
+		u64 cpi_base:           10;
+		u64 rsvd_11_10:         2;
+		u64 add_shift:          3;
+		u64 rsvd_15:            1;
+		u64 add_mask:           8;
+		u64 add_offset:         8;
+		u64 flags_mask:         8;
+		u64 flags_match:        8;
+		u64 ltype_mask:         4;
+		u64 ltype_match:        4;
+		u64 lid:                3;
+		u64 rsvd_62_59:         4;
+		u64 ena:                1;
+	} s;
+};
+
+/**
+ * NPC AF KPU Entry CAM Registers
+ * KPU comparison ternary data. The field values in NPC_AF_KPU()_ENTRY()_CAM()
+ * are ternary, where each data bit of the search key matches as follows: _
+ * [CAM(1)]<n>=0, [CAM(0)]<n>=0: Always match; search key data<n> don't care.
+ * _ [CAM(1)]<n>=0, [CAM(0)]<n>=1: Match when search key data<n> == 0. _
+ * [CAM(1)]<n>=1, [CAM(0)]<n>=0: Match when search key data<n> == 1. _
+ * [CAM(1)]<n>=1, [CAM(0)]<n>=1: Reserved. The reserved combination is not
+ * allowed. Hardware suppresses any write to CAM(0) or CAM(1) that would
+ * result in the reserved combination for any CAM bit. Software must program a
+ * default entry for each KPU, e.g. by programming each KPU's last entry {b}
+ * (NPC_AF_KPU()_ENTRY({b})_CAM()) to always match all bits.
+ */
+union cavm_npc_af_kpux_entryx_camx {
+	u64 u;
+	struct npc_af_kpux_entryx_camx_s {
+		u64 dp0_data:   16;
+		u64 dp1_data:   16;
+		u64 dp2_data:   16;
+		u64 state:      8;
+		u64 rsvd_63_56: 8;
+	} s;
+};
+
+/**
+ * NPC AF KPU Entry Action Data 0 Registers
+ * When a KPU's search data matches a KPU CAM entry in
+ * NPC_AF_KPU()_ENTRY()_CAM(), the corresponding entry action in
+ * NPC_AF_KPU()_ENTRY()_ACTION0 and NPC_AF_KPU()_ENTRY()_ACTION1 specifies the
+ * next state and operations to perform before exiting the KPU.
+ */
+union cavm_npc_af_kpux_entryx_action0 {
+	u64 u;
+	struct npc_af_kpux_entryx_action0_s {
+		u64 var_len_shift:      3;
+		u64 var_len_right:      1;
+		u64 var_len_mask:       8;
+		u64 var_len_offset:     8;
+		u64 ptr_advance:        8;
+		u64 capture_flags:      8;
+		u64 capture_ltype:      4;
+		u64 capture_lid:        3;
+		u64 rsvd_43:            1;
+		u64 next_state:         8;
+		u64 parse_done:         1;
+		u64 capture_ena:        1;
+		u64 byp_count:          3;
+		u64 rsvd_63_57:         7;
+	} s;
+};
+
+/**
+ * NPC AF KPU Entry Action Data 0 Registers
+ * See NPC_AF_KPU()_ENTRY()_ACTION0.
+ */
+union cavm_npc_af_kpux_entryx_action1 {
+	u64 u;
+	struct npc_af_kpux_entryx_action1_s {
+		u64 dp0_offset: 8;
+		u64 dp1_offset: 8;
+		u64 dp2_offset: 8;
+		u64 errcode:    8;
+		u64 errlev:     4;
+		u64 rsvd_63_36: 28;
+	} s;
+};
+
+/**
+ * NPC AF KPU Entry Disable Registers
+ * See NPC_AF_KPU()_ENTRY()_ACTION0.
+ */
+union cavm_npc_af_kpux_entry_disx {
+	u64 u;
+	struct npc_af_kpux_entry_disx_s {
+		u64 dis;                            
+	} s;
+};
+
+/**
+ * NPC AF Channel Parse Index Table Registers
+ */
+union cavm_npc_af_cpix_cfg {
+	u64 u;
+	struct npc_af_cpix_cfg_s {
+		u64 padd:       4;
+		u64 rsvd_63_4:  60;
+	} s;
+};
+
+/**
+ * NPC AF Interface Layer Data Extract Configuration Registers
+ * These registers control the extraction of layer data (LDATA) into the MCAM
+ * search key for each interface. Up to two LDATA fields can be extracted per
+ * layer (LID(0..7) indexed by NPC_LID_E), with up to 16 bytes per LDATA
+ * field. For each layer, the corresponding NPC_LAYER_INFO_S[LTYPE] value in
+ * NPC_RESULT_S is used as the LTYPE(0..15) index and select the associated
+ * LDATA(0..1) registers. NPC_LAYER_INFO_S[LTYPE]=0x0 means the corresponding
+ * layer not parsed (invalid), so software should keep
+ * NPC_AF_INTF()_LID()_LT(0)_LD()_CFG[ENA] clear to disable extraction when
+ * LTYPE is zero.
+ */
+union cavm_npc_af_intfx_lidx_ltx_ldx_cfg {
+	u64 u;
+	struct npc_af_intfx_lidx_ltx_ldx_cfg_s {
+		u64 key_offset: 6;
+		u64 flags_ena:  1;
+		u64 ena:        1;
+		u64 hdr_offset: 8;
+		u64 bytesm1:    4;
+		u64 rsvd_63_20: 44;
+	} s;
+};
+
+/**
+ * NPC AF Interface Layer Data Flags Configuration Registers
+ * These registers control the extraction of layer data (LDATA) into the MCAM
+ * search key for each interface based on the FLAGS<3:0> bits of two layers
+ * selected by NPC_AF_KEX_LDATA()_FLAGS_CFG.
+ */
+union cavm_npc_af_intfx_ldatax_flagsx_cfg {
+	u64 u;
+	struct npc_af_intfx_ldatax_flagsx_cfg_s {
+		u64 key_offset: 6;
+		u64 rsvd_6:     1;
+		u64 ena:        1;
+		u64 hdr_offset: 8;
+		u64 bytesm1:    4;
+		u64 rsvd_63_20: 44;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank CAM Data Interface Registers
+ * MCAM comparison ternary data interface word. The field values in
+ * NPC_AF_MCAME()_BANK()_CAM()_INTF, NPC_AF_MCAME()_BANK()_CAM()_W0 and
+ * NPC_AF_MCAME()_BANK()_CAM()_W1 are ternary, where each data bit of the
+ * search key matches as follows: _ [CAM(1)]<n>=0, [CAM(0)]<n>=0: Always
+ * match; search key data<n> don't care. _ [CAM(1)]<n>=0, [CAM(0)]<n>=1: Match
+ * when search key data<n> == 0. _ [CAM(1)]<n>=1, [CAM(0)]<n>=0: Match when
+ * search key data<n> == 1. _ [CAM(1)]<n>=1, [CAM(0)]<n>=1: Reserved. The
+ * reserved combination is not allowed. Hardware suppresses any write to
+ * CAM(0) or CAM(1) that would result in the reserved combination for any CAM
+ * bit. When an interface is configured to use the NPC_MCAM_KEY_X1_S search
+ * key format (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X1), the four
+ * banks of every MCAM entry are used as individual entries, each of which is
+ * independently compared with the search key as follows: _
+ * NPC_AF_MCAME()_BANK()_CAM()_INTF[INTF] corresponds to
+ * NPC_MCAM_KEY_X1_S[INTF]. _ NPC_AF_MCAME()_BANK()_CAM()_W0[MD] corresponds
+ * to NPC_MCAM_KEY_X1_S[KW0]. _ NPC_AF_MCAME()_BANK()_CAM()_W1[MD] corresponds
+ * to NPC_MCAM_KEY_X1_S[KW1]. When an interface is configured to use the
+ * NPC_MCAM_KEY_X2_S search key format (NPC_AF_INTF()_KEX_CFG[KEYW] =
+ * NPC_MCAMKEYW_E::X2), banks 0-1 of every MCAM entry are used as one
+ * double-wide entry, banks 2-3 as a second double-wide entry, and each
+ * double-wide entry is independently compared with the search key as follows:
+ * _ NPC_AF_MCAME()_BANK(0,2)_CAM()_INTF[INTF] corresponds to
+ * NPC_MCAM_KEY_X2_S[INTF]. _ NPC_AF_MCAME()_BANK(0,2)_CAM()_W0[MD]
+ * corresponds to NPC_MCAM_KEY_X2_S[KW0]. _
+ * NPC_AF_MCAME()_BANK(0,2)_CAM()_W1[MD] corresponds to
+ * NPC_MCAM_KEY_X2_S[KW1]<47:0>. _ NPC_AF_MCAME()_BANK(1,3)_CAM()_INTF[INTF]
+ * corresponds to NPC_MCAM_KEY_X2_S[INTF]. _
+ * NPC_AF_MCAME()_BANK(1,3)_CAM()_W0[MD]<15:0> corresponds to
+ * NPC_MCAM_KEY_X2_S[KW1]<63:48>. _
+ * NPC_AF_MCAME()_BANK(1,3)_CAM()_W0[MD]<63:16> corresponds to
+ * NPC_MCAM_KEY_X2_S[KW2]<47:0>. _ NPC_AF_MCAME()_BANK(1,3)_CAM()_W1[MD]<15:0>
+ * corresponds to NPC_MCAM_KEY_X2_S[KW2]<63:48>. _
+ * NPC_AF_MCAME()_BANK(1,3)_CAM()_W1[MD]<47:16> corresponds to
+ * NPC_MCAM_KEY_X2_S[KW3]<31:0>. When an interface is configured to use the
+ * NPC_MCAM_KEY_X4_S search key format (NPC_AF_INTF()_KEX_CFG[KEYW] =
+ * NPC_MCAMKEYW_E::X4), the four banks of every MCAM entry are used as a
+ * single quad-wide entry that is compared with the search key as follows: _
+ * NPC_AF_MCAME()_BANK(0)_CAM()_INTF[INTF] corresponds to
+ * NPC_MCAM_KEY_X4_S[INTF]. _ NPC_AF_MCAME()_BANK(0)_CAM()_W0[MD] corresponds
+ * to NPC_MCAM_KEY_X4_S[KW0]. _ NPC_AF_MCAME()_BANK(0)_CAM()_W1[MD]
+ * corresponds to NPC_MCAM_KEY_X4_S[KW1]<47:0>. _
+ * NPC_AF_MCAME()_BANK(1)_CAM()_INTF[INTF] corresponds to
+ * NPC_MCAM_KEY_X4_S[INTF]. _ NPC_AF_MCAME()_BANK(1)_CAM()_W0[MD]<15:0>
+ * corresponds to NPC_MCAM_KEY_X4_S[KW1]<63:48>. _
+ * NPC_AF_MCAME()_BANK(1)_CAM()_W0[MD]<63:16> corresponds to
+ * NPC_MCAM_KEY_X4_S[KW2]<47:0>. _ NPC_AF_MCAME()_BANK(1)_CAM()_W1[MD]<15:0>
+ * corresponds to NPC_MCAM_KEY_X4_S[KW2]<63:48>. _
+ * NPC_AF_MCAME()_BANK(1)_CAM()_W1[MD]<47:16> corresponds to
+ * NPC_MCAM_KEY_X4_S[KW3]<31:0>. _ NPC_AF_MCAME()_BANK(2)_CAM()_INTF[INTF]
+ * corresponds to NPC_MCAM_KEY_X4_S[INTF]. _
+ * NPC_AF_MCAME()_BANK(2)_CAM()_W0[MD]<31:0> corresponds to
+ * NPC_MCAM_KEY_X4_S[KW3]<63:32>. _ NPC_AF_MCAME()_BANK(2)_CAM()_W0[MD]<63:32>
+ * corresponds to NPC_MCAM_KEY_X4_S[KW4]<31:0>. _
+ * NPC_AF_MCAME()_BANK(2)_CAM()_W1[MD]<31:0> corresponds to
+ * NPC_MCAM_KEY_X4_S[KW4]<63:32>. _ NPC_AF_MCAME()_BANK(2)_CAM()_W1[MD]<47:32>
+ * corresponds to NPC_MCAM_KEY_X4_S[KW5]<15:0>. _
+ * NPC_AF_MCAME()_BANK(3)_CAM()_INTF[INTF] corresponds to
+ * NPC_MCAM_KEY_X4_S[INTF]. _ NPC_AF_MCAME()_BANK(3)_CAM()_W0[MD]<47:0>
+ * corresponds to NPC_MCAM_KEY_X4_S[KW5]<63:16>. _
+ * NPC_AF_MCAME()_BANK(3)_CAM()_W0[MD]<63:48> corresponds to
+ * NPC_MCAM_KEY_X4_S[KW6]<15:0>. _ NPC_AF_MCAME()_BANK(3)_CAM()_W1[MD]
+ * corresponds to NPC_MCAM_KEY_X4_S[KW6]<63:16>. Note that for the X2 and X4
+ * formats, a wide entry will not match unless the INTF fields from the
+ * associated two or four banks match the INTF value from the search key. For
+ * the X1 and X2 formats, a match in a lower-numbered bank takes priority over
+ * a match in any higher numbered banks. Within each bank, the lowest numbered
+ * matching entry takes priority over any higher numbered entry.
+ */
+union cavm_npc_af_mcamex_bankx_camx_intf {
+	u64 u;
+	struct npc_af_mcamex_bankx_camx_intf_s {
+		u64 intf:       2;
+		u64 rsvd_63_2:  62;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank CAM Data Word 0 Registers
+ * MCAM comparison ternary data word 0. See NPC_AF_MCAME()_BANK()_CAM()_INTF.
+ */
+union cavm_npc_af_mcamex_bankx_camx_w0 {
+	u64 u;
+	struct npc_af_mcamex_bankx_camx_w0_s {
+		u64 md;                             
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank Data Word 1 Registers
+ * MCAM comparison ternary data word 1. See NPC_AF_MCAME()_BANK()_CAM()_INTF.
+ */
+union cavm_npc_af_mcamex_bankx_camx_w1 {
+	u64 u;
+	struct npc_af_mcamex_bankx_camx_w1_s {
+		u64 md:         48;
+		u64 rsvd_63_48: 16;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank Configuration Registers
+ */
+union cavm_npc_af_mcamex_bankx_cfg {
+	u64 u;
+	struct npc_af_mcamex_bankx_cfg_s {
+		u64 ena:        1;
+		u64 rsvd_63_1:  63;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank Statistics Action Registers
+ * Used to optionally increment a NPC_AF_MATCH_STAT() counter when a packet
+ * matches an MCAM entry. See also NPC_AF_MCAME()_BANK()_ACTION.
+ */
+union cavm_npc_af_mcamex_bankx_stat_act {
+	u64 u;
+	struct npc_af_mcamex_bankx_stat_act_s {
+		u64 stat_sel:   9;
+		u64 ena:        1;
+		u64 rsvd_63_10: 54;
+	} s;
+};
+
+/**
+ * NPC AF Match Statistics Registers
+ */
+union cavm_npc_af_match_statx {
+	u64 u;
+	struct npc_af_match_statx_s {
+		u64 count:      48;
+		u64 rsvd_63_48: 16;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank Action Data Registers
+ * Specifies a packet's match action captured in NPC_RESULT_S[ACTION]. When an
+ * interface is configured to use the NPC_MCAM_KEY_X2_S search key format
+ * (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X2), *
+ * NPC_AF_MCAME()_BANK(0)_ACTION/_TAG_ACT/_STAT_ACT are used if the search key
+ * matches NPC_AF_MCAME()_BANK(0..1)_CAM()_W*. *
+ * NPC_AF_MCAME()_BANK(2)_ACTION/_TAG_ACT/_STAT_ACT are used if the search key
+ * matches NPC_AF_MCAME()_BANK(2..3)_CAM()_W*. *
+ * NPC_AF_MCAME()_BANK(1,3)_ACTION/_TAG_ACT/_STAT_ACT are not used. When an
+ * interface is configured to use the NPC_MCAM_KEY_X4_S search key format
+ * (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X4): *
+ * NPC_AF_MCAME()_BANK(0)_ACTION/_TAG_ACT/_STAT_ACT are used if the search key
+ * matches NPC_AF_MCAME()_BANK(0..3)_CAM()_W*. *
+ * NPC_AF_MCAME()_BANK(1..3)_ACTION/_TAG_ACT/_STAT_ACT are not used.
+ */
+union cavm_npc_af_mcamex_bankx_action {
+	u64 u;
+	struct npc_af_mcamex_bankx_action_s {
+		u64 action;                         
+	} s;
+};
+
+/**
+ * NPC AF MCAM Entry Bank VTag Action Data Registers
+ * Specifies a packet's match Vtag action captured in
+ * NPC_RESULT_S[VTAG_ACTION]. See also NPC_AF_MCAME()_BANK()_ACTION.
+ */
+union cavm_npc_af_mcamex_bankx_tag_act {
+	u64 u;
+	struct npc_af_mcamex_bankx_tag_act_s {
+		u64 vtag_action;                    
+	} s;
+};
+
+/**
+ * NPC AF MCAM Bank Hit Registers
+ */
+union cavm_npc_af_mcam_bankx_hitx {
+	u64 u;
+	struct npc_af_mcam_bankx_hitx_s {
+		u64 hit;                            
+	} s;
+};
+
+/**
+ * NPC AF Software Lookup Control Registers
+ */
+union cavm_npc_af_lkup_ctl {
+	u64 u;
+	struct npc_af_lkup_ctl_s {
+		u64 intf:       2;
+		u64 pkind:      6;
+		u64 chan:       12;
+		u64 hdr_sizem1: 8;
+		u64 op:         3;
+		u64 exec:       1;
+		u64 rsvd_63_32: 32;
+	} s;
+};
+
+/**
+ * NPC AF Software Lookup Data Registers
+ */
+union cavm_npc_af_lkup_datax {
+	u64 u;
+	struct npc_af_lkup_datax_s {
+		u64 data;                           
+	} s;
+};
+
+/**
+ * NPC AF Software Lookup Result Registers
+ */
+union cavm_npc_af_lkup_resultx {
+	u64 u;
+	struct npc_af_lkup_resultx_s {
+		u64 data;                           
+	} s;
+};
+
+/**
+ * NPC AF Interface Statistics Registers
+ * Statistics per interface. Index enumerated by NPC_INTF_E.
+ */
+union cavm_npc_af_intfx_stat {
+	u64 u;
+	struct npc_af_intfx_stat_s {
+		u64 count:      48;
+		u64 rsvd_63_48: 16;
+	} s;
+};
+
+/**
+ * NPC AF Debug Control Register
+ * This register controls the capture of debug information in
+ * NPC_AF_KPU()_DBG, NPC_AF_MCAM_DBG, NPC_AF_DBG_DATA() and
+ * NPC_AF_DBG_RESULT().
+ */
+union cavm_npc_af_dbg_ctl {
+	u64 u;
+	struct npc_af_dbg_ctl_s {
+		u64 continuous: 1;
+		u64 lkup_dbg:   1;
+		u64 intf_dbg:   4;
+		u64 rsvd_63_6:  58;
+	} s;
+};
+
+/**
+ * NPC AF Debug Status Register
+ * This register controls the capture of debug information in
+ * NPC_AF_KPU()_DBG, NPC_AF_MCAM_DBG, NPC_AF_LKUP_DATA() and
+ * NPC_AF_LKUP_RESULT().
+ */
+union cavm_npc_af_dbg_status {
+	u64 u;
+	struct npc_af_dbg_status_s {
+		u64 done:       1;
+		u64 rsvd_63_1:  63;
+	} s;
+};
+
+/**
+ * NPC AF KPU Debug Registers
+ * This register contains information for the last packet/lookup for which
+ * debug is enabled by NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
+ */
+union cavm_npc_af_kpux_dbg {
+	u64 u;
+	struct npc_af_kpux_dbg_s {
+		u64 hit_entry:  8;
+		u64 byp:        1;
+		u64 rsvd_63_9:  55;
+	} s;
+};
+
+/**
+ * NPC AF KPU Error Control Registers
+ * This register specifies values captured in NPC_RESULT_S[ERRLEV,ERRCODE]
+ * when errors are detected by a KPU.
+ */
+union cavm_npc_af_kpux_err_ctl {
+	u64 u;
+	struct npc_af_kpux_err_ctl_s {
+		u64 errlev:                     4;
+		u64 dp_offset_errcode:          8;
+		u64 ptr_advance_errcode:        8;
+		u64 var_len_offset_errcode:     8;
+		u64 rsvd_63_28:                 36;
+	} s;
+};
+
+/**
+ * NPC AF MCAM Debug Register
+ * This register contains information for the last packet/lookup for which
+ * debug is enabled by NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
+ */
+union cavm_npc_af_mcam_dbg {
+	u64 u;
+	struct npc_af_mcam_dbg_s {
+		u64 hit_entry:  10;
+		u64 rsvd_11_10: 2;
+		u64 hit_bank:   2;
+		u64 rsvd_15_14: 2;
+		u64 miss:       1;
+		u64 rsvd_63_17: 47;
+	} s;
+};
+
+/**
+ * NPC AF Debug Data Registers
+ * This register contains packet header data for the last packet/lookup for
+ * which debug information is captured by NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
+ */
+union cavm_npc_af_dbg_datax {
+	u64 u;
+	struct npc_af_dbg_datax_s {
+		u64 data;                           
+	} s;
+};
diff --git a/drivers/net/cavium/octeontx2/npc_regs.h b/drivers/net/cavium/octeontx2/npc_regs.h
deleted file mode 100644
index b769e9be13..0000000000
--- a/drivers/net/cavium/octeontx2/npc_regs.h
+++ /dev/null
@@ -1,362 +0,0 @@
-/*
- * Copyright (C) 2018 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This file defines the NPC registers for the Cavium OcteonTX2.
- */
-
-#ifndef __NPC_REG_H__
-#define __NPC_REG_H__
-
-/**
- * Enumeration npc_intf_e
- *
- * NPC Interface Enumeration
- * Enumerates the NPC interfaces.
- */
-/**
- * Enumeration npc_errlev_e
- *
- * NPC Error Level Enumeration
- * Enumerates the lowest protocol layer containing an error.
- */
-#define CAVM_NPC_ERRLEV_E_LA (1)
-#define CAVM_NPC_ERRLEV_E_LB (2)
-#define CAVM_NPC_ERRLEV_E_LC (3)
-#define CAVM_NPC_ERRLEV_E_LD (4)
-#define CAVM_NPC_ERRLEV_E_LE (5)
-#define CAVM_NPC_ERRLEV_E_LF (6)
-#define CAVM_NPC_ERRLEV_E_LG (7)
-#define CAVM_NPC_ERRLEV_E_LH (8)
-#define CAVM_NPC_ERRLEV_E_NIX (0xf)
-#define CAVM_NPC_ERRLEV_E_RX(a) (0 + (a))
-#define CAVM_NPC_ERRLEV_E_RE (0)
-
-/**
- * Enumeration npc_intf_e
- *
- * NPC Interface Enumeration
- * Enumerates the NPC interfaces.
- */
-#define CAVM_NPC_INTF_E_NIXX_RX(a) (0 + 2 * (a))
-#define CAVM_NPC_INTF_E_NIXX_TX(a) (1 + 2 * (a))
-
-/**
- * Enumeration npc_lid_e
- *
- * NPC Layer ID Enumeration
- * Enumerates layers parsed by NPC.
- */
-#define CAVM_NPC_LID_E_LA (0)
-#define CAVM_NPC_LID_E_LB (1)
-#define CAVM_NPC_LID_E_LC (2)
-#define CAVM_NPC_LID_E_LD (3)
-#define CAVM_NPC_LID_E_LE (4)
-#define CAVM_NPC_LID_E_LF (5)
-#define CAVM_NPC_LID_E_LG (6)
-#define CAVM_NPC_LID_E_LH (7)
-
-/**
- * Enumeration npc_lkupop_e
- *
- * NPC Lookup Operation Enumeration
- * Enumerates the lookup operation for NPC_AF_LKUP_CTL[OP].
- */
-#define CAVM_NPC_LKUPOP_E_KEY (1)
-#define CAVM_NPC_LKUPOP_E_PKT (0)
-
-/**
- * Enumeration npc_mcamkeyw_e
- *
- * NPC MCAM Search Key Width Enumeration
- */
-#define CAVM_NPC_MCAMKEYW_E_X1 (0)
-#define CAVM_NPC_MCAMKEYW_E_X2 (1)
-#define CAVM_NPC_MCAMKEYW_E_X4 (2)
-
-#define CAVM_NPC_AF_CFG			(0x0000)
-#define CAVM_NPC_AF_ACTIVE_PC		(0x0010)
-#define CAVM_NPC_AF_CONST		(0x0020)
-#define CAVM_NPC_AF_CONST1		(0x0030)
-#define CAVM_NPC_AF_BLK_RST		(0x0040)
-#define CAVM_NPC_AF_DV_FC_SCRATCH	(0x0060)
-#define CAVM_NPC_AF_MCAM_SCRUB_CTL	(0x00a0)
-#define CAVM_NPC_AF_KCAM_SCRUB_CTL	(0x00b0)
-
-#define CAVM_NPC_AF_ECO0		(0x0200)
-#define CAVM_NPC_AF_KPUX_CFG(x)		(0x0500 + ((x) & 0xf) * 0x8)
-#define CAVM_NPC_AF_PCK_CFG		(0x0600)
-#define CAVM_NPC_AF_PCK_DEF_OL2		(0x0610)
-#define CAVM_NPC_AF_PCK_DEF_OIP4	(0x0620)
-#define CAVM_NPC_AF_PCK_DEF_OIP6	(0x0630)
-#define CAVM_NPC_AF_PCK_DEF_IIP4	(0x0640)
-#define CAVM_NPC_AF_KEX_LDATAX_FLAGS_CFG(x)	(0x0800 + ((x) & 0x1) * 0x8)
-#define CAVM_NPC_AF_INTFX_CFG(x)	(0x1000 + ((x) & 0x1) * 0x100)
-#define CAVM_NPC_AF_INTFX_KEX_CFG	(0x1010 + ((x) & 0x1) * 0x100)
-
-#define CAVM_NPC_AF_PKINDX_ACTION0(x)			\
-		(0x0080000 + ((x) & 0x3f) * 0x40ll)
-#define CAVM_NPC_AF_PKINDX_ACTION1(x)			\
-		(0x0080008 + ((x) & 0x3f) * 0x40ll)
-#define CAVM_NPC_AF_PKINDX_CPI_DEFX(a, b)		\
-		(0x0080020 + ((a) & 0x3f) * 0x40 + ((b) & 0x1) * 0x8)
-
-#define CAVM_NPC_AF_KPUX_ENTRYX_CAMX(a, b, c)		\
-		(0x100000 + ((a) & 0xf) * 0x4000 +	\
-		 ((b) & 0x7f) * 0x40 + ((c) & 0x1) * 0x8)
-#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION0(a, b)		\
-		(0x100020 + ((a) & 0xf) * 0x4000 + ((b) & 0x3f) * 0x40)
-#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION1(a, b)		\
-		(0x100028 + ((a) & 0xf) * 0x4000 + ((b) & 0x3f) * 0x40)
-#define CAVM_NPC_AF_KPUX_ENTRY_DISX(a, b)		\
-		(0x180000 + ((a) & 0xf) + ((b) & 0x1) * 0x8)
-
-#define CAVM_NPC_AF_CPIX_CFG(x)		(0x200000 + ((x) & 0x3ff) * 0x8)
-
-#define CAVM_NPC_AF_INTFX_LIDX_LTX_LDX_CFG(a, b, c, d)	\
-		(0x900000 + ((a) & 0x1) * 0x10000 +	\
-		 ((b) & 0x7) * 0x1000 + ((c) & 0xf) * 0x20 + ((d) & 0x1) * 0x8)
-#define CAVM_NPC_AF_INTFX_LDATAX_FLAGSX_CFG(a, b, c)	\
-		(0x980000 + ((a) & 0x1) * 0x10000 +	\
-		 ((b) & 0x1) * 0x1000 + ((c) & 0xf) * 0x8)
-#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(a, b, c)	\
-		(0x1000000 + 0x400 * ((a) & 0x3ff) +	\
-		 0x40 * ((b) & 0x3) + 8 * ((c) & 0x1))
-#define CAVM__NPC_AF_MCAMEX_BANKX_CAMX_W0(a, b, c)	\
-		(0x1000010 + 0x400 * ((a) & 0x3ff) +	\
-		 0x40 * ((b) & 0x3) + 8 * ((c) & 0x1))
-#define CAVM__NPC_AF_MCAMEX_BANKX_CAMX_W1(a, b, c)	\
-		(0x1000020 + 0x400 * ((a) & 0x3ff) +	\
-		 0x40 * ((b) & 0x3) + 8 * ((c) & 0x1))
-#define CAVM_NPC_AF_INTFX_MISS_ACT(x)			\
-		(0x1a00000 + ((x) & 0x1) * 0x10)
-/**
- * Register (RVU_PF_BAR0) npc_af_pkind#_action0
- *
- * NPC AF Port Kind Action Data 0 Registers
- * NPC_AF_PKIND()_ACTION0 and NPC_AF_PKIND()_ACTION1 specify the initial parse state and
- * operations to perform before entering KPU 0.
- */
-union cavm_npc_af_pkindx_action0 {
-	u64 u;
-	struct cavm_npc_af_pkindx_action0_s {
-		u64 var_len_shift:3;		/**< [  2:  0](R/W) Variable length shift size in bits. See [VAR_LEN_OFFSET]. */
-		u64 var_len_right:1;		/**< [  3:  3](R/W) Variable length shift direction.
-                                                                 0 = Left shift.
-                                                                 1 = Right shift. */
-		u64 var_len_mask:8;		/**< [ 11:  4](R/W) Variable length mask. See [VAR_LEN_OFFSET]. */
-		u64 var_len_offset:8;		/**< [ 19: 12](R/W) Variable length byte offset. When [VAR_LEN_MASK] is nonzero, byte offset
-                                                                 from current header pointer of the packet byte that supplies a variable
-                                                                 pointer advance value.
-
-                                                                 The pointer advance algorithm is as follows:
-
-                                                                 \<pre\>
-                                                                 var_len_byte = packet byte at (NPC_RESULT_S[EOH_PTR] + [VAR_LEN_OFFSET]);
-                                                                 masked_var_len_byte = var_len_byte & [VAR_LEN_MASK];
-
-                                                                 if ([VAR_LEN_RIGHT])
-                                                                    var_len_advance = masked_var_len_byte \>\> [VAR_LEN_SHIFT];
-                                                                 else
-                                                                    var_len_advance = masked_var_len_byte \<\< [VAR_LEN_SHIFT];
-
-                                                                 NPC_RESULT_S[EOH_PTR] += ([PTR_ADVANCE] + var_len_advance);
-                                                                 \</pre\>
-
-                                                                 NPC_RESULT_S[EOH_PTR] must always be even. Therefore,
-                                                                 [VAR_LEN_SHIFT], [VAR_LEN_RIGHT] and [VAR_LEN_MASK] must produce an
-                                                                 even var_len_advance value. */
-		u64 ptr_advance:8;		/**< [ 27: 20](R/W) Pointer advance. Fixed value added to NPC_RESULT_S[EOH_PTR]. Must be
-                                                                 even. See also [VAR_LEN_OFFSET]. */
-		u64 capture_flags:8;		/**< [ 35: 28](R/W) Capture flags. When nonzero, specifies which NPC_LAYER_INFO_S[FLAGS] bits
-                                                                 to set in the approprate layer within
-                                                                 NPC_RESULT_S, as follows:
-                                                                 _ NPC_LAYER_INFO_S[FLAGS] |= [CAPTURE_FLAGS]
-
-                                                                 Note that flags are captured irrespective of the [CAPTURE_ENA] value. */
-		u64 capture_ltype:4;		/**< [ 39: 36](R/W) Capture layer type. When [CAPTURE_ENA] is set, specifies
-                                                                 NPC_LAYER_INFO_S[LTYPE] value captured in the approprate layer within
-                                                                 NPC_RESULT_S. */
-		u64 capture_lid:3;		/**< [ 42: 40](R/W) Capture layer ID. Specifies the layer for which information is captured in
-                                                                 NPC_RESULT_S. Enumerated by NPC_LID_E. */
-		u64 reserved_43:1;
-		u64 next_state:8;		/**< [ 51: 44](R/W) Search value for ternary comparison with the next KPU's
-                                                                 NPC_AF_KPU()_ENTRY()_CAM()[STATE]. */
-		u64 parse_done:1;		/**< [ 52: 52](R/W) Parse done. When set, terminate parse after this KPU and bypass subsequent KPUs. */
-		u64 capture_ena:1;		/**< [ 53: 53](R/W) Layer capture enable. When set, layer information is captured in
-                                                                 NPC_RESULT_S. When clear, layer information is not captured by the KPU. */
-		u64 byp_count:3;		/**< [ 56: 54](R/W) Bypass count. When nonzero, specifies the number of enabled KPUs to be
-                                                                 bypassed. For example, if the bypass count is two in the matching entry for
-                                                                 KPU 3, NPC_AF_KPU(4,6,7)_CFG[ENA] = 1 and NPC_AF_KPU(5)_CFG[ENA] = 0, then:
-                                                                 * KPUs 4 and 6 are bypassed.
-                                                                 * The matching entry's [NEXT_STATE] and
-                                                                 NPC_AF_KPU()_ENTRY()_ACTION1[DP*_OFFSET] in KPU 3 are used for the lookup in
-                                                                 KPU 7. */
-		u64 reserved_57_63:7;
-	} s;
-	/* struct cavm_npc_af_pkindx_action0_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_intf#_miss_act
- *
- * NPC AF Interface MCAM Miss Action Data Registers
- * When a combination of NPC_AF_MCAME()_BANK()_CAM()_* and
- * NPC_AF_MCAME()_BANK()_CFG[ENA] yields an MCAM miss for a packet, this
- * register specifies the packet's match action captured in NPC_RESULT_S[ACTION].
- */
-union cavm_npc_af_intfx_miss_act {
-	u64 u;
-	struct cavm_npc_af_intfx_miss_act_s {
-		u64 action:64;			/**< [ 63:  0](R/W) Match action. Format is NIX_RX_ACTION_S for RX packet, NIX_TX_ACTION_S for
-                                                                 TX packet. */
-	} s;
-	/* struct cavm_npc_af_intfx_miss_act_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_mcame#_bank#_cam#_intf
- *
- * NPC AF MCAM Entry Bank CAM Data Interface Registers
- * MCAM comparison ternary data interface word. The field values in
- * NPC_AF_MCAME()_BANK()_CAM()_INTF, NPC_AF_MCAME()_BANK()_CAM()_W0 and
- * NPC_AF_MCAME()_BANK()_CAM()_W1 are ternary, where  each data bit of the
- * search key matches as follows:
- * _ [CAM(1)]\<n\>=0, [CAM(0)]\<n\>=0: Always match; search key data\<n\> don't care.
- * _ [CAM(1)]\<n\>=0, [CAM(0)]\<n\>=1: Match when search key data\<n\> == 0.
- * _ [CAM(1)]\<n\>=1, [CAM(0)]\<n\>=0: Match when search key data\<n\> == 1.
- * _ [CAM(1)]\<n\>=1, [CAM(0)]\<n\>=1: Reserved.
- *
- * The reserved combination is not allowed. Hardware suppresses any write to
- * CAM(0) or CAM(1) that would result in the reserved combination for any CAM bit.
- *
- * When an interface is configured to use the NPC_MCAM_KEY_X1_S search key
- * format (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X1), the four banks
- * of every MCAM entry are used as individual entries, each of which is
- * independently compared with the search key as follows:
- * _ NPC_AF_MCAME()_BANK()_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X1_S[INTF].
- * _ NPC_AF_MCAME()_BANK()_CAM()_W0[MD] corresponds to NPC_MCAM_KEY_X1_S[KW0].
- * _ NPC_AF_MCAME()_BANK()_CAM()_W1[MD] corresponds to NPC_MCAM_KEY_X1_S[KW1].
- *
- * When an interface is configured to use the NPC_MCAM_KEY_X2_S search key
- * format (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X2), banks 0-1 of
- * every MCAM entry are used as one double-wide entry, banks 2-3 as a second
- * double-wide entry, and each double-wide entry is independently compared
- * with the search key as follows:
- * _ NPC_AF_MCAME()_BANK(0,2)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X2_S[INTF].
- * _ NPC_AF_MCAME()_BANK(0,2)_CAM()_W0[MD] corresponds to NPC_MCAM_KEY_X2_S[KW0].
- * _ NPC_AF_MCAME()_BANK(0,2)_CAM()_W1[MD] corresponds to NPC_MCAM_KEY_X2_S[KW1\<47:0\>].
- * _ NPC_AF_MCAME()_BANK(1,3)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X2_S[INTF].
- * _ NPC_AF_MCAME()_BANK(1,3)_CAM()_W0[MD\<15:0\>] corresponds to NPC_MCAM_KEY_X2_S[KW1\<63:48\>].
- * _ NPC_AF_MCAME()_BANK(1,3)_CAM()_W0[MD\<63:16\>] corresponds to NPC_MCAM_KEY_X2_S[KW2\<47:0\>].
- * _ NPC_AF_MCAME()_BANK(1,3)_CAM()_W1[MD\<15:0\>] corresponds to NPC_MCAM_KEY_X2_S[KW2\<63:48\>].
- * _ NPC_AF_MCAME()_BANK(1,3)_CAM()_W1[MD\<47:16\>] corresponds to NPC_MCAM_KEY_X2_S[KW3\<31:0\>].
- *
- * When an interface is configured to use the NPC_MCAM_KEY_X4_S search key
- * format (NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X4), the four banks of every MCAM entry
- * are used as a single quad-wide entry that is compared with the search key as follows:
- * _ NPC_AF_MCAME()_BANK(0)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X4_S[INTF].
- * _ NPC_AF_MCAME()_BANK(0)_CAM()_W0[MD] corresponds to NPC_MCAM_KEY_X4_S[KW0].
- * _ NPC_AF_MCAME()_BANK(0)_CAM()_W1[MD] corresponds to NPC_MCAM_KEY_X4_S[KW1\<47:0\>].
- * _ NPC_AF_MCAME()_BANK(1)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X4_S[INTF].
- * _ NPC_AF_MCAME()_BANK(1)_CAM()_W0[MD\<15:0\>] corresponds to NPC_MCAM_KEY_X4_S[KW1\<63:48\>].
- * _ NPC_AF_MCAME()_BANK(1)_CAM()_W0[MD\<63:16\>] corresponds to NPC_MCAM_KEY_X4_S[KW2\<47:0\>].
- * _ NPC_AF_MCAME()_BANK(1)_CAM()_W1[MD\<15:0\>] corresponds to NPC_MCAM_KEY_X4_S[KW2\<63:48\>].
- * _ NPC_AF_MCAME()_BANK(1)_CAM()_W1[MD\<47:16\>] corresponds to NPC_MCAM_KEY_X4_S[KW3\<31:0\>].
- * _ NPC_AF_MCAME()_BANK(2)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X4_S[INTF].
- * _ NPC_AF_MCAME()_BANK(2)_CAM()_W0[MD\<31:0\>] corresponds to NPC_MCAM_KEY_X4_S[KW3\<63:32\>].
- * _ NPC_AF_MCAME()_BANK(2)_CAM()_W0[MD\<63:32\>] corresponds to NPC_MCAM_KEY_X4_S[KW4\<31:0\>].
- * _ NPC_AF_MCAME()_BANK(2)_CAM()_W1[MD\<31:0\>] corresponds to NPC_MCAM_KEY_X4_S[KW4\<63:32\>].
- * _ NPC_AF_MCAME()_BANK(2)_CAM()_W1[MD\<47:32\>] corresponds to NPC_MCAM_KEY_X4_S[KW5\<15:0\>].
- * _ NPC_AF_MCAME()_BANK(3)_CAM()_INTF[INTF] corresponds to NPC_MCAM_KEY_X4_S[INTF].
- * _ NPC_AF_MCAME()_BANK(3)_CAM()_W0[MD\<47:0\>] corresponds to NPC_MCAM_KEY_X4_S[KW5\<63:16\>].
- * _ NPC_AF_MCAME()_BANK(3)_CAM()_W0[MD\<63:48\>] corresponds to NPC_MCAM_KEY_X4_S[KW6\<15:0\>].
- * _ NPC_AF_MCAME()_BANK(3)_CAM()_W1[MD] corresponds to NPC_MCAM_KEY_X4_S[KW6\<63:16\>]
- *
- * Note that for the X2 and X4 formats, a wide entry will not match unless
- * the INTF fields from the associated two or four banks match the INTF
- * value from the search key.
- *
- * For the X1 and X2 formats, a match in a lower-numbered bank takes priority over
- * a match in any higher numbered banks. Within each bank, the lowest numbered
- * matching entry takes priority over any higher numbered entry.
- */
-union cavm_npc_af_mcamex_bankx_camx_intf {
-	u64 u;
-	struct cavm_npc_af_mcamex_bankx_camx_intf_s {
-		u64 intf:2;			/**< [  1:  0](R/W) NPC interface. Enumerated by NPC_INTF_E. */
-		u64 reserved_2_63:62;
-	} s;
-	/* struct cavm_npc_af_mcamex_bankx_camx_intf_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_mcame#_bank#_cam#_w0
- *
- * NPC AF MCAM Entry Bank CAM Data Word 0 Registers
- * MCAM comparison ternary data word 0. See NPC_AF_MCAME()_BANK()_CAM()_INTF.
- */
-union cavm_npc_af_mcamex_bankx_camx_w0 {
-	u64 u;
-	struct cavm_npc_af_mcamex_bankx_camx_w0_s {
-		u64 md:64;			/**< [ 63:  0](R/W) Match data. */
-	} s;
-	/* struct cavm_npc_af_mcamex_bankx_camx_w0_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_mcame#_bank#_cam#_w1
- *
- * NPC AF MCAM Entry Bank Data Word 1 Registers
- * MCAM comparison ternary data word 1. See NPC_AF_MCAME()_BANK()_CAM()_INTF.
- */
-union cavm_npc_af_mcamex_bankx_camx_w1 {
-	u64 u;
-	struct cavm_npc_af_mcamex_bankx_camx_w1_s {
-		u64 md:48;			/**< [ 47:  0](R/W) Match data. */
-		u64 reserved_48_63:16;
-	} s;
-	/* struct cavm_npc_af_mcamex_bankx_camx_w1_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_mcame#_bank#_cfg
- *
- * NPC AF MCAM Entry Bank Configuration Registers
- */
-union cavm_npc_af_mcamex_bankx_cfg {
-	u64 u;
-	struct cavm_npc_af_mcamex_bankx_cfg_s {
-		u64 ena:1;			/**< [  0:  0](R/W) Enable entry. When clear, the entry is disabled and may be safely modified
-                                                                 by software. */
-		u64 reserved_1_63:63;
-	} s;
-	/* struct cavm_npc_af_mcamex_bankx_cfg_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR0) npc_af_intf#_kex_cfg
- *
- * NPC AF Interface Key Extract Configuration Registers
- */
-union cavm_npc_af_intfx_kex_cfg {
-	u64 u;
-	struct cavm_npc_af_intfx_kex_cfg_s {
-		u64 parse_nibble_ena:31;	/**< [ 30:  0](R/W) Parse key extract nibble enable. Enable bit for each nibble in
-                                                                 NPC_PARSE_KEX_S to be included in the MCAM search key: bit 0 for
-                                                                 NPC_PARSE_KEX_S[CHAN]\<3:0\>, bit 1 for NPC_PARSE_KEX_S[CHAN]\<7:4\>, ..., bit
-                                                                 30 for NPC_PARSE_KEX_S[LH]\<11..8\>. The extracted nibbles are concatenated
-                                                                 and and written to NPC_MCAM_KEY_X*_S, with the first extracted nibble
-                                                                 written to the least significant nibble of the key (NPC_MCAM_KEY_X*_S[KW0]\<3:0\>). */
-		u64 reserved_31:1;
-		u64 keyw:3;			/**< [ 34: 32](R/W) MCAM search key width selection for the interface. Enumerated by NPC_MCAMKEYW_E. */
-		u64 reserved_35_63:29;
-	} s;
-	/* struct cavm_npc_af_intfx_kex_cfg_s cn; */
-};
-
-#endif /* __NPC_REG_H__ */
diff --git a/drivers/net/cavium/octeontx2/rvu.h b/drivers/net/cavium/octeontx2/rvu.h
index 343493949e..4958d11e6f 100644
--- a/drivers/net/cavium/octeontx2/rvu.h
+++ b/drivers/net/cavium/octeontx2/rvu.h
@@ -11,26 +11,48 @@
 #ifndef __RVU_H__
 #define __RVU_H__
 
-#include "rvu_hw.h"
+/*#include "rvu_hw.h"*/
 
 #define PCI_DEVICE_ID_OCTEONTX2_RVU_PF	0xA063
 #define PCI_DEVICE_ID_OCTEONTX2_RVU_VF	0xA064
 #define PCI_DEVICE_ID_OCTEONTX2_RVU_AF	0xA065
 
+struct nix_af_handle;
+
 struct rvu_af {
+	struct udevice *dev;
 	u8 pf_id;
 	void __iomem *base;
 	void __iomem *bar2;
 	void __iomem *nix_af_base;
+	void __iomem *nix_af_bar2;
 	void __iomem *npa_af_base;
+	void __iomem *npc_af_base;
+	struct rvu_hwinfo *hw;
+	struct nix_af_handle *nix_af;
 };
 
 struct rvu_pf {
-	u8 pf_id;
+	struct udevice *dev;
 	void __iomem *base;
 	void __iomem *nix_base;
 	void __iomem *npa_base;
+	void __iomem *npc_base;
+	void __iomem *lmt_base;
+	struct rvu_hwinfo *hw;
+	struct nix_handle *nix;
+	u8 pf_id;
+	u8 pf;
 };
 
+/**
+ * Given the PF base address, return the NIX AF
+ *
+ * @param nix_pf_base		NIX PF base address
+ *
+ * @return	nix_af handle or NULL if not found.
+ */
+struct nix_af_handle *nix_get_af(u64 nix_pf_base);
+
 #endif /* __RVU_H__ */
 
diff --git a/drivers/net/cavium/octeontx2/rvu_af.c b/drivers/net/cavium/octeontx2/rvu_af.c
index 5e4b788d50..b0a82f0f90 100644
--- a/drivers/net/cavium/octeontx2/rvu_af.c
+++ b/drivers/net/cavium/octeontx2/rvu_af.c
@@ -7,25 +7,92 @@
  * the License, or (at your option) any later version.
  *
  */
-
-#include <config.h>
+#define DEBUG
 #include <common.h>
 #include <net.h>
 #include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
-#include <asm/io.h>
 #include <errno.h>
-
+#include <linux/list.h>
+#include <asm/io.h>
+#include <asm/arch/octeontx2.h>
+#include "cavm-csrs-rvu.h"
 #include "rvu.h"
+#include "rvu_common.h"
+#include "nix.h"
+
+static LIST_HEAD(nix_af_list);
+
+/**
+ * Given the PF base address, return the NIX AF
+ *
+ * @param nix_pf_base		NIX PF base address
+ *
+ * @return	nix_af handle or NULL if not found.
+ */
+struct nix_af_handle *nix_get_af(u64 nix_pf_base)
+{
+	struct nix_af_handle *nix_af;
+	static const u64 mask = ~(0xffffffffff);
+	nix_pf_base &= mask;
+
+	list_for_each_entry(nix_af, &nix_af_list, nix_af_list) {
+		if (((u64)(nix_af->nix_af_base) & mask) == (nix_pf_base & mask))
+			return nix_af;
+	}
+	debug("%s: No NIX AF found for address 0x%llx\n", __func__,
+	      nix_pf_base);
+	return NULL;
+}
+
+/**
+ * Allocates an admin queue for instructions and results
+ *
+ * @param	aq	admin queue to allocate for
+ * @param	qsize	Number of entries in the queue
+ * @param	inst_size	Size of each instruction
+ * @param	res_size	Size of each result
+ *
+ * @return	-ENOMEM on error, 0 on success
+ */
+int cavm_rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
+		      size_t inst_size, size_t res_size)
+{
+	int err;
+
+	err = qmem_alloc(&aq->inst, qsize, inst_size);
+	if (err)
+		return err;
+	err = qmem_alloc(&aq->res, qsize, res_size);
+	if (err)
+		qmem_free(&aq->inst);
+
+	return err;
+}
+
+/**
+ * Frees an admin queue
+ *
+ * @param	aq	Admin queue to free
+ */
+void cavm_rvu_aq_free(struct admin_queue *aq)
+{
+	qmem_free(&aq->inst);
+	qmem_free(&aq->res);
+	memset(aq, 0, sizeof(*aq));
+}
 
-int rvu_af_probe(struct udevice *dev)
+int cavm_rvu_af_probe(struct udevice *dev)
 {
 	struct rvu_af *af_ptr = dev_get_priv(dev);
+	struct nix_af_handle *nix_af;
 	size_t size;
 	union cavm_rvu_af_addr_s func_addr;
+	static int instance = 0;
 
+	debug("%s(%s) instance: %d\n", __func__, dev->name, instance);
 	af_ptr->base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
 	debug("RVU AF BAR0 %p\n", af_ptr->base);
 	af_ptr->bar2 = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
@@ -35,17 +102,35 @@ int rvu_af_probe(struct udevice *dev)
 	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
 	af_ptr->nix_af_base = af_ptr->base + func_addr.u;
 	debug("RVU AF BAR0 NIX BASE %p\n", af_ptr->nix_af_base);
+	af_ptr->nix_af_bar2 = af_ptr->bar2 + func_addr.u;
+	debug("RVU AF BAR2 NIX BASE %p\n", af_ptr->nix_af_bar2);
 	//nix_af_init(af_ptr->nix_af_base);
 
 	func_addr.u = 0;
 	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPA;
 	af_ptr->npa_af_base = af_ptr->base + func_addr.u;
 	debug("RVU AF BAR0 NPA BASE %p\n", af_ptr->npa_af_base);
+	func_addr.u = 0;
+	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
+	af_ptr->npc_af_base = af_ptr->base + func_addr.u;
+	debug("RVU AF BAR0 NPC BASE %p\n", af_ptr->npc_af_base);
+
+	debug("%s: Initializing nix instance %d\n", __func__, instance);
+	nix_af = nix_af_initialize(instance++, dev,
+				   af_ptr->nix_af_base, 0,
+				   af_ptr->npa_af_base);
+	if (!nix_af) {
+		printf("%s: Error: could not initialize NIX AF\n", __func__);
+		return -1;
+	}
+	debug("%s: Adding list, nix_af: %p\n", __func__, nix_af);
+	list_add(&nix_af->nix_af_list, &nix_af_list);
+	af_ptr->nix_af = nix_af;
+	debug("%s: Done\n", __func__);
 
 	return 0;
 }
 
-
 static const struct udevice_id rvu_af_ids[] = {
         { .compatible = "cavium,rvu-af" },
         {}
@@ -54,7 +139,7 @@ static const struct udevice_id rvu_af_ids[] = {
 U_BOOT_DRIVER(rvu_af) = {
         .name   = "rvu_af",
         .id     = UCLASS_MISC,
-        .probe  = rvu_af_probe,
+        .probe  = cavm_rvu_af_probe,
         .of_match = rvu_af_ids,
         .priv_auto_alloc_size = sizeof(struct rvu_af),
 };
diff --git a/drivers/net/cavium/octeontx2/rvu_common.c b/drivers/net/cavium/octeontx2/rvu_common.c
new file mode 100644
index 0000000000..7948051f41
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/rvu_common.c
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ */
+
+#include <common.h>
+#include <net.h>
+#include <netdev.h>
+#include <malloc.h>
+#include <dm.h>
+#include <misc.h>
+#include <asm/io.h>
+#include <errno.h>
+
+#include "rvu.h"
+#include "rvu_common.h"
+
+int rvu_alloc_bitmap(struct rsrc_bmap *rsrc)
+{
+	size_t size = (rsrc->max + sizeof(rsrc->bmap) * 8 - 1);
+
+	rsrc->bmap = calloc(size / (sizeof(rsrc->bmap) * 8), 1);
+	if (!rsrc->bmap)
+		return -ENOMEM;
+	return 0;
+}
+
+int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz)
+{
+	q->base = memalign(CONFIG_SYS_CACHELINE_SIZE, qsize * entry_sz);
+	if (!q->base)
+		return -ENOMEM;
+	q->entry_sz = entry_sz;
+	q->qsize = qsize;
+	q->alloc_sz = qsize * entry_sz;
+	q->iova = (dma_addr_t)(q->base);
+	return 0;
+}
+
+void qmem_free(struct qmem *q)
+{
+	if (q->base)
+		free(q->base);
+	memset(q, 0, sizeof(*q));
+}
diff --git a/drivers/net/cavium/octeontx2/rvu_common.h b/drivers/net/cavium/octeontx2/rvu_common.h
new file mode 100644
index 0000000000..7bd9c492c2
--- /dev/null
+++ b/drivers/net/cavium/octeontx2/rvu_common.h
@@ -0,0 +1,202 @@
+/*
+ * Copyright (C) 2017 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of version 2 of the GNU General Public License
+ * as published by the Free Software Foundation.
+ */
+
+#ifndef __RVU_COMMON_H__
+#define __RVU_COMMON_H__
+
+#define ALIGNED		__aligned(CONFIG_SYS_CACHELINE_SIZE)
+
+/* PCI device IDs */
+#define	PCI_DEVID_OCTEONTX2_CGX			0xA059
+#define	PCI_DEVID_OCTEONTX2_RVU_AF		0xA065
+#define	PCI_DEVID_OCTEONTX2_RVU_PF		0xA063
+#define	PCI_DEVID_OCTEONTX2_RVU_VF		0xA064
+
+/* PCI BAR nos */
+#define	PCI_AF_REG_BAR_NUM			0
+#define	PCI_CFG_REG_BAR_NUM			2
+#define	PCI_MBOX_BAR_NUM			4
+
+#define RVU_PFVF_PF_SHIFT	10
+#define RVU_PFVF_PF_MASK	0x3F
+#define RVU_PFVF_FUNC_SHIFT	0
+#define RVU_PFVF_FUNC_MASK	0x3FF
+
+#define MAX_NIX			1
+
+#define NAME_SIZE				32
+
+#define OTX2_ALIGN	CONFIG_SYS_CACHELINE_SIZE  /* Align to cacheline */
+
+#define Q_SIZE_16		0ULL /* 16 entries */
+#define Q_SIZE_64		1ULL /* 64 entries */
+#define Q_SIZE_256		2ULL
+#define Q_SIZE_1K		3ULL
+#define Q_SIZE_4K		4ULL
+#define Q_SIZE_16K		5ULL
+#define Q_SIZE_64K		6ULL
+#define Q_SIZE_256K		7ULL
+#define Q_SIZE_1M		8ULL /* Million entries */
+#define Q_SIZE_MIN		Q_SIZE_16
+#define Q_SIZE_MAX		Q_SIZE_1M
+
+#define Q_COUNT(x)		(16ULL << (2 * x))
+#define Q_SIZE(x, n)		((ilog2(x) - (n)) / 2)
+
+#define NIX_INTF_TYPE_CGX		0
+#define NIX_INTF_TYPE_LBK		1
+#define NIX_MAX_HW_MTU			9212
+#define NIX_MIN_HW_MTU			64
+
+#define MAX_LMAC_PKIND			12
+
+/* Admin queue info */
+
+/* Since we intend to add only one instruction at a time,
+ * keep queue size to it's minimum.
+ */
+#define AQ_SIZE			Q_SIZE_16
+/* HW head & tail pointer mask */
+#define AQ_PTR_MASK		0xFFFFF
+
+#define RQ_LEN		QCOUNT(Q_SIZE_1K)
+#define SQ_LEN		QCOUNT(Q_SIZE_16)
+
+/** RVU Block Type Enumeration */
+enum rvu_block_type_e {
+	BLKTYPE_RVUM = 0x0,
+	BLKTYPE_MSIX = 0x1,
+	BLKTYPE_LMT  = 0x2,
+	BLKTYPE_NIX  = 0x3,
+	BLKTYPE_NPA  = 0x4,
+	BLKTYPE_NPC  = 0x5,
+	BLKTYPE_SSO  = 0x6,
+	BLKTYPE_SSOW = 0x7,
+	BLKTYPE_TIM  = 0x8,
+	BLKTYPE_CPT  = 0x9,
+	BLKTYPE_NDC  = 0xa,
+	BLKTYPE_MAX  = 0xa,
+};
+
+
+/** Resource bitmap */
+struct rsrc_bmap {
+	unsigned long *bmap;
+	u16  max;
+};
+
+struct rvu_block {
+	struct rsrc_bmap	rsrc;
+	u16			*fn_map;	/** LF to pcifunc mapping */
+	bool			multislot;
+	u8			blkid;
+	u8			addr;
+	u8			lfshift;
+	u64			lookup_reg;
+	u64			pf_lfcnt_reg;
+	u64			vf_lfcnt_reg;
+	u64			lfcfg_reg;
+	u64			msixcfg_reg;
+	u64			lfreset_reg;
+	unsigned char		name[32];
+};
+
+struct rvu_hwinfo {
+	struct rvu_block block[BLKTYPE_MAX];
+	u8	total_pfs;	/** MAX RVU PFs HW supports */
+	u8	total_vfs;	/** Max RVU VFs HW supports */
+	u16	max_vfs_per_pf;	/** Max VFs that can be attached to PF */
+	u8	ndc;		/** Number of cache units available */
+	u8	cgx;
+	u8	lmac_per_cgx;
+	u8	cgx_links;
+	u8	lbk_links;
+	u8	sdp_links;
+	u8	npc_kpus;
+	u16	sso_hwgrps;
+	u16	sso_xaq_num_works;
+	u16	sso_xaq_buf_size;
+
+	u8	sso_hws;
+};
+
+struct qmem {
+	void		*base;
+	dma_addr_t	iova;
+	size_t		alloc_sz;
+	u32		qsize;
+	u8		entry_sz;
+};
+
+struct admin_queue {
+	struct qmem inst;
+	struct qmem res;
+};
+
+/**
+ * Store 128 bit value
+ *
+ * @param[out]	dest	pointer to destination address
+ * @param	val0	first 64 bits to write
+ * @param	val1	second 64 bits to write
+ */
+static inline void cavm_st128(void *dest, u64 val0, u64 val1)
+{
+	__asm__ __volatile__(
+		"stp %x[x0], %x[x1], [%[pm]]"
+		:
+		: [x0]"r"(val0), [x1]"r"(val1), [pm]"r"(dest)
+		: "memory");
+}
+
+/**
+ * Load 128 bit value
+ *
+ * @param[in]	source		pointer to 128 bits of data to load
+ * @param[out]	val0		first 64 bits of data
+ * @param[out]	val1		second 64 bits of data
+ */
+static inline void cavm_ld128(const u64 *src, u64 *val0, u64 *val1)
+{
+	__asm__ __volatile__ (
+		"ldp %x[x0], %x[x1], [%[pm]]"
+		:
+		: [x0]"r"(*val0), [x1]"r"(*val1), [pm]"r"(src));
+}
+
+void qmem_free(struct qmem *q);
+int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz);
+
+/**
+ * Allocates an admin queue for instructions and results
+ *
+ * @param	aq	admin queue to allocate for
+ * @param	qsize	Number of entries in the queue
+ * @param	inst_size	Size of each instruction
+ * @param	res_size	Size of each result
+ *
+ * @return	-ENOMEM on error, 0 on success
+ */
+int cavm_rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
+		      size_t inst_size, size_t res_size);
+
+/**
+ * Frees an admin queue
+ *
+ * @param	aq	Admin queue to free
+ */
+void cavm_rvu_aq_free(struct admin_queue *aq);
+
+static inline uint32_t rvu_get_pf(u16 pcifunc)
+{
+	return (pcifunc >> RVU_PFVF_PF_SHIFT) & RVU_PFVF_PF_MASK;
+}
+
+int rvu_alloc_bitmap(struct rsrc_bmap *rsrc);
+
+#endif /* __RVU_COMMON_H__ */
diff --git a/drivers/net/cavium/octeontx2/rvu_pf.c b/drivers/net/cavium/octeontx2/rvu_pf.c
index 0f8b7208c6..358a83fa0e 100644
--- a/drivers/net/cavium/octeontx2/rvu_pf.c
+++ b/drivers/net/cavium/octeontx2/rvu_pf.c
@@ -7,8 +7,7 @@
  * the License, or (at your option) any later version.
  *
  */
-
-#include <config.h>
+#define DEBUG
 #include <common.h>
 #include <net.h>
 #include <netdev.h>
@@ -17,21 +16,108 @@
 #include <misc.h>
 #include <asm/io.h>
 #include <errno.h>
-
+#include <asm/types.h>
+#include <asm/arch/octeontx2.h>
+#include "cavm-csrs-rvu.h"
+#include "cavm-csrs-npa.h"
+#include "rvu_common.h"
 #include "rvu.h"
+#include "cgx.h"
+#include "nix.h"
 
 static int pfid = 1;
 
+int rvu_add_nix(struct rvu_pf *rvu)
+{
+	struct nix_af_handle *nix_af = nix_get_af((u64)(rvu->nix_base));
+	struct eth_device *netdev;
+	struct nix_handle *nix;
+	struct cgx *cgx;
+	struct lmac *lmac;
+	struct nix_lf_alloc_req req;
+	struct nix_lf_alloc_rsp res;
+	int err;
+
+	if (!nix_af) {
+		printf("%s: Error: Could not find NIX AF for PF base %p\n",
+		       __func__, rvu->nix_base);
+		return -1;
+	}
+	if (rvu->pf < 1) {
+		printf("%s: Error: RVU PF %d invalid\n", __func__, rvu->pf);
+		return -1;
+	}
+	lmac = cgx_get_lmac(rvu->pf - 1);
+	if (!lmac) {
+		printf("%s: Error: No LMAC found for pf %d\n",
+		       __func__, rvu->pf);
+		return -1;
+	}
+	cgx = lmac->cgx;
+	memset(&req, 0, sizeof(req));
+	memset(&res, 0, sizeof(res));
+	req.rq_cnt = 1;
+	req.sq_cnt = 1;
+	req.cq_cnt = 1;
+	req.rss_grps = 1;
+	req.xqe_sz = CAVM_NIX_XQESZ_E_W16;
+	req.npa_func = rvu->pf;
+
+	debug("%s: Allocating nix lf\n", __func__);
+	nix = cavm_nix_lf_alloc(nix_af, rvu->dev, rvu->pf, rvu->pf,
+				rvu->nix_base,
+				rvu->npc_base, rvu->lmt_base,
+				cgx->cgx_id, lmac->lmac_id, &req, &res);
+	if (!nix) {
+		printf("%s: Error allocating lf for pf %d\n",
+		       __func__, rvu->pf);
+		return -1;
+	}
+
+	netdev = calloc(sizeof(*netdev), 1);
+	if (!netdev) {
+		printf("%s: Out of memory!\n", __func__);
+		/* TODO: call cleanup function */
+		return -1;
+	}
+	rvu->nix = nix;
+	netdev->priv = rvu;
+	snprintf(netdev->name, sizeof(netdev->name), "eth%u", nix->nic_id);
+	netdev->halt = NULL;	/* TODO */
+	netdev->init = NULL;	/* TODO */
+	netdev->send = NULL;	/* TODO */
+	netdev->recv = NULL;	/* TODO */
+
+	if (!eth_env_get_enetaddr_by_index("eth", nix->nic_id,
+					   netdev->enetaddr)) {
+		eth_env_get_enetaddr("ethaddr", netdev->enetaddr);
+		netdev->enetaddr[5] += nix->nic_id;
+	}
+	err = eth_register(netdev);
+	if (!err)
+		return 0;
+
+	printf("Failed to register Ethernet device %s\n", netdev->name);
+
+	return err;
+}
+
 int rvu_pf_probe(struct udevice *dev)
 {
 	struct rvu_pf *pf_ptr = dev_get_priv(dev);
 	size_t size;
 	union cavm_rvu_func_addr_s func_addr;
+	int nix_af_pf;
+	int err;
+
+	debug("%s: name: %s\n", __func__, dev->name);
 
+	pf_ptr->dev = dev;
 	pf_ptr->base = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
 	pf_ptr->pf_id = pfid++;
+	pf_ptr->pf = ((u64)(pf_ptr->base) >> 36) & 0x0f;
 
-	debug("RVU PF BAR2 %p\n", pf_ptr->base);
+	debug("RVU PF BAR2 RVU BASE %p, pf: %u\n", pf_ptr->base, pf_ptr->pf);
 
 	func_addr.u = 0;
 	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
@@ -44,7 +130,22 @@ int rvu_pf_probe(struct udevice *dev)
 	pf_ptr->npa_base = pf_ptr->base + func_addr.u;
 	debug("RVU PF BAR2 NPA BASE %p\n", pf_ptr->npa_base);
 
-	return 0;
+	func_addr.u = 0;
+	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
+	pf_ptr->npc_base = pf_ptr->base + func_addr.u;
+	debug("RVU PF BAR2 NPC BASE %p\n", pf_ptr->npc_base);
+
+	func_addr.u = 0;
+	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_LMT;
+	pf_ptr->lmt_base = pf_ptr->base + func_addr.u;
+	debug("RVU PF BAR2 LMT BASE %p\n", pf_ptr->lmt_base);
+
+	err = rvu_add_nix(pf_ptr);
+
+	if (err)
+		printf("%s: Error %d adding nix\n", __func__, err);
+
+	return err;
 }
 
 
diff --git a/drivers/spi/cavium_spi.c b/drivers/spi/cavium_spi.c
index f163fef73e..fa2426202a 100755
--- a/drivers/spi/cavium_spi.c
+++ b/drivers/spi/cavium_spi.c
@@ -27,14 +27,25 @@
 #define MPI_STS				0x1008
 #define MPI_TX				0x1010
 #define MPI_WIDE_DAT			0x1040
+#define MPI_IO_CTL			0x1048
 #define MPI_DAT(X)			(0x1080 + ((X) << 3))
+#define MPI_WIDE_BUF(X)			(0x1800 + ((X) << 3))
+#define MPI_CYA_CFG			0x2000
+#define MPI_CLKEN			0x2080
 
 union mpi_cfg {
 	uint64_t u;
 	struct mpi_cfg_s {
 #if __BYTE_ORDER == __BIG_ENDIAN /* Word 0 - Big Endian */
-		uint64_t		:35;
-
+		uint64_t		:14;
+		uint64_t tb100_en	:1;
+		uint64_t		:1;
+		uint64_t cs_espi_en	:4;
+		uint64_t		:8;
+		uint64_t iomode		:2;
+		uint64_t		:2;
+		uint64_t legacy_dis	:1;
+		uint64_t		:2;
 		uint64_t clkdiv		:13;	/** clock divisor */
 		uint64_t csena3		:1;	/** cs enable 3. */
 		uint64_t csena2		:1;	/** cs enable 2 */
@@ -108,7 +119,15 @@ union mpi_cfg {
 		uint64_t csena2		:1;
 		uint64_t csena3		:1;
 		uint64_t clkdiv		:13;
-		uint64_t 		:35;	/** Reserved */
+		uint64_t		:2;
+		uint64_t legacy_dis	:1;
+		uint64_t		:2;
+		uint64_t iomode		:2;
+		uint64_t		:8;
+		uint64_t cs_espi_en	:4;
+		uint64_t		:1;
+		uint64_t tb100_en	:1;
+		uint64_t		:14;
 #endif /* Word 0 - End */
 	} s;
 	/* struct mpi_cfg_s cn; */
@@ -143,7 +162,11 @@ union mpi_sts {
 	uint64_t u;
 	struct mpi_sts_s {
 #if __BYTE_ORDER == __BIG_ENDIAN /* Word 0 - Big Endian */
-		uint64_t reserved_13_63	:51;
+		uint64_t reserved_40_63	:24;
+		uint64_t crc		:8;
+		uint64_t		:5;
+		uint64_t crc_err	:1;
+		uint64_t		:6;
 		uint64_t rxnum		:5;	/** Number of bytes */
 		uint64_t reserved_2_7	:6;
 		uint64_t mpi_intr	:1;	/** Transaction done int */
@@ -153,7 +176,11 @@ union mpi_sts {
 		uint64_t mpi_intr	:1;
 		uint64_t reserved_2_7	:6;
 		uint64_t rxnum		:5;
-		uint64_t reserved_13_63	:51;
+		uint64_t		:6;
+		uint64_t crc_err	:1;
+		uint64_t		:5;
+		uint64_t crc		:8;
+		uint64_t reserved_40_63	:24;
 #endif /* Word 0 - End */
 	} s;
 	/* struct mpi_sts_s cn; */
diff --git a/npc.c b/npc.c
new file mode 100644
index 0000000000..8d1c8b69c3
--- /dev/null
+++ b/npc.c
@@ -0,0 +1 @@
+ 
diff --git a/npc_profile.h b/npc_profile.h
new file mode 100644
index 0000000000..77e3a31065
--- /dev/null
+++ b/npc_profile.h
@@ -0,0 +1,3356 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Cavium OcteonTx2 RVU Admin function driver
+ *
+ * Copyright (C) 2018 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef NPC_PROFILE_H
+#define NPC_PROFILE_H
+
+#define NPC_ETYPE_IP		0x0800
+#define NPC_ETYPE_IP6		0x86dd
+#define NPC_ETYPE_ARP		0x0806
+#define NPC_ETYPE_RARP		0x8035
+#define NPC_ETYPE_MPLSU		0x8847
+#define NPC_ETYPE_MPLSM		0x8848
+#define NPC_ETYPE_ETAG		0x893f
+#define NPC_ETYPE_CTAG		0x8100
+#define NPC_ETYPE_SBTAG		0x88a8
+#define NPC_ETYPE_ITAG		0X88e7
+#define NPC_ETYPE_QINQ		0x9100
+#define NPC_ETYPE_TRANS_ETH_BR	0x6558
+#define NPC_ETYPE_PPP		0x880b
+
+#define NPC_IPNH_HOP		0
+#define NPC_IPNH_ICMP		1
+#define NPC_IPNH_IGMP		2
+#define NPC_IPNH_IP		4
+#define NPC_IPNH_TCP		6
+#define NPC_IPNH_UDP		17
+#define NPC_IPNH_IP6		41
+#define NPC_IPNH_ROUT		43
+#define NPC_IPNH_FRAG		44
+#define NPC_IPNH_GRE		47
+#define NPC_IPNH_ESP		50
+#define NPC_IPNH_AH		51
+#define NPC_IPNH_ICMP6		58
+#define NPC_IPNH_NONH		59
+#define NPC_IPNH_DEST		60
+#define NPC_IPNH_SCTP		132
+
+#define NPC_UDP_PORT_GTPC	2123
+#define NPC_UDP_PORT_GTPU	2152
+#define NPC_UDP_PORT_VXLAN	4789
+#define NPC_UDP_PORT_GENEVE	6081
+
+#define NPC_TCP_PORT_HTTP	80
+#define NPC_TCP_PORT_HTTPS	443
+
+#define NPC_IP_VER_4		0x4000
+#define NPC_IP_VER_6		0x6000
+#define NPC_IP_VER_MASK		0xf000
+#define NPC_IP_HDR_LEN_5	0x0500
+#define NPC_IP_HDR_LEN_MASK	0x0f00
+
+#define NPC_GRE_F_CSUM		(0x1 << 15)
+#define NPC_GRE_F_ROUTE		(0x1 << 14)
+#define NPC_GRE_F_KEY		(0x1 << 13)
+#define NPC_GRE_F_SEQ		(0x1 << 12)
+#define NPC_GRE_F_ACK		(0x1 << 7)
+#define NPC_GRE_FLAG_MASK	(NPC_GRE_F_CSUM | NPC_GRE_F_ROUTE | \
+				 NPC_GRE_F_KEYNPC_GRE_F_SEQNPC_GRE_F_ACK)
+#define NPC_GRE_VER_MASK	0x0003
+#define NPC_GRE_VER_1		0x0001
+
+#define NPC_VXLAN_I		0x0800
+
+#define NPC_GENEVE_F_OAM	(0x1 << 7)
+#define NPC_GENEVE_F_CRI_OPT	(0x1 << 6)
+#define NPC_GTP_PT_GTP		(0x1 << 12)
+#define NPC_GTP_PT_MASK		(0x1 << 12)
+#define NPC_GTP_VER1		(0x1 << 13)
+#define NPC_GTP_VER_MASK	(0x7 << 13)
+#define NPC_GTP_MT_G_PDU	0xff
+#define NPC_GTP_MT_MASK		0xff
+
+#define NPC_TCP_DATA_OFFSET_5		0x5000
+#define NPC_TCP_DATA_OFFSET_MASK	0xf000
+
+enum NPC_ERRLEV_E {
+	NPC_ERRLEV_RE = 0,
+	NPC_ERRLEV_LA = 1,
+	NPC_ERRLEV_LB = 2,
+	NPC_ERRLEV_LC = 3,
+	NPC_ERRLEV_LD = 4,
+	NPC_ERRLEV_LE = 5,
+	NPC_ERRLEV_LF = 6,
+	NPC_ERRLEV_LG = 7,
+	NPC_ERRLEV_LH = 8,
+	NPC_ERRLEV_NIX = 15,
+	NPC_ERRLEV_ENUM_LAST = 16,
+};
+
+enum npc_kpu_err_code {
+	NPC_EC_NOERR = 0, /* has to be zero */
+	NPC_EC_UNK,
+	NPC_EC_L2_K1,
+	NPC_EC_L2_K2,
+	NPC_EC_L2_K3,
+	NPC_EC_L2_K3_ETYPE_UNK,
+	NPC_EC_IP_VER,
+	NPC_EC_IP6_VER,
+	NPC_EC_VXLAN,
+	NPC_EC_NVGRE,
+	NPC_EC_GRE,
+	NPC_EC_GRE_VER1,
+	NPC_EC_L4,
+	NPC_EC_LAST /* has to be the last item */
+};
+
+enum npc_kpu_parser_state {
+	NPC_S_NA = 0,
+	NPC_S_KPU1_ETHER,
+	NPC_S_KPU1_PKI,
+	NPC_S_KPU2_CTAG,
+	NPC_S_KPU2_SBTAG,
+	NPC_S_KPU2_QINQ,
+	NPC_S_KPU2_ETAG,
+	NPC_S_KPU3_CTAG,
+	NPC_S_KPU3_STAG,
+	NPC_S_KPU3_QINQ,
+	NPC_S_KPU4_MPLS,
+	NPC_S_KPU5_IP,
+	NPC_S_KPU5_IP6,
+	NPC_S_KPU5_ARP,
+	NPC_S_KPU5_RARP,
+	NPC_S_KPU6_IP6_EXT,
+	NPC_S_KPU7_IP6_EXT,
+	NPC_S_KPU8_TCP,
+	NPC_S_KPU8_UDP,
+	NPC_S_KPU8_SCTP,
+	NPC_S_KPU8_ICMP,
+	NPC_S_KPU8_IGMP,
+	NPC_S_KPU8_ICMP6,
+	NPC_S_KPU8_GRE,
+	NPC_S_KPU8_ESP,
+	NPC_S_KPU8_AH,
+	NPC_S_KPU9_TU_ETHER,
+	NPC_S_KPU9_TU_PPP,
+	NPC_S_KPU11_TU_IP,
+	NPC_S_KPU11_TU_IP6,
+	NPC_S_KPU11_TU_ARP,
+	NPC_S_KPU12_TU_IP6_EXT,
+	NPC_S_KPU13_TU_IP6_EXT,
+	NPC_S_KPU14_TU_TCP,
+	NPC_S_KPU14_TU_UDP,
+	NPC_S_KPU14_TU_SCTP,
+	NPC_S_KPU14_TU_ICMP,
+	NPC_S_KPU14_TU_IGMP,
+	NPC_S_KPU14_TU_ICMP6,
+	NPC_S_KPU14_TU_ESP,
+	NPC_S_KPU14_TU_AH,
+	NPC_S_KPU15_HTTP_DATA,
+	NPC_S_KPU15_HTTPS_DATA,
+	NPC_S_KPU15_TCP_DATA,
+	NPC_S_KPU15_UDP_DATA,
+	NPC_S_LAST /* has to be the last item */
+};
+
+enum npc_kpu_parser_flag {
+	NPC_F_NA = 0,
+	NPC_F_HAS_PKI,
+	NPC_F_HAS_PKI_HAS_VLAN,
+	NPC_F_HAS_PKI_HAS_ETAG,
+	NPC_F_HAS_PKI_HAS_MPLS,
+	NPC_F_ETYPE_UNK,
+	NPC_F_ETHER_HAS_VLAN,
+	NPC_F_ETHER_HAS_ETAG,
+	NPC_F_ETHER_HAS_MPLS,
+	NPC_F_VLAN_2_TAGS,
+	NPC_F_VLAN_2_TAGS_ETYPE_UNK,
+	NPC_F_VLAN_3_TAGS,
+	NPC_F_VLAN_4_TAGS,
+	NPC_F_QINQ_DBL,
+	NPC_F_BTAG_HAS_CTAG,
+	NPC_F_IP_HAS_OPTIONS,
+	NPC_F_IP_IN_IP,
+	NPC_F_IP_6TO4,
+	NPC_F_IP_UNK_PROTO,
+	NPC_F_IP_IN_IP_HAS_OPTIONS,
+	NPC_F_IP_6TO4_HAS_OPTIONS,
+	NPC_F_IP_UNK_PROTO_HAS_OPTIONS,
+	NPC_F_IP6_HAS_EXT,
+	NPC_F_IP6_TUN_IP6,
+	NPC_F_TCP_HAS_OPTIONS,
+	NPC_F_TCP_HTTP,
+	NPC_F_TCP_HTTPS,
+	NPC_F_TCP_UNK_PORT,
+	NPC_F_TCP_HTTP_HAS_OPTIONS,
+	NPC_F_TCP_HTTPS_HAS_OPTIONS,
+	NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+	NPC_F_UDP_VXLAN_NOVNI,
+	NPC_F_UDP_GTPU_G_PDU,
+	NPC_F_UDP_GTPU_UNK,
+	NPC_F_UDP_UNK_PORT,
+	NPC_F_UDP_GENEVE_OAM,
+	NPC_F_UDP_GENEVE_CRI_OPT,
+	NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+	NPC_F_GRE_HAS_SRE,
+	NPC_F_GRE_HAS_CSUM,
+	NPC_F_GRE_HAS_KEY,
+	NPC_F_GRE_HAS_SEQ,
+	NPC_F_GRE_HAS_CSUM_KEY,
+	NPC_F_GRE_HAS_CSUM_SEQ,
+	NPC_F_GRE_HAS_KEY_SEQ,
+	NPC_F_GRE_HAS_CSUM_KEY_SEQ,
+	NPC_F_GRE_HAS_ROUTE,
+	NPC_F_GRE_UNK_PROTO,
+	NPC_F_GRE_VER1,
+	NPC_F_GRE_VER1_HAS_SEQ,
+	NPC_F_GRE_VER1_HAS_ACK,
+	NPC_F_GRE_VER1_HAS_SEQ_ACK,
+	NPC_F_GRE_VER1_UNK_PROTO,
+	NPC_F_TU_ETHER_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_CTAG,
+	NPC_F_TU_ETHER_HAS_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_STAG_CTAG,
+	NPC_F_TU_ETHER_HAS_STAG_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_STAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_QINQ_CTAG,
+	NPC_F_TU_ETHER_HAS_QINQ_CTAG_ETYPE_UNK,
+	NPC_F_TU_ETHER_HAS_QINQ_ETYPE_UNK,
+	NPC_F_LAST /* has to be the last item */
+};
+
+struct npc_kpu_profile_action ikpu_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 14, 16,
+		0, 0, NPC_S_KPU1_ETHER, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 1, 0xff,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_cam kpu1_cam_entries[] = {
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_SBTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_QINQ, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_ETAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0000, 0xfc00, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0400, 0xfe00, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_ETHER, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_SBTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_QINQ, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_ETAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0010,
+		0x0010, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0010,
+		0x0010, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU1_PKI, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu2_cam_entries[] = {
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_MPLSU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, NPC_ETYPE_MPLSM, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_CTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_MPLSU,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_MPLSM,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_CTAG, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		NPC_ETYPE_CTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		NPC_ETYPE_SBTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_RARP, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, NPC_ETYPE_CTAG, 0xffff,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, NPC_ETYPE_ITAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_SBTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_IP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_IP6, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_ARP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_RARP, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_MPLSU, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		NPC_ETYPE_MPLSM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		NPC_ETYPE_CTAG, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_QINQ, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		NPC_ETYPE_QINQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_IP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_IP6, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_ARP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_RARP, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_CTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_SBTAG, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, NPC_ETYPE_QINQ, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU2_ETAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu3_cam_entries[] = {
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_IP6, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_ARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, NPC_ETYPE_RARP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_CTAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_STAG, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, NPC_ETYPE_CTAG, 0xffff, NPC_ETYPE_RARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU3_QINQ, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu4_cam_entries[] = {
+	{
+		NPC_S_KPU4_MPLS, 0xff, NPC_ETYPE_IP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu5_cam_entries[] = {
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_TCP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_UDP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_SCTP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ICMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IGMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ESP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_AH, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_GRE, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP6, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_TCP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_UDP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_SCTP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ICMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IGMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_ESP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_AH, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_GRE, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, NPC_IPNH_IP6, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_ARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_RARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_TCP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_UDP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_SCTP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ICMP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ICMP6 << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_ESP << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_AH << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_GRE << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, NPC_IPNH_IP6 << 8, 0xff00, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, 0x0000, 0x0000, NPC_IP_VER_6,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU5_IP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu6_cam_entries[] = {
+	{
+		NPC_S_KPU6_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu7_cam_entries[] = {
+	{
+		NPC_S_KPU7_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu8_cam_entries[] = {
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTP,
+		0xffff, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTPS,
+		0xffff, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, 0x0000, 0x0000, NPC_TCP_DATA_OFFSET_5,
+		NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_TCP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, NPC_VXLAN_I,
+		NPC_VXLAN_I, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, 0x0000,
+		0xffff, 0x0000, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_VXLAN, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		0x0000, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		0x0000, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff, 0x0000,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_CRI_OPT, NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GENEVE, 0xffff,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT,
+		NPC_GENEVE_F_OAM | NPC_GENEVE_F_CRI_OPT, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPC, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPU, 0xffff,
+		NPC_GTP_PT_GTP | NPC_GTP_VER1 | NPC_GTP_MT_G_PDU,
+		NPC_GTP_PT_MASK | NPC_GTP_VER_MASK | NPC_GTP_MT_MASK,
+		0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, NPC_UDP_PORT_GTPU, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_UDP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_SCTP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ICMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_IGMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ICMP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_ESP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_AH, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_TRANS_ETH_BR, 0xffff,
+		0x0000, 0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		0x0000, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY | NPC_GRE_F_SEQ,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		0x0000, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_IP6, 0xffff,
+		NPC_GRE_F_CSUM | NPC_GRE_F_KEY | NPC_GRE_F_SEQ,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, NPC_GRE_F_ROUTE,
+		0x4fff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0000,
+		0x4fff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0000,
+		0x0003, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_VER_1, 0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_ACK | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, NPC_ETYPE_PPP, 0xffff,
+		NPC_GRE_F_KEY | NPC_GRE_F_SEQ | NPC_GRE_F_ACK | NPC_GRE_VER_1,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x2001,
+		0xef7f, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU8_GRE, 0xff, 0x0000, 0xffff, 0x0001,
+		0x0003, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu9_cam_entries[] = {
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_IP,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_IP6,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_ARP,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_SBTAG,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_IP6, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, NPC_ETYPE_ARP, 0xffff,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, NPC_ETYPE_CTAG,
+		0xffff, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, NPC_ETYPE_QINQ,
+		0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_ETHER, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU9_TU_PPP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu10_cam_entries[] = {
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu11_cam_entries[] = {
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_TCP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_UDP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_SCTP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ICMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_IGMP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ESP, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_AH, 0x00ff,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_4 | NPC_IP_HDR_LEN_5,
+		NPC_IP_VER_MASK | NPC_IP_HDR_LEN_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_TCP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_UDP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_SCTP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ICMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_IGMP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_ESP, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, NPC_IPNH_AH, 0x00ff, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000, NPC_IP_VER_4,
+		NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_ARP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_TCP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_UDP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_SCTP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ICMP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ICMP6 << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_ESP << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, NPC_IPNH_AH << 8, 0xff00,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, 0x0000, 0x0000,
+		NPC_IP_VER_6, NPC_IP_VER_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU11_TU_IP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu12_cam_entries[] = {
+	{
+		NPC_S_KPU12_TU_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu13_cam_entries[] = {
+	{
+		NPC_S_KPU13_TU_IP6_EXT, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu14_cam_entries[] = {
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, 0x0000, 0x0000,
+		NPC_TCP_DATA_OFFSET_5, NPC_TCP_DATA_OFFSET_MASK, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTP, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, NPC_TCP_PORT_HTTPS, 0xffff, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_TCP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_UDP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_SCTP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ICMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_IGMP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ICMP6, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_ESP, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU14_TU_AH, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_NA, 0X00, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_cam kpu15_cam_entries[] = {
+	{
+		NPC_S_KPU15_TCP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_HTTP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_HTTPS_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+	{
+		NPC_S_KPU15_UDP_DATA, 0xff, 0x0000, 0x0000, 0x0000,
+		0x0000, 0x0000, 0x0000,
+	},
+};
+
+struct npc_kpu_profile_action kpu1_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		3, 0, NPC_S_KPU5_IP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		3, 0, NPC_S_KPU5_IP6, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_ARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_RARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_CTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 20,
+		0, 0, NPC_S_KPU2_SBTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_QINQ, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		0, 0, NPC_S_KPU2_ETAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_ETAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETHER_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_8023, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_8023, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		3, 0, NPC_S_KPU5_IP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		3, 0, NPC_S_KPU5_IP6, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_ARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		3, 0, NPC_S_KPU5_RARP, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_CTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 20,
+		0, 0, NPC_S_KPU2_SBTAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU2_QINQ, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_VLAN, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		0, 0, NPC_S_KPU2_ETAG, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_ETAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 14, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_HAS_PKI_HAS_MPLS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LA, NPC_LT_LA_ETHER, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LA, NPC_EC_L2_K1, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu2_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_CTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_2_TAGS_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_3_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_STAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_4_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU3_CTAG, 22, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_BTAG_HAS_CTAG, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_BTAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU4_MPLS, 4, 1,
+		NPC_LID_LB, NPC_LT_LB_VLAN_MPLS, NPC_F_VLAN_2_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_QINQ, NPC_F_VLAN_2_TAGS_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_3_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_QINQ, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_STAG, NPC_F_VLAN_4_TAGS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU5_IP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU5_IP6, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_ARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU5_RARP, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_CTAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_CTAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_STAG, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_STAG, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 6, 0,
+		0, 0, NPC_S_KPU3_QINQ, 8, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG_QINQ, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LB, NPC_LT_LB_ETAG, NPC_F_ETYPE_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K2, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LA, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu3_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU5_IP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU5_IP6, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_ARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU5_RARP, 8, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3_ETYPE_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LB, NPC_EC_L2_K3, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu4_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		0, 0, NPC_S_KPU5_IP, 4, 0,
+		NPC_LID_LB, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu5_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_IGMP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_ESP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_AH, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_IN_IP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 20, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_6TO4, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_IGMP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_ESP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU8_AH, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_IN_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_6TO4_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, NPC_F_IP_UNK_PROTO_HAS_OPTIONS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_IP_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_ARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_RARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU8_TCP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 8, 10,
+		2, 0, NPC_S_KPU8_UDP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_SCTP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ICMP6, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_ESP, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_AH, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU8_GRE, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		5, 0, NPC_S_KPU11_TU_IP6, 40, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, NPC_F_IP6_TUN_IP6, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU6_IP6_EXT, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, NPC_F_IP6_HAS_EXT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_IP6_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LC, NPC_LT_LC_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LC, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu6_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu7_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu8_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTP_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTPS_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTPS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_TCP_DATA, 20, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTP_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTP_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_HTTPS_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_HTTPS_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_TCP_DATA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_TCP, NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_VXLAN, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_VXLAN, NPC_F_UDP_VXLAN_NOVNI,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_VXLAN, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, 0, 8, 0x3f,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GENEVE, NPC_F_UDP_GENEVE_OAM_CRI_OPT,
+		8, 0x3f, 0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPC, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPU, NPC_F_UDP_GTPU_G_PDU, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP_GTPU, NPC_F_UDP_GTPU_UNK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		6, 0, NPC_S_KPU15_UDP_DATA, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_UDP, NPC_F_UDP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_SCTP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ICMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_IGMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ICMP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_ESP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_AH, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 12, 16, 20,
+		0, 0, NPC_S_KPU9_TU_ETHER, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_NVGRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_NVGRE, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 4, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 4, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		2, 0, NPC_S_KPU11_TU_IP6, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_CSUM_KEY_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_HAS_ROUTE, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_GRE, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 8, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_SEQ, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 12, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_ACK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU9_TU_PPP, 16, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_HAS_SEQ_ACK, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LD, NPC_LT_LD_GRE, NPC_F_GRE_VER1_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_GRE_VER1, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LD, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LD, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu9_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 14, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 18, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER, NPC_F_TU_ETHER_HAS_STAG_CTAG,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_STAG_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_STAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 8, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 6, 0, 0,
+		1, 0, NPC_S_KPU11_TU_IP6, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		1, 0, NPC_S_KPU11_TU_ARP, 22, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_CTAG_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_HAS_QINQ_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_ETHER,
+		NPC_F_TU_ETHER_ETYPE_UNK, 0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LE, NPC_LT_LE_TU_PPP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LE, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LE, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu10_action_entries[] = {
+	{
+		NPC_ERRLEV_LE, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LE, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu11_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_IGMP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 20, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_UNK_PROTO, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_IGMP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_HAS_OPTIONS, 0, 0xf,
+		0, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, NPC_F_IP_UNK_PROTO_HAS_OPTIONS,
+		0, 0, 0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_IP_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_ARP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 12, 0,
+		2, 0, NPC_S_KPU14_TU_TCP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		2, 0, NPC_S_KPU14_TU_UDP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_SCTP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ICMP6, 40, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_ESP, 40, 1,
+		NPC_LID_LC, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		2, 0, NPC_S_KPU14_TU_AH, 40, 1,
+		NPC_LID_LC, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 2, 0, 0,
+		0, 0, NPC_S_KPU12_TU_IP6_EXT, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, NPC_F_IP6_HAS_EXT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_IP6_VER, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LF, NPC_LT_LF_TU_IP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LF, NPC_EC_UNK, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LF, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu12_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu13_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LC, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu14_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTP_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTP, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTPS_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTPS, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_TCP_DATA, 20, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTP_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTP_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_HTTPS_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_HTTPS_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_TCP_DATA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_TCP, NPC_F_TCP_UNK_PORT_HAS_OPTIONS,
+		12, 0xf0, 1, 2,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 0, NPC_S_KPU15_UDP_DATA, 8, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_UDP, NPC_F_UDP_UNK_PORT, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_SCTP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ICMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_IGMP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ICMP6, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_ESP, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LG, NPC_LT_LG_TU_AH, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_LG, NPC_EC_L4, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 0,
+		NPC_LID_LG, NPC_LT_NA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile_action kpu15_action_entries[] = {
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_TCP_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_HTTP_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_HTTPS_DATA, 0, 0, 0,
+		0, 0,
+	},
+	{
+		NPC_ERRLEV_RE, NPC_EC_NOERR, 0, 0, 0,
+		0, 1, NPC_S_NA, 0, 1,
+		NPC_LID_LH, NPC_LT_LH_UDP_DATA, 0, 0, 0,
+		0, 0,
+	},
+};
+
+struct npc_kpu_profile npc_kpu_profiles[] = {
+	{
+		ARRAY_SIZE(kpu1_cam_entries),
+		ARRAY_SIZE(kpu1_action_entries),
+		&kpu1_cam_entries[0],
+		&kpu1_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu2_cam_entries),
+		ARRAY_SIZE(kpu2_action_entries),
+		&kpu2_cam_entries[0],
+		&kpu2_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu3_cam_entries),
+		ARRAY_SIZE(kpu3_action_entries),
+		&kpu3_cam_entries[0],
+		&kpu3_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu4_cam_entries),
+		ARRAY_SIZE(kpu4_action_entries),
+		&kpu4_cam_entries[0],
+		&kpu4_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu5_cam_entries),
+		ARRAY_SIZE(kpu5_action_entries),
+		&kpu5_cam_entries[0],
+		&kpu5_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu6_cam_entries),
+		ARRAY_SIZE(kpu6_action_entries),
+		&kpu6_cam_entries[0],
+		&kpu6_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu7_cam_entries),
+		ARRAY_SIZE(kpu7_action_entries),
+		&kpu7_cam_entries[0],
+		&kpu7_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu8_cam_entries),
+		ARRAY_SIZE(kpu8_action_entries),
+		&kpu8_cam_entries[0],
+		&kpu8_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu9_cam_entries),
+		ARRAY_SIZE(kpu9_action_entries),
+		&kpu9_cam_entries[0],
+		&kpu9_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu10_cam_entries),
+		ARRAY_SIZE(kpu10_action_entries),
+		&kpu10_cam_entries[0],
+		&kpu10_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu11_cam_entries),
+		ARRAY_SIZE(kpu11_action_entries),
+		&kpu11_cam_entries[0],
+		&kpu11_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu12_cam_entries),
+		ARRAY_SIZE(kpu12_action_entries),
+		&kpu12_cam_entries[0],
+		&kpu12_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu13_cam_entries),
+		ARRAY_SIZE(kpu13_action_entries),
+		&kpu13_cam_entries[0],
+		&kpu13_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu14_cam_entries),
+		ARRAY_SIZE(kpu14_action_entries),
+		&kpu14_cam_entries[0],
+		&kpu14_action_entries[0],
+	},
+	{
+		ARRAY_SIZE(kpu15_cam_entries),
+		ARRAY_SIZE(kpu15_action_entries),
+		&kpu15_cam_entries[0],
+		&kpu15_action_entries[0],
+	},
+};
+
+#endif /* NPC_PROFILE_H */
-- 
2.29.0

