From 7bde881dc9e9e049b6bbb98511cd09811b0ec185 Mon Sep 17 00:00:00 2001
From: Suneel Garapati <sgarapati@caviumnetworks.com>
Date: Mon, 30 Jul 2018 12:56:19 -0700
Subject: [PATCH 0812/1239] drivers: net: octeontx2: initial working checkin
 for NIX

Changes to nix driver code to make it work on asim for
static ping and also in LAN for dhcp and tftp commands to work.
 - Headers are updated to latest using the csr-tool in bdk
 - cleanup of all unused files
 - update cgx_intf.h file from ATF
 - prune all AF access to admin function driver and LF access
   to physical function driver
 - use u-boot driver model for eth uclass
 - fix some compiler warnings
 - implementation relies on single active interface at any time
 - each lmac is mapped to single physical function per rvu
   provisioning in ATF
 - clean up of board file wrt above changes
 - each lmac is brought up during cgx probe but rx_tx disabled
 - each lmac is initialized with mac filtering on its mac addr
 - each command entered at u-boot prompt will enable rx_tx on
   the mapped lmac and start packet transfers
 - cleanup of rx/tx buffers and disable rx_tx before command exit
 - initialization of BOARD-MAC-ADDRESS and BOARD-MAC-ADDRESS-NUM
   in bdk is mandatory to get proper mac addresses for all interfaces
   in ATF and u-boot

Test update on simulator -
static ping between host machine and asimnic interfaces
In LAN, dhcp and tftp of a file in few KB is validated.
tested across interfaces in cgx0/1/2.

TODO
- bugs may exist
- comments on code
- revisit buffer count on rx/tx for each pf

Signed-off-by: Suneel Garapati <sgarapati@caviumnetworks.com>
---
 board/cavium/octeontx2/fdt.c                 |    2 +-
 board/cavium/octeontx2/octeontx2.c           |   43 +-
 configs/octeontx2_96xx_defconfig             |    3 +-
 drivers/net/cavium/octeontx2/cavm-csrs-nix.h |    2 -
 drivers/net/cavium/octeontx2/cavm-csrs-npc.h |   11 +-
 drivers/net/cavium/octeontx2/cavm-csrs-rvu.h |   13 +-
 drivers/net/cavium/octeontx2/cgx.c           |  277 +-
 drivers/net/cavium/octeontx2/cgx.h           |   67 +-
 drivers/net/cavium/octeontx2/cgx_fw_if.h     |  225 --
 drivers/net/cavium/octeontx2/cgx_intf.c      |   91 +-
 drivers/net/cavium/octeontx2/cgx_intf.h      |   24 +-
 drivers/net/cavium/octeontx2/lmt.h           |    4 +-
 drivers/net/cavium/octeontx2/lmt_hw.h        |   51 -
 drivers/net/cavium/octeontx2/lmt_reg.h       |   22 -
 drivers/net/cavium/octeontx2/nix.c           | 1752 +++--------
 drivers/net/cavium/octeontx2/nix.h           |  240 +-
 drivers/net/cavium/octeontx2/nix_af.c        | 1393 +++------
 drivers/net/cavium/octeontx2/nix_af.h        |   15 -
 drivers/net/cavium/octeontx2/nix_lf.h        |    0
 drivers/net/cavium/octeontx2/npa_hw.h        | 2734 ------------------
 drivers/net/cavium/octeontx2/npc.c           |    4 +-
 drivers/net/cavium/octeontx2/npc_hw.h        |  331 ---
 drivers/net/cavium/octeontx2/rvu.h           |  130 +-
 drivers/net/cavium/octeontx2/rvu_af.c        |  209 +-
 drivers/net/cavium/octeontx2/rvu_common.c    |   54 +-
 drivers/net/cavium/octeontx2/rvu_common.h    |  202 --
 drivers/net/cavium/octeontx2/rvu_hw.h        | 2121 --------------
 drivers/net/cavium/octeontx2/rvu_pf.c        |  148 +-
 include/configs/octeontx2_96xx.h             |    1 +
 29 files changed, 1636 insertions(+), 8533 deletions(-)
 delete mode 100644 drivers/net/cavium/octeontx2/cgx_fw_if.h
 delete mode 100644 drivers/net/cavium/octeontx2/lmt_hw.h
 delete mode 100644 drivers/net/cavium/octeontx2/lmt_reg.h
 delete mode 100644 drivers/net/cavium/octeontx2/nix_af.h
 delete mode 100644 drivers/net/cavium/octeontx2/nix_lf.h
 delete mode 100644 drivers/net/cavium/octeontx2/npa_hw.h
 delete mode 100644 drivers/net/cavium/octeontx2/npc_hw.h
 delete mode 100644 drivers/net/cavium/octeontx2/rvu_common.h
 delete mode 100644 drivers/net/cavium/octeontx2/rvu_hw.h

diff --git a/board/cavium/octeontx2/fdt.c b/board/cavium/octeontx2/fdt.c
index a466ef5e48..61e778472e 100644
--- a/board/cavium/octeontx2/fdt.c
+++ b/board/cavium/octeontx2/fdt.c
@@ -42,7 +42,7 @@ void octeontx2_parse_board_info(void)
 	const char *str;
 	int node;
 	int ret = 0, len = 16;
-	u64 midr, val;
+	u64 midr;
 
 	debug("%s: ENTER\n", __func__);
 
diff --git a/board/cavium/octeontx2/octeontx2.c b/board/cavium/octeontx2/octeontx2.c
index 150b99b7a1..297c64fc64 100644
--- a/board/cavium/octeontx2/octeontx2.c
+++ b/board/cavium/octeontx2/octeontx2.c
@@ -8,7 +8,6 @@
 #include <dm.h>
 #include <malloc.h>
 #include <errno.h>
-#include <netdev.h>
 #include <asm/io.h>
 #include <linux/compiler.h>
 #include <libfdt.h>
@@ -32,10 +31,8 @@ void board_quiesce_devices(void)
 }
 
 #ifdef CONFIG_BOARD_EARLY_INIT_R
-extern void eth_common_init(void);
 int board_early_init_r(void)
 {
-	eth_common_init();
 	pci_init();
 	return 0;
 }
@@ -84,6 +81,25 @@ void reset_cpu(ulong addr)
 	writeq(val, CAVM_RST_CHIP_DOM_W1S);
 }
 
+/**
+ * Board misc devices initialization routine.
+ */
+void board_misc_init(void)
+{
+	struct udevice *bus;
+
+	/*
+	 * Enumerate all known miscellaneous devices.
+	 * Enumeration has the side-effect of probing them,
+	 * so CGX and RVU AF devices will get enumerated.
+	 */
+	for (uclass_first_device(UCLASS_MISC, &bus);
+	     bus;
+	     uclass_next_device(&bus)) {
+		;
+	}
+}
+
 /**
  * Board late initialization routine.
  */
@@ -101,27 +117,10 @@ int board_late_init(void)
 	snprintf(boardname, sizeof(boardname), "%s> ", p_cavm_bdt->type);
 	env_set("prompt", boardname);
 	set_working_fdt_addr(env_get_hex("fdtcontroladdr", fdt_base_addr));
-	return 0;
-}
 
-/*
- * Board specific ethernet initialization routine.
- */
-
-int board_eth_init(bd_t *bis)
-{
-	int rc = 0;
-	unsigned char ethaddr[6];
+	board_misc_init();
 
-	if (!eth_env_get_enetaddr("ethaddr", ethaddr)) {
-		net_random_ethaddr(ethaddr);
-		printf("Generating random MAC address: %pM\n", ethaddr);
-		eth_env_set_enetaddr("ethaddr", ethaddr);
-	}
-
-	rc = pci_eth_init(bis);
-
-	return rc;
+	return 0;
 }
 
 #ifdef CONFIG_HW_WATCHDOG
diff --git a/configs/octeontx2_96xx_defconfig b/configs/octeontx2_96xx_defconfig
index 77e40b08f5..8cc0a48787 100644
--- a/configs/octeontx2_96xx_defconfig
+++ b/configs/octeontx2_96xx_defconfig
@@ -70,9 +70,10 @@ CONFIG_SPI_FLASH_MACRONIX=y
 CONFIG_SPI_FLASH_SPANSION=y
 CONFIG_SPI_FLASH_STMICRO=y
 CONFIG_SPI_FLASH_WINBOND=y
-CONFIG_NETDEVICES=y
+CONFIG_DM_ETH=y
 CONFIG_CAVIUM_NET_OCTEONTX2=y
 CONFIG_OCTEONTX2_CGX=y
+CONFIG_OCTEONTX2_RVU=y
 CONFIG_PCI=y
 CONFIG_DM_PCI=y
 CONFIG_DM_PCI_COMPAT=y
diff --git a/drivers/net/cavium/octeontx2/cavm-csrs-nix.h b/drivers/net/cavium/octeontx2/cavm-csrs-nix.h
index 890dca78eb..a8e0a52fe3 100644
--- a/drivers/net/cavium/octeontx2/cavm-csrs-nix.h
+++ b/drivers/net/cavium/octeontx2/cavm-csrs-nix.h
@@ -1862,7 +1862,6 @@ static inline u64 CAVM_NIXX_AF_AQ_DONE_ACK(void)
  * Register (RVU_PF_BAR0) nix#_af_aq_done_ena_w1c
  *
  * NIX AF Admin Queue Done Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
  */
 union cavm_nixx_af_aq_done_ena_w1c {
 	u64 u;
@@ -1884,7 +1883,6 @@ static inline u64 CAVM_NIXX_AF_AQ_DONE_ENA_W1C(void)
  * Register (RVU_PF_BAR0) nix#_af_aq_done_ena_w1s
  *
  * NIX AF Admin Queue Done Interrupt Enable Set Register
- * This register sets interrupt enable bits.
  */
 union cavm_nixx_af_aq_done_ena_w1s {
 	u64 u;
diff --git a/drivers/net/cavium/octeontx2/cavm-csrs-npc.h b/drivers/net/cavium/octeontx2/cavm-csrs-npc.h
index 254da30474..490ab5c9a3 100644
--- a/drivers/net/cavium/octeontx2/cavm-csrs-npc.h
+++ b/drivers/net/cavium/octeontx2/cavm-csrs-npc.h
@@ -445,7 +445,7 @@ static inline u64 CAVM_NPC_AF_DBG_CTL(void)
  * Register (RVU_PF_BAR0) npc_af_dbg_data#
  *
  * NPC AF Debug Data Registers
- * This register contains packet header data for the last packet/lookup whose
+ * These registers contain the packet header data of the last packet/lookup whose
  * debug information is captured by NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
  */
 union cavm_npc_af_dbg_datax {
@@ -467,9 +467,8 @@ static inline u64 CAVM_NPC_AF_DBG_DATAX(u64 a)
  * Register (RVU_PF_BAR0) npc_af_dbg_result#
  *
  * NPC AF Debug Result Registers
- * This register contains packet result data with format NPC_RESULT_S, for the
- * last packet/lookup for which debug information is captured by
- * NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
+ * These registers contain the result data of the last packet/lookup whose debug
+ * information is captured by NPC_AF_DBG_CTL[INTF_DBG,LKUP_DBG].
  */
 union cavm_npc_af_dbg_resultx {
 	u64 u;
@@ -1416,7 +1415,7 @@ static inline u64 CAVM_NPC_AF_PCK_CFG(void)
 /**
  * Register (RVU_PF_BAR0) npc_af_pck_def_iip4
  *
- * NPC AF Protocol Check Outer IPv4 Definition Register
+ * NPC AF Protocol Check Inner IPv4 Definition Register
  * Provides layer information used by the protocol checker to identify an inner IPv4 header.
  */
 union cavm_npc_af_pck_def_iip4 {
@@ -1464,7 +1463,7 @@ static inline u64 CAVM_NPC_AF_PCK_DEF_OIP4(void)
 /**
  * Register (RVU_PF_BAR0) npc_af_pck_def_oip6
  *
- * NPC AF Protocol Check Outer IPv4 Definition Register
+ * NPC AF Protocol Check Outer IPv6 Definition Register
  * Provides layer information used by the protocol checker to identify an outer
  * IPv6 header. [LID] must have the same value as NPC_AF_PCK_DEF_OIP4[LID].
  */
diff --git a/drivers/net/cavium/octeontx2/cavm-csrs-rvu.h b/drivers/net/cavium/octeontx2/cavm-csrs-rvu.h
index 8a56294f9c..cb796bc351 100644
--- a/drivers/net/cavium/octeontx2/cavm-csrs-rvu.h
+++ b/drivers/net/cavium/octeontx2/cavm-csrs-rvu.h
@@ -1162,10 +1162,9 @@ static inline u64 CAVM_RVU_PF_MSIX_PBAX(u64 a)
  * The number of MSI-X vectors for a given PF is specified by
  * RVU_PRIV_PF()_MSIX_CFG[PF_MSIXT_SIZEM1] (plus 1).
  *
- * Internal:
- * PF vector count of 256 is sized to allow up to 120 for AF, 4 for PF/VF
- * mailboxes, and 128 for LF resources from various blocks that are directly
- * provisioned to the PF.
+ * Software must do a read after any writes to the MSI-X vector table to ensure
+ * that the writes have completed before interrupts are generated to the modified
+ * vectors.
  */
 union cavm_rvu_pf_msix_vecx_addr {
 	u64 u;
@@ -2243,9 +2242,9 @@ static inline u64 CAVM_RVU_VF_MSIX_PBAX(u64 a)
  * The number of MSI-X vectors for a given VF is specified by
  * RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_SIZEM1] (plus 1).
  *
- * Internal:
- * VF vector count of 128 allows up to that number to be provisioned to the VF
- * from LF resources of various blocks.
+ * Software must do a read after any writes to the MSI-X vector table to ensure
+ * that the writes have completed before interrupts are generated to the modified
+ * vectors.
  */
 union cavm_rvu_vf_msix_vecx_addr {
 	u64 u;
diff --git a/drivers/net/cavium/octeontx2/cgx.c b/drivers/net/cavium/octeontx2/cgx.c
index 49e225d1bf..8f1e0f32e0 100644
--- a/drivers/net/cavium/octeontx2/cgx.c
+++ b/drivers/net/cavium/octeontx2/cgx.c
@@ -7,10 +7,8 @@
  * the License, or (at your option) any later version.
  *
  */
-#define DEBUG
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -18,160 +16,140 @@
 #include <errno.h>
 #include <linux/list.h>
 #include <asm/arch/octeontx2.h>
-
 #include "cavm-csrs-cgx.h"
-#include "cgx_intf.h"
 #include "cgx.h"
 
-static LIST_HEAD(cgx_list);
-
-static inline struct lmac *lmac_pdata(u8 lmac_id, struct cgx *cgx)
-{
-	if (!cgx || lmac_id > MAX_LMAC_PER_CGX)
-		return NULL;
-
-	return cgx->lmac_idmap[lmac_id];
-}
-
-int cgx_get_cgx_cnt(void)
-{
-	struct cgx *cgx_dev;
-	int count = 0;
-
-	list_for_each_entry(cgx_dev, &cgx_list, cgx_list)
-		count++;
-
-	return count;
-}
-
-int cgx_get_lmac_cnt(void *cgxd)
-{
-	struct cgx *cgx = cgxd;
-
-	if (!cgx)
-		return -ENODEV;
-
-	return cgx->lmac_count;
-}
-
-void *cgx_get_pdata(int cgx_id)
-{
-	struct cgx *cgx_dev;
-
-	list_for_each_entry(cgx_dev, &cgx_list, cgx_list) {
-		if (cgx_dev->cgx_id == cgx_id)
-			return cgx_dev;
-	}
-	return NULL;
-}
+char lmac_type_to_str [][8] = {
+	"SGMII",
+	"XAUI",
+	"RXAUI",
+	"10G_R",
+	"40G_R",
+	"RGMII",
+	"QSGMII",
+	"25G_R",
+	"50G_R",
+	"100G_R",
+	"USXGMII",
+};
 
 /**
- * Given an LMAC instance number, return the lmac
+ * Given an LMAC/PF instance number, return the lmac
+ * Per design, each PF has only one LMAC mapped.
  *
  * @param instance	instance to find
  *
  * @return	pointer to lmac data structure or NULL if not found
  */
-struct lmac *cgx_get_lmac(int instance)
+struct lmac *nix_get_cgx_lmac(int lmac_instance)
 {
 	struct cgx *cgx;
-	int i;
-
-	list_for_each_entry(cgx, &cgx_list, cgx_list) {
-		for (i = 0; i < MAX_LMAC_PER_CGX; i++) {
-			if (cgx->lmac_idmap[i] &&
-			    cgx->lmac_idmap[i]->instance == instance)
-				return cgx->lmac_idmap[i];
+	struct udevice *dev;
+	int i, idx, err;
+
+	for (i = 0; i < CGX_PER_NODE; i++) {
+		err = dm_pci_find_device(PCI_VENDOR_ID_CAVIUM,
+					 PCI_DEVICE_ID_OCTEONTX2_CGX, i,
+					 &dev);
+		if (err)
+			continue;
+
+		cgx = dev_get_priv(dev);
+		debug("%s udev %p cgx %p instance %d\n", __func__, dev, cgx,
+			lmac_instance);
+		for (idx = 0; idx < cgx->lmac_count; idx++) {
+			if (cgx->lmac[idx]->instance == lmac_instance)
+				return cgx->lmac[idx];
 		}
 	}
 	return NULL;
 }
 
-static void cgx_write(struct cgx *cgx, u64 lmac, u64 offset, u64 val)
+void cgx_lmac_mac_filter_setup(struct lmac *lmac)
 {
-	writeq(val, cgx->reg_base + (lmac << 18) + offset);
+	union cavm_cgxx_cmrx_rx_dmac_ctl0 dmac_ctl0;
+	union cavm_cgxx_cmr_rx_dmacx_cam0 dmac_cam0;
+#if 0
+	union cavm_cgxx_cmr_rx_steering0x steering0;
+	union cavm_cgxx_cmr_rx_steering_default0 steering_default0;
+	static int str_idx = 1;
+#endif
+	u64 mac, tmp;
+	void *reg_addr;
+
+	memcpy((void *)&tmp, lmac->mac_addr, 6);
+	debug("%s: tmp %llx\n", __func__, tmp);
+	debug("%s: swab tmp %llx\n", __func__, swab64(tmp));
+	mac = swab64(tmp) >> 16;
+	debug("%s: mac %llx\n", __func__, mac);
+	dmac_cam0.u = 0x0;
+	dmac_cam0.s.id = lmac->lmac_id;
+	dmac_cam0.s.adr = mac;
+	dmac_cam0.s.en = 1;
+	reg_addr = lmac->cgx->reg_base + 
+			CAVM_CGXX_CMR_RX_DMACX_CAM0(lmac->lmac_id * 8);
+	writeq(dmac_cam0.u, reg_addr);
+	debug("%s: reg %p dmac_cam0 %llx\n", __func__, reg_addr, dmac_cam0.u);
+	dmac_ctl0.u = 0x0;
+	dmac_ctl0.s.bcst_accept = 0;
+	dmac_ctl0.s.mcst_mode = 0;
+	dmac_ctl0.s.cam_accept = 1;
+	reg_addr = lmac->cgx->reg_base +
+			CAVM_CGXX_CMRX_RX_DMAC_CTL0(lmac->lmac_id);
+	writeq(dmac_ctl0.u, reg_addr);
+	debug("%s: reg %p dmac_ctl0 %llx\n", __func__, reg_addr, dmac_ctl0.u);
+
+#if 0
+	steering_default0.u = 0x0;
+	steering_default0.s.pass = 0;
+	reg_addr = lmac->cgx->reg_base + CAVM_CGXX_CMR_RX_STEERING_DEFAULT0();
+	writeq(steering_default0.u, reg_addr);
+	debug("%s: reg %p str_def0 %llx\n", __func__, reg_addr,
+			 steering_default0.u);
+
+	steering0.u = 0x0;
+	steering0.s.pass = 1;
+	steering0.s.mcst_en = 0;
+	steering0.s.dmac_en = 1;
+	steering0.s.dmac = mac;
+	reg_addr = lmac->cgx->reg_base + CAVM_CGXX_CMR_RX_STEERING0X(0);
+	writeq(steering0.u, reg_addr);
+	debug("%s: reg %p steering00 %llx\n", __func__, reg_addr,
+			 steering0.u);
+
+	mac = 0x0000FFFFFFFFFFFF;	/* broadcast addr */
+	steering0.u = 0x0;
+	steering0.s.pass = 1;
+	steering0.s.mcst_en = 0;
+	steering0.s.dmac_en = 1;
+	steering0.s.dmac = mac;
+	reg_addr = lmac->cgx->reg_base + CAVM_CGXX_CMR_RX_STEERING0X(1);
+	writeq(steering0.u, reg_addr);
+	debug("%s: reg %p steering01 %llx\n", __func__, reg_addr,
+			 steering0.u);
+#endif
 }
 
-static u64 cgx_read(struct cgx *cgx, u64 lmac, u64 offset)
-{
-	return readq(cgx->reg_base + (lmac << 18) + offset);
-}
 
-int cgx_set_pkind(void *cgxd, u8 lmac_id, int pkind)
+int cgx_lmac_set_pkind(struct lmac *lmac, u8 lmac_id, int pkind)
 {
-	struct cgx *cgx = cgxd;
-
-	if (!cgx || lmac_id >= cgx->lmac_count)
-		return -ENODEV;
-
-	cgx_write(cgx, lmac_id, CAVM_CGXX_CMRX_RX_ID_MAP(0), (pkind & 0x3f));
+	cgx_write(lmac->cgx, lmac_id, CAVM_CGXX_CMRX_RX_ID_MAP(0),
+		  (pkind & 0x3f));
 	return 0;
 }
 
-/**
- * Given a linear link number, get the cgx and lmac
- *
- * @param	linear_link_number	Linear link number
- * @param[out]	cgx_id			cgx_id number
- * @parma[out]	lmac_id			lmac_id number
- *
- * @return 0 for success or -1 if not found
- */
-int cgx_get_identifiers(int linear_link_number, int *cgx_id, int *lmac_id)
-{
-	int index = 0;
-	struct cgx *cgx;
-
-	for (cgx = cgx_get_pdata(index); cgx; index++) {
-		if (linear_link_number < cgx->lmac_count) {
-			*cgx_id = cgx->cgx_id;
-			*lmac_id = linear_link_number;
-			return 0;
-		} else {
-			linear_link_number -= cgx->lmac_count;
-		}
-	}
-	return -1;
-}
-
-int cgx_channel_number(int linear_link_number)
-{
-	int cgx_id, lmac_id, err;
-
-	err = cgx_get_identifiers(linear_link_number, &cgx_id, &lmac_id);
-	if (err)
-		return -1;
-	else
-		return (0x800 + 0x100 * cgx_id + 0x10 * lmac_id + 0);
-}
-
-int cgx_link_number(int linear_link_number)
-{
-	int cgx_id, lmac_id, err;
 
-	err = cgx_get_identifiers(linear_link_number, &cgx_id, &lmac_id);
-	if (err)
-		return -1;
-	else
-		return (4 * cgx_id + lmac_id);
-}
-
-u64 cgx_get_channel_number(struct cgx *cgx, int linear_link_number)
+int cgx_lmac_link_enable(struct lmac *lmac, int lmac_id, bool enable)
 {
-	int lmac_id;
-	if (!cgx->lmac_idmap[linear_link_number]) {
-		printf("%s: Invalid link number %d for cgx %d\n", __func__,
-		       linear_link_number, cgx->cgx_id);
-		return 0;
-	}
+	u64 link;
 
-	lmac_id = cgx->lmac_idmap[linear_link_number]->lmac_id;
-	return (0x800 + 0x100 * cgx->cgx_id + 0x10 * lmac_id + 0);
+	return cgx_intf_link_up_dwn(lmac->cgx->cgx_id,
+					lmac_id, enable, &link);
 }
 
-int cgx_lmac_internal_loopback(void *cgxd, int lmac_id, bool enable)
+int cgx_lmac_internal_loopback(struct lmac *lmac, int lmac_id, bool enable)
 {
-	struct cgx *cgx = cgxd;
+	struct cgx *cgx = lmac->cgx;
 	union cavm_cgxx_cmrx_config cmrx_cfg;
 	union cavm_cgxx_gmp_pcs_mrx_control mrx_control;
 	union cavm_cgxx_spux_control1 spux_control1;
@@ -198,18 +176,17 @@ int cgx_lmac_internal_loopback(void *cgxd, int lmac_id, bool enable)
 	return 0;
 }
 
-int cgx_lmac_rx_tx_enable(void *cgxd, int lmac_id, bool enable)
+int cgx_lmac_rx_tx_enable(struct lmac *lmac, int lmac_id, bool enable)
 {
-	struct cgx *cgx = cgxd;
+	struct cgx *cgx = lmac->cgx;
 	union cavm_cgxx_cmrx_config cmrx_config;
 
 	if (!cgx || lmac_id >= cgx->lmac_count)
 		return -ENODEV;
 
 	cmrx_config.u = cgx_read(cgx, lmac_id, CAVM_CGXX_CMRX_CONFIG(0));
-	cmrx_config.s.enable =
-		cmrx_config.s.data_pkt_rx_en =
-		cmrx_config.s.data_pkt_tx_en = enable ? 1 : 0;
+	cmrx_config.s.data_pkt_rx_en =
+	cmrx_config.s.data_pkt_tx_en = enable ? 1 : 0;
 	cgx_write(cgx, lmac_id, CAVM_CGXX_CMRX_CONFIG(0), cmrx_config.u);
 	return 0;
 }
@@ -217,15 +194,13 @@ int cgx_lmac_rx_tx_enable(void *cgxd, int lmac_id, bool enable)
 static int cgx_lmac_init(struct cgx *cgx)
 {
 	struct lmac *lmac;
-	int i;
 	union cavm_cgxx_cmrx_config cmrx_cfg;
-	static int instance = 0;
+	static int instance = 1;
+	int i;
 
 	cgx->lmac_count = cgx_read(cgx, 0, CAVM_CGXX_CMR_RX_LMACS());
 	debug("%s: Found %d lmacs for cgx %d@%p\n", __func__, cgx->lmac_count,
 	      cgx->cgx_id, cgx->reg_base);
-	if (cgx->lmac_count > MAX_LMAC_PER_CGX)
-		cgx->lmac_count = MAX_LMAC_PER_CGX;
 
 	for (i = 0; i < cgx->lmac_count; i++) {
 		lmac = calloc(1, sizeof(*lmac));
@@ -240,38 +215,40 @@ static int cgx_lmac_init(struct cgx *cgx)
 
 		lmac->lmac_id = i;
 		lmac->cgx = cgx;
-		cgx->lmac_idmap[i] = lmac;
-		debug("%s: mapping id %d to lmac %p (%s), lmac type: %d\n",
-		      __func__, i, lmac, lmac->name, lmac->lmac_type);
+		cgx->lmac[i] = lmac;
+		debug("%s: mapping id %d to lmac %p (%s), lmac type: %d"
+			" lmac instance %d\n", __func__, i, lmac, lmac->name,
+			 lmac->lmac_type, lmac->instance);
+		cgx_intf_get_mac_addr(cgx->cgx_id, i, lmac->mac_addr);
+		debug("%s: cgx%d lmac%d mac_addr\n",__func__,cgx->cgx_id, i);
+		debug("%s: MAC %pM\n", __func__, lmac->mac_addr);
+		eth_env_set_enetaddr_by_index("eth", lmac->instance-1,
+						 lmac->mac_addr);
+		printf("CGX%d LMAC%d %s \n", cgx->cgx_id, lmac->lmac_id,
+					lmac_type_to_str[lmac->lmac_type]);
+
+		cgx_lmac_mac_filter_setup(lmac);
+		cgx_lmac_link_enable(lmac, lmac->lmac_id, true);
+		cgx_lmac_rx_tx_enable(lmac, lmac->lmac_id, false);
 	}
 	return 0;
 }
 
-void enumerate_lmacs(void)
-{
-
-}
-
 int cgx_probe(struct udevice *dev)
 {
 	struct cgx *cgx = dev_get_priv(dev);
 	size_t size;
 	int err;
-	static int instance = 0;
 
 	cgx->reg_base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
 	cgx->dev = dev;
 	cgx->cgx_id = ((u64)(cgx->reg_base) >> 24) & 0x7;
-	cgx->instance = instance++;
-
-	debug("CGX BAR %p, id: %d, instance: %d\n",
-	      cgx->reg_base, cgx->cgx_id, cgx->instance);
 
-	/*enumerate_lmacs();*/
+	debug("%s CGX BAR %p, id: %d\n", __func__,
+		 cgx->reg_base, cgx->cgx_id);
+	debug("%s CGX %p, udev: %p\n", __func__, cgx, dev);
 
 	err = cgx_lmac_init(cgx);
-	if (!err)
-		list_add(&cgx->cgx_list, &cgx_list);
 
 	return err;
 }
diff --git a/drivers/net/cavium/octeontx2/cgx.h b/drivers/net/cavium/octeontx2/cgx.h
index 78125c595a..d61973d387 100644
--- a/drivers/net/cavium/octeontx2/cgx.h
+++ b/drivers/net/cavium/octeontx2/cgx.h
@@ -11,20 +11,13 @@
 #ifndef __CGX_H__
 #define __CGX_H__
 
+#include "cgx_intf.h"
+
 #define PCI_DEVICE_ID_OCTEONTX2_CGX	0xA059
 
-#define CGX_FIRWARE_MAJOR_VER		1
-#define CGX_FIRWARE_MINOR_VER		0
 #define MAX_LMAC_PER_CGX		4
 #define CGX_PER_NODE 			3
 
-/* Register offsets */
-#define CGX_CMR_SCRATCH0	0x87e0e0001050
-#define CGX_CMR_SCRATCH1	0x87e0e0001058
-
-#define CGX_SHIFT(x)		(0x1000000 * (x & 0x3))
-#define CMR_SHIFT(x)		(0x40000 * (x & 0x3))
-
 enum lmac_type {
 	LMAC_MODE_SGMII		= 0,
 	LMAC_MODE_XAUI		= 1,
@@ -48,53 +41,59 @@ struct lmac_priv {
 };
 
 struct cgx;
-struct nix_handle;
-struct nix_af_handle;
+struct nix;
+struct nix_af;
 
 struct lmac {
 	struct cgx	*cgx;
-	struct nix_handle *nix;
+	struct nix	*nix;
 	char		name[16];
 	enum lmac_type	lmac_type;
 	bool		cmd_pend;
 	u8		instance;
 	u8		lmac_id;
-	u32		linear_link_number;
+	u8		pknd;
+	u8		link_num;
+	u32		chan_num;
+	u8		mac_addr[6];
 };
 
 struct cgx {
-	struct nix_af_handle	*nix_af;
+	struct nix_af		*nix_af;
 	void __iomem		*reg_base;
 	struct udevice		*dev;
-	struct lmac		*lmac_idmap[MAX_LMAC_PER_CGX];
-	struct list_head	cgx_list;
-	u8			instance;
+	struct lmac		*lmac[MAX_LMAC_PER_CGX];
 	u8			cgx_id;
 	u8			lmac_count;
 };
 
-int cgx_get_cgx_cnt(void);
-int cgx_get_lmac_cnt(void *cgxd);
+static inline void cgx_write(struct cgx *cgx, u8 lmac, u64 offset, u64 val)
+{
+	writeq(val, cgx->reg_base + CMR_SHIFT(lmac) + offset);
+}
+
+static inline u64 cgx_read(struct cgx *cgx, u8 lmac, u64 offset)
+{
+	return readq(cgx->reg_base + CMR_SHIFT(lmac) + offset);
+}
+
 /**
- * Given an LMAC instance number, return the lmac
+ * Given an LMAC/PF instance number, return the lmac
+ * Per design, each PF has only one LMAC mapped.
  *
  * @param instance	instance to find
  *
  * @return	pointer to lmac data structure or NULL if not found
  */
-struct lmac *cgx_get_lmac(int instance);
-void *cgx_get_pdata(int cgx_id);
-int cgx_set_pkind(void *cgxd, u8 lmac_id, int pkind);
-u64 cgx_get_channel_number(struct cgx *cgx, int linear_link_number);
-/**
- * Given a linear link number, get the cgx and lmac
- *
- * @param	linear_link_number	Linear link number
- * @param[out]	cgx_id			cgx_id number
- * @parma[out]	lmac_id			lmac_id number
- *
- * @return 0 for success or -1 if not found
- */
-int cgx_get_identifiers(int linear_link_number, int *cgx_id, int *lmac_id);
+struct lmac *nix_get_cgx_lmac(int lmac_instance);
+
+int cgx_lmac_set_pkind(struct lmac *lmac, u8 lmac_id, int pkind);
+int cgx_lmac_internal_loopback(struct lmac *lmac, int lmac_id, bool enable);
+int cgx_lmac_rx_tx_enable(struct lmac *lmac, int lmac_id, bool enable);
+int cgx_lmac_link_enable(struct lmac *lmac, int lmac_id, bool enable);
+void cgx_lmac_mac_filter_setup(struct lmac *lmac);
+
+int cgx_intf_link_up_dwn(u8 cgx, u8 lmac, u8 up_dwn, u64 *lnk_sts);
+int cgx_intf_get_mac_addr(u8 cgx, u8 lmac, u8 *mac);
 
 #endif /* __CGX_H__ */
diff --git a/drivers/net/cavium/octeontx2/cgx_fw_if.h b/drivers/net/cavium/octeontx2/cgx_fw_if.h
deleted file mode 100644
index c83ba7c3f5..0000000000
--- a/drivers/net/cavium/octeontx2/cgx_fw_if.h
+++ /dev/null
@@ -1,225 +0,0 @@
-/*
- * Copyright (C) 2017 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of version 2 of the GNU General Public License
- * as published by the Free Software Foundation.
- */
-
-#ifndef __CGX_FW_INTF_H__
-#define __CGX_FW_INTF_H__
-
-#define CGX_FIRMWARE_MAJOR_VER		1
-#define CGX_FIRMWARE_MINOR_VER		0
-
-#define CGX_EVENT_ACK                   1UL
-
-/** CGX error types. set for cmd response status as CGX_STAT_FAIL */
-enum cgx_error_type {
-	CGX_ERR_NONE,
-	CGX_ERR_LMAC_NOT_ENABLED,
-	CGX_ERR_LMAC_MODE_INVALID,
-	CGX_ERR_REQUEST_ID_INVALID,
-	CGX_ERR_PREV_ACK_NOT_CLEAR,
-	CGX_ERR_PHY_LINK_DOWN,
-	CGX_ERR_PCS_RESET_FAIL,
-	CGX_ERR_AN_CPT_FAIL,
-	CGX_ERR_TX_NOT_IDLE,
-	CGX_ERR_RX_NOT_IDLE,
-	CGX_ERR_SPUX_BR_BLKLOCK_FAIL,
-	CGX_ERR_SPUX_RX_ALIGN_FAIL,
-	CGX_ERR_SPUX_TX_FAULT,
-	CGX_ERR_SPUX_RX_FAULT,
-	CGX_ERR_SPUX_RESET_FAIL,
-	CGX_ERR_SMUX_RX_LINK_NOT_OK,
-	CGX_ERR_PCS_RECV_LINK_FAIL,
-	CGX_ERR_TRAINING_FAIL,
-	CGX_ERR_RX_EQU_FAIL,		/* = 18 */
-	/* FIXME : add more error types when adding support for new modes */
-};
-
-/* LINK speed types */
-enum cgx_link_speed {
-	CGX_LINK_NONE,
-	CGX_LINK_10M,
-	CGX_LINK_100M,
-	CGX_LINK_1G,
-	CGX_LINK_10G,
-	CGX_LINK_25G,
-	CGX_LINK_40G,
-	CGX_LINK_50G,
-	CGX_LINK_100G,
-};
-
-/* REQUEST ID types. Input to firmware */
-enum cgx_cmd_id {
-	CGX_CMD_NONE,
-	CGX_CMD_GET_FW_VER,
-	CGX_CMD_GET_MAC_ADDR,
-	CGX_CMD_SET_MTU,
-	CGX_CMD_GET_LINK_STS,		/* optional to user */
-	CGX_CMD_LINK_BRING_UP,
-	CGX_CMD_LINK_BRING_DOWN,
-	CGX_CMD_INTERNAL_LBK,
-	CGX_CMD_EXTERNAL_LBK,
-	CGX_CMD_HIGIG,
-	CGX_CMD_LINK_STATE_CHANGE,
-	CGX_CMD_MODE_CHANGE,		/* hot plug support */
-	CGX_CMD_INTF_SHUTDOWN,
-	CGX_CMD_IRQ_ENABLE,
-	CGX_CMD_IRQ_DISABLE,
-};
-
-/* async event ids */
-enum cgx_evt_id {
-	CGX_EVT_NONE,
-	CGX_EVT_LINK_CHANGE,
-};
-
-/* event types - cause of interrupt */
-enum cgx_evt_type {
-	CGX_EVT_ASYNC,
-	CGX_EVT_CMD_RESP
-};
-
-enum cgx_stat {
-	CGX_STAT_SUCCESS,
-	CGX_STAT_FAIL
-};
-
-enum cgx_cmd_own {
-	/* set by kernel/uefi/u-boot after posting a new request to ATF */
-	/* set by firmware */
-	CGX_CMD_OWN_NS,
-	CGX_CMD_OWN_FIRMWARE,
-};
-
-/* scratchx(0) CSR used for ATF->non-secure SW communication.
- * This acts as the status register
- * Provides details on command ack/status, link status, error details
- */
-
-/* CAUTION : below structures are placed in order based on the bit positions
- * For any updates/new bitfields, corresponding structures needs to be updated
- */
-struct cgx_evt_sts {			/* start from bit 0 */
-	uint64_t ack:1;
-	uint64_t evt_type:1;		/* cgx_evt_type */
-	uint64_t stat:1;		/* cgx_stat */
-	uint64_t id:6;			/* cgx_evt_id/cgx_cmd_id */
-	uint64_t reserved:55;
-};
-
-/* all the below structures are in the same memory location of SCRATCHX(0)
- * value can be read/written based on command ID
- */
-
-/* Resp to command IDs with command status as CGX_STAT_FAIL
- *
- * Not applicable for commands :
- * CGX_CMD_LINK_BRING_UP/DOWN/CGX_EVT_LINK_CHANGE
- * check struct cgx_lnk_sts comments
- */
-struct cgx_err_sts_s {			/* start from bit 9 */
-	uint64_t reserved1:9;
-	uint64_t type:10;		/* cgx_error_type */
-	uint64_t reserved2:35;
-};
-
-/* Resp to cmd ID as CGX_CMD_GET_FW_VER with cmd status as CGX_STAT_SUCCESS */
-struct cgx_ver_s {			/* start from bit 9 */
-	uint64_t reserved1:9;
-	uint64_t major_ver:4;
-	uint64_t minor_ver:4;
-	uint64_t reserved2:47;
-};
-
-/* Resp to cmd ID as CGX_CMD_GET_MAC_ADDR with cmd status as CGX_STAT_SUCCESS */
-struct cgx_mac_addr_s {			/* start from bit 9 */
-	uint64_t reserved1:9;
-	uint64_t local_mac_addr:48;
-	uint64_t reserved2:7;
-};
-
-/* Resp to cmd ID - CGX_CMD_LINK_BRING_UP/DOWN, event ID CGX_EVT_LINK_CHANGE
- * status can be either CGX_STAT_FAIL or CGX_STAT_SUCCESS
- * In case of CGX_STAT_FAIL, it indicates CGX configuration failed
- * when processing link up/down/change command.
- * Both err_type and current link status will be updated
- * In case of CGX_STAT_SUCCESS, err_type will be CGX_ERR_NONE and current
- * link status will be updated
- */
-struct cgx_lnk_sts {
-	uint64_t reserved1:9;
-	uint64_t link_up:1;
-	uint64_t full_duplex:1;
-	uint64_t speed:4;		/* cgx_link_speed */
-	uint64_t err_type:10;
-	uint64_t reserved2:39;
-};
-
-union cgx_evtreg {
-	u64 val;
-	struct cgx_evt_sts evt_sts; /* common for all commands/events */
-	struct cgx_lnk_sts link_sts; /* response to LINK_BRINGUP/DOWN/CHANGE */
-	struct cgx_ver_s ver;		/* response to CGX_CMD_GET_FW_VER */
-	struct cgx_mac_addr_s mac_addr;	/* response to CGX_CMD_GET_MAC_ADDR */
-	struct cgx_err_sts_s err;	/* response if evt_status = CMD_FAIL */
-};
-
-/* scratchx(1) CSR used for non-secure SW->ATF communication
- * This CSR acts as a command register
- */
-struct cgx_cmd {			/* start from bit 2 */
-	uint64_t own:2;			/* cgx_csr_own */
-	uint64_t id:6;			/* cgx_request_id */
-	uint64_t reserved2:56;
-};
-
-/* all the below structures are in the same memory location of SCRATCHX(1)
- * corresponding arguments for command Id needs to be updated
- */
-
-/* Any command using enable/disable as an argument need
- * to pass the option via this structure.
- * Ex: Loopback, HiGig...
- */
-struct cgx_ctl_args {			/* start from bit 8 */
-	uint64_t reserved1:8;
-	uint64_t enable:1;
-	uint64_t reserved2:55;
-};
-
-/* command argument to be passed for cmd ID - CGX_CMD_SET_MTU */
-struct cgx_mtu_args {
-	uint64_t reserved1:8;
-	uint64_t size:16;
-	uint64_t reserved2:40;
-};
-
-/* command argument to be passed for cmd ID - CGX_CMD_LINK_CHANGE */
-struct cgx_link_change_args {		/* start from bit 8 */
-	uint64_t reserved1:8;
-	uint64_t link_up:1;
-	uint64_t full_duplex:1;
-	uint64_t speed:4;		/* cgx_link_speed */
-	uint64_t reserved2:50;
-};
-
-struct cgx_irq_cfg {
-	uint64_t reserved1:8;
-	uint64_t irq_phys:32;
-	uint64_t reserved2:24;
-};
-
-union cgx_cmdreg {
-	u64 val;
-	struct cgx_cmd cmd;
-	struct cgx_ctl_args cmd_args;
-	struct cgx_mtu_args mtu_size;
-	struct cgx_irq_cfg irq_cfg; /* Input to CGX_CMD_IRQ_ENABLE */
-	struct cgx_link_change_args lnk_args;/* Input to CGX_CMD_LINK_CHANGE */
-	/* any other arg for command id * like : mtu, dmac filtering control */
-};
-
-#endif /* __CGX_FW_INTF_H__ */
diff --git a/drivers/net/cavium/octeontx2/cgx_intf.c b/drivers/net/cavium/octeontx2/cgx_intf.c
index fd7c4df68f..13bcb3d66f 100644
--- a/drivers/net/cavium/octeontx2/cgx_intf.c
+++ b/drivers/net/cavium/octeontx2/cgx_intf.c
@@ -9,7 +9,6 @@
 
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -18,8 +17,8 @@
 #include <linux/list.h>
 #include <asm/arch/octeontx2.h>
 
-#include "cgx.h"
 #include "cgx_intf.h"
+#include "cgx.h"
 
 static u64 cgx_rd_scrx(u8 cgx, u8 lmac, u8 index)
 {
@@ -59,7 +58,7 @@ static void cgx_wr_scr1(u8 cgx, u8 lmac, u64 val)
 	return cgx_wr_scrx(cgx, lmac, 1, val);
 }
 
-static void set_ownership(u8 cgx, u8 lmac, u8 val)
+static inline void set_ownership(u8 cgx, u8 lmac, u8 val)
 {
 	union cgx_scratchx1 scr1;
 	scr1.u = cgx_rd_scr1(cgx, lmac);
@@ -73,19 +72,18 @@ static int wait_for_ownership(u8 cgx, u8 lmac)
 	union cgx_scratchx0 scr0;
 	int timeout = 5000;
 
-	scr1.u = cgx_rd_scr1(cgx, lmac);
-	scr0.u = cgx_rd_scr0(cgx, lmac);
-
-	while (scr1.s.own_status == CGX_OWN_FIRMWARE &&
-		scr0.s.evt_sts.ack) {
+	do {
+	
+		scr1.u = cgx_rd_scr1(cgx, lmac);
+		scr0.u = cgx_rd_scr0(cgx, lmac);
 		if (timeout-- < 0) {
 			debug("timeout waiting for ownership\n");
 			return -ETIMEDOUT;
 		}
 		mdelay(1);
-		scr1.u = cgx_rd_scr1(cgx, lmac);
-		scr0.u = cgx_rd_scr0(cgx, lmac);
-	}
+	} while ((scr1.s.own_status == CGX_OWN_FIRMWARE) &&
+		  scr0.s.evt_sts.ack);
+
 	return 0;
 }
 
@@ -94,10 +92,13 @@ int cgx_intf_req(u8 cgx, u8 lmac, u8 cmd, u64 *rsp)
 	union cgx_scratchx1 scr1;
 	union cgx_scratchx0 scr0;
 	int timeout = 500;
+	int err = 0;
 
-	if (wait_for_ownership(cgx, lmac))
-		return -ETIMEDOUT;
-
+	if (wait_for_ownership(cgx, lmac)) {
+		err = -ETIMEDOUT;
+		goto error;
+	}
+ 
 	set_ownership(cgx, lmac, CGX_OWN_NON_SECURE_FW);
 
 	/* send command */
@@ -107,32 +108,52 @@ int cgx_intf_req(u8 cgx, u8 lmac, u8 cmd, u64 *rsp)
 
 	set_ownership(cgx, lmac, CGX_OWN_FIRMWARE);
 
-	/* wait for response */
+	/* wait for response and ownership */
 	do {
 		scr0.u = cgx_rd_scr0(cgx, lmac);
+		scr1.u = cgx_rd_scr1(cgx, lmac);
 		mdelay(10);
-	} while (timeout-- && ( !scr0.s.evt_sts.ack));
+	} while (timeout-- && ( !scr0.s.evt_sts.ack) &&
+		 (scr1.s.own_status == CGX_OWN_FIRMWARE));
 	if (timeout < 0) {
 		debug("%s timeout waiting for ack\n",__func__);
-		return -1;
+		err = -ETIMEDOUT;
+		goto error;
 	}
-	/* wait for release */
-	do {
-		scr1.u = cgx_rd_scr1(cgx, lmac);
-		mdelay(1);
-	} while (scr1.s.own_status == CGX_OWN_FIRMWARE);
 
 	set_ownership(cgx, lmac, CGX_OWN_NON_SECURE_FW);
 
-	*rsp = scr0.u;
-
+	if (scr0.s.evt_sts.evt_type != CGX_EVT_CMD_RESP) {
+		printf("%s received async event instead of cmd resp event\n",
+			__func__);
+		err = -1;
+		goto error;
+	}
+	if (scr0.s.evt_sts.id != cmd) {
+		printf("%s received resp for cmd %d expected cmd %d \n",
+				__func__, scr0.s.evt_sts.id, cmd);
+		err = -1;
+		goto error;
+	}
+	if (scr0.s.evt_sts.stat != CGX_STAT_SUCCESS) {
+		printf("%s failure for cmd %d on cgx %u lmac %u with errcode"
+			" %d\n", __func__, cmd, cgx, lmac, scr0.s.err.type);
+		err = -1;
+		goto error;
+	}
+	
 	/* clear ownership and ack */
-	scr0.u = cgx_rd_scr0(cgx, lmac);
 	scr0.s.evt_sts.ack = 0;
 	cgx_wr_scr0(cgx, lmac, scr0.u);
 	set_ownership(cgx, lmac, CGX_OWN_NONE);
 
-	return 0;
+	*rsp = scr0.u;
+
+error:
+	if (err)
+		*rsp = 0;
+
+	return err;
 }
 
 
@@ -148,6 +169,7 @@ int cgx_intf_get_mac_addr(u8 cgx, u8 lmac, u8 *mac)
 
 	scr0.u >>= 9;
 	memcpy(mac, &scr0.u, 6);
+
 	return 0;
 }
 
@@ -167,7 +189,7 @@ int cgx_intf_get_ver(u8 cgx, u8 lmac, u8 *ver)
 	return 0;
 }
 
-int cgx_intf_get_link_sts(u8 cgx, u8 lmac, u8 *lnk_sts)
+int cgx_intf_get_link_sts(u8 cgx, u8 lmac, u64 *lnk_sts)
 {
 	union cgx_scratchx0 scr0;
 	int ret;
@@ -185,17 +207,15 @@ int cgx_intf_get_link_sts(u8 cgx, u8 lmac, u8 *lnk_sts)
 	return 0;
 }
 
-int cgx_intf_link_up_dwn(u8 cgx, u8 lmac, u8 up_dwn, u8 *lnk_sts)
+int cgx_intf_link_up_dwn(u8 cgx, u8 lmac, u8 up_dwn, u64 *lnk_sts)
 {
 	union cgx_scratchx0 scr0;
 	int ret;
+	u8 cmd;
 
-	if (up_dwn)
-		ret = cgx_intf_req(cgx, lmac,
-					 CGX_CMD_LINK_BRING_UP, &scr0.u);
-	else
-		ret = cgx_intf_req(cgx, lmac,
-					 CGX_CMD_LINK_BRING_DOWN, &scr0.u);
+	cmd = up_dwn ? CGX_CMD_LINK_BRING_UP : CGX_CMD_LINK_BRING_DOWN;
+
+	ret = cgx_intf_req(cgx, lmac, cmd, &scr0.u);
 	if (ret)
 		return -1;
 
@@ -214,6 +234,3 @@ void cgx_intf_shutdown(void)
 	cgx_intf_req(0, 0, CGX_CMD_INTF_SHUTDOWN, &scr0.u);
 }
 
-
-
-
diff --git a/drivers/net/cavium/octeontx2/cgx_intf.h b/drivers/net/cavium/octeontx2/cgx_intf.h
index 67dee06d62..a46ea03b24 100644
--- a/drivers/net/cavium/octeontx2/cgx_intf.h
+++ b/drivers/net/cavium/octeontx2/cgx_intf.h
@@ -7,15 +7,11 @@
  * the License, or (at your option) any later version.
  */
 
-#ifndef __OCTEONTX2_CGX_INTF_H__
-#define __OCTEONTX2_CGX_INTF_H__
-
-#define PCI_DEVICE_ID_OCTEONTX2_CGX	0xA059
+#ifndef __CGX_INTF_H__
+#define __CGX_INTF_H__
 
 #define CGX_FIRWARE_MAJOR_VER		1
 #define CGX_FIRWARE_MINOR_VER		0
-#define MAX_LMAC_PER_CGX		4
-#define CGX_PER_NODE 			3
 
 /* Register offsets */
 #define CGX_CMR_SCRATCH0	0x87e0e0001050
@@ -41,10 +37,14 @@ enum cgx_error_type {
 	CGX_ERR_SPUX_TX_FAULT,
 	CGX_ERR_SPUX_RX_FAULT,
 	CGX_ERR_SPUX_RESET_FAIL,
+	CGX_ERR_SPUX_AN_RESET_FAIL,
+	CGX_ERR_SPUX_USX_AN_RESET_FAIL,
 	CGX_ERR_SMUX_RX_LINK_NOT_OK,
 	CGX_ERR_PCS_RECV_LINK_FAIL,
 	CGX_ERR_TRAINING_FAIL,
-	CGX_ERR_RX_EQU_FAIL,		/* = 18 */
+	CGX_ERR_RX_EQU_FAIL,
+	CGX_ERR_SPUX_BER_FAIL,
+	CGX_ERR_SPUX_RSFEC_ALGN_FAIL,	/* = 22 */
 	/* FIXME : add more error types when adding support for new modes */
 };
 
@@ -54,11 +54,15 @@ enum cgx_link_speed {
 	CGX_LINK_10M,
 	CGX_LINK_100M,
 	CGX_LINK_1G,
+	CGX_LINK_2HG,	/* 2.5 Gbps */
+	CGX_LINK_5G,
 	CGX_LINK_10G,
+	CGX_LINK_20G,
 	CGX_LINK_25G,
 	CGX_LINK_40G,
 	CGX_LINK_50G,
 	CGX_LINK_100G,
+	CGX_LINK_MAX,
 };
 
 /* REQUEST ID types. Input to firmware */
@@ -144,7 +148,7 @@ struct cgx_ver_s {			/* start from bit 9 */
 };
 
 /* Resp to cmd ID as CGX_CMD_GET_MAC_ADDR with cmd status as CGX_STAT_SUCCESS
- * Returns each byte of MAC address in a seperate bit field
+ * Returns each byte of MAC address in a separate bit field
  */
 struct cgx_mac_addr_s {			/* start from bit 9 */
 	uint64_t reserved1:9;
@@ -202,7 +206,7 @@ struct cgx_cmd {			/* start from bit 2 */
 };
 
 /* all the below structures are in the same memory location of SCRATCHX(1)
- * corresponding arguements for command Id needs to be updated
+ * corresponding arguments for command Id needs to be updated
  */
 
 /* Any command using enable/disable as an argument need
@@ -245,4 +249,4 @@ union cgx_scratchx1 {
 	union cgx_cmd_s s;
 };
 
-#endif
+#endif /* __CGX_INTF_H__ */
diff --git a/drivers/net/cavium/octeontx2/lmt.h b/drivers/net/cavium/octeontx2/lmt.h
index 61b92f62f1..8018b801df 100644
--- a/drivers/net/cavium/octeontx2/lmt.h
+++ b/drivers/net/cavium/octeontx2/lmt.h
@@ -32,12 +32,12 @@ static inline s64 cavm_atomic_fetch_and_add64_nosync(s64 *ptr, s64 incr)
 	return result;
 }
 
-static inline void cavm_lmt_cancel(const struct nix_handle *nix)
+static inline void cavm_lmt_cancel(const struct nix *nix)
 {
 	writeq(0, nix->lmt_base + CAVM_LMT_LF_LMTCANCEL());
 }
 
-static inline volatile u64 *cavm_lmt_store_ptr(struct nix_handle *nix)
+static inline volatile u64 *cavm_lmt_store_ptr(struct nix *nix)
 {
 	return (volatile u64 *)((u8 *)(nix->lmt_base) +
 				       CAVM_LMT_LF_LMTLINEX(0));
diff --git a/drivers/net/cavium/octeontx2/lmt_hw.h b/drivers/net/cavium/octeontx2/lmt_hw.h
deleted file mode 100644
index 41c47c34f6..0000000000
--- a/drivers/net/cavium/octeontx2/lmt_hw.h
+++ /dev/null
@@ -1,51 +0,0 @@
-/* This file is auto-generated. Do not edit */
-
-/***********************license start***************
- * Copyright (c) 2003-2018  Cavium Inc. (support@cavium.com). All rights
- * reserved.
- *
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *
- *   * Redistributions in binary form must reproduce the above
- *     copyright notice, this list of conditions and the following
- *     disclaimer in the documentation and/or other materials provided
- *     with the distribution.
-
- *   * Neither the name of Cavium Inc. nor the names of
- *     its contributors may be used to endorse or promote products
- *     derived from this software without specific prior written
- *     permission.
-
- * This Software, including technical data, may be subject to U.S. export
- * control laws, including the U.S. Export Administration Act and its
- * associated regulations, and may be subject to export or import regulations
- * in other countries.
-
- * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
- * AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
- * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
- * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
- * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
- * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
- * OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
- * PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT,
- * QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING
- * OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
- ***********************license end**************************************/
-
-#ifndef __LMT_HW_H__
-#define __LMT_HW_H__
-
-/* Register offsets */
-
-#define CAVM_LMT_LF_LMTLINEX(a)    (0x0ull | (u64)(a) << 3)
-#define CAVM_LMT_LF_LMTCANCEL      (0x400ull)
-
-
-#endif /* __LMT_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/lmt_reg.h b/drivers/net/cavium/octeontx2/lmt_reg.h
deleted file mode 100644
index 6f57996f6d..0000000000
--- a/drivers/net/cavium/octeontx2/lmt_reg.h
+++ /dev/null
@@ -1,22 +0,0 @@
-
-/* Register definitions */
-
-/**
- * RVU VF LMT Line Registers
- */
-union cavm_lmt_lf_lmtlinex {
-	u64 u;
-	struct lmt_lf_lmtlinex_s {
-		u64 data;                           
-	} s;
-};
-
-/**
- * RVU VF LMT Cancel Register
- */
-union cavm_lmt_lf_lmtcancel {
-	u64 u;
-	struct lmt_lf_lmtcancel_s {
-		u64 data;                           
-	} s;
-};
diff --git a/drivers/net/cavium/octeontx2/nix.c b/drivers/net/cavium/octeontx2/nix.c
index b220ba9bd6..19b8def90f 100644
--- a/drivers/net/cavium/octeontx2/nix.c
+++ b/drivers/net/cavium/octeontx2/nix.c
@@ -9,7 +9,6 @@
 
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -19,67 +18,13 @@
 #include <asm/types.h>
 #include <asm/io.h>
 #include <linux/types.h>
+#include <linux/log2.h>
 #include <asm/arch/octeontx2.h>
-#include "cavm-csrs-nix.h"
-#include "cavm-csrs-npa.h"
 #include "cavm-csrs-lmt.h"
-#include "rvu_common.h"
 #include "nix.h"
 #include "lmt.h"
 #include "cgx.h"
 
-#define CAVM_NUMA_MAX_NODES	2	/** TODO: Move this elsewhere */
-#define CAVM_MAX_GATHER		1	/** Maximum scatter/gather */
-
-/** Offset from RVU PFVF BAR 2 */
-#define CAVM_LMT_LMTLINE(x)		((x) * 0x8)
-#define CAVM_LMT_LF_LMTCANCEL		(0x400)
-
-static const int USE_SSO = 0;	/** Do not use SSO, use completion queues */
-static const int MAX_MTU = 9212;/** Maximum packet size */
-static const int MAX_CQS = 32;	/** Maximum of 32 completion queues */
-static const int MAX_SQS = 32;	/** Maximum of 32 send queues */
-static const int MAX_RQS = 32;	/** Maximum of 32 receive queues */
-/** Size of RSS table (256) See NIX_AF_LFX_RSS_CFG[size] */
-static const int RSS_SIZE = 0;
-/** Each completion queue contains 256 entries, see NIC_CQ_CTX_S[qsize] */
-static const unsigned int CQS_QSIZE = 2;
-/** Number of CQ entries */
-static const unsigned int CQ_ENTRIES = 16 << (2 /*CQS_QSIZE*/ * 2);
-static const int AQ_RING_SIZE = 16 << (AQ_SIZE * 2);
-/**
- * Each completion queue entry contains 512 bytes, see
- * NIXX_AF_LFX_CFG[xqe_size]
- */
-static const int CQ_ENTRY_SIZE = 512;
-
-struct nix_node_state {
-	int next_free_lf;
-	int next_free_sq;
-	int next_free_rq;
-	int next_free_cq;
-	int next_free_rssi;
-	int next_free_bpid;
-};
-
-/* Globals */
-static struct nix_node_state global_node_state[CAVM_NUMA_MAX_NODES];
-static const struct pci_device_id npc_devid = {
-
-};
-
-#if 0
-static u64 npc_reg_read(struct nix_handle *nix, u64 offset)
-{
-	return readq(nix->npc_base + offset);
-}
-
-static void npc_reg_write(struct nix_handle *nix, u64 offset, u64 val)
-{
-	writeq(val, nix->npc_base + offset);
-}
-#endif
-
 /**
  * NIX needs a lot of memory areas. Rather than handle all the failure cases,
  * we'll use a wrapper around alloc that prints an error if a memory
@@ -88,7 +33,7 @@ static void npc_reg_write(struct nix_handle *nix, u64 offset, u64 val)
  * @param num_elements
  *                  Number of elements to allocate
  * @param elem_size Size of each element
- * @param msge      Text string to show when allocation fails
+ * @param msg       Text string to show when allocation fails
  *
  * @return A valid memory location or NULL on failure
  */
@@ -104,10 +49,26 @@ static void *nix_memalloc(int num_elements, size_t elem_size, const char *msg)
 	else
 		memset(base, 0, alloc_size);
 
+	debug("NIX: Memory alloc for %s (%d * %zu = %zu bytes) at %p\n",
+	       msg ? msg : __func__, num_elements, elem_size,
+	       alloc_size, base);
 	return base;
 }
 
-static int npa_setup_pool(struct nix_handle *nix, u32 pool_id,
+int npc_lf_setup(struct nix *nix)
+{
+	int err;
+
+	err = npc_lf_admin_setup(nix);
+	if (err) {
+		printf("%s: Error setting up npc lf admin\n", __func__);
+		return err;
+	}
+
+	return 0;
+}
+
+static int npa_setup_pool(struct npa *npa, u32 pool_id,
 			  size_t buffer_size, u32 queue_length, void *buffers[])
 {
 	struct {
@@ -124,6 +85,8 @@ static int npa_setup_pool(struct nix_handle *nix, u32 pool_id,
 			       __func__, index, buffer_size);
 			return -ENOMEM;
 		}
+		debug("%s: allocating buffer %d, addr %p size: %zu\n",
+		       __func__, index, buffers[index], buffer_size);
 
 		/* Add the newly obtained pointer to the pool.  128 bit
 		 * writes only.
@@ -132,132 +95,155 @@ static int npa_setup_pool(struct nix_handle *nix, u32 pool_id,
 		aura_descr.f1.u = 0;
 		aura_descr.f1.s.fabs = 1;
 		aura_descr.f1.s.aura = pool_id;
-		cavm_st128(nix->npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
+		cavm_st128(npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
 			   aura_descr.f0.u, aura_descr.f1.u);
 	}
 
 	return 0;
 }
 
-static int npa_lf_setup(struct nix_handle *nix)
+int npa_lf_setup(struct nix *nix)
 {
-	struct npa_handle *npa = nix->npa;
-	struct nix_af_handle *nix_af = nix->nix_af;
-	union cavm_npa_aura_s aura_ctx[NPA_POOL_COUNT];
-	union cavm_npa_pool_s pool_ctx[NPA_POOL_COUNT];
+	struct rvu_pf *rvu = dev_get_priv(nix->dev);
+	struct nix_af *nix_af = nix->nix_af;
+	struct npa *npa; 
 	union cavm_npa_af_const npa_af_const;
-	int pool;
-	int queue_len[NPA_POOL_COUNT];
-	int buffer_size[NPA_POOL_COUNT];
+	union cavm_npa_aura_s *aura;
+	union cavm_npa_pool_s *pool;
+	union cavm_rvu_func_addr_s block_addr;
+	int idx;
 	int stack_page_pointers;
 	int stack_page_bytes;
 	int err;
-	int lf = 0;
 
-	npa->aura_ctx = memalign(CONFIG_SYS_CACHELINE_SIZE,
-				 NPA_AURA_HW_CTX_SIZE * NPA_POOL_COUNT);
-	if (!npa->aura_ctx) {
-		printf("%s: Out of memory for aura context\n", __func__);
+	npa = (struct npa *)calloc(1, sizeof(struct npa));
+	if (!npa) {
+		printf("%s: out of memory for npa instance\n", __func__);
 		return -ENOMEM;
 	}
-	npa_af_const.u = npa_af_reg_read(nix->nix_af->npa_af,
-					 CAVM_NPA_AF_CONST());
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPA;
+	npa->npa_base = rvu->pf_base + block_addr.u;
+	npa->npa_af = nix_af->npa_af;
+	nix->npa = npa;
+
+	npa_af_const.u = npa_af_reg_read(npa->npa_af, CAVM_NPA_AF_CONST());
 	stack_page_pointers = npa_af_const.s.stack_page_ptrs;
 	stack_page_bytes = npa_af_const.s.stack_page_bytes;
-	npa->rx_pool_stack_pages = (RQ_QLEN + stack_page_pointers - 1) /
+
+	npa->stack_pages[NPA_POOL_RX] = (RQ_QLEN + stack_page_pointers - 1) /
 							stack_page_pointers;
-	npa->tx_pool_stack_pages = (SQ_QLEN + stack_page_pointers - 1) /
+	npa->stack_pages[NPA_POOL_TX] = (SQ_QLEN + stack_page_pointers - 1) /
 							stack_page_pointers;
-
 	npa->pool_stack_pointers = stack_page_pointers;
 
 	npa->q_len[NPA_POOL_RX] = RQ_QLEN;
 	npa->q_len[NPA_POOL_TX] = SQ_QLEN;
 
-	npa->buf_size[NPA_POOL_RX] = NIX_MAX_HW_MTU + CONFIG_SYS_CACHELINE_SIZE;
-	npa->buf_size[NPA_POOL_TX] = NIX_MAX_HW_MTU + CONFIG_SYS_CACHELINE_SIZE;
+	npa->buf_size[NPA_POOL_RX] = MAX_MTU + CONFIG_SYS_CACHELINE_SIZE;
+	npa->buf_size[NPA_POOL_TX] = nix_af->sqb_size;
 
-	npa->stack_pages[NPA_POOL_RX] = npa->rx_pool_stack_pages;
-	npa->stack_pages[NPA_POOL_TX] = npa->tx_pool_stack_pages;
+	npa->rx_pool_stack_pages = npa->stack_pages[NPA_POOL_RX];
+	npa->tx_pool_stack_pages = npa->stack_pages[NPA_POOL_TX];
 
-	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
-		npa->pool_ctx[pool] = memalign(CONFIG_SYS_CACHELINE_SIZE,
-					       npa->stack_pages[pool] *
-					       sizeof(union cavm_npa_pool_s));
-		if (!npa->pool_ctx[pool]) {
+	npa->aura_ctx = nix_memalloc(NPA_POOL_COUNT, sizeof(union cavm_npa_aura_s),
+					"aura context");
+	if (!npa->aura_ctx) {
+		printf("%s: Out of memory for aura context\n", __func__);
+		return -ENOMEM;
+	}
+
+	for (idx = 0; idx < NPA_POOL_COUNT; idx++) {
+		npa->pool_ctx[idx] = nix_memalloc(1, sizeof(union cavm_npa_pool_s),
+							"pool context");
+		if (!npa->pool_ctx[idx]) {
 			printf("%s: Out of memory for pool context\n",
 			       __func__);
 			return -ENOMEM;
 		}
-		npa->pool_stack[pool] = memalign(CONFIG_SYS_CACHELINE_SIZE,
-						 npa->stack_pages[pool] *
-						 stack_page_bytes);
-		if (!npa->pool_stack[pool]){
+		npa->pool_stack[idx] = nix_memalloc(npa->stack_pages[idx],
+							 stack_page_bytes,
+							 "pool stack");
+		if (!npa->pool_stack[idx]){
 			printf("%s: Out of memory for pool stack\n", __func__);
 			return -ENOMEM;
 		}
 	}
+
+	err = npa_lf_admin_setup(npa, nix->lf, (dma_addr_t) npa->aura_ctx);
+	if (err) {
+		printf("%s: Error setting up NPA LF admin for lf %d\n",
+		       __func__, nix->lf);
+		return err;
+	}
+
 	/* Set up the auras */
-	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
-		union cavm_npa_aura_s *aura = &aura_ctx[pool];
-		union cavm_npa_pool_s *poo = &pool_ctx[pool];
+	for (idx = 0; idx < NPA_POOL_COUNT; idx++) {
+		aura = npa->aura_ctx + (idx * sizeof(union cavm_npa_aura_s));
+		pool = npa->pool_ctx[idx];
+		debug("%s aura %p pool %p\n",__func__,aura,pool);
 		memset(aura, 0, sizeof(union cavm_npa_aura_s));
 		aura->s.fc_ena = 0;
-		aura->s.pool_addr = (u64)&npa->pool_ctx[pool];
-		aura->s.shift = 64 - __builtin_clzll(npa->q_len[pool]) - 8;
-		aura->s.count = npa->q_len[pool];
-		aura->s.limit = npa->q_len[pool];
+		aura->s.pool_addr = (u64)npa->pool_ctx[idx];
+		debug("%s aura.s.pool_addr %llx pool_addr %p\n",__func__,
+			aura->s.pool_addr,npa->pool_ctx[idx]);
+		aura->s.shift = 64 - __builtin_clzll(npa->q_len[idx]) - 8;
+		aura->s.count = npa->q_len[idx];
+		aura->s.limit = npa->q_len[idx];
 		aura->s.ena = 1;
+		err = npa_attach_aura(nix_af, nix->lf, aura, idx);
+		if (err)
+			return err;
 
-		memset(poo, 0, sizeof(*poo));
-		poo->s.fc_ena = 0;
-		poo->s.stack_base = (u64)(&npa->pool_stack[pool]);
-		poo->s.buf_size = npa->buf_size[pool];
-		poo->s.stack_max_pages = npa->stack_pages[pool];
-		poo->s.shift =
+		memset(pool, 0, sizeof(*pool));
+		pool->s.fc_ena = 0;
+		pool->s.nat_align = 1;
+		pool->s.stack_base = (u64)(npa->pool_stack[idx]);
+		debug("%s pool.s.stack_base %llx stack_base %p\n",__func__,
+			pool->s.stack_base,npa->pool_stack[idx]);
+		pool->s.buf_size = 
+			npa->buf_size[idx]/CONFIG_SYS_CACHELINE_SIZE;
+		pool->s.stack_max_pages = npa->stack_pages[idx];
+		pool->s.shift =
 			64 - __builtin_clzll(npa->pool_stack_pointers) - 8;
-		poo->s.ptr_start = 0;
-		poo->s.ptr_end = (1ULL << 40) -  1;
-		poo->s.ena = 1;
-	}
-
-	err = npa_lf_admin_setup(nix_af, lf, NPA_AURA_SIZE_DEFAULT,
-				 aura_ctx, (dma_addr_t)&(npa->aura_ctx),
-				 pool_ctx, NPA_POOL_COUNT);
-	if (err) {
-		printf("%s: Error setting up NPA LF admin for lf %d\n",
-		       __func__, lf);
-		return err;
+		pool->s.ptr_start = 0;
+		pool->s.ptr_end = (1ULL << 40) -  1;
+		pool->s.ena = 1;
+		err = npa_attach_pool(nix_af, nix->lf, pool, idx);
+		if (err)
+			return err;
 	}
 
-	npa->rx_buffers = calloc(queue_len[NPA_POOL_RX], sizeof(void *));
+	npa->rx_buffers = nix_memalloc(npa->q_len[NPA_POOL_RX], sizeof(void *),
+					"rx_buffers");
 	if (!npa->rx_buffers) {
 		printf("%s: Out of memory\n", __func__);
 		return -ENOMEM;
 	}
 
-	npa->tx_buffers = calloc(queue_len[NPA_POOL_TX], sizeof(void *));
+	npa->tx_buffers = nix_memalloc(npa->q_len[NPA_POOL_TX], sizeof(void *),
+					"tx_buffers");
 	if (!npa->tx_buffers) {
 		printf("%s: Out of memory\n", __func__);
 		return -ENOMEM;
 	}
 
-	for (pool = 0; pool < NPA_POOL_COUNT; pool++) {
-		err = npa_setup_pool(nix, pool, buffer_size[pool],
-				     queue_len[pool], pool == NPA_POOL_RX ?
+	for (idx = 0; idx < NPA_POOL_COUNT; idx++) {
+		err = npa_setup_pool(npa, idx, npa->buf_size[idx],
+				     npa->q_len[idx], idx == NPA_POOL_RX ?
 				     npa->rx_buffers : npa->tx_buffers);
 		if (err) {
 			printf("%s: Error setting up pool %d\n",
-			       __func__, pool);
+			       __func__, idx);
 			return err;
 		}
 	}
 	return 0;
 }
 
-int npa_lf_shutdown(struct nix_handle *nix)
+int npa_lf_shutdown(struct nix *nix)
 {
-	struct npa_handle *npa = nix->npa;
+	struct npa *npa = nix->npa;
 	int err;
 	int pool;
 
@@ -285,109 +271,64 @@ int npa_lf_shutdown(struct nix_handle *nix)
 	return 0;
 }
 
-int nix_rx_tx_iface_setup(struct nix_handle *nix)
-{
-	union cavm_nixx_af_rx_linkx_cfg link_cfg;
-
-	link_cfg.u = 0;
-	link_cfg.s.maxlen = NIX_MAX_HW_MTU;
-	link_cfg.s.minlen = NIX_MIN_HW_MTU;
-	nix_af_reg_write(nix->nix_af,
-			 CAVM_NIXX_AF_RX_LINKX_CFG(nix->lmac->lmac_id),
-			 link_cfg.u);
-
-	return 0;
-}
-
-int nix_lf_setup(struct nix_handle *nix)
+int nix_lf_setup(struct nix *nix)
 {
-	union cavm_nix_rq_ctx_s rq;
-	union cavm_nix_sq_ctx_s sq;
-	union cavm_nix_cq_ctx_s cq[NIX_CQ_COUNT];
-	int index;
-	int err;
-	bool admin_setup = false;
+	struct nix_af *nix_af = nix->nix_af;
+	int idx;
+	int err = -1;
 
-	nix->rq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
-				    sizeof(union cavm_nix_rq_ctx_hw_s));
-	if (!nix->rq_ctx_base) {
-		printf("%s: Out of memory\n", __func__);
-		return -ENOMEM;
-	}
-	memset(nix->rq_ctx_base, 0, sizeof(union cavm_nix_rq_ctx_hw_s));
-
-	nix->sq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
-				    sizeof(union cavm_nix_sq_ctx_hw_s));
-	if (!nix->sq_ctx_base) {
-		printf("%s: Out of memory\n", __func__);
-		err = -ENOMEM;
+	/* Alloc NIX RQ HW context memory */
+	nix->rq_ctx_base = nix_memalloc(nix->rq_cnt, nix_af->rq_ctx_sz,
+					"RQ CTX");
+	if (!nix->rq_ctx_base)
 		goto error;
-	}
-	memset(nix->sq_ctx_base, 0, sizeof(union cavm_nix_sq_ctx_hw_s));
+	memset(nix->rq_ctx_base, 0, nix_af->rq_ctx_sz);
 
-	nix->cq_ctx_base = memalign(CONFIG_SYS_CACHELINE_SIZE,
-				sizeof(union cavm_nix_cq_ctx_s) * NIX_CQ_COUNT);
-	if (!nix->cq_ctx_base) {
-		printf("%s: Out of memory\n", __func__);
-		err = -ENOMEM;
+	/* Alloc NIX SQ HW context memory */
+	nix->sq_ctx_base = nix_memalloc(nix->sq_cnt, nix_af->sq_ctx_sz,
+					"SQ CTX");
+	if (!nix->sq_ctx_base)
 		goto error;
-	}
-	memset(nix->cq_ctx_base, 0,
-	       sizeof(union cavm_nix_cq_ctx_s) * NIX_CQ_COUNT);
+	memset(nix->sq_ctx_base, 0, nix_af->sq_ctx_sz);
 
-	for (index = 0; index < NIX_CQ_COUNT; index++) {
-		err = qmem_alloc(&nix->cq[index], NIX_CQE_SIZE_W64,
-				 Q_COUNT(Q_SIZE_256));
-		if (err) {
-			printf("%s: Error allocating completion queue\n",
-			       __func__);
+	/* Alloc NIX CQ HW context memory */
+	nix->cq_ctx_base = nix_memalloc(nix->cq_cnt, nix_af->cq_ctx_sz,
+					"CQ CTX");
+	if (!nix->cq_ctx_base)
+		goto error;
+	memset(nix->cq_ctx_base, 0, nix_af->cq_ctx_sz * NIX_CQ_COUNT);
+	/* Alloc NIX CQ Ring memory */
+	for (idx = 0; idx < NIX_CQ_COUNT; idx++) {
+		err = qmem_alloc(&(nix->cq[idx]), CQ_ENTRIES, CQ_ENTRY_SIZE);
+		if (err)
 			goto error;
-		}
 	}
 
-	for (index = 0; index < NIX_CQ_COUNT; index++) {
-		memset(&cq[index], 0, sizeof(union cavm_nix_cq_ctx_s));
-
-		cq[index].s.qsize = Q_SIZE_256;
-		cq[index].s.ena = 1;
-		cq[index].s.caching = 1;
-		cq[index].s.base = nix->cq[index].iova;
-		cq[index].s.cint_idx = 0;
-	}
+	/* Alloc memory for Qints HW contexts */
+	nix->qint_base = nix_memalloc(nix_af->qints, nix_af->qint_ctx_sz,
+					"Qint CTX");
+	if (!nix->qint_base)
+		goto error;
+	/* Alloc memory for CQints HW contexts */
+	nix->cint_base = nix_memalloc(nix_af->cints, nix_af->cint_ctx_sz,
+					"Cint CTX");
+	if (!nix->cint_base)
+		goto error;
+	/* Alloc NIX RSS HW context memory and config the base */
+	nix->rss_base = nix_memalloc(nix->rss_grps, nix_af->rsse_ctx_sz,
+					"RSS CTX");
+	if (!nix->rss_base)
+		goto error;
 
-	memset(&sq, 0, sizeof(union cavm_nix_sq_ctx_s));
-	sq.s.cq = NIX_CQ_TX;
-	sq.s.max_sqe_size = CAVM_NIX_MAXSQESZ_E_W16;
-	sq.s.cq_ena = 1;
-	sq.s.ena = 1;
-	sq.s.sqb_aura = NPA_POOL_TX;
-	sq.s.sqe_stype = CAVM_NIX_STYPE_E_STF;
-	sq.s.default_chan = nix->lmac->lmac_id;
-
-	err = nix_lf_admin_setup(nix->nix_af, nix->lf, nix->pf,
-				 cq, (dma_addr_t)nix->cq_ctx_base, NIX_CQ_COUNT,
-				 &rq, (dma_addr_t)nix->rq_ctx_base, 1,
-				 &sq, (dma_addr_t)nix->sq_ctx_base, 1);
+	err = nix_lf_admin_setup(nix);
 	if (err) {
 		printf("%s: Error setting up LF\n", __func__);
 		goto error;
 	}
-	admin_setup = true;
-
-	memset(nix->send_descriptors, 0, sizeof(nix->send_descriptors));
-	for (index = 0; index < SQ_QLEN; index++) {
-		nix->send_descriptors[index].hdr.s.sqe_id = index;
-		nix->free_send_descriptors[index] =
-			&nix->send_descriptors[index];
-	}
-
-	nix->current_free_send_descriptor = 0;
 
 	return 0;
-error:
-	if (admin_setup)
-		nix_lf_admin_shutdown(nix->nix_af, nix->lf, NIX_CQ_COUNT, 1, 1);
 
+error:
 	if (nix->rq_ctx_base)
 		free(nix->rq_ctx_base);
 	nix->rq_ctx_base = NULL;
@@ -401,15 +342,15 @@ error:
 		free(nix->cq_ctx_base);
 	nix->cq_ctx_base = NULL;
 
-	for (index = 0; index < NIX_CQ_COUNT; index++)
-		qmem_free(&nix->cq[index]);
+	for (idx = 0; idx < NIX_CQ_COUNT; idx++)
+		qmem_free(&nix->cq[idx]);
 
 	return err;
 }
 
-int nix_lf_shutdown(struct nix_handle *nix)
+int nix_lf_shutdown(struct nix *nix)
 {
-	struct nix_af_handle *nix_af = nix->nix_af;
+	struct nix_af *nix_af = nix->nix_af;
 	int index;
 	int err;
 
@@ -438,1168 +379,409 @@ int nix_lf_shutdown(struct nix_handle *nix)
 	return 0;
 }
 
-struct nix_tx_descr *nix_alloc_send_descriptor(struct nix_handle *nix)
-{
-	if (nix->current_free_send_descriptor == SQ_QLEN)
-		return NULL;
 
-	return nix->free_send_descriptors[nix->current_free_send_descriptor++];
-}
-
-void nix_free_send_descriptor(struct nix_handle *nix,
-			      struct nix_tx_descr *tx_descr)
-{
-	nix->free_send_descriptors[nix->current_free_send_descriptor] =
-		tx_descr;
-}
-
-static inline void nix_write_lmt(struct nix_handle *nix, void *buffer,
-				 int num_words)
+struct nix *nix_lf_alloc(struct udevice *dev)
 {
-	int i;
-	u64 *ptr = buffer;
-
-	for (i = 0; i < num_words; i++)
-		writeq(ptr[i], nix->lmt_base + CAVM_LMT_LF_LMTLINEX(i));
-}
+	union cavm_rvu_func_addr_s block_addr;
+	struct nix *nix;
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct rvu_af *rvu_af = dev_get_priv(rvu->afdev);
+	union cavm_rvu_pf_func_s pf_func;
+	int err;
 
-static int nix_xmit(struct eth_device *netdev, void *pkt, int pkt_len)
-{
-	struct nix_handle *nix = netdev->priv;
-	struct nix_tx_descr *tx_descr;
-	const int descr_size = (sizeof(struct nix_tx_descr) + 15) / 16 - 1;
-	s64 result;
+	debug("%s(%s )\n", __func__, dev->name);
 
-	tx_descr = nix_alloc_send_descriptor(nix);
-	if (!tx_descr) {
-		printf("%s: Error: out of tx descriptors\n", __func__);
-		return -1;
+	nix = (struct nix *)calloc(1, sizeof(*nix));
+	if (!nix) {
+		printf("%s: Out of memory for nix instance\n", __func__);
+		return NULL;
 	}
-	tx_descr->hdr.s.aura = 0xa5a5;
-	tx_descr->hdr.s.df = 1;
-	tx_descr->hdr.s.pnc = 1;
-	tx_descr->hdr.s.sq = 0;
-	tx_descr->hdr.s.total = pkt_len;
-	tx_descr->hdr.s.sizem1 = descr_size;
-	tx_descr->segments.s.segs = 1;
-	tx_descr->segments.s.subdc = CAVM_NIX_SUBDC_E_SG;
-	tx_descr->segments.s.seg1_size = pkt_len;
-	tx_descr->segments.s.ld_type = CAVM_NIX_SENDLDTYPE_E_LDT;
-	tx_descr->dev_addr = (dma_addr_t)pkt;
-	tx_descr->host_addr = pkt;
+	nix->nix_af = rvu_af->nix_af;
+
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
+	nix->nix_base = rvu->pf_base + block_addr.u;
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
+	nix->npc_base = rvu->pf_base + block_addr.u;
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_LMT;
+	nix->lmt_base = rvu->pf_base + block_addr.u;
+
+	pf_func.u = 0;
+	pf_func.s.pf = rvu->pfid;
+	nix->pf_func = pf_func.u;
+	nix->lf = rvu->nix_lfid;
+	nix->pf = rvu->pfid;
+	nix->dev = dev;
+	nix->sq_cnt = nix->rq_cnt = nix->rss_grps = 1;
+	nix->cq_cnt = 2;
+	nix->xqe_sz = NIX_CQE_SIZE_W16; 
+
+	nix->lmac = nix_get_cgx_lmac(nix->pf);
+	if (!nix->lmac) {
+		printf("%s: Error: could not find lmac for pf %d\n",
+		       __func__, nix->pf);
+		free(nix);
+		return NULL;
+	}
+	nix->lmac->link_num =
+		CAVM_NIX_LINK_E_CGXX_LMACX(nix->lmac->cgx->cgx_id,
+					   nix->lmac->lmac_id);
+	nix->lmac->chan_num =
+		CAVM_NIX_CHAN_E_CGXX_LMACX_CHX(nix->lmac->cgx->cgx_id,
+						nix->lmac->lmac_id, 0);
+	/* This is rx pkind in 1:1 mapping to NIX_LINK_E */
+	nix->lmac->pknd = nix->lmac->link_num;
+
+	cgx_lmac_set_pkind(nix->lmac, nix->lmac->lmac_id, nix->lmac->pknd);
+	debug("%s(%s CGX%x LMAC%x)\n", __func__, dev->name,
+			nix->lmac->cgx->cgx_id, nix->lmac->lmac_id);
+	debug("%s(%s Link %x Chan %x Pknd %x)\n", __func__, dev->name,
+			nix->lmac->link_num, nix->lmac->chan_num,
+			nix->lmac->pknd);
+
+	err = npa_lf_setup(nix);
+	if (err)
+		return NULL;
+	
+	err = npc_lf_setup(nix);
+	if (err)
+		return NULL;
 
-	do {
-		nix_write_lmt(nix, tx_descr, sizeof(*tx_descr) / sizeof(u64));
-		__iowmb();
-		result = cavm_lmt_submit((u64)(nix->nix_base +
-					       CAVM_NIXX_LF_OP_SENDX(0)));
-		WATCHDOG_RESET();
-	} while (result == 0);
+	err = nix_lf_setup(nix);
+	if (err)
+		return NULL;
 
-	return 0;
+	return nix;
 }
 
-int nix_get_pf_num(const struct nix_handle *nix)
+u64 nix_cq_op_status(struct nix *nix, u64 cq_id)
 {
-	return (((u64)(nix->nix_base)) >> 36) & 0x0f;
-}
+	union cavm_nixx_lf_cq_op_status op_status;
 
-int nix_linear_link_number(const struct nix_handle *nix)
-{
-	return nix_get_pf_num(nix) - 1;
+	op_status.u = cavm_atomic_fetch_and_add64_nosync(
+			nix->nix_base + CAVM_NIXX_LF_CQ_OP_STATUS(),
+			(u64)cq_id << 32);
+	return op_status.u;
 }
 
-int npc_lf_setup(struct nix_handle *nix)
+/* TX */
+int nix_alloc_tx_dr(struct nix *nix)
 {
-	struct nix_af_handle *nix_af = nix->nix_af;
-	int link_num = nix_linear_link_number(nix);
-	int err;
+	int i;
 
-	err = npc_lf_admin_setup(nix_af, nix->lmac->cgx, link_num);
-	if (err) {
-		printf("%s: Error setting up npc lf admin\n", __func__);
-		return err;
+	for (i = 0; i < (SQ_QLEN*2); i++) {
+		if (nix->tx_desc[i].in_use == 0) {
+	debug("%s i%d tx_desc %p  in_use %llx\n", __func__,
+		 i, &nix->tx_desc[i], nix->tx_desc[i].in_use);
+			return i;
+		}
 	}
+	return -1;
+}
 
-	return 0;
+void nix_free_tx_dr(struct nix *nix, int sqe_id)
+{
+	debug("%s sqe_id %d\n", __func__, sqe_id);
+	nix->tx_desc[sqe_id].in_use = 0;
 }
 
-int nix_rx_tx_completion(struct nix_handle *nix, uint queue_idx,
-			 u32 *completion_type)
+static inline void nix_write_lmt(struct nix *nix, void *buffer,
+				 int num_words)
 {
-	union cavm_nixx_lf_cq_op_status op_status;
-	union cavm_nix_cqe_hdr_s *completion;
-	u32 head, tail;
+	int i;
+	volatile u64 *lmt_ptr = cavm_lmt_store_ptr(nix);
+	u64 *ptr = buffer;
 
-	op_status.u =
-		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
-						   CAVM_NIXX_LF_CQ_OP_STATUS(),
-						   (u64)queue_idx << 32);
-	head = op_status.s.head;
-	tail = op_status.s.tail;
-	if (head != tail) {
-		head &= (nix->cq[queue_idx].qsize - 1);
-		tail &= (nix->cq[queue_idx].qsize - 1);
-		completion = (union cavm_nix_cqe_hdr_s *)
-					(nix->cq[queue_idx].base) + head;
-		debug("%s: completion: %p (%d)\n", __func__, completion,
-		      completion->s.cqe_type);
-		*completion_type = completion->s.cqe_type;
+	debug("%s lmt_ptr %p %p\n", __func__, nix->lmt_base, lmt_ptr);
+	for (i = 0; i < num_words; i++) {
+		debug("%s data %llx lmt_ptr %p\n", __func__, ptr[i],
+			 lmt_ptr+i);
+		lmt_ptr[i] = ptr[i];
 	}
-	return tail > head ?
-	       tail - head : (nix->cq[queue_idx].qsize - head) + tail;
 }
 
-void *nix_dequeue_tx_packet(struct nix_handle *nix)
+void nix_cqe_tx_pkt_handler(struct nix *nix, void *cqe)
 {
-	u32 head, tail;
-	union cavm_nixx_lf_cq_op_status op_status;
-	union cavm_nix_cqe_hdr_s *completion;
+	union cavm_nix_cqe_hdr_s *txcqe = (union cavm_nix_cqe_hdr_s *)cqe;
 	union cavm_nix_send_comp_s *send_comp;
-	struct nix_tx_descr *tx_descr;
-	void *packet = NULL;
-
-	op_status.u =
-		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
-						   CAVM_NIXX_LF_CQ_OP_STATUS(),
-						   NIX_CQ_TX << 32);
-	head = op_status.s.head;
-	tail = op_status.s.tail;
 
-	if (head == tail)
-		return NULL;
+	debug("%s: txcqe: %p\n", __func__, txcqe);
 
-	head &= (nix->cq[NIX_CQ_TX].qsize - 1);
-
-	completion = (union cavm_nix_cqe_hdr_s *)
-			((void *)(nix->cq[NIX_CQ_TX].base) +
-				head * sizeof(nix->cq[NIX_CQ_TX].entry_sz));
-
-	debug("%s: completion: %p\n", __func__, completion);
-
-	if (completion->s.cqe_type != CAVM_NIX_XQE_TYPE_E_SEND)
-		return NULL;
-
-	send_comp= (union cavm_nix_send_comp_s *)(completion + 1);
-
-	tx_descr = &nix->send_descriptors[send_comp->s.sqe_id];
-
-	debug("%s: tx descriptor: %p\n", __func__, tx_descr);
+	if (txcqe->s.cqe_type != CAVM_NIX_XQE_TYPE_E_SEND) {
+		printf("%s: Error: Unsupported CQ header type %d\n",
+		       __func__, txcqe->s.cqe_type);
+		return;
+	}
 
-	packet = tx_descr->host_addr;
+	send_comp = (union cavm_nix_send_comp_s *)(txcqe + 1);
 
-	nix_free_send_descriptor(nix, tx_descr);
+	debug("%s: tx descriptor id: %d\n", __func__, send_comp->s.sqe_id);
 
-	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(), (NIX_CQ_TX << 32) | 1);
+	nix_free_tx_dr(nix, send_comp->s.sqe_id);
 
-	return packet;
+	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(),
+			 (NIX_CQ_TX << 32) | 1);
 }
 
-static int nix_recv(struct eth_device *netdev)
+int nix_lf_xmit(struct udevice *dev, void *pkt, int pkt_len)
 {
-	return 0;
-}
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
+	struct nix_tx_dr *tx_dr;
+	int dr_sz = (sizeof(struct nix_tx_dr) + 15) / 16 - 1;
+	s64 result;
+	int sqe_id;
 
-static int nix_xmmit(struct eth_device *netdev, void *pkt, int pkt_len)
-{
+	sqe_id = nix_alloc_tx_dr(nix);
+	if (sqe_id < 0) {
+		printf("%s: Error: out of tx descriptors\n", __func__);
+		return -1;
+	}
+	tx_dr = &nix->tx_desc[sqe_id];
+	debug("%s sqe_id %d tx_dr %p\n", __func__, sqe_id, tx_dr);
+	memset((void *)tx_dr, 0, sizeof(struct nix_tx_dr));
+
+	tx_dr->hdr.s.aura = 0xa5a5;
+	tx_dr->hdr.s.df = 1;
+	tx_dr->hdr.s.pnc = 1;
+	tx_dr->hdr.s.sq = 0;
+	tx_dr->hdr.s.sqe_id = sqe_id;
+	tx_dr->hdr.s.total = pkt_len;
+	tx_dr->hdr.s.sizem1 = dr_sz - 2; /* FIXME - for now hdr+sg+sg1addr */
+	debug("%s dr_sz %d \n", __func__, dr_sz);
+
+	tx_dr->tx_sg.s.segs = 1;
+	tx_dr->tx_sg.s.subdc = CAVM_NIX_SUBDC_E_SG;
+	tx_dr->tx_sg.s.seg1_size = pkt_len;
+	tx_dr->tx_sg.s.ld_type = CAVM_NIX_SENDLDTYPE_E_LDT;
+
+	tx_dr->sg1_addr = (dma_addr_t)pkt;
+	tx_dr->in_use = 0x1;
+
+#define DEBUG_PKT
+#ifdef DEBUG_PKT
+	debug("TX PKT Data\n");
+	for (int i = 0; i < pkt_len; i++) {
+		if (i && (i%8 == 0))
+			debug("\n");
+		debug("%02x ", *((u8 *)pkt + i));
+	}
+	debug("\n");
+#endif
+	do {
+		nix_write_lmt(nix, tx_dr, (dr_sz - 1) * 2);
+		__iowmb();
+		result = cavm_lmt_submit((u64)(nix->nix_base +
+					       CAVM_NIXX_LF_OP_SENDX(0)));
+		WATCHDOG_RESET();
+	} while (result == 0);
+	
 	return 0;
 }
 
-int nix_dequeue_rx_packet(struct nix_handle *nix, void *buffer, int *buf_size)
+/* RX */
+void nix_lf_flush_rx(struct udevice *dev)
 {
-	struct nix_rx_descr *rx_descr;
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
 	union cavm_nixx_lf_cq_op_status op_status;
-	u8 *ptr = (u8 *)buffer;
-	u64 *addr;
+	void *cq_rx_base = nix->cq[NIX_CQ_RX].base;
+	struct nix_rx_dr *rx_dr;
+	union cavm_nix_rx_parse_s *rxparse;
 	u32 head, tail;
-	int seg;
+	u32 rx_cqe_sz = nix->cq[NIX_CQ_RX].entry_sz;
+	u64 *seg;
 
-	op_status.u =
-		cavm_atomic_fetch_and_add64_nosync(nix->nix_base +
-						   CAVM_NIXX_LF_CQ_OP_STATUS(),
-						   NIX_CQ_RX << 32);
+	/* flush rx cqe entries */
+	op_status.u = nix_cq_op_status(nix, NIX_CQ_RX);
 	head = op_status.s.head;
 	tail = op_status.s.tail;
-
-	if (head == tail)
-		return -1;
-
 	head &= (nix->cq[NIX_CQ_RX].qsize - 1);
-	rx_descr = (struct nix_rx_descr *)(nix->cq[NIX_CQ_RX].base) + head;
-	debug("%s: completion: %p\n", __func__, rx_descr);
+	tail &= (nix->cq[NIX_CQ_RX].qsize - 1);
 
-	if (rx_descr->hdr.s.cqe_type != CAVM_NIX_XQE_TYPE_E_RX)
-		return -1;
+	debug("%s cq rx head %d tail %d\n", __func__, head, tail);
+	while (head != tail) {
+		rx_dr = (struct nix_rx_dr *)cq_rx_base + head * rx_cqe_sz;
+		rxparse = &(rx_dr->rx_parse);
 
-	addr = (dma_addr_t *)(rx_descr + 1);
-	debug("%s: segs: %d (%d@0x%llx, %d@0x%llx, %d@0x%llx)\n", __func__,
-	      rx_descr->rx_sg.s.segs, rx_descr->rx_sg.s.seg1_size, addr[0],
-	      rx_descr->rx_sg.s.seg2_size, addr[1],
-	      rx_descr->rx_sg.s.seg3_size, addr[2]);
-	if (*buf_size < rx_descr->rx_sg.s.seg1_size +
-			rx_descr->rx_sg.s.seg2_size +
-			rx_descr->rx_sg.s.seg3_size) {
-		debug("%s: Error: rx buffer size %d too small\n",
-		      __func__, *buf_size);
-		return -1;
-	}
+		debug("%s: rx parse: %p\n", __func__, rxparse);
+		debug("%s: rx parse: desc_sizem1 %x pkt_lenm1 %x \n",
+		 __func__, rxparse->s.desc_sizem1, rxparse->s.pkt_lenm1);
 
-	memcpy(ptr, (void *)addr[0], rx_descr->rx_sg.s.seg1_size);
-	ptr += rx_descr->rx_sg.s.seg1_size;
-	if (rx_descr->rx_sg.s.seg2_size) {
-		memcpy(ptr, (void *)addr[1], rx_descr->rx_sg.s.seg2_size);
-		ptr += rx_descr->rx_sg.s.seg2_size;
-	}
-	if (rx_descr->rx_sg.s.seg3_size) {
-		memcpy(ptr, (void *)addr[2], rx_descr->rx_sg.s.seg3_size);
-		ptr += rx_descr->rx_sg.s.seg3_size;
-	}
+		seg = (dma_addr_t *)(&rx_dr->rx_sg + 1);
 
-	for (seg = 0; seg < rx_descr->rx_sg.s.segs; seg++)
 		cavm_st128(nix->npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
-			   addr[seg], (1ULL << 63) | NPA_POOL_RX);
+			   seg[0], (1ULL << 63) | NPA_POOL_RX);
 
-	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(), (NIX_CQ_RX << 32) | 1);
+		debug("%s return %llx to NPA \n", __func__, seg[0]);
+		nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(),
+				 (NIX_CQ_RX << 32) | 1);
 
-	return 0;
+		op_status.u = nix_cq_op_status(nix, NIX_CQ_RX);
+		head = op_status.s.head;
+		tail = op_status.s.tail;
+		head &= (nix->cq[NIX_CQ_RX].qsize - 1);
+		tail &= (nix->cq[NIX_CQ_RX].qsize - 1);
+		debug("%s cq rx head %d tail %d\n", __func__, head, tail);
+	}
 }
 
-#if 0
-
-static int nix_lf_alloc(struct nix_handle *nix)
+int nix_lf_free_pkt(struct udevice *dev, uchar *pkt, int pkt_len)
 {
-	struct nix_node_state *state = &global_node_state[nix->hw->node];
-	union cavm_nixx_af_const2 const2;
-	union cvmx_rvu_pf_func rvu_pf_func;
-	union cvmx_nixx_af_lfx_cfg lfx_cfg;
-	union cavm_nix_af_lfx_cqs_cfg lfx_cqs_cfg;
-	union cavm_nix_af_lfx_rqs_cfg rqs_cfg;
-	union cavm_nix_af_lfx_rss_cfg rss_cfg;
-	union cavm_nix_af_lfx_sqs_cfg sqs_cfg;
-	union cavm_nix_af_lfx_tx_cfg tx_cfg;
-	union cavm_nix_af_lfx_tx_cfg2 tx_cfg2;
-	union cavm_nix_af_lfx_tx_parse_cfg tx_parse_cfg;
-	int lf;
-	void *cint_base = NULL, *cq_base = NULL, *qint_base = NULL;
-	void *rq_base = NULL, *rss_base = NULL, *sqs_base = NULL;
-	int retcode = -1;
-
-	const2.u = nix_reg_read(nix, CAVM_NIX_AF_CONST2);
-
-	if (state->next_free_lf >= const2.s.lfs) {
-		printf("N%d NIX: Ran out of LFs\n", nix->hw->node);
-		return -1;
-	}
-	lf = state->next_free_lf++;
-
-	rvu_pf_func.u = 0;
-	rvu_pf_func.s.pf = 0;
-	rvu_pf_func.s.func = 0;
-	lfx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_CFG(lf));
-	lfx_cfg.s.xqe_size = (CQ_ENTRY_SIZE == 128) ?
-			CAVM_NIX_XQESZ_E_W16 : CAVM_NIX_XQESZ_E_W64;
-	lfx_cfg.s.sso_pf_func = rvu_pf_func.s.func;
-	lfx_cfg.s.npa_pf_func = rvu_pf_func.s.func;
-	/* Allocate space for storing LF Completion Interrupts */
-	cint_base = nix_memaloc(const2.s.cints,
-				sizeof(union cavm_nix_cint_hw_s), __func__);
-	if (!cint_base)
-		goto error;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_CINTS_BASE(lf), (u64)cints_base);
-
-	/* Allocate space for storing LF Completion Queues Admin */
-	cq_base = nix_memalloc(MAX_CQS, sizeof(union cavm_nix_cq_ctx_s),
-			       __func__);
-	if (!cq_base)
-		goto error;
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
+	union cavm_nixx_lf_cq_op_status op_status;
+	u32 head, tail;
+	void *cq_tx_base = nix->cq[NIX_CQ_TX].base;
+	union cavm_nix_cqe_hdr_s *cqe;
+
+	/* Return rx packet to NPA */
+	debug("%s return %p to NPA \n", __func__, pkt);
+	cavm_st128(nix->npa->npa_base + CAVM_NPA_LF_AURA_OP_FREE0(),
+		   (u64)pkt, (1ULL << 63) | NPA_POOL_RX);
+	nix_pf_reg_write(nix, CAVM_NIXX_LF_CQ_OP_DOOR(),
+			 (NIX_CQ_RX << 32) | 1);
+
+	/* ack tx cqe entries */
+	op_status.u = nix_cq_op_status(nix, NIX_CQ_TX);
+	head = op_status.s.head;
+	tail = op_status.s.tail;
+	head &= (nix->cq[NIX_CQ_TX].qsize - 1);
+	tail &= (nix->cq[NIX_CQ_TX].qsize - 1);
 
-	nix_reg_write(nix, CAVM_NIXX_AF_LFX_CQS_BASE(lf), (u64)cq_base);
-	lfx_cqs_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_CQS_CFG(lf));
-	lfx_cqs_cfg.s.max_queuesm1 = MAX_CQS - 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_CQS_CFG(lf), lfx_cqs_cfg.u);
-	/* Allocate space for storing LF Queue Interrupts */
-	qint_base = nix_memalloc(const2.s.qints,
-				 sizeof(union cavm_nix_qint_hw_s), __func__);
-	if (!qint_base)
-		goto error;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_QINTS_BASE(lf),
-		      (u64)qint_base);
+	debug("%s cq tx head %d tail %d\n", __func__, head, tail);
+	while (head != tail) {
+		cqe = cq_tx_base + head * nix->cq[NIX_CQ_TX].entry_sz;
+		nix_cqe_tx_pkt_handler(nix, cqe);
 
-	rq_base = nix_memalloc(MAX_RQS, sizeof(union cavm_nix_rq_ctx_s),
-			       __func__);
-	if (!rq_base)
-		goto error;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_RQS_BASE(lf), (u64)rq_base);
-	rqs_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_RQS_CFG(lf));
-	rqs_cfg.s.max_queuesm1 = MAX_RQS - 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_RQS_CFG(lf), rqs_cfg.u);
-
-	/* Allocate space for storing LF RSS tables */
-	rss_base = nix_memalloc(256 << RSS_SIZE, sizeof(union cavm_nix_rsse_s),
-				__func__);
-	if (!rss_base)
-		goto error;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_RSS_BASE(lf),
-		      (u64)rss_base);
-	rss_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_RSS_CFG(lf));
-	rss_cfg.s.ena = 1;
-	rss_cfg.s.size = RSS_SIZE;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_RSS_CFG(lf), rss_cfg.u);
-
-	/* Allocate space for storing LF Send Queues */
-	sqs_base = nix_memalloc(MAX_SQS, sizeof(union cavm_nix_sq_ctx_s),
-				__func__);
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_SQS_BASE(lf), (u64)sqs_base);
-	sqs_cfg.u nix_reg_read(nix, CAVM_NIX_AF_LFX_SQS_CFG(lf));
-	sqs_cfg.s.queuesm1 = MAX_SQS - 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_SQS_CFG(lf), sqs_cfg.u);
-
-	/* NIX AF Local Function Transmit Configuration Register */
-	tx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_TX_CFG(lf));
-	tx_cfg.s.lock_ena = 1;
-	tx_cfg.s.lock_viol_cqe_ena = 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_TX_CFG(lf), tx_cfg.u);
-	tx_cfg2.u = nix_reg_read(nix, CAVM_NIX_AF_LFX_TX_CFG2(lf));
-	tx_cfg2.s.lmt_ena = 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_TX_CFG2(lf), tx_cfg2.u);
-
-	tx_parse_cfg.u = nix_reg_read(nix,
-				      CAVM_NIX_AF_LFX_PARSE_CFG(lf));
-	tx_parse_cfg.s.pkind = 1;
-	nix_reg_write(nix, CAVM_NIX_AF_LFX_PARSE_CFG(lf),
-		      tx_parse_cfg.u);
-
-	nix->cint_base = cint_base;
-	nix->cq_ctx_base = cq_base;
-	nix->qint_base = qint_base;
-	nix->rq_ctx_base = rq_base;
-	nix->rss_base = rss_base;
-	nix->sq_ctx_base = sqs_base;
+		op_status.u = nix_cq_op_status(nix, NIX_CQ_TX);
+		head = op_status.s.head;
+		tail = op_status.s.tail;
+		head &= (nix->cq[NIX_CQ_TX].qsize - 1);
+		tail &= (nix->cq[NIX_CQ_TX].qsize - 1);
+		debug("%s cq tx head %d tail %d\n", __func__, head, tail);
+	}
 
 	return 0;
-error:
-
-	if (cint_base)
-		free(cint_base);
-	if (cq_base)
-		free(cq_base);
-	if (qint_base)
-		free(qint_base);
-	if (rq_base)
-		free(rq_base);
-	if (rss_base)
-		free(rss_base);
-	if (sqs_base)
-		free(sqs_base);
-	return retcode;
 }
 
-/**
- * Issue a command to the NIX AF Admin Queue
- *
- * @param nix    nix handle
- * @param op     Operation
- * @param ctype  Context type
- * @param cindex Context index
- * @param resp   Result pointer
- *
- * @return	0 for success, -1 on failure
- */
-static int nix_aq_issue_command(struct nix_handle *nix, enum nix_aq_instop_e op,
-				enum nix_aq_ctype_e ctype,
-				int cindex, void *resp)
+int nix_lf_recv(struct udevice *dev, int flags, uchar **packetp)
 {
-	union cavm_nix_af_aq_status aq_status;
-	union cavm_nix_aq_inst_s *aq_inst = nix->aq_base + aq_status.s.head_ptr;
-	volatile union cavm_nix_aq_res_s *result = resp;
-	int lf = nix->lf;
-
-	aq_inst->u[0] = 0;
-	aq_inst->u[1] = 0;
-	aq_inst->s.op = op;
-	aq_inst->s.ctype = ctype;
-	aq_inst->s.lf = lf;
-	aq_inst->s.cindex = cindex;
-	aq_inst->s.doneint = 0;
-	aq_inst->s.res_addr = resp;
-	__iowmb();
-	nix_reg_write(nix, CAVM_NIX_AF_AQ_DOOR, 1);
-
-	/* Wait for completion */
-	do {
-		WATCHDOG_RESET();
-	} while (result->s.compcode == 0);
-	if (result->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
-		printf("N%d, NIX: Admin Queue failed with code %d\n",
-		       nix->hw->node, result->s.compcode);
-		return -1;
-	}
-	return 0;
-}
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
+	union cavm_nixx_lf_cq_op_status op_status;
+	void *cq_rx_base = nix->cq[NIX_CQ_RX].base;
+	struct nix_rx_dr *rx_dr;
+	union cavm_nix_rx_parse_s *rxparse;
+	void *pkt, *cqe;
+	int pkt_len = 0;
+	u64 *addr;
+	u32 head, tail;
 
-/**
- * Allocate and setup a new Completion Queue for use
- *
- * @param nix Handle for port to config
- *
- * @return Completion Queue number, or negative on failure
- */
-static int nix_lf_alloc_cq(struct nix_handle *nix)
-{
-	struct nix_node_state *state = &global_node_state[nix->hw->node];
-	struct nix_aq_cq_request aq_request
-					__aligned(CONFIG_SYS_CACHELINE_SIZE);
-	int cq = state->next_free_cq++;
-	static const int cqe_size = 16 << (CQS_QSIZE * 2);
-	void *cqe_mem = nix_memalloc(cqe_size, CQ_ENTRY_SIZE,
-				     __func__ "CQ Data");
-	int retcode;
-
-	memset(&aq_request, 0, sizeof(aq_request));
-	aq_request.cq.s.ena = 1;
-	aq_request.cq.s.bpid = nix->pki_channel;
-	aq_request.cq.s.substream = 0;	/* FIXME: Substream IDs? */
-	aq_request.cq.s.drop_ena = 1;
-	aq_request.cq.s.caching = 1;
-	aq_request.cq.s.qsize = CQS_QSIZE;
-	aq_request.cq.s.drop = 255 * 7 / 8;
-	aq_request.cq.s.qint_idx = 0;
-	aq_request.cq.s.cint_idx = 0;
-	aq_request.cq.s.base = (u64)cqe_mem;
-
-	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
-				       CAVM_NIX_AQ_CTYPE_E_CQ, nix->lf, cq,
-				       &aq_request.resp);
-	if (retcode) {
-		printf("%s: Error requesting completion queue\n", __func__);
+	/* fetch rx cqe entries */
+	op_status.u = nix_cq_op_status(nix, NIX_CQ_RX);
+	head = op_status.s.head;
+	tail = op_status.s.tail;
+	head &= (nix->cq[NIX_CQ_RX].qsize - 1);
+	tail &= (nix->cq[NIX_CQ_RX].qsize - 1);
+	debug("%s cq rx head %d tail %d\n", __func__, head, tail);
+	if (head == tail)
+		return -EAGAIN;
+
+	debug("%s: rx_base %p head %d sz %d \n", __func__, cq_rx_base, head, nix->cq[NIX_CQ_RX].entry_sz);
+	cqe = cq_rx_base + head * nix->cq[NIX_CQ_RX].entry_sz;
+	rx_dr = (struct nix_rx_dr *)cqe;
+	rxparse = &(rx_dr->rx_parse);
+
+	debug("%s: rx completion: %p\n", __func__, cqe);
+	debug("%s: rx dr: %p\n", __func__, rx_dr);
+	debug("%s: rx parse: %p\n", __func__, rxparse);
+	debug("%s: rx parse: desc_sizem1 %x pkt_lenm1 %x \n",
+		 __func__, rxparse->s.desc_sizem1, rxparse->s.pkt_lenm1);
+	debug("%s: rx parse: pkind %x chan %x \n",
+		 __func__, rxparse->s.pkind, rxparse->s.chan);
+
+	if (rx_dr->hdr.s.cqe_type != CAVM_NIX_XQE_TYPE_E_RX) {
+		printf("%s: Error: Unsupported CQ header type in Rx %d\n",
+		       __func__, rx_dr->hdr.s.cqe_type);
 		return -1;
 	}
-	debug("%s: CQ(%d) allocated, base %p\n", __func__, cq, cqe_mem);
 
-	nix->cq = cq;
-	nix->cqe_base = cqe_mem;
-	return cq;
-}
+	pkt_len = rxparse->s.pkt_lenm1 + 1;
+	addr = (dma_addr_t *)(&rx_dr->rx_sg + 1);
+	pkt = (void *)addr[0];
 
-/**
- * Allocate and setup a new Receive Queue for use
- *
- * @param nix Handle for port to config
- *
- * @return Receive Queue number, or negative on failure
- */
-static int nix_lf_alloc_rq(struct nix_handle *nix)
-{
-	struct nix_node_state *state = &global_node_state[nix->hw->node];
-	struct nix_aq_rq_request aq_request __aligned(CONFIG_SYS_CACHELINE_SIZE);
-	int cq = nix->cq;
-	int rq;
-	int retcode;
-
-	if (state->next_free_rq >= MAX_RQS) {
-		printf("%s: NIX: Ran out of Receive Queues\n", __func__);
+	debug("%s: segs: %d (%d@0x%llx, %d@0x%llx, %d@0x%llx)\n", __func__,
+	      rx_dr->rx_sg.s.segs, rx_dr->rx_sg.s.seg1_size, addr[0],
+	      rx_dr->rx_sg.s.seg2_size, addr[1],
+	      rx_dr->rx_sg.s.seg3_size, addr[2]);
+	if (pkt_len < rx_dr->rx_sg.s.seg1_size + rx_dr->rx_sg.s.seg2_size +
+			rx_dr->rx_sg.s.seg3_size) {
+		debug("%s: Error: rx buffer size too small\n", __func__);
 		return -1;
 	}
-	rq = state->next_free_rq++;
-
-	memset(&aq_request, 0, sizeof(aq_request));
-
-	aq_request.rq.s.ena = 1;
-	aq_request.rq.s.sso_ena = USE_SSO;
-	aq_request.rq.s.ipsech_ena = 0;
-	aq_request.rq.s.ena_wqwd = 1;
-	aq_request.rq.s.cq = cq;
-	aq_request.rq.s.substream = 0;	/* FIXME: Substream IDs? */
-	aq_request.rq.s.wqe_aura = -1;	/* No WQE aura */
-	aq_request.rq.s.spb_aura = CAVM_NPA_PACKET_POOL;	/* TODO */
-	aq_request.rq.s.lpb_aura = CAVM_NPA_PACKET_POOL;	/* TODO */
-	/* U-Boot doesn't use WQE group for anything */
-	aq_request.rq.s.sso_grp = 0;
-	aq_request.rq.s.sso_tt = CAVM_SSO_TT_E_ORDERED;		/* TODO */
-	aq_request.rq.s.pb_caching = 1;
-	aq_request.rq.s.wqe_caching = 1;
-	aq_request.rq.s.xqe_drop_ena = 0;	/* Disable RED dropping */
-	aq_request.rq.s.spb_drop_ena = 0;
-	aq_request.rq.s.lpb_drop_ena = 0;
-	aq_request.rq.s.spb_sizem1 =
-		nix_npa_get_block_size(nix, CAVM_NPA_PACKET_POOL) / 8 - 1;
-	aq_request.rq.s.sbp_ena = 1;
-	aq_request.rq.s.lpb_sizem1 =
-		nix_npa_get_block_size(nix, CAVM_NPA_PACKET_POOL) / 8 - 1;
-	aq_request.rq.s.first_skip =
-			(!USE_SSO) ? 0 : (CQ_ENTRY_SIZE == 128) ? 16 : 64;
-	aq_request.rq.s.later_skip = 0;
-	aq_request.rq.s.xqe_imm_copy = 0;
-	aq_request.rq.s.xqe_hdr_split = 0;
-	aq_request.rq.s.xqe_drop = 255;
-	aq_request.rq.s.xqe_pass = 255;
-	aq_request.rq.s.wqe_pool_drop = 0;	/* No WQE pool */
-	aq_request.rq.s.wqe_pool_pass = 0;	/* No WQE pool */
-	aq_request.rq.s.spb_aura_drop = 255;
-	aq_request.rq.s.spb_aura_pass = 255;
-	aq_request.rq.s.spb_pool_drop = 0;
-	aq_request.rq.s.spb_pool_pass = 0;
-	aq_request.rq.s.lpb_aura_drop = 255;
-	aq_request.rq.s.lpb_aura_pass = 255;
-	aq_request.rq.s.lpb_pool_drop = 0;
-	aq_request.rq.s.lpb_pool_pass = 0;
-	aq_request.rq.s.qint_idx = 0;
-	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
-				       CAVM_NIX_AQ_CTYPE_E_RQ, rq,
-				       &aq_request.resp);
-
-	debug("%s: RQ(%d) allocated\n", __func__, rq);
-	if (retcode < 0)
-		return retcode;
-
-	nix->rq = rq;
-	return rq;
-}
-
-/**
- * Setup SMQ -> TL4 -> TL3 -> TL2 -> TL1 -> MAC mapping
- *
- * @param nix     Handle to setup
- * @param nix_link_e NIX link number enumeration
- *
- * @return SMQ number, or negative on failure
- */
-static int nix_af_setup_sq(struct nix_handle *nix, int nix_link_e)
-{
-	union cavm_nixx_af_tl1x_schedule tl1_sched;
-	union cavm_nixx_af_tl2x_parent tl2_parent;
-	union cavm_nixx_af_tl3x_parent tl3_parent;
-	union cavm_nixx_af_tl3_tl2x_cfg tl3_tl2_cfg;
-	union cavm_nixx_af_tl3_tl2x_linkx_cfg tl3_tl2_link_cfg;
-	union cavm_nixx_af_tl4x_parent tl4_parent;
-	union cavm_nixx_af_tl4x_sdp_link_cfg tl4_sdp_link_cfg;
-	union cavm_nixx_af_smqx_cfg smq_cfg;
-	union cavm_nixx_af_mdqx_schedule mdq_sched;
-	union cavm_nixx_af_mdqx_parent mdq_parent;
-	union cavm_npc_af_pkindx_action0 pkindx_action0;
-	union cavm_npc_intfx_miss_act miss_act;
-	int tl1_index = nix_link_e; /* NIX_LINK_E enum */
-	int tl2_index = tl1_index;
-	int tl3_index = tl2_index;
-	int tl4_index = tl3_index;
-	int smq_index = tl4_index;
-
-	tl1_sched.u = nix_reg_read(nix,
-				CAVM_NIX_AF_TL1X_SCHEDULE(tl1_index));
-	tl1_sched.s.rr_quantum = MAX_MTU;
-	nix_reg_write(nix, CAVM_NIX_AF_TL1X_SCHEDULE(tl1_index),
-		      tl1_sched.u);
-	tl2_parent.u = nix_reg_read(nix,
-				CAVM_NIX_AF_TL2X_PARENT(tl2_index));
-	tl2_parent.s.parent = tl1_index;
-	nix_reg_write(nix, CAVM_NIX_AF_TL2X_PARENT(tl2_index),
-		      tl2_parent.u);
-	tl3_parent.u = nix_reg_read(nix,
-				CAVM_NIX_AF_TL3X_PARENT(tl3_index));
-	tl3_parent.s.parent = tl2_index;
-	nix_reg_write(nix, CAVM_NIX_AF_TL3X_PARENT(tl3_index),
-		      tl3_parent.u);
-	tl3_tl2_cfg.u = nix_reg_read(nix,
-				CAVM_NIX_AF_TL3_TL2X_CFG(tl3_index));
-	tl3_tl2_cfg.s.express = 0;
-	nix_reg_write(nix, CAVM_NIX_AF_TL3_TL2X_CFG(tl3_index),
-		      tl3_tl2_cfg.u);
-
-	if (nix_link_e != CAVM_NIX_LINK_E_SDP) {
-		tl3_tl2_link_cfg.u =
-			nix_reg_read(nix,
-			  CAVM_NIX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
-								  nix_link_e));
-		tl3_tl2_link_cfg.s.bp_ena = 1;
-		tl3_tl2_link_cfg.s.ena = 1;
-		tl3_tl2_link_cfg.s.relchan = 0;
-		nix_reg_write(nix,
-			      CAVM_NIX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
-								nix_link_e));
-	}
-	tl4_parent.u = nix_reg_read(nix,
-				CAVM_NIX_AF_TL4X_PARENT(tl4_index));
-	tl4_parent.s.parent = tl3_index;
-	nix_reg_write(nix, CAVM_NIX_AF_TL4X_PARENT(tl4_index),
-		      tl4_parent.u);
-	tl4_sdp_link_cfg.u =
-		nix_reg_read(nix,
-			     CAVM_NIX_AF_TL4X_SDP_LINK_CFG(tl4_index));
-	tl4_sdp_link_cfg.s.bp_ena = (nix_link_e == CAVM_NIX_LINK_E_SDP);
-	tl4_sdp_link_cfg.s.ena = (nix_link_e == CAVM_NIX_LINK_E_SDP);
-	tl4_sdp_link_cfg.s.relchan = nix->index;
-	nix_reg_write(nix, CAVM_NIX_AF_TL4X_SDP_LINK_CFG_RBU_BAR0(tl4_index),
-		      tl4_sdp_link_cfg.u);
-	smq_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_SMQX_CFG(smq_index));
-	smq_cfg.s.express = 0;
-	smq_cfg.s.lf = nix->lf;
-	smq_cfg.s.maxlen = MAX_MTU;
-	smq_cfg.s.minlen = 60;
-	nix_reg_write(nix, CAVM_NIX_AF_SMQX_CFG(smq_index), smq_cfg.u);
-	mdq_sched.u = nix_reg_read(nix,
-				CAVM_NIX_AF_MDQX_SCHEDULE(smq_index));
-	mdq_sched.s.rr_quantum = MAX_MTU;
-	nix_reg_write(nix, CAVM_NIX_AF_MDQX_SCHEDULE(smq_index),
-		      mdq_sched.u);
-	mdq_parent.u = nix_reg_read(nix,
-				CAVM_NIX_AF_MDQX_PARENT(smq_index));
-	mdq_parent.s.parent = tl4_index;
-	nix_reg_write(nix, CAVM_NIX_AF_MDQX_PARENT(smq_index),
-		      mdq_parent.u);
-	pkindx_action0.u = npc_reg_read(nix,
-				CAVM_NPC_AF_PKINDX_ACTION0_RBU_BAR0(nix->pknd));
-	pkindx_action0.s.parse_done = 1;
-	npc_reg_write(nix, CAVM_NPC_AF_PKINDX_ACTION0_RBU_BAR0(nix->pknd),
-		      pkindx_action0.u);
-	miss_act.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_MISS_ACT(
-						CAVM_NPC_INTF_E_NIXX_RX(0)));
-	miss_act.s.action = CAVM_NIX_RX_ACTIONOP_E_UCAST;
-	npc_reg_write(nix,
-		CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_RX(0)),
-		      miss_act.u);
-	miss_act.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_MISS_ACT(
-						CAVM_NPC_INTF_E_NIXX_TX(0)));
-	miss_act.s.action = CAVM_NIX_TX_ACTIONOP_E_UCAST_DEFAULT;
-	npc_reg_write(nix,
-		CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_TX(0)),
-		      miss_act.u);
-
-	return smq_index;
-}
-
-/**
- * Allocate and setup a new Send Queue for use
- *
- * @param nix     Handle for port to config
- * @param nix_link_e NIX link number enumeration
- *
- * @return Send Queue number, or negative on failure
- */
-static int nix_lf_alloc_sq(struct nix_handle *nix, int nix_link_e)
-{
-    struct nix_node_state *state = &global_node_state[nix->hw->node];
-    struct nix_aq_sq_request aq_request;
-    int sq;
-    int smq;
-
-    if (state->next_free_sq >= MAX_SQS) {
-        printf("%s NIX: Ran out of Send Queues\n", __func__);
-        return -1;
-    }
-    sq = state->next_free_sq++;
-    smq = nix_af_setup_sq(nix, sq, nix_link_e);
-
-    memset(&aq_request, 0, sizeof(aq_request));
-
-    aq_request.sq.s.ena = 1;
-    aq_request.sq.s.cq_ena = !USE_SSO;
-    aq_request.sq.s.max_sqe_size = CAVM_NIX_MAXSQESZ_E_W16;
-    aq_request.sq.s.substream = 0; // FIXME: Substream IDs?
-    aq_request.sq.s.sdp_mcast = 0;
-    aq_request.sq.s.cq = nix->cq;
-    aq_request.sq.s.cq_limit = 0;
-    aq_request.sq.s.smq = smq;
-    aq_request.sq.s.sso_ena = 1; /* Always allow a SQ to submit work */
-    aq_request.sq.s.smq_rr_quantum = MAX_MTU / 4;
-    aq_request.sq.s.default_chan = nix->pki_channel;
-    aq_request.sq.s.sqe_stype = CAVM_NIX_STYPE_E_STP;
-    aq_request.sq.s.qint_idx = 0;
-    aq_request.sq.s.sqb_aura = CAVM_NPA_PKO_POOL;
-    nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_INIT,
-			 CAVM_NIX_AQ_CTYPE_E_SQ, sq, &aq_request.resp);
-    nix->sq = sq;
-    return sq;
-}
 
-/**
- * Setup the NPC MCAM to route incoming packets to the NIX
- *
- * @param rq     NIX receive queue
- */
-static void nix_setup_mcam(struct nix_handle *nix)
-{
-	union cavm_npc_af_mcamex_bankx_camx_intf camx_intf;
-	union cavm_npc_af_mcamex_bankx_camx_w0 camx_w0;
-	union cavm_npc_af_mcamex_bankx_camx_w1 camx_w1;
-	union cavm_npc_af_mcamex_bankx_cfg bankx_cfg;
-	union cavm_nix_rx_action_s rx_action;
-	union cavm_npc_intf_e_nixx_rx nixx_rx;
-	union cavm_npc_intf_e_nixx_tx nixx_tx;
-	union cavm_npc_af_mcamex_kex_cfg kex_cfg;
-	u64 key0 = nix->pki_channel;
-	int mcam = nix->pko_queue;
-	int rq = nix->rq;
-	int bank = 0;
-
-	/* Setup receive direction MCAM match */
-	/* First require interface direction to exactly match  */
-	camx_intf.u = npc_reg_read(nix,
-			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
-								    bank, 0));
-	/* Mask for bits that must be zero */
-	camx_intf.s.intf = ~CAVM_NPC_INTF_E_NIXX_RX(0);
-	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
-								       bank, 0),
-		      camx_intf.u);
-	/* Second set of bits to match, must be zero */
-	camx_intf.u = npc_reg_read(nix,
-			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
-								    bank, 1));
-	/* Mask for bits that must be zero */
-	camx_intf.s.intf = CAVM_NPC_INTF_E_NIXX_RX(0);
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(mcam,
-								  bank, 1),
-		      camx_intf.u);
-
-	/* Second require the first 12 bits of the key to match, the channel */
-	camx_w0.u = npc_reg_read(nix,
-			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam,
-								  bank, 0));
-	/* Mask for bits that must be zero */
-	camx_w0.s.md = ~key0 & ~((~0x0ull) << 12);
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam, bank, 0),
-		      camx_w0.u);
-	camx_w0.u = npc_reg_read(nix,
-				 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam,
-								       bank, 1));
-	/* Mask for bits that must be one */
-	camx_w0.s.md = key0;
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(mcam, bank, 1),
-		      camx_w0.u);
-
-	/* Third requires none of the other key bits to match */
-	camx_w1.u = npc_reg_read(nix,
-				 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam,
-								       bank, 0));
-	camx_w1.s.md = 0;
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam, bank, 0),
-		      camx_w1.u);
-	camx_w1.u = npc_reg_read(nix,
-			CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam,
-								  bank, 1));
-	camx_w1.s.md = 0;
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(mcam, bank, 1),
-		      camx_w1.u);
-
-	/* Setup receive direction action */
-	rx_action.u = 0;
-	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_UCAST;
-	rx_action.s.pf_func = nix->lf;
-	rx_action.s.index = nix->rq;
-	rx_action.s.match_id = 0;
-	rx_action.s.flow_key_alg = 0;
-	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_ACTION(mcam, bank),
-		      rx_action.u);
-
-	/* Enable the MCAM entry */
-	bankx_cfg.u = npc_reg_read(nix,
-				   CAVM_NPC_AF_MCAMEX_BANKX_CFG(mcam,
-									 bank));
-	bankx_cfg.s.ena = 1;
-	npc_reg_write(nix, CAVM_NPC_AF_MCAMEX_BANKX_CFG(mcam, bank),
-		      bankx_cfg.u);
-
-	/* Program key size and nibbles to include */
-	kex_cfg.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_KEX_CFG(
-						CAVM_NPC_INTF_E_NIXX_RX(0)));
-	kex_cfg.s.keyw = CAVM_NPC_MCAMKEYW_E_X1;
-	kex_cfg.s.parse_nibble_ena = 0x7;
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_INTFX_KEX_CFG(
-					CAVM_NPC_INTF_E_NIXX_RX(0)),
-		      kex_cfg.u);
-	kex_cfg.u = npc_reg_read(nix, CAVM_NPC_AF_INTFX_KEX_CFG(
-						CAVM_NPC_INTF_E_NIXX_TX(0)));
-	kex_cfg.s.keyw = CAVM_NPC_MCAMKEYW_E_X1;
-	kex_cfg.s.parse_nibble_ena = 0xfffffff;
-	npc_reg_write(nix,
-		      CAVM_NPC_AF_INTFX_KEX_CFG(
-					CAVM_NPC_INTF_E_NIXX_TX(0)),
-		      kex_cfg.u);
-}
-
-static void nix_assign_channel_bp(struct nix_handle *nix)
-{
-	int channel;
-	int bpid = 0;
-
-
-}
-
-/**
- * Allocates the nix handle and performs low-level initialization
- *
- * @param	node		CPU node number
- * @param	nix_base	NIX BAR 0 base address
- * @param	nix2_base	NIX BAR 2 base address
- * @param	npc_base	NPC BAR 0 base address
- * @param	rvu_pf_func	RVU pf function number
- *
- * @return	Pointer to nix handle or NULL if failure
- */
-static struct *nix_handle nix_init_handle(int node, void *nix_base,
-					  void *nix2_base, void *npc_base,
-					  int rvu_pf_func)
-{
-	union cavm_nixx_af_cfg af_cfg;
-	union cavm_nixx_af_status af_status;
-	union cavm_nixx_af_rx_cfg rx_cfg;
-	union cavm_nixx_af_ndc_cfg ndc_cfg;
-	union cavm_nixx_priv_lfx_cfg lfx_cfg;
-	union cavm_nixx_af_rx_chanx_cfg chanx_cfg;
-	struct nix_node_state *state = &global_node_state[node];
-	struct nix_handle *nix = NULL;
-	int channel;
-	int bpid = 0;
-
-	debug("%s(%d, %p, %p, %d)\n", __func__,
-	      nix_base, npc_base, rvu_pf_func);
-	nix = calloc(1, sizeof(*nix));
-	if (!nix)
-		goto out_of_mem;
-	nix->hw = calloc(1, sizeof(struct hw_info));
-	if (!nix->hw)
-		goto out_of_mem;
-	nix->nix_base = nix_base;
-	nix->npc_base = npc_base;
-	/* Fill the NPA pool */
-
-
-	nix->aq_base = nix_memalloc(AQ_RING_SIZE,
-				    sizeof(union c avm_nix_aq_inst_s),
-				    __func__);
-	debug("%s: aq base: %p\n", __func__, nix->aq_base);
-	if (!nix->aq_base)
-		goto out_of_mem;
-
-#if 0	/* Don't do this in ASIM */
-	af_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_CFG);
-	af_cfg.s.calibrate_x2p = 1;
-	nix_reg_write(nix, CAVM_NIX_AF_CFG, af_cfg.u);
-
-	do {
-		af_status.u = nix_reg_read(nix, CAVM_NIXX_AF_STATUS);
-	} while (!af_status.s.calibrate_done);
-	af_status.u = nix_reg_read(nix, CAVM_NIXX_AF_STATUS);
-	if (!af_status.s.calibrate_status) {
-		printf("N%d NIX: AF failed X2P calibration\n", node);
-		goto error;
-	}
+	__iowmb();
+#define DEBUG_PKT
+#ifdef DEBUG_PKT
+	debug("RX PKT Data\n");
+	for (int i = 0; i < pkt_len; i++) {
+		if (i && (i%8 == 0))
+			debug("\n");
+		debug("%02x ", *((u8 *)pkt + i));
+	}
+	debug("\n");
 #endif
-	/* Enable channel backpressure */
-	rx_cfg.u = nix_reg_read(nix, CAVM_NIX_AF_RX_CFG);
-	rx_cfg.s.cbp_ena = 1;
-	nix_reg_write(nix, CAVM_NIX_AF_RX_CFG, rx_cfg.u);
-
-	/* Assign channel BP numbers sequentially */
-	for (channel = 0; channel < 4096; channel++) {
-		chanx_cfg.u = nix_reg_read(nix,
-				CAVM_NIXX_AF_RX_CHANX_CFG(channel));
-		if (!chanx_cfg.s.imp)
-			continue;
-
-		debug("%s: implementing back-pressure channel %d\n",
-		      __func__, channel);
-		chanx_cfg.s.bp_ena = 1;
-		chanx_cfg.s.bpid = bpid;
-		nix_reg_write(nix,
-			      CAVM_NIXX_AF_RX_CHANX_CFG(channel),
-			      chanx_cfg.u);
-		if (bpid < 512) {
-			bpid++;
-		} else {
-			printf("N%d NIX: Ran out of BPID at channel %d\n",
-			       node, channel);
-			break;
-		}
-	}
-
-	/* Enable NDC cache */
-	ndc_cfg.u = 0;
-	nix_reg_write(nix, CAVM_NIX_AF_NDC_CFG(), ndc_cfg.u);
-
-	/* Allocate MSIX space for NPA AF (not needed?) */
-	/* Enable NIX */
-
-
-	if (nix_lf_alloc(nix) < 0) {
-		printf("%s: Could not allocate lf\n", __func__);
-		goto error;
-	}
-
-	lfx_cfg.u = nix_reg_read(nix, CAVM_NIX_PRIV_LFX_CFG(nix->lf));
-	lfx_cfg.s.ena = 1;
-	lfx_cfg.s.pf_func = rvu_pf_func;
-	lfx_cfg.s.slot = 0;
-	nix_reg_write(nix, CAVM_NIX_PRIV_LFX_CFG(nix->lf), lfx_cfg.u);
-
-	return nix;
-
-out_of_mem:
-	printf("%s(%d): Error: out of memory\n", __func__, node);
-error:
-	if (nix) {
-		if (nix->hw)
-			free(nix->hw);
-		free(nix);
-	}
-	return NULL;
-}
-
-/**
- * Transmits an Ethernet packet
- *
- * @param	netdev		Ethernet device
- * @param	pkt		Pointer to packet data
- * @param	pkt_len		Length of packet
- *
- * @return	0 for success, -1 on error
- */
-static int nix_xmit(struct eth_device *netdev, void *pkt, int pkt_len)
-{
-	struct nix_handle *nix = netdev->priv;
-	union cavm_nix_op_q_wdata_s q_wdata_s;
-	union cavm_nix_send_hdr_s send_hdr_s;
-	union cavm_nixx_lf_sq_op_status sq_op_status;
-	union cavm_nix_send_sg_s send_sg_s;
-	volatile u64 *lmt_ptr;
-	u64 depth;
-	u64 io_address;
-	s64 lmt_status;
-
-	debug("%s(%s, %p, %d)\n", __func__, netdev->name, pkt, pkt_len);
-	q_wdata_s.u = 0;
-	q_wdata_s.q = nix->pko_queue;
-	sq_op_status.u = cavm_atomic_fetch_and_add64_nosync(nix->reg2_base +
-				CAVM_NIX_LF_SQ_OP_STATUS_RVU_BAR2, q_wdata_s.u);
-	depth = sq_op_status.s.sqb_count;
-	if (depth > 64)
-		return -1;
-	io_address = nix->reg_base + CAVM_NIX_LF_OP_SENDX(0);
-	do {
-		cavm_lmt_cancel(nix);
-		lmt_ptr = cavm_lmt_store_ptr();
-
-		send_hdr_s.u[0] = 0;
-		send_hdr_s.u[1] = 0;
-		send_hdr_s.s.total = pkt_len;
-		send_hdr_s.s.df = 1;
-		send_hdr_s.s.aura = CAVM_NPA_PACKET_POOL;
-		send_hdr_s.s.sizem1 = 0;
-		send_hdr_s.s.pnc = 0;	/* No completion posted */
-		send_hdr_s.s.sq = nix->pko_queue;
-		send_hdr_s.s.sqe_id = 0;
-		/* Don't worry about TCP/UDP checksum support here */
-
-		send_sg_s.u = 0;
-		send_sg_s.s.seg1_size = pktlen;
-		send_sg_s.s.ld_type = CAVM_NIX_SENDLDTYPE_E_LDD;
-		send_sg_s.s.subdc = CAVM_NIX_SUBDC_E_SG;
-		send_sg_s.s.segs = 1;
-		debug("%s(%s): Sending packet, hdr: 0x%lx 0x%lx sg: 0x%lx, pkt: %p\n",
-		      __func__, ethdev->name, send_hdr_s.u[0], send_hdr_s.u[1],
-		      send_sg_s.u, pkt);
-		*lmt_ptr++ = send_hdr_s.u[0];
-		*lmt_ptr++ = send_hdr_s.u[1];
-		*lmt_ptr++ = send_sg_s.u;
-		*lmt_ptr++ = pkt;
-		/* We only have one segment to worry about */
-		__iowmb();
-		lmt_status = cavm_lmt_submit(io_address);
-		if (!lmt_status) {
-			debug("%s: Error: unexpected lmt_status 0x%lx\n",
-			      __func__, lmt_status);
-		}
-	} while (lmt_status == 0);
 
-	nix->stats.tx.packets++;
-	nix->stats.tx.octets += pkt_len;
-
-	return 0;
-}
-
-static int nix_process_rx_complete(struct eth_device *netdev,
-				   union cavm_nix_rx_parse_s *rx_parse)
-{
-	struct nix_handle *nix = netdev->priv;
-	const union cavm_nix_rx_sg_s *rx_sg_ptr =
-			(const union cavm_nix_rx_sg_s *)(rx_parse + 1);
-	union cavm_nix_rx_sg_s rx_sg;
-	int qwords;
-	int num_segs;
-	int segments;
-	int segment_length;
-	int pkt_len;
-	void *pkt;
-	u64 addr;
-
-	qwords = rx_parse->s.desc_sizem1 + 1;
-	while (qwords > 0) {
-		pkt_len = rx_parse->s.pkt_lenm1 + 1;
-		rx_sg.u = rx_sg_ptr->u;
-		num_segs = rx_sg.s.segs;
-		segment_length += rx_sg_ptr->s.seg1_size;
-		addr = rx_sg_ptr[1].u;
-		pkt = (void *)addr;
-		prefetch(pkt);
-		if (num_segs < 2)
-			break;
-		printf("%s(%s): Only one segment supported\n", __func__,
-		       netdev->name);
-		qwords -= 2;
-	}
-	net_process_received_packet(pkt, pkt_len);
+	*packetp = (uchar *)pkt;
 
 	return pkt_len;
 }
-static int nix_recv(struct eth_device *netdev)
-{
-	struct nix_handle *nix = netdev->priv;
-	struct nix_aq_cq_request aq_request;
-	union cavm_nix_cqe_hdr_s *cq_next;
-	union cavm_nixx_lf_cq_op_status cq_op_status;
-	union cavm_nix_op_q_wdata_s q_wdata_s;
-	union cavm_nix_cqe_hdr_s cq_hdr;
-	union cavm_nix_rx_parse_s *rx_parse;
-	s64 *cq_op_status_ptr;
-	union cavm_nix_cqe_header_s *cq_ptr;
-	union cavm_nixx_lf_cq_op_door op_door;
-	const union cavm_nix_rx_sg_s *rx_sg_ptr;
-	union cavm_nix_rx_sg_s rg_sg;
-	u64 addr;
-	int loc;
-	int retcode;
-	int pkt_len = 0;
-
-	memset(&aq_request, 0, sizeof(aq_request));
-	retcode = nix_aq_issue_command(nix, CAVM_NIX_AQ_INSTOP_E_READ,
-				       CAVM_NIX_AQ_CTYPE_E_CQ,
-				       &aq_request.resp);
-	if (retcode) {
-		printf("%s(%s): Error issuing command\n", __func__,
-		       netdev->name);
-		return -1;
-	}
-	cq_ptr = (void *)aq_request.cq.s.base;
-	cq_op_status_ptr = (s64 *)(nix->reg2_base +
-				   CAVM_NIX_LF_CQ_OP_STATUS_RVU_BAR2);
-	q_wdata_s.u = 0;
-	q_wdata_s.s.q = nix->cq;
-
-		cq_op_status.u =
-			cavm_atomic_fetch_and_add64_nosync(cq_op_status_ptr,
-							   q_wdata_s.u);
-	if (cq_op_status.s.head == cq_op_status.s.tail)
-		return 0;
-
-	loc = cq_op_status.s.head;
-	cq_next = cq_ptr + loc;
-	cq_hdr.u = cq->next.u;
-	rx_parse = (const union cavm_nix_rx_parse_s *)(cq_next + 1);
-	loc++;
-	loc &= CQ_ENTRIES - 1;
-	cq_next = cq_ptr + loc;
-	prefetch(cq_next);
-	if (cq_hdr.s.cqe_type == CAVM_NIX_XQE_TYPE_E_RX)
-		pkt_len = nix_process_rx_complete(nix, rx_parse);
-	else
-		printf("%s(%s): Error: Unsupported CQ header type %d\n",
-		       __func__, ethdev->name, cq_hdr.s.cqe_type);
-	op_door.u = 0;
-	op_door.s.cq = nix->cq;
-	op_door.s.count = 1;
-	nix_reg2_write(nix, CAVM_NIX_LF_CQ_OP_DOOR_RVU_BAR2, op_door.u);
 
-	return pkt_len;
-}
-
-static int nix_open(struct eth_device *netdev)
+int nix_lf_setup_mac(struct udevice *dev)
 {
-	return 0;
+	return -ENOSYS;
 }
 
-static int nix_halt(struct eth_device *netdev)
+int nix_lf_read_rom_mac(struct udevice *dev)
 {
-	return 0;
+	return -ENOSYS;
 }
 
-int nix_initialize(struct udevice *pdev, int vf_num)
+void nix_lf_halt(struct udevice *dev)
 {
-	struct eth_device *netdev;
-	struct nix_handle *nix = NULL;
-	struct udevice *npcdev;
-	struct udevice *pci_bus;
-	size_t size;
-	void *reg_base;
-	void *reg2_base;
-
-	int retcode;
-
-	netdev = calloc(1, sizeof(struct eth_device));
-	if (!netdev) {
-		retcode = -ENOMEM;
-		goto fail;
-	}
-
-	reg_base = dm_pci_map_bar(pdev, 0, &size, PCI_REGION_MEM);
-	reg2_base = dm_pci_map_bar(pdev, 2, &size, PCI_REGION_MEM);
-	pci_bus =
-	retcode = pci_find_device_id()
-	netdev->halt = nix_halt;
-	netdev->init = nix_open;
-	netdev->send = nix_xmit;
-	netdev->recv = nix_recv;
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
 
+#if 0
+	/* Bring down LMAC */
+	cgx_lmac_link_enable(nix->lmac, nix->lmac->lmac_id, false);
+#endif
+	cgx_lmac_rx_tx_enable(nix->lmac, nix->lmac->lmac_id, false);
 
-	retcode = eth_register(netdev);
-
-fail:
-	return retcode;
+	mdelay(1);
 
+	/* Flush tx and rx descriptors */
+	nix_lf_flush_rx(dev);
+	for (int i = 0; i < (SQ_QLEN * 2); i++)
+		if (nix->tx_desc[i].in_use)
+			nix_free_tx_dr(nix, i);
 }
-#endif
-#if 0
-int octeontx2_nix_probe(struct udevice *dev)
-{
-	int vf;
-	void *nix_regs;
-	void *nix_regs2;
-	size_t size;
-
-	nix_regs = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
-	nix_regs2 = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
 
-	debug("%s: %d, bar0: %p, bar2: %p\n", __func__, __LINE__,
-	      nix_regs, nix_regs2);
+int nix_lf_init(struct udevice *dev)
+{
+	struct rvu_pf *rvu = dev_get_priv(dev);
+	struct nix *nix = rvu->nix;
+#if 0
+	cgx_lmac_mac_filter_setup(nix->lmac);
+	/* Bring up LMAC */
+	cgx_lmac_link_enable(nix->lmac, nix->lmac->lmac_id, true);
+	cgx_lmac_mac_filter_setup(nix->lmac);
+#endif
+	cgx_lmac_rx_tx_enable(nix->lmac, nix->lmac->lmac_id, true);
 
 	return 0;
 }
 
-static const struct misc_ops octeontx2_nix_ops = {
-};
-
-static const struct udevice_id octeontx2_nix_ids[] = {
-	{ .compatible = "cavium,nix" },
-};
-
-U_BOOT_DRIVER(octeontx2_nix) = {
-	.name	= "octeontx2_nix",
-	.id	= UCLASS_MISC,
-	.probe	= octeontx2_nix_probe,
-	.of_match = octeontx2_nix_ids,
-	.ops = &octeontx2_nix_ops,
-	.priv_auto_alloc_size = sizeof(struct nix_handle),
-};
-
-static const struct pci_device_id octeontx2_nix_supported[] = {
-	{ PCI_VDEVICE(CAVIUM, PCI_DEVICE_ID_OCTEONTX2_RVU) },
-	{}
-};
-
-U_BOOT_PCI_DEVICE(octeontx2_nix, octeontx2_nix_supported);
-#endif
diff --git a/drivers/net/cavium/octeontx2/nix.h b/drivers/net/cavium/octeontx2/nix.h
index 4ebdf03a2b..49cc714150 100644
--- a/drivers/net/cavium/octeontx2/nix.h
+++ b/drivers/net/cavium/octeontx2/nix.h
@@ -10,22 +10,12 @@
 #ifndef __NIX_H__
 #define	__NIX_H__
 
-#include "rvu_common.h"
+#include "cavm-csrs-npa.h"
 #include "cavm-csrs-nix.h"
+#include "rvu.h"
 
 /** Maximum number of LMACs supported */
-#define MAX_LMAC				12
-
-#define PCI_DEVICE_ID_OCTEONTX2_RVU		0xa063
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_SSO_TIM_PF	0xa0f9
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_SSO_TIM_VF	0xa0fa
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_NPA_PF	0xa0fb
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_NPA_VF	0xa0fc
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_CPT_PF	0xa0fd
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_CPT_VF	0xa0fe
-
-#define NIX_PCI_NPC_FN
-#define NIX_PCI_FN
+#define MAX_LMAC			12
 
 /* NIX RX action operation*/
 #define NIX_RX_ACTIONOP_DROP		(0x0ull)
@@ -47,14 +37,15 @@
 #define NIX_INTF_TYPE_CGX		0
 #define NIX_INTF_TYPE_LBK		1
 #define NIX_MAX_HW_MTU			9212
-#define NIX_MIN_HW_MTU			64
+#define NIX_MIN_HW_MTU			60
+#define MAX_MTU				1536
 
 #define NPA_POOL_COUNT			2
 #define NPA_AURA_COUNT(x)		(1ULL << ((x) + 6))
 #define NPA_POOL_RX			0ULL
 #define NPA_POOL_TX			1ULL
-#define RQ_QLEN				1024
-#define SQ_QLEN				128
+#define RQ_QLEN				Q_COUNT(Q_SIZE_1K)
+#define SQ_QLEN				Q_COUNT(Q_SIZE_16)
 
 #define NIX_CQ_RX			0ULL
 #define NIX_CQ_TX			1ULL
@@ -75,6 +66,18 @@
 #define NIX_CHAN_LBK_CHX(a, b)		(0 + 0x100 * (a) + (b))
 #define MAX_LMAC_PKIND			12
 
+/** Number of Admin queue entries */
+#define AQ_RING_SIZE 			Q_COUNT(Q_SIZE_16)
+
+/** Each completion queue contains 256 entries, see NIC_CQ_CTX_S[qsize] */
+#define CQS_QSIZE			Q_SIZE_256
+#define CQ_ENTRIES			Q_COUNT(CQS_QSIZE)
+/**
+ * Each completion queue entry contains 128 bytes, see
+ * NIXX_AF_LFX_CFG[xqe_size]
+ */
+#define CQ_ENTRY_SIZE			NIX_CQE_SIZE_W16
+
 enum npa_aura_size {
 	NPA_AURA_SZ_0,
 	NPA_AURA_SZ_128,
@@ -107,33 +110,23 @@ enum nix_scheduler {
 };
 
 struct cgx;
-struct rvu_pf;
 
 struct nix_stats {
 	u64	num_packets;
 	u64	num_bytes;
 };
 
-struct nix_af_handle;
-
-struct nix_txsch {
-	struct rsrc_bmap rsrc;
-	u8	lvl;
-	u16	*pfvf_map;
-};
-
-struct nix_handle;
-struct cgx;
+struct nix;
 struct lmac;
 
-struct npa_af_handle {
-	void __iomem		*npa_base;
+struct npa_af {
+	void __iomem		*npa_af_base;
 	struct admin_queue	aq;
 	u32			aura;
 };
 
-struct npa_handle {
-	struct npa_af_handle	*npa_af;
+struct npa {
+	struct npa_af		*npa_af;
 	void __iomem		*npa_base;
 	void __iomem		*npc_base;
 	void __iomem		*lmt_base;
@@ -152,38 +145,47 @@ struct npa_handle {
 	u32			stack_pages[NPA_POOL_COUNT];
 };
 
-struct nix_af_handle {
+struct nix_af {
 	struct udevice			*dev;
-	struct list_head		nix_af_list;
-	struct nix_handle		*lmacs[MAX_LMAC];
-	struct npa_af_handle		*npa_af;
+	struct nix			*lmacs[MAX_LMAC];
+	struct npa_af			*npa_af;
 	void __iomem			*nix_af_base;
 	void __iomem			*npc_af_base;
 	struct admin_queue		aq;
 	u8				num_lmacs;
 	s8				index;
 	u8				xqe_size;
+	u32				sqb_size;
+	u32				qints;
+	u32				cints;
+	u32				sq_ctx_sz;
+	u32				rq_ctx_sz;
+	u32				cq_ctx_sz;
+	u32				rsse_ctx_sz;
+	u32				cint_ctx_sz;
+	u32				qint_ctx_sz;
 };
 
-struct nix_tx_descr {
+struct nix_tx_dr {
 	union cavm_nix_send_hdr_s	hdr;
-	union cavm_nix_send_sg_s	segments;
-	dma_addr_t			dev_addr;
-	void				*host_addr;
+	union cavm_nix_send_sg_s	tx_sg;
+	dma_addr_t			sg1_addr;
+	dma_addr_t			sg2_addr;
+	dma_addr_t			sg3_addr;
+	u64				in_use;
 };
 
-struct nix_rx_descr {
+struct nix_rx_dr {
 	union cavm_nix_cqe_hdr_s hdr;
 	union cavm_nix_rx_parse_s rx_parse;
 	union cavm_nix_rx_sg_s rx_sg;
 };
 
-struct nix_handle {
+struct nix {
 	struct udevice			*dev;
 	struct eth_device		*netdev;
-	struct list_head		nix_list;
-	struct nix_af_handle		*nix_af;
-	struct npa_handle		*npa;
+	struct nix_af			*nix_af;
+	struct npa			*npa;
 	struct lmac			*lmac;
 	union cavm_nix_cint_hw_s	*cint_base;
 	union cavm_nix_cq_ctx_s		*cq_ctx_base;
@@ -202,130 +204,124 @@ struct nix_handle {
 	void __iomem			*nix_base;	/** PF reg base */
 	void __iomem			*npc_base;
 	void __iomem			*lmt_base;
-	struct nix_tx_descr		send_descriptors[SQ_QLEN];
-	struct nix_tx_descr		*free_send_descriptors[SQ_QLEN];
-	u32				current_free_send_descriptor;
+	struct nix_tx_dr		tx_desc[SQ_QLEN*2];
 	struct nix_stats		tx_stats;
 	struct nix_stats		rx_stats;
 	u32				aura;
 	int				pknd;
-	u16				pki_channel;
-	u16				pki_dstat;
-	u16				pko_queue;
-	u16				nic_id;
 	int				lf;
 	int				pf;
-	int				rq_idx;
-	int				sq_idx;
-	int				cq_idx;
+	u16				pf_func;
+	u32				rq_cnt;		/** Number of receive queues */
+	u32				sq_cnt;		/** Number of send squeues */
+	u32				cq_cnt;		/** Number of completion queues */
+	u16				rss_sz;
+	u16				sqb_size;
+	u8				rss_grps;
+	u8				xqe_sz;
+};
+
+struct nix_aq_cq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_cq_ctx_s	cq	ALIGNED;
 };
 
-struct nix_lf_alloc_req {
-	u32	rq_cnt;		/** Number of receive queues */
-	u32	sq_cnt;		/** Number of send squeues */
-	u32	cq_cnt;		/** Number of completion queues */
-	u16	rss_sz;
-	u8	rss_grps;
-	u8	xqe_sz;
-	u16	npa_func;
+struct nix_aq_rq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_rq_ctx_s	rq	ALIGNED;
 };
 
-struct nix_lf_alloc_rsp {
-	u16	sqb_size;
-	u16	chan_base;
-	u8	chan_cnt;
-#if 0
-	u8	lso_tsov4_idx;
-	u8	lso_tsov6_idx;
-#endif
-	u8	mac_addr[6];
+struct nix_aq_sq_request {
+	union cavm_nix_aq_res_s	resp	ALIGNED;
+	union cavm_nix_sq_ctx_s	sq	ALIGNED;
 };
 
-static inline u64 nix_af_reg_read(struct nix_af_handle *nix_af, u64 offset)
+static inline u64 nix_af_reg_read(struct nix_af *nix_af, u64 offset)
 {
+	debug("%s reg %p val %llx\n", __func__, nix_af->nix_af_base + offset,
+		readq(nix_af->nix_af_base + offset));
 	return readq(nix_af->nix_af_base + offset);
 }
 
-static inline void nix_af_reg_write(struct nix_af_handle *nix_af, u64 offset,
+static inline void nix_af_reg_write(struct nix_af *nix_af, u64 offset,
 				    u64 val)
 {
+	debug("%s reg %p val %llx\n", __func__, nix_af->nix_af_base + offset,
+		val);
 	writeq(val, nix_af->nix_af_base + offset);
 }
 
-static inline u64 nix_pf_reg_read(struct nix_handle *nix, u64 offset)
+static inline u64 nix_pf_reg_read(struct nix *nix, u64 offset)
 {
+	debug("%s reg %p val %llx\n", __func__, nix->nix_base + offset,
+		readq(nix->nix_base + offset));
 	return readq(nix->nix_base + offset);
 }
 
-static inline void nix_pf_reg_write(struct nix_handle *nix, u64 offset,
+static inline void nix_pf_reg_write(struct nix *nix, u64 offset,
 				    u64 val)
 {
+	debug("%s reg %p val %llx\n", __func__, nix->nix_base + offset,
+		val);
 	writeq(val, nix->nix_base + offset);
 }
 
-static inline u64 npa_af_reg_read(struct npa_af_handle *npa_af, u64 offset)
+static inline u64 npa_af_reg_read(struct npa_af *npa_af, u64 offset)
 {
-	return readq(npa_af->npa_base + offset);
+	debug("%s reg %p val %llx\n", __func__, npa_af->npa_af_base + offset,
+		readq(npa_af->npa_af_base + offset));
+	return readq(npa_af->npa_af_base + offset);
 }
 
-static inline void npa_af_reg_write(struct npa_af_handle *npa_af, u64 offset,
+static inline void npa_af_reg_write(struct npa_af *npa_af, u64 offset,
 				    u64 val)
 {
-	writeq(val, npa_af->npa_base + offset);
+	debug("%s reg %p val %llx\n", __func__, npa_af->npa_af_base + offset,
+		val);
+	writeq(val, npa_af->npa_af_base + offset);
 }
 
-static inline u64 npc_af_reg_read(struct nix_af_handle *nix_af, u64 offset)
+static inline u64 npc_af_reg_read(struct nix_af *nix_af, u64 offset)
 {
+	debug("%s reg %p val %llx\n", __func__, nix_af->npc_af_base + offset,
+		readq(nix_af->npc_af_base + offset));
 	return readq(nix_af->npc_af_base + offset);
 }
 
-static inline void npc_af_reg_write(struct nix_af_handle *nix_af, u64 offset,
+static inline void npc_af_reg_write(struct nix_af *nix_af, u64 offset,
 				    u64 val)
 {
+	debug("%s reg %p val %llx\n", __func__, nix_af->npc_af_base + offset,
+		val);
 	writeq(val, nix_af->npc_af_base + offset);
 }
 
-struct nix_af_handle *nix_af_initialize(int instance, struct udevice *dev,
-					void *bar0_ptr, void *bar2_ptr,
-					void *npa_bar0_ptr);
-int npa_lf_admin_setup(struct nix_af_handle *nix_af, int lf,
-		       u32 aura_size,
-		       const union cavm_npa_aura_s *aura_ctx,
-		       dma_addr_t auras_dev_addr,
-		       const union cavm_npa_pool_s *pool_ctx,
-		       u32 pool_cnt);
-
-int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count);
-
-int npc_lf_admin_setup(struct nix_af_handle *nix_af, struct cgx *cgx,
-		       u64 link_num);
-
-int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
-		       union cavm_nix_cq_ctx_s *cq_descriptors,
-		       dma_addr_t cq_dev_addr,
-		       u32 cq_count,
-		       union cavm_nix_rq_ctx_s *rq_descriptors,
-		       dma_addr_t rq_dev_addr,
-		       u32 rq_count,
-		       union cavm_nix_sq_ctx_s *sq_descriptors,
-		       dma_addr_t sq_dev_addr,
-		       u32 sq_count);
-int nix_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf,
+int npa_attach_aura(struct nix_af *nix_af, int lf,
+			const union cavm_npa_aura_s *desc, u32 aura_id);
+int npa_attach_pool(struct nix_af *nix_af, int lf,
+			const union cavm_npa_pool_s *desc, u32 pool_id);
+int npa_af_setup(struct npa_af *npa_af);
+int npa_lf_setup(struct nix *nix);
+int npa_lf_admin_setup(struct npa *npa, int lf, dma_addr_t aura_base);
+int npa_lf_admin_shutdown(struct nix_af *nix_af, int lf, u32 pool_count);
+
+int npc_lf_admin_setup(struct nix *nix);
+
+int nix_af_setup(struct nix_af *nix_af);
+int nix_af_shutdown(struct nix_af *nix_af);
+int nix_lf_setup(struct nix *nix);
+struct nix *nix_lf_alloc(struct udevice *dev);
+int nix_lf_admin_setup(struct nix *nix);
+int nix_lf_admin_shutdown(struct nix_af *nix_af, int lf,
 			  u32 cq_count, u32 rq_count, u32 sq_count);
-struct nix_handle *nix_get_pdata(int nic_id);
-int nix_get_nix_cnt(void);
-int nix_get_pf_num(const struct nix_handle *nix);
-int nix_linear_link_number(const struct nix_handle *nix);
-struct nix_af_handle *nix_get_af(u64 nix_pf_base);
-struct nix_handle *cavm_nix_lf_alloc(struct nix_af_handle *nix_af,
-				     struct udevice *dev,
-				     u16 pcifunc,
-				     u16 nix_lf,
-				     void __iomem *nix_base,
-				     void __iomem *npc_base,
-				     void __iomem *lmt_base,
-				     int cgx_id, int lmac_id,
-				     struct nix_lf_alloc_req *req,
-				     struct nix_lf_alloc_rsp *rsp);
+struct rvu_af *get_af(void);
+
+int nix_lf_setup_mac(struct udevice *dev);
+int nix_lf_read_rom_mac(struct udevice *dev);
+void nix_lf_halt(struct udevice *dev);
+int nix_lf_free_pkt(struct udevice *dev, uchar *pkt, int pkt_len);
+int nix_lf_recv(struct udevice *dev, int flags, uchar **packetp);
+int nix_lf_init(struct udevice *dev);
+int nix_lf_xmit(struct udevice *dev, void *pkt, int pkt_len);
 
 #endif /* __NIX_H__ */
diff --git a/drivers/net/cavium/octeontx2/nix_af.c b/drivers/net/cavium/octeontx2/nix_af.c
index 9330839b05..851b269f12 100644
--- a/drivers/net/cavium/octeontx2/nix_af.c
+++ b/drivers/net/cavium/octeontx2/nix_af.c
@@ -7,10 +7,8 @@
  * the License, or (at your option) any later version.
  *
  */
-#define DEBUG
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -22,159 +20,19 @@
 #include <linux/list.h>
 #include <linux/log2.h>
 #include <asm/arch/octeontx2.h>
-#include "cavm-csrs-lmt.h"
-#include "cavm-csrs-nix.h"
-#include "cavm-csrs-npa.h"
 #include "cavm-csrs-npc.h"
-#include "cavm-csrs-rvu.h"
-#include "rvu_common.h"
-#include "rvu.h"
-#include "nix_af.h"
+#include "cavm-csrs-lmt.h"
 #include "nix.h"
 #include "lmt.h"
 #include "cgx.h"
 
-static const int USE_SSO = 0;	/** Do not use SSO, use completion queues */
-static const int MAX_MTU = 9212;/** Maximum packet size */
-static const int MAX_CQS = 32;	/** Maximum of 32 completion queues */
-static const int MAX_SQS = 32;	/** Maximum of 32 send queues */
-static const int MAX_RQS = 32;	/** Maximum of 32 receive queues */
-/** Size of RSS table (256) See NIX_AF_LFX_RSS_CFG[size] */
-static const int RSS_SIZE = 0;
-/** Each completion queue contains 256 entries, see NIC_CQ_CTX_S[qsize] */
-static const int CQS_QSIZE = Q_SIZE_256;
-/** Number of CQ entries */
-static const int AQ_RING_SIZE = 16 << (AQ_SIZE * 2);
-/**
- * Each completion queue entry contains 512 bytes, see
- * NIXX_AF_LFX_CFG[xqe_size]
- */
-static const int CQ_ENTRY_SIZE = 64;
-
-struct nix_aq_cq_request {
-	union cavm_nix_aq_res_s	resp	ALIGNED;
-	union cavm_nix_cq_ctx_s	cq	ALIGNED;
-};
-
-struct nix_aq_rq_request {
-	union cavm_nix_aq_res_s	resp	ALIGNED;
-	union cavm_nix_rq_ctx_s	rq	ALIGNED;
-};
-
-struct nix_aq_sq_request {
-	union cavm_nix_aq_res_s	resp	ALIGNED;
-	union cavm_nix_sq_ctx_s	sq	ALIGNED;
-};
-
-static struct nix_af_state {
-	int next_free_lf;
-	int next_free_sq;
-	int next_free_rq;
-	int next_free_cq;
-	int next_free_rssi;
-	int next_free_bpid;
-} af_state;
-
-static int nix_lf_alloc_cq(struct nix_af_handle *nix_af,
-			   struct nix_handle *nix);
-
-static struct nix_af_handle nix_afs[MAX_NIX];
-static int nix_afs_references[MAX_NIX] = {0,};
-static LIST_HEAD(nix_list);
-/**
- * NIX needs a lot of memory areas. Rather than handle all the failure cases,
- * we'll use a wrapper around alloc that prints an error if a memory
- * allocation fails.
- *
- * @param num_elements
- *                  Number of elements to allocate
- * @param elem_size Size of each element
- * @param msge      Text string to show when allocation fails
- *
- * @return A valid memory location or NULL on failure
- */
-void *nix_memalloc(int num_elements, size_t elem_size, const char *msg)
-{
-	size_t alloc_size = num_elements * elem_size;
-	void *base = memalign(CONFIG_SYS_CACHELINE_SIZE, alloc_size);
-
-	if (!base)
-		printf("NIX: Memory alloc failed for %s (%d * %zd = %zd bytes)\n",
-		       msg ? msg : __func__, num_elements, elem_size,
-		       alloc_size);
-	else
-		memset(base, 0, alloc_size);
-
-	return base;
-}
-
-int nix_get_af_num(u64 base_addr)
-{
-	return (base_addr >> 28) & 0;
-}
-
-struct nix_handle *nix_get_pdata(int nic_id)
-{
-	struct nix_handle *nix;
-
-	list_for_each_entry(nix, &nix_list, nix_list) {
-		if (nix->nic_id == nic_id)
-			return nix;
-	}
-	return NULL;
-}
-
-int nix_get_nix_cnt(void)
-{
-	struct nix_handle *nix;
-	int count = 0;
-
-	list_for_each_entry(nix, &nix_list, nix_list)
-		count++;
-
-	return count;
-}
-
-static int npa_setup_admin(struct nix_af_handle *nix_af)
-{
-	int err;
-	struct npa_af_handle *npa = nix_af->npa_af;
-	union cavm_npa_af_gen_cfg npa_cfg;
-	union cavm_npa_af_ndc_cfg ndc_cfg;
-	union cavm_npa_af_aq_cfg aq_cfg;
-
-	err = cavm_rvu_aq_alloc(&npa->aq, Q_COUNT(AQ_SIZE),
-				sizeof(union cavm_npa_aq_inst_s),
-				sizeof(union cavm_npa_aq_res_s));
-	if (err) {
-		printf("%s: Error %d allocating admin queue\n", __func__, err);
-		return err;
-	}
-	debug("%s: NPA admin queue allocated at %p\n", __func__,
-	      npa->aq.inst.base);
-
-	/* Set little Endian */
-	npa_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_GEN_CFG());
-	npa_cfg.s.af_be = 0;
-	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_GEN_CFG(), npa_cfg.u);
-	/* Enable NDC cache */
-	ndc_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_NDC_CFG());
-	ndc_cfg.s.ndc_bypass = 0;
-	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_NDC_CFG(), ndc_cfg.u);
-	/* Set up queue size */
-	aq_cfg.u = npa_af_reg_read(nix_af->npa_af, CAVM_NPA_AF_AQ_CFG());
-	aq_cfg.s.qsize = AQ_SIZE;
-	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_AQ_CFG(), aq_cfg.u);
-	/* Set up queue base address */
-	npa_af_reg_write(npa, CAVM_NPA_AF_AQ_BASE(), npa->aq.inst.iova);
-
-	return 0;
-}
-
-static int npa_attach_aura(struct nix_af_handle *nix_af, int lf,
+/***************
+ * NPA API 
+ ***************/
+int npa_attach_aura(struct nix_af *nix_af, int lf,
 			   const union cavm_npa_aura_s *desc, u32 aura_id)
 {
-	struct npa_af_handle *npa = nix_af->npa_af;
+	struct npa_af *npa = nix_af->npa_af;
 	union cavm_npa_aq_inst_s *inst;
 	volatile union cavm_npa_aq_res_s *res;
 	union cavm_npa_af_aq_status aq_stat;
@@ -216,13 +74,13 @@ static int npa_attach_aura(struct nix_af_handle *nix_af, int lf,
 	return 0;
 }
 
-static int npa_attach_pool(struct nix_af_handle *nix_af, int lf,
+int npa_attach_pool(struct nix_af *nix_af, int lf,
 			   const union cavm_npa_pool_s *desc, u32 pool_id)
 {
 	union cavm_npa_aq_inst_s *inst;
 	volatile union cavm_npa_aq_res_s *res;
 	union cavm_npa_af_aq_status aq_stat;
-	struct npa_af_handle *npa = nix_af->npa_af;
+	struct npa_af *npa = nix_af->npa_af;
 	union cavm_npa_aura_s *context;
 	u64 head;
 	ulong start;
@@ -263,60 +121,40 @@ static int npa_attach_pool(struct nix_af_handle *nix_af, int lf,
 	return 0;
 }
 
-int npa_lf_admin_setup(struct nix_af_handle *nix_af, int lf,
-		       u32 aura_size,
-		       const union cavm_npa_aura_s *aura_ctx,
-		       dma_addr_t auras_dev_addr,
-		       const union cavm_npa_pool_s *pool_ctx,
-		       u32 pool_cnt)
+
+int npa_lf_admin_setup(struct npa *npa, int lf, dma_addr_t aura_base)
 {
 	union cavm_npa_af_lf_rst lf_rst;
-	union cavm_npa_af_const af_const;
 	union cavm_npa_af_lfx_auras_cfg auras_cfg;
-	struct npa_af_handle *npa = nix_af->npa_af;
-	int index;
-	int err;
+	struct npa_af *npa_af = npa->npa_af;
 
-	debug("%s(%p, %d, %u, %p, 0x%llx, %p, %u)\n", __func__, nix_af, lf,
-	      aura_size, aura_ctx, auras_dev_addr, pool_ctx, pool_cnt);
+	debug("%s(%p, %d, 0x%llx)\n", __func__, npa_af, lf, aura_base);
 	lf_rst.u = 0;
 	lf_rst.s.exec = 1;
 	lf_rst.s.lf = lf;
-	npa_af_reg_write(npa, CAVM_NPA_AF_LF_RST(), lf_rst.u);
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_LF_RST(), lf_rst.u);
 
 	do {
-		lf_rst.u = npa_af_reg_read(npa, CAVM_NPA_AF_LF_RST());
+		lf_rst.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_LF_RST());
 		WATCHDOG_RESET();
 	} while (lf_rst.s.exec);
 
-	/* TODO: remove this */
-	af_const.u = npa_af_reg_read(npa, CAVM_NPA_AF_CONST());
-	debug("%s: %d NPA local functions\n", __func__, af_const.s.lfs);
 	/* Set Aura size and enable caching of contexts */
-	auras_cfg.u = npa_af_reg_read(npa, CAVM_NPA_AF_LFX_AURAS_CFG(lf));
-	auras_cfg.s.loc_aura_size = aura_size;
+	auras_cfg.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_LFX_AURAS_CFG(lf));
+	auras_cfg.s.loc_aura_size = NPA_AURA_SIZE_DEFAULT; //FIXME aura_size;
 	auras_cfg.s.caching = 1;
 	auras_cfg.s.rmt_aura_size = 0;
 	auras_cfg.s.rmt_aura_offset = 0;
 	auras_cfg.s.rmt_lf = 0;
-	npa_af_reg_write(npa, CAVM_NPA_AF_LFX_AURAS_CFG(lf), auras_cfg.u);
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_LFX_AURAS_CFG(lf), auras_cfg.u);
 	/* Configure aura HW context base */
-	npa_af_reg_write(npa, CAVM_NPA_AF_LFX_LOC_AURAS_BASE(lf),
-			 auras_dev_addr);
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_LFX_LOC_AURAS_BASE(lf),
+			 aura_base);
 
-	/* Set up the auras */
-	for (index = 0; index < pool_cnt; index++) {
-		err = npa_attach_aura(nix_af, lf, &aura_ctx[index], index);
-		if (err)
-			return err;
-		err = npa_attach_pool(nix_af, lf, &pool_ctx[index], index);
-		if (err)
-			return err;
-	}
 	return 0;
 }
 
-int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count)
+int npa_lf_admin_shutdown(struct nix_af *nix_af, int lf, u32 pool_count)
 {
 	int pool_id;
 	u32 head;
@@ -326,7 +164,7 @@ int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count)
 	union cavm_npa_pool_s *pool_ctx;
 	union cavm_npa_af_aq_status aq_stat;
 	union cavm_npa_af_lf_rst lf_rst;
-	struct npa_af_handle *npa = nix_af->npa_af;
+	struct npa_af *npa = nix_af->npa_af;
 	ulong start;
 
 	for (pool_id = 0; pool_id < pool_count; pool_id++) {
@@ -415,256 +253,435 @@ int npa_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf, u32 pool_count)
 	return 0;
 }
 
-static int nix_af_setup(struct nix_af_handle *nix_af)
+int npa_af_setup(struct npa_af *npa_af)
 {
 	int err;
-	union cavm_nixx_af_cfg af_cfg;
-	union cavm_nixx_af_ndc_cfg ndc_cfg;
-	union cavm_nixx_af_aq_cfg aq_cfg;
+	union cavm_npa_af_gen_cfg npa_cfg;
+	union cavm_npa_af_ndc_cfg ndc_cfg;
+	union cavm_npa_af_aq_cfg aq_cfg;
+	union cavm_npa_af_blk_rst blk_rst;
 
-	debug("%s(%p)\n", __func__, nix_af);
-	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
-				sizeof(union cavm_nix_aq_inst_s),
-				sizeof(union cavm_nix_aq_res_s));
+	err = rvu_aq_alloc(&npa_af->aq, Q_COUNT(AQ_SIZE),
+				sizeof(union cavm_npa_aq_inst_s),
+				sizeof(union cavm_npa_aq_res_s));
 	if (err) {
-		printf("%s: Error allocating nix admin queue\n", __func__);
+		printf("%s: Error %d allocating admin queue\n", __func__, err);
 		return err;
 	}
+	debug("%s: NPA admin queue allocated at %p %llx\n", __func__,
+	      npa_af->aq.inst.base, npa_af->aq.inst.iova);
 
-	/* Put in LE mode */
-	af_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CFG());
-	if (af_cfg.s.force_cond_clk_en ||
-	    af_cfg.s.calibrate_x2p || af_cfg.s.force_intf_clk_en) {
-		    printf("%s: Error: Invalid NIX_AF_CFG value 0x%llx\n",
-			   __func__, af_cfg.u);
-		    return -1;
-	}
-	af_cfg.s.af_be = 0;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_CFG(), af_cfg.u);
+	blk_rst.u = 0;
+	blk_rst.s.rst = 1;
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_BLK_RST(), blk_rst.u);
 
-	/* Enable NDC cache */
-	ndc_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_NDC_CFG());
-	ndc_cfg.s.ndc_ign_pois = 0;
-	ndc_cfg.s.byp_sq = 0;
-	ndc_cfg.s.byp_sqb = 0;
-	ndc_cfg.s.byp_cqs = 0;
-	ndc_cfg.s.byp_cints = 0;
-	ndc_cfg.s.byp_dyno = 0;
-	ndc_cfg.s.byp_mce = 0;
-	ndc_cfg.s.byp_rqc = 0;
-	ndc_cfg.s.byp_rsse = 0;
-	ndc_cfg.s.byp_mc_data = 0;
-	ndc_cfg.s.byp_mc_wqe = 0;
-	ndc_cfg.s.byp_mr_data = 0;
-	ndc_cfg.s.byp_mr_wqe = 0;
-	ndc_cfg.s.byp_qints = 0;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_NDC_CFG(), ndc_cfg.u);
+	/* Wait for reset to complete */
+	do {
+		blk_rst.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_BLK_RST());
+		WATCHDOG_RESET();
+	} while (blk_rst.s.busy);
 
+	/* Set little Endian */
+	npa_cfg.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_GEN_CFG());
+	npa_cfg.s.af_be = 0;
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_GEN_CFG(), npa_cfg.u);
+	/* Enable NDC cache */
+	ndc_cfg.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_NDC_CFG());
+	ndc_cfg.s.ndc_bypass = 0;
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_NDC_CFG(), ndc_cfg.u);
 	/* Set up queue size */
-	aq_cfg.u = 0;
+	aq_cfg.u = npa_af_reg_read(npa_af, CAVM_NPA_AF_AQ_CFG());
 	aq_cfg.s.qsize = AQ_SIZE;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_CFG(), aq_cfg.u);
-
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_AQ_CFG(), aq_cfg.u);
 	/* Set up queue base address */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_BASE(), nix_af->aq.inst.iova);
+	npa_af_reg_write(npa_af, CAVM_NPA_AF_AQ_BASE(), npa_af->aq.inst.iova);
 
 	return 0;
 }
 
-static int nix_attach_receive_queue(struct nix_af_handle *nix_af, int lf,
-				    union cavm_nix_rq_ctx_s *desc, u32 index)
+
+/***************
+ * NIX API 
+ ***************/
+/**
+ * Setup SMQ -> TL4 -> TL3 -> TL2 -> TL1 -> MAC mapping
+ *
+ * @param nix     Handle to setup
+ *
+ * @return 0, or negative on failure
+ */
+static int nix_af_setup_sq(struct nix *nix)
+{
+	union cavm_nixx_af_tl1x_schedule tl1_sched;
+	union cavm_nixx_af_tl2x_parent tl2_parent;
+	union cavm_nixx_af_tl3x_parent tl3_parent;
+	union cavm_nixx_af_tl3_tl2x_cfg tl3_tl2_cfg;
+	union cavm_nixx_af_tl3_tl2x_linkx_cfg tl3_tl2_link_cfg;
+	union cavm_nixx_af_tl4x_parent tl4_parent;
+	union cavm_nixx_af_tl4x_sdp_link_cfg tl4_sdp_link_cfg;
+	union cavm_nixx_af_smqx_cfg smq_cfg;
+	union cavm_nixx_af_mdqx_schedule mdq_sched;
+	union cavm_nixx_af_mdqx_parent mdq_parent;
+	union cavm_nixx_af_rx_linkx_cfg link_cfg;
+	int tl1_index = nix->lmac->link_num; /* NIX_LINK_E enum */
+	int tl2_index = tl1_index;
+	int tl3_index = tl2_index;
+	int tl4_index = tl3_index;
+	int smq_index = tl4_index;
+	struct nix_af *nix_af = nix->nix_af;
+
+	tl1_sched.u = nix_af_reg_read(nix_af,
+					CAVM_NIXX_AF_TL1X_SCHEDULE(tl1_index));
+	tl1_sched.s.rr_quantum = MAX_MTU;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL1X_SCHEDULE(tl1_index),
+				      tl1_sched.u);
+
+	tl2_parent.u = nix_af_reg_read(nix_af,
+					CAVM_NIXX_AF_TL2X_PARENT(tl2_index));
+	tl2_parent.s.parent = tl1_index;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL2X_PARENT(tl2_index),
+				      tl2_parent.u);
+
+	tl3_parent.u = nix_af_reg_read(nix_af,
+					CAVM_NIXX_AF_TL3X_PARENT(tl3_index));
+	tl3_parent.s.parent = tl2_index;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL3X_PARENT(tl3_index),
+				      tl3_parent.u);
+	tl3_tl2_cfg.u = nix_af_reg_read(nix_af,
+					CAVM_NIXX_AF_TL3_TL2X_CFG(tl3_index));
+	tl3_tl2_cfg.s.express = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL3_TL2X_CFG(tl3_index),
+				      tl3_tl2_cfg.u);
+
+	tl3_tl2_link_cfg.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
+				nix->lmac->link_num));
+	tl3_tl2_link_cfg.s.bp_ena = 1;
+	tl3_tl2_link_cfg.s.ena = 1;
+	tl3_tl2_link_cfg.s.relchan = 0;
+	nix_af_reg_write(nix_af,
+				CAVM_NIXX_AF_TL3_TL2X_LINKX_CFG(tl3_index,
+				nix->lmac->link_num), tl3_tl2_link_cfg.u);
+
+	tl4_parent.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_TL4X_PARENT(tl4_index));
+	tl4_parent.s.parent = tl3_index;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL4X_PARENT(tl4_index),
+				tl4_parent.u);
+	tl4_sdp_link_cfg.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_TL4X_SDP_LINK_CFG(tl4_index));
+	tl4_sdp_link_cfg.s.bp_ena = 0;
+	tl4_sdp_link_cfg.s.ena = 0;
+	tl4_sdp_link_cfg.s.relchan = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_TL4X_SDP_LINK_CFG(tl4_index),
+				tl4_sdp_link_cfg.u);
+
+	smq_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_SMQX_CFG(smq_index));
+	smq_cfg.s.express = 0;
+	smq_cfg.s.lf = nix->lf;
+	smq_cfg.s.desc_shp_ctl_dis = 1;
+	smq_cfg.s.maxlen = MAX_MTU;
+	smq_cfg.s.minlen = NIX_MIN_HW_MTU;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_SMQX_CFG(smq_index), smq_cfg.u);
+
+	mdq_sched.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_MDQX_SCHEDULE(smq_index));
+	mdq_sched.s.rr_quantum = MAX_MTU;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_MDQX_SCHEDULE(smq_index),
+		      mdq_sched.u);
+	mdq_parent.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_MDQX_PARENT(smq_index));
+	mdq_parent.s.parent = tl4_index;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_MDQX_PARENT(smq_index),
+		      mdq_parent.u);
+
+	link_cfg.u = 0;
+	link_cfg.s.maxlen = NIX_MAX_HW_MTU;
+	link_cfg.s.minlen = NIX_MIN_HW_MTU;
+	nix_af_reg_write(nix->nix_af,
+			 CAVM_NIXX_AF_RX_LINKX_CFG(nix->lmac->lmac_id),
+			 link_cfg.u);
+
+	return 0;
+}
+
+/**
+ * Issue a command to the NIX AF Admin Queue
+ *
+ * @param nix    nix handle
+ * @param lf     Logical function number for command
+ * @param op     Operation
+ * @param ctype  Context type
+ * @param cindex Context index
+ * @param resp   Result pointer
+ *
+ * @return	0 for success, -EBUSY on failure
+ */
+static int nix_aq_issue_command(struct nix_af *nix_af,
+				int lf,
+				int op,
+				int ctype,
+				int cindex, union cavm_nix_aq_res_s *resp)
 {
-	union cavm_nix_aq_inst_s *inst;
-	volatile union cavm_nix_aq_res_s *res;
-	union cavm_nix_rq_ctx_s *context;
 	union cavm_nixx_af_aq_status aq_status;
+	union cavm_nix_aq_inst_s *aq_inst;
+	volatile union cavm_nix_aq_res_s *result = resp;
 	ulong start;
 
-	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
+	debug("%s(%p, 0x%x, 0x%x, 0x%x, 0x%x, %p)\n", __func__, nix_af, lf,
+	      op, ctype, cindex, resp);
 	aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
-
-	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
+	aq_inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
 						aq_status.s.head_ptr;
-	memset(inst, 0, sizeof(*inst));
-	inst->s.cindex = index;
-	inst->s.doneint = 0;
-	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_RQ;
-	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
-	inst->s.res_addr = nix_af->aq.res.iova;
-
-	res = nix_af->aq.res.base;
-
-	/* Context base address */
-	context = (union cavm_nix_rq_ctx_s *)
-			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
-	memset((void *)res, 0, nix_af->aq.res.entry_sz);
-	memcpy(context, desc, sizeof(*context));
+	aq_inst->u[0] = 0;
+	aq_inst->u[1] = 0;
+	aq_inst->s.op = op;
+	aq_inst->s.ctype = ctype;
+	aq_inst->s.lf = lf;
+	aq_inst->s.cindex = cindex;
+	aq_inst->s.doneint = 0;
+	aq_inst->s.res_addr = (u64)resp;
+	debug("%s: inst@%p: 0x%llx 0x%llx\n", __func__, aq_inst,
+	      aq_inst->u[0], aq_inst->u[1]);
 	__iowmb();
 
-	/* Submit the aura context to HW */
+	/* Ring doorbell and wait for result */
 	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
 
 	start = get_timer(0);
-	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
-	       (get_timer(start) < 1000))
+	/* Wait for completion */
+	do {
 		WATCHDOG_RESET();
-	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
-		printf("%s: Bad result code 0x%x\n",
-		       __func__, res->s.compcode);
-		return -1;
+		dsb();
+	} while (result->s.compcode == 0 && get_timer(start) < 2);
+
+	if (result->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
+		printf("NIX: Admin Queue failed or timed out with code %d after %ld ms\n",
+		       result->s.compcode, get_timer(start));
+		return -EBUSY;
 	}
 	return 0;
 }
 
-static int nix_attach_send_queue(struct nix_af_handle *nix_af, int lf,
-				 const union cavm_nix_sq_ctx_s *desc,
-				 u32 index)
+static int nix_attach_receive_queue(struct nix_af *nix_af, int lf)
 {
-	union cavm_nix_aq_inst_s *inst;
-	volatile union cavm_nix_aq_res_s *res;
-	union cavm_nix_sq_ctx_s *context;
-	union cavm_nixx_af_aq_status aq_stat;
-	ulong start;
-
-	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
-	res = (union cavm_nix_aq_res_s *)nix_af->aq.res.base;
-	aq_stat.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
-	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
-							aq_stat.s.head_ptr;
-	memset(inst, 0, sizeof(*inst));
-	inst->s.cindex = index;
-	inst->s.lf = lf;
-	inst->s.doneint = 0;
-	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_SQ;
-	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
-	inst->s.res_addr = nix_af->aq.res.iova;
-
-	context = (union cavm_nix_sq_ctx_s *)
-			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
-	memset((void *)res, 0, nix_af->aq.res.entry_sz);
-	memcpy(context, desc, sizeof(*context));
-	__iowmb();
-
-	/* Now submit the aura context to HW */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+	struct nix_aq_rq_request rq_req ALIGNED;
+	int err;
 
-	start = get_timer(0);
-	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
-	       (get_timer(start) < 1000))
-		WATCHDOG_RESET();
-	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
-		printf("%s: Bad result code 0x%x\n",
-		       __func__, res->s.compcode);
-		return -1;
+	debug("%s(%p, %d)\n", __func__, nix_af, lf);
+
+	memset(&rq_req, 0, sizeof(struct nix_aq_rq_request));
+	
+	rq_req.rq.s.ena = 1;
+	rq_req.rq.s.ipsech_ena = 0;
+	rq_req.rq.s.ena_wqwd = 0;
+	rq_req.rq.s.cq = NIX_CQ_RX;
+	rq_req.rq.s.substream = 0;	/* FIXME: Substream IDs? */
+	rq_req.rq.s.wqe_aura = -1;	/* No WQE aura */
+	rq_req.rq.s.spb_aura = NPA_POOL_RX;
+	rq_req.rq.s.lpb_aura = NPA_POOL_RX;
+	/* U-Boot doesn't use WQE group for anything */
+	rq_req.rq.s.pb_caching = 1;
+	rq_req.rq.s.xqe_drop_ena = 0;	/* Disable RED dropping */
+	rq_req.rq.s.spb_drop_ena = 0;
+	rq_req.rq.s.lpb_drop_ena = 0;
+	rq_req.rq.s.spb_sizem1 = (MAX_MTU / (3 * 8)) - 1; /* 512 bytes */
+	rq_req.rq.s.lpb_sizem1 = (MAX_MTU / 8) - 1;
+	rq_req.rq.s.first_skip = 0;
+	rq_req.rq.s.later_skip = 0;
+	rq_req.rq.s.xqe_imm_copy = 0;
+	rq_req.rq.s.xqe_hdr_split = 0;
+	rq_req.rq.s.xqe_drop = 255;
+	rq_req.rq.s.xqe_pass = 255;
+	rq_req.rq.s.wqe_pool_drop = 0;	/* No WQE pool */
+	rq_req.rq.s.wqe_pool_pass = 0;	/* No WQE pool */
+	rq_req.rq.s.spb_aura_drop = 255;
+	rq_req.rq.s.spb_aura_pass = 255;
+	rq_req.rq.s.spb_pool_drop = 0;
+	rq_req.rq.s.spb_pool_pass = 0;
+	rq_req.rq.s.lpb_aura_drop = 255;
+	rq_req.rq.s.lpb_aura_pass = 255;
+	rq_req.rq.s.lpb_pool_drop = 0;
+	rq_req.rq.s.lpb_pool_pass = 0;
+	rq_req.rq.s.qint_idx = 0;
+
+	err = nix_aq_issue_command(nix_af, lf,
+				   CAVM_NIX_AQ_INSTOP_E_INIT,
+				   CAVM_NIX_AQ_CTYPE_E_RQ,
+				   0, &rq_req.resp);
+	if (err) { 
+		printf("%s: Error requesting send queue\n", __func__);
+		return err;
 	}
+
 	return 0;
 }
 
-static int nix_attach_completion_queue(struct nix_af_handle *nix_af, int lf,
-				       const union cavm_nix_cq_ctx_s *desc,
-				       u32 index)
+static int nix_attach_send_queue(struct nix *nix)
 {
-	union cavm_nix_aq_inst_s *inst;
-	volatile union cavm_nix_aq_res_s *res;
-	union cavm_nix_cq_ctx_s *context;
-	union cavm_nixx_af_aq_status aq_stat;
-	ulong start;
+	struct nix_af *nix_af = nix->nix_af;
+	struct nix_aq_sq_request sq_req ALIGNED;
+	int err;
 
-	debug("%s(%p, %d, %p, %u)\n", __func__, nix_af, lf, desc, index);
-	aq_stat.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
-	inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
-							aq_stat.s.head_ptr;
-	res = (union cavm_nix_aq_res_s *)nix_af->aq.res.base;
-	memset(inst, 0, sizeof(*inst));
-	inst->s.cindex = index;
-	inst->s.lf = lf;
-	inst->s.doneint = 0;
-	inst->s.ctype = CAVM_NIX_AQ_CTYPE_E_CQ;
-	inst->s.op = CAVM_NIX_AQ_INSTOP_E_INIT;
-	inst->s.res_addr = nix_af->aq.res.iova;
-
-	context = (union cavm_nix_cq_ctx_s *)
-			(nix_af->aq.res.base + CONFIG_SYS_CACHELINE_SIZE);
-	memset((void *)res, 0, nix_af->aq.res.entry_sz);
-	memcpy(context, desc, sizeof(*context));
-	__iowmb();
+	debug("%s(%p)\n", __func__, nix_af);
+	err = nix_af_setup_sq(nix); 
+
+	memset(&sq_req, 0, sizeof(sq_req));
+
+	sq_req.sq.s.ena = 1;
+	sq_req.sq.s.cq_ena = 1;
+	sq_req.sq.s.max_sqe_size = CAVM_NIX_MAXSQESZ_E_W16;
+	sq_req.sq.s.substream = 0; // FIXME: Substream IDs?
+	sq_req.sq.s.sdp_mcast = 0;
+	sq_req.sq.s.cq = NIX_CQ_TX;
+	sq_req.sq.s.cq_limit = 0;
+	sq_req.sq.s.smq = nix->lf;
+	sq_req.sq.s.sso_ena = 0;
+	sq_req.sq.s.smq_rr_quantum = MAX_MTU / 4;
+	sq_req.sq.s.default_chan = nix->lmac->chan_num;
+	sq_req.sq.s.sqe_stype = CAVM_NIX_STYPE_E_STP;
+	sq_req.sq.s.qint_idx = 0;
+	sq_req.sq.s.sqb_aura = NPA_POOL_TX;
+
+	err = nix_aq_issue_command(nix_af, nix->lf,
+				   CAVM_NIX_AQ_INSTOP_E_INIT,
+				   CAVM_NIX_AQ_CTYPE_E_SQ,
+				   0, &sq_req.resp);
+	if (err) { 
+		printf("%s: Error requesting send queue\n", __func__);
+		return err;
+	}
 
-	/* Now submit the aura context to HW */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
+	return 0;
+}
 
-	start = get_timer(0);
-	while ((res->s.compcode == CAVM_NIX_AQ_COMP_E_NOTDONE) &&
-	       (get_timer(start) < 1000))
-		WATCHDOG_RESET();
-	if (res->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
-		printf("%s: Bad result code 0x%x\n",
-		       __func__, res->s.compcode);
-		return -1;
+static int nix_attach_completion_queue(struct nix *nix, int cq_idx)
+{
+	struct nix_af *nix_af = nix->nix_af;
+	struct nix_aq_cq_request cq_req ALIGNED;
+	int err;
+
+	debug("%s(%p)\n", __func__, nix_af);
+	memset(&cq_req, 0, sizeof(cq_req));
+	cq_req.cq.s.ena = 1;
+	cq_req.cq.s.bpid = nix->lmac->pknd;
+	cq_req.cq.s.substream = 0;	/* FIXME: Substream IDs? */
+	cq_req.cq.s.drop_ena = 1;
+	cq_req.cq.s.caching = 1;
+	cq_req.cq.s.qsize = CQS_QSIZE;
+	cq_req.cq.s.drop = 255 * 7 / 8;
+	cq_req.cq.s.qint_idx = 0;
+	cq_req.cq.s.cint_idx = 0;
+	cq_req.cq.s.base = nix->cq[cq_idx].iova;
+	debug("%s: CQ(%d)  base %p \n", __func__, cq_idx,
+	      nix->cq[cq_idx].base);
+
+	err = nix_aq_issue_command(nix_af, nix->lf,
+				   CAVM_NIX_AQ_INSTOP_E_INIT,
+				   CAVM_NIX_AQ_CTYPE_E_CQ,
+				   cq_idx, &cq_req.resp);
+	if (err) {
+		printf("%s: Error requesting completion queue\n", __func__);
+		return err;
 	}
+	debug("%s: CQ(%d) allocated, base %p\n", __func__, cq_idx,
+	      nix->cq[cq_idx].base);
+
 	return 0;
 }
 
-int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
-		       union cavm_nix_cq_ctx_s *cq_descriptors,
-		       dma_addr_t cq_dev_addr,
-		       u32 cq_count,
-		       union cavm_nix_rq_ctx_s *rq_descriptors,
-		       dma_addr_t rq_dev_addr,
-		       u32 rq_count,
-		       union cavm_nix_sq_ctx_s *sq_descriptors,
-		       dma_addr_t sq_dev_addr,
-		       u32 sq_count)
+int nix_lf_admin_setup(struct nix *nix)
 {
 	union cavm_nixx_af_lfx_rqs_cfg rqs_cfg;
-	union cavm_nixx_af_lfx_rqs_cfg sqs_cfg;
-	union cavm_nixx_af_lfx_rqs_cfg cqs_cfg;
+	union cavm_nixx_af_lfx_sqs_cfg sqs_cfg;
+	union cavm_nixx_af_lfx_cqs_cfg cqs_cfg;
+	union cavm_nixx_af_lfx_rss_cfg rss_cfg;
+	union cavm_nixx_af_lfx_cints_cfg cints_cfg;
+	union cavm_nixx_af_lfx_qints_cfg qints_cfg;
+	union cavm_nixx_af_lfx_rss_grpx rss_grp;
 	union cavm_nixx_af_lfx_tx_cfg2 tx_cfg2;
 	union cavm_nixx_af_lfx_cfg lfx_cfg;
-	union cavm_nixx_af_smqx_cfg smqx_cfg;
 	u32 index;
+	struct nix_af *nix_af = nix->nix_af;
 	int err;
 
-	debug("%s(%p, %d, %d, %p, 0x%llx, %u, %p, 0x%llx, %u, %p, 0x%llx, %u)\n",
-	      __func__, nix_af, lf, pf, cq_descriptors, cq_dev_addr, cq_count,
-	      rq_descriptors, rq_dev_addr, rq_count,
-	      sq_descriptors, sq_dev_addr, sq_count);
-	/* Request queues */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_BASE(lf), rq_dev_addr);
-	rqs_cfg.u = 0;
+	/* Config NIX RQ HW context and base*/
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_BASE(nix->lf),
+			 (u64)nix->rq_ctx_base);
+	/* Set caching and queue count in HW */
+	rqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix->lf));
 	rqs_cfg.s.caching = 1;
-	rqs_cfg.s.max_queuesm1 = rq_count - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(lf), rqs_cfg.u);
+	rqs_cfg.s.max_queuesm1 = nix->rq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix->lf), rqs_cfg.u);
 
-	/* Send queues */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_BASE(lf), sq_dev_addr);
-	sqs_cfg.u = 0;
+	/* Config NIX SQ HW context and base*/
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_BASE(nix->lf),
+			 (u64)nix->sq_ctx_base);
+	sqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix->lf));
 	sqs_cfg.s.caching = 1;
-	sqs_cfg.s.max_queuesm1 = sq_count - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(lf), sqs_cfg.u);
+	sqs_cfg.s.max_queuesm1 = nix->sq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix->lf), sqs_cfg.u);
 
-	/* Completion queues */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_BASE(lf), cq_dev_addr);
-	cqs_cfg.u = 0;
+	/* Config NIX CQ HW context and base*/
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_BASE(nix->lf),
+			 (u64)nix->cq_ctx_base);
+	cqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix->lf));
 	cqs_cfg.s.caching = 1;
-	cqs_cfg.s.max_queuesm1 = cq_count - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(lf), cqs_cfg.u);
+	cqs_cfg.s.max_queuesm1 = nix->cq_cnt - 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix->lf), cqs_cfg.u);
+
+	/* Config NIX RSS HW context and base */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_BASE(nix->lf),
+			 (u64)nix->rss_base);
+	rss_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix->lf));
+	rss_cfg.s.ena = 1;
+	rss_cfg.s.size = ilog2(nix->rss_sz) / 256;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix->lf), rss_cfg.u);
+
+	for (index = 0; index < nix->rss_grps; index++) {
+		rss_grp.u = 0;
+		rss_grp.s.sizem1 = 0x7;
+		rss_grp.s.offset = nix->rss_sz * index;
+		nix_af_reg_write(nix_af,
+				 CAVM_NIXX_AF_LFX_RSS_GRPX(nix->lf, index),
+				 rss_grp.u);
+	}
+
+	/* Config CQints HW contexts and base */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_BASE(nix->lf),
+			 (u64)nix->cint_base);
+	cints_cfg.u = nix_af_reg_read(nix_af,
+				      CAVM_NIXX_AF_LFX_CINTS_CFG(nix->lf));
+	cints_cfg.s.caching = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_CFG(nix->lf),
+			 cints_cfg.u);
+
+	/* Config Qints HW context and base */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_BASE(nix->lf),
+			 (u64)nix->qint_base);
+	qints_cfg.u = nix_af_reg_read(nix_af,
+				      CAVM_NIXX_AF_LFX_QINTS_CFG(nix->lf));
+	qints_cfg.s.caching = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_CFG(nix->lf),
+			 qints_cfg.u);
+
+	debug("%s(%p, %d, %d)\n", __func__, nix_af, nix->lf, nix->pf);
 
 	/* Enable LMTST for this NIX LF */
-	tx_cfg2.u = 0;
+	tx_cfg2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix->lf));
 	tx_cfg2.s.lmt_ena = 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(lf), tx_cfg2.u);
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix->lf), tx_cfg2.u);
 
-	/* Use 16-word XQEs, write the NPA PF|LF number only */
-	lfx_cfg.u = 0;
-	lfx_cfg.s.npa_pf_func = pf << 10;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CFG(lf), lfx_cfg.u);
+	/* Use 16-word XQEs, write the npa pf_func number only */
+	lfx_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CFG(nix->lf));
+	lfx_cfg.s.xqe_size = CAVM_NIX_XQESZ_E_W16;
+	lfx_cfg.s.npa_pf_func = nix->pf_func;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CFG(nix->lf), lfx_cfg.u);
 
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RX_CFG(lf), 0);
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RX_CFG(nix->lf), 0);
 
-	for (index = 0; index < cq_count; index++) {
-		err = nix_attach_completion_queue(nix_af, lf,
-						  &cq_descriptors[index],
-						  index);
+	for (index = 0; index < nix->cq_cnt; index++) {
+		err = nix_attach_completion_queue(nix, index);
 		if (err) {
 			printf("%s: Error attaching completion queue %d\n",
 			       __func__, index);
@@ -672,9 +689,8 @@ int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
 		}
 	}
 
-	for (index = 0; index < rq_count; index++) {
-		err = nix_attach_receive_queue(nix_af, lf,
-					       &rq_descriptors[index], index);
+	for (index = 0; index < nix->rq_cnt; index++) {
+		err = nix_attach_receive_queue(nix_af, nix->lf);
 		if (err) {
 			printf("%s: Error attaching receive queue %d\n",
 			       __func__, index);
@@ -682,9 +698,8 @@ int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
 		}
 	}
 
-	for (index = 0; index < sq_count; index++) {
-		err = nix_attach_send_queue(nix_af, lf,
-					    &sq_descriptors[index], index);
+	for (index = 0; index < nix->sq_cnt; index++) {
+		err = nix_attach_send_queue(nix);
 		if (err) {
 			printf("%s: Error attaching send queue %d\n",
 			       __func__, index);
@@ -692,18 +707,10 @@ int nix_lf_admin_setup(struct nix_af_handle *nix_af, int lf, int pf,
 		}
 	}
 
-	smqx_cfg.u = 0;
-	/* Disable shaper control for packets */
-	smqx_cfg.s.desc_shp_ctl_dis = 1;
-	smqx_cfg.s.minlen = NIX_MIN_HW_MTU;
-	smqx_cfg.s.maxlen = NIX_MIN_HW_MTU;
-	smqx_cfg.s.lf = lf;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_SMQX_CFG(lf), smqx_cfg.u);
-
 	return 0;
 }
 
-int nix_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf,
+int nix_lf_admin_shutdown(struct nix_af *nix_af, int lf,
 			  u32 cq_count, u32 rq_count, u32 sq_count)
 {
 	union cavm_nixx_af_rx_sw_sync sw_sync;
@@ -837,218 +844,7 @@ int nix_lf_admin_shutdown(struct nix_af_handle *nix_af, int lf,
 	return 0;
 }
 
-struct nix_af_handle *nix_af_initialize(int instance, struct udevice *dev,
-					void *bar0_ptr, void *bar2_ptr,
-					void *npa_bar0_ptr)
-{
-	struct nix_af_handle *nix_af;
-	struct npa_af_handle *npa;
-	int err;
-
-	if (instance >= MAX_NIX)
-		return NULL;
-
-	nix_af = &nix_afs[instance];
-	debug("%s(%d, %s, %p, %p, %p): nix_af: %p\n",
-	      __func__, instance, dev->name, bar0_ptr, bar2_ptr, npa_bar0_ptr,
-	      nix_af);
-
-	if (nix_afs_references[instance]++) {
-		debug("%s: NIX %d already initialized\n", __func__, instance);
-		return nix_af;
-	}
-
-	nix_af->index = instance;
-	nix_af->dev = dev;
-	nix_af->nix_af_base = bar0_ptr;
-	if (!nix_af->npa_af) {
-		nix_af->npa_af = calloc(1, sizeof(struct npa_af_handle));
-		if (!nix_af->npa_af) {
-			printf("%s: out of memory\n", __func__);
-			goto error;
-		}
-	}
-	npa = nix_af->npa_af;
-	npa->npa_base = npa_bar0_ptr;
-
-	debug("%s: Setting up npa admin\n", __func__);
-	err = npa_setup_admin(nix_af);
-	if (err) {
-		printf("%s: Error %d setting up NPA admin\n", __func__, err);
-		goto error;
-	}
-	debug("%s: Setting up nix af\n", __func__);
-	err = nix_af_setup(nix_af);
-	if (err) {
-		printf("%s: Error %d setting up NIX admin\n", __func__, err);
-		goto error;
-	}
-	debug("%s: nix_af: %p\n", __func__, nix_af);
-	return nix_af;
-
-error:
-	nix_afs_references[instance]--;
-	if (nix_af->npa_af) {
-		free(nix_af->npa_af);
-		memset(nix_af, 0, sizeof(*nix_af));
-	}
-	return NULL;
-}
-
-static int nix_af_shutdown(struct nix_af_handle *nix_af)
-{
-	union cavm_nixx_af_blk_rst blk_rst;
-
-	if (!nix_afs_references[nix_af->index])
-		return 0;
-	if (--nix_afs_references[nix_af->index])
-		return 0;
-
-	blk_rst.u = 0;
-	blk_rst.s.rst = 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
-
-	/* Wait for reset to complete */
-	do {
-		blk_rst.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_BLK_RST());
-		WATCHDOG_RESET();
-	} while (blk_rst.s.busy);
-
-	blk_rst.u = 0;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
-	cavm_rvu_aq_free(&nix_af->npa_af->aq);
-	cavm_rvu_aq_free(&nix_af->aq);
-
-	return 0;
-}
-
-static int nix_aq_init(struct nix_af_handle *nix_af)
-{
-	union cavm_nixx_af_cfg cfg;
-	union cavm_nixx_af_ndc_cfg ndc_cfg;
-	union cavm_nixx_af_aq_cfg aq_cfg;
-	int err;
-
-	if (nix_af->aq.inst.base)
-		return 0;
-
-	debug("%s(%p)\n", __func__, nix_af);
-	nix_af->xqe_size = CAVM_NIX_XQESZ_E_W16;
-
-	/* Set admin queue endianess */
-	cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CFG());
-	cfg.s.af_be = 0;	/* Force little-endian */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_CFG(), cfg.u);
-
-	/* Do not bypass NDC cache */
-	ndc_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_NDC_CFG());
-	ndc_cfg.s.ndc_ign_pois = 0;
-	ndc_cfg.s.byp_sq = 0;
-	ndc_cfg.s.byp_sqb = 0;
-	ndc_cfg.s.byp_cqs = 0;
-	ndc_cfg.s.byp_cints = 0;
-	ndc_cfg.s.byp_dyno = 0;
-	ndc_cfg.s.byp_mce = 0;
-	ndc_cfg.s.byp_rqc = 0;
-	ndc_cfg.s.byp_rsse = 0;
-	ndc_cfg.s.byp_mc_data = 0;
-	ndc_cfg.s.byp_mc_wqe = 0;
-	ndc_cfg.s.byp_mr_data = 0;
-	ndc_cfg.s.byp_mr_wqe = 0;
-	ndc_cfg.s.byp_qints = 0;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_NDC_CFG(), ndc_cfg.u);
-
-	/* Result structure can be followed by RQ/SQ/CQ context at
-	 * res + 128 bytes and a write mask at RES + 256 bytes depending on
-	 * the operation type.  Alloc sufficient result memory for all
-	 * operations.
-	 */
-	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
-				sizeof(union cavm_nix_aq_inst_s),
-				ALIGN(sizeof(union cavm_nix_aq_res_s),
-				      CONFIG_SYS_CACHELINE_SIZE) + 256);
-	if (err)
-		return err;
-
-	aq_cfg.u = 0;
-	aq_cfg.s.qsize = AQ_SIZE;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_CFG(), aq_cfg.u);
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_BASE(), nix_af->aq.inst.iova);
-
-	return 0;
-}
-
-/**
- * Issue a command to the NIX AF Admin Queue
- *
- * @param nix    nix handle
- * @param lf     Logical function number for command
- * @param op     Operation
- * @param ctype  Context type
- * @param cindex Context index
- * @param resp   Result pointer
- *
- * @return	0 for success, -EBUSY on failure
- */
-static int nix_aq_issue_command(struct nix_af_handle *nix_af,
-				int lf,
-				int op,
-				int ctype,
-				int cindex, union cavm_nix_aq_res_s *resp)
-{
-	union cavm_nixx_af_aq_status aq_status;
-	union cavm_nix_aq_inst_s *aq_inst;
-	volatile union cavm_nix_aq_res_s *result = resp;
-	ulong start;
-
-	debug("%s(%p, 0x%x, 0x%x, 0x%x, 0x%x, %p)\n", __func__, nix_af, lf,
-	      op, ctype, cindex, resp);
-	memset(result, 0, sizeof(*result));
-	aq_status.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_AQ_STATUS());
-	aq_inst = (union cavm_nix_aq_inst_s *)(nix_af->aq.inst.base) +
-						aq_status.s.head_ptr;
-	aq_inst->u[0] = 0;
-	aq_inst->u[1] = 0;
-	aq_inst->s.op = op;
-	aq_inst->s.ctype = ctype;
-	aq_inst->s.lf = lf;
-	aq_inst->s.cindex = cindex;
-	aq_inst->s.doneint = 0;
-	aq_inst->s.res_addr = (u64)resp;
-	debug("%s: inst@%p: 0x%llx 0x%llx\n", __func__, aq_inst,
-	      aq_inst->u[0], aq_inst->u[1]);
-	__iowmb();
-
-	/* Ring doorbell and wait for result */
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_DOOR(), 1);
-
-	start = get_timer(0);
-	/* Wait for completion */
-	do {
-		WATCHDOG_RESET();
-	} while (result->s.compcode == 0 && get_timer(start) < 2);
-
-	if (result->s.compcode != CAVM_NIX_AQ_COMP_E_GOOD) {
-		printf("NIX: Admin Queue failed or timed out with code %d after %ld ms\n",
-		       result->s.compcode, get_timer(start));
-		return -EBUSY;
-	}
-	return 0;
-}
-
-static void nix_get_cgx_lmac_id(u8 map, u8 *cgx_id, u8 *lmac_id)
-{
-	*cgx_id = (map >> 4) & 0xf;
-	*lmac_id = (map & 0xf);
-}
-
-int nix_af_get_pf_num(const struct nix_af_handle *nix)
-{
-	return (((u64)(nix->nix_af_base)) >> 36) & 0x0f;
-}
-
-int npc_lf_admin_setup(struct nix_af_handle *nix_af,
-		       struct cgx *cgx, u64 link_num)
+int npc_lf_admin_setup(struct nix *nix)
 {
 	union cavm_npc_af_const af_const;
 	union cavm_npc_af_pkindx_action0 action0;
@@ -1059,17 +855,12 @@ int npc_lf_admin_setup(struct nix_af_handle *nix_af,
 	union cavm_npc_af_mcamex_bankx_cfg bankx_cfg;
 	union cavm_nix_rx_action_s rx_action;
 	union cavm_nix_tx_action_s tx_action;
-	int pf = nix_af_get_pf_num(nix_af);
+	struct nix_af *nix_af = nix->nix_af;
 	u32 kpus;
-	int pkind = link_num;
+	int pkind = nix->lmac->link_num;
 	int index;
 
-	debug("%s(%p, 0x%llx)\n", __func__, nix_af, link_num);
-	if (!cgx) {
-		printf("%s: No CGX data found for link number 0x%llx\n",
-		       __func__, link_num);
-		return -1;
-	}
+	debug("%s(%p, pkind 0x%x)\n", __func__, nix_af, pkind);
 	af_const.u = npc_af_reg_read(nix_af, CAVM_NPC_AF_CONST());
 	kpus = af_const.s.kpus;
 
@@ -1099,13 +890,13 @@ int npc_lf_admin_setup(struct nix_af_handle *nix_af,
 			 camx_intf.u);
 
 	camx_w0.u = 0;
-	camx_w0.s.md = ~cgx_get_channel_number(cgx, link_num);
+	camx_w0.s.md = ~(nix->lmac->chan_num);
 	npc_af_reg_write(nix_af,
 			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(pkind, 0, 0),
 			 camx_w0.u);
 
 	camx_w0.u = 0;
-	camx_w0.s.md = cgx_get_channel_number(cgx, link_num);
+	camx_w0.s.md = nix->lmac->chan_num;
 	npc_af_reg_write(nix_af,
 			 CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(pkind, 0, 1),
 			 camx_w0.u);
@@ -1122,7 +913,7 @@ int npc_lf_admin_setup(struct nix_af_handle *nix_af,
 			 bankx_cfg.u);
 
 	rx_action.u = 0;
-	rx_action.s.pf_func = pf << 10;
+	rx_action.s.pf_func = nix->pf_func;
 	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_UCAST;
 	npc_af_reg_write(nix_af, CAVM_NPC_AF_MCAMEX_BANKX_ACTION(pkind, 0),
 			 rx_action.u);
@@ -1131,7 +922,7 @@ int npc_lf_admin_setup(struct nix_af_handle *nix_af,
 		npc_af_reg_write(nix_af, CAVM_NPC_AF_KPUX_CFG(index), 0);
 
 	rx_action.u = 0;
-	rx_action.s.pf_func = pf << 10;
+	rx_action.s.pf_func = nix->pf_func;
 	rx_action.s.op = CAVM_NIX_RX_ACTIONOP_E_DROP;
 	npc_af_reg_write(nix_af,
 			 CAVM_NPC_AF_INTFX_MISS_ACT(CAVM_NPC_INTF_E_NIXX_RX(0)),
@@ -1145,335 +936,107 @@ int npc_lf_admin_setup(struct nix_af_handle *nix_af,
 	return 0;
 }
 
-static int nix_interface_init(struct nix_af_handle *nix_af,
-			      struct nix_handle *nix, u16 pcifunc,
-			      int type, int nixlf)
+int nix_af_setup(struct nix_af *nix_af)
 {
-	union cavm_rvu_pf_func_s pf_func;
-	struct cgx *cgx = nix->lmac->cgx;
 	int err;
-	int pkind, pf, lmac_cnt;
-	u64 tx_credit;
-	u16 link;
-	u8 cgx_id = nix->lmac->cgx->cgx_id;
-	u8 lmac_id = nix->lmac->lmac_id;
-
-	pf = rvu_get_pf(pcifunc);
-
-	debug("%s(%p, %p, 0x%x, 0x%x, 0x%x) pf: 0x%x\n", __func__, nix_af, nix,
-	      pcifunc, type, nixlf, pf);
-
-	switch (type) {
-	case NIX_INTF_TYPE_CGX:
-		pkind = npc_get_pkind(nix_af, pf);
-		if (pkind < 0) {
-			printf("%s: Error: invalid pkind 0x%x for pf 0x%x\n",
-			       __func__, pkind, pf);
-			return -EINVAL;
-		}
-		cgx_set_pkind(cgx, lmac_id, pkind);
-		link = NIX_LINK_CGX_LMAC(cgx_id, lmac_id);
-		break;
-	case NIX_INTF_TYPE_LBK:
-		link = NIX_LINK_LBK(0);
-		break;
-	}
-	return 0;
-}
-
-struct nix_handle *cavm_nix_lf_alloc(struct nix_af_handle *nix_af,
-				     struct udevice *dev,
-				     u16 pcifunc,
-				     u16 nix_lf,
-				     void __iomem *nix_base,
-				     void __iomem *npc_base,
-				     void __iomem *lmt_base,
-				     int cgx_id, int lmac_id,
-				     struct nix_lf_alloc_req *req,
-				     struct nix_lf_alloc_rsp *rsp)
-{
-	union cavm_nixx_af_sq_const sq_const;
 	union cavm_nixx_af_const2 af_const2;
 	union cavm_nixx_af_const3 af_const3;
-	union cavm_nixx_af_lfx_rqs_cfg rqs_cfg;
-	union cavm_nixx_af_lfx_sqs_cfg sqs_cfg;
-	union cavm_nixx_af_lfx_cqs_cfg cqs_cfg;
-	union cavm_nixx_af_lfx_rss_cfg rss_cfg;
-	union cavm_nixx_af_lfx_cints_cfg cints_cfg;
-	union cavm_nixx_af_lfx_qints_cfg qints_cfg;
-	union cavm_nixx_af_lfx_rss_grpx rss_grp;
-	union cavm_nixx_af_lfx_tx_cfg2 tx_cfg2;
-	union cavm_nixx_af_lfx_cfg lfx_cfg;
-	int idx, hwctx_size;
-	int qints;
-	struct nix_handle *nix;
-	int err;
-	static int instance = 0;
-
-	debug("%s(%p, %s, 0x%x, 0x%x, %p, %p, %p, 0x%x, 0x%x, %p, %p)\n",
-	      __func__, nix_af, dev->name, pcifunc, nix_lf, nix_base, npc_base,
-	      lmt_base, cgx_id, lmac_id, req, rsp);
-
-	if (!nix_lf)
-		return NULL;
-
-	if (!req->rq_cnt || !req->sq_cnt || !req->cq_cnt)
-		return NULL;
-
-	af_const3.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST3());
-	hwctx_size = 1ULL << af_const3.s.rq_ctx_log2bytes;
+	union cavm_nixx_af_sq_const sq_const;
+	union cavm_nixx_af_cfg af_cfg;
+	union cavm_nixx_af_ndc_cfg ndc_cfg;
+	union cavm_nixx_af_aq_cfg aq_cfg;
+	union cavm_nixx_af_blk_rst blk_rst;
 
-	nix = (struct nix_handle *)calloc(1, sizeof(*nix));
-	if (!nix) {
-		printf("%s: Out of memory\n", __func__);
-		return NULL;
-	}
-	nix->nic_id = instance++;
-	nix->nix_af = nix_af;
-	nix->nix_base = nix_base;
-	nix->npc_base = npc_base;
-	nix->lmt_base = lmt_base;
-	nix->lf = nix_lf;
-	nix->dev = dev;
-	nix->pf = pcifunc;
-	nix->lmac = cgx_get_lmac(pcifunc - 1);
-	if (!nix->lmac) {
-		printf("%s: Error: could not find lmac for pf %d\n",
-		       __func__, nix->pf);
-		free(nix);
-		return NULL;
+	debug("%s(%p)\n", __func__, nix_af);
+	err = rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
+				sizeof(union cavm_nix_aq_inst_s),
+				sizeof(union cavm_nix_aq_res_s));
+	if (err) {
+		printf("%s: Error allocating nix admin queue\n", __func__);
+		return err;
 	}
 
-	/* Alloc NIX RQ HW context memory and config base */
-	err = qmem_alloc(&(nix->rq), req->rq_cnt, hwctx_size);
-	if (err)
-		goto error;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_BASE(nix_lf),
-			 nix->rq.iova);
+	blk_rst.u = 0;
+	blk_rst.s.rst = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
 
-	/* Set caching and queue count in HW */
-	rqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix_lf));
-	rqs_cfg.s.caching = 1;
-	rqs_cfg.s.max_queuesm1 = req->rq_cnt - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RQS_CFG(nix_lf), rqs_cfg.u);
-
-	/* Alloc NIX SQ HW context memory and config the base */
-	hwctx_size = 1ULL << af_const3.s.sq_ctx_log2bytes;
-	err = qmem_alloc(&(nix->sq), req->sq_cnt, hwctx_size);
-	if (err)
-		goto error;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_BASE(nix_lf),
-			 nix->sq.iova);
-	sqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix_lf));
-	sqs_cfg.s.caching = 1;
-	sqs_cfg.s.max_queuesm1 = req->sq_cnt - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_SQS_CFG(nix_lf), sqs_cfg.u);
-
-	/* Alloc NIX CQ HW context memory and config the base */
-	hwctx_size = 1ULL << af_const3.s.cq_ctx_log2bytes;
-	for (idx = 0; idx < NIX_CQ_COUNT; idx++) {
-		err = qmem_alloc(&(nix->cq[idx]), req->cq_cnt, hwctx_size);
-		if (err)
-			goto error;
-	}
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_BASE(nix_lf),
-			 nix->cq[NIX_CQ_TX].iova);
-	cqs_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix_lf));
-	cqs_cfg.s.caching = 1;
-	cqs_cfg.s.max_queuesm1 = req->cq_cnt - 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CQS_CFG(nix_lf), cqs_cfg.u);
-
-	/* Alloc NIX RSS HW context memory and config the base */
-	hwctx_size = 1ULL << af_const3.s.rsse_log2bytes;
-	err = qmem_alloc(&(nix->rss), req->rss_sz * req->rss_grps, hwctx_size);
-	if (err)
-		goto error;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_BASE(nix_lf),
-			 nix->rss.iova);
-	rss_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix_lf));
-	rss_cfg.s.ena = 1;
-	rss_cfg.s.size = ilog2(req->rss_sz) / 256;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_CFG(nix_lf), rss_cfg.u);
+	/* Wait for reset to complete */
+	do {
+		blk_rst.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_BLK_RST());
+		WATCHDOG_RESET();
+	} while (blk_rst.s.busy);
 
-	for (idx = 0; idx < req->rss_grps; idx++) {
-		rss_grp.u = 0;
-		rss_grp.s.sizem1 = 0x7;
-		rss_grp.s.offset = req->rss_sz * idx;
-		nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_RSS_GRPX(nix_lf, idx),
-				 rss_grp.u);
+	/* Put in LE mode */
+	af_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CFG());
+	if (af_cfg.s.force_cond_clk_en ||
+	    af_cfg.s.calibrate_x2p || af_cfg.s.force_intf_clk_en) {
+		    printf("%s: Error: Invalid NIX_AF_CFG value 0x%llx\n",
+			   __func__, af_cfg.u);
+		    return -1;
 	}
+	af_cfg.s.af_be = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_CFG(), af_cfg.u);
 
-	/* Alloc memory for CQints HW contextxs */
-	af_const2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST2());
-	qints = af_const2.s.cints;
-	hwctx_size = 1ULL << af_const3.s.cint_log2bytes;
-	err = qmem_alloc(&nix->cq_ints, qints, hwctx_size);
-	if (err)
-		goto error;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_BASE(nix_lf),
-			 nix->cq_ints.iova);
-	cints_cfg.u = nix_af_reg_read(nix_af,
-				      CAVM_NIXX_AF_LFX_CINTS_CFG(nix_lf));
-	cints_cfg.s.caching = 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CINTS_CFG(nix_lf),
-			 cints_cfg.u);
-
-	/* Alloc memory for Qints HW contexts */
-	qints = af_const2.s.qints;
-	hwctx_size = 1ULL << af_const3.s.qint_log2bytes;
-	err = qmem_alloc(&(nix->qints), qints, hwctx_size);
-	if (err)
-		goto error;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_BASE(nix_lf),
-			 nix->qints.iova);
-	qints_cfg.u = nix_af_reg_read(nix_af,
-				      CAVM_NIXX_AF_LFX_QINTS_CFG(nix_lf));
-	qints_cfg.s.caching = 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_QINTS_CFG(nix_lf),
-			 qints_cfg.u);
-
-	/* Enable LMTST for this NIX LF */
-	tx_cfg2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix_lf));
-	tx_cfg2.s.lmt_ena = 1;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_TX_CFG2(nix_lf), tx_cfg2.u);
+	/* Enable NDC cache */
+	ndc_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_NDC_CFG());
+	ndc_cfg.s.ndc_ign_pois = 0;
+	ndc_cfg.s.byp_sq = 0;
+	ndc_cfg.s.byp_sqb = 0;
+	ndc_cfg.s.byp_cqs = 0;
+	ndc_cfg.s.byp_cints = 0;
+	ndc_cfg.s.byp_dyno = 0;
+	ndc_cfg.s.byp_mce = 0;
+	ndc_cfg.s.byp_rqc = 0;
+	ndc_cfg.s.byp_rsse = 0;
+	ndc_cfg.s.byp_mc_data = 0;
+	ndc_cfg.s.byp_mc_wqe = 0;
+	ndc_cfg.s.byp_mr_data = 0;
+	ndc_cfg.s.byp_mr_wqe = 0;
+	ndc_cfg.s.byp_qints = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_NDC_CFG(), ndc_cfg.u);
 
-	lfx_cfg.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_LFX_CFG(nix_lf));
-	lfx_cfg.s.xqe_size = req->xqe_sz;
-	lfx_cfg.s.npa_pf_func = pcifunc;
-	lfx_cfg.s.sso_pf_func = pcifunc;
-	nix_af_reg_write(nix_af, CAVM_NIXX_AF_LFX_CFG(nix_lf), lfx_cfg.u);
+	/* Set up queue size */
+	aq_cfg.u = 0;
+	aq_cfg.s.qsize = AQ_SIZE;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_CFG(), aq_cfg.u);
 
-	/* Config Rx pkt length, csum checks and apad enable/disable */
+	/* Set up queue base address */
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_AQ_BASE(), nix_af->aq.inst.iova);
 
+	af_const3.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST3());
+	af_const2.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_CONST2());
 	sq_const.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_SQ_CONST());
-	rsp->sqb_size = sq_const.s.sqb_size;
-	rsp->chan_base = CAVM_NIX_CHAN_E_CGXX_LMACX_CHX(cgx_id, lmac_id, 0);
-	rsp->chan_cnt = 1;
+	nix_af->rq_ctx_sz = 1ULL << af_const3.s.rq_ctx_log2bytes;
+	nix_af->sq_ctx_sz = 1ULL << af_const3.s.sq_ctx_log2bytes;
+	nix_af->cq_ctx_sz = 1ULL << af_const3.s.cq_ctx_log2bytes;
+	nix_af->rsse_ctx_sz = 1ULL << af_const3.s.rsse_log2bytes;
+	nix_af->qints = af_const2.s.qints;
+	nix_af->cints = af_const2.s.cints;
+	nix_af->cint_ctx_sz = 1ULL << af_const3.s.cint_log2bytes;
+	nix_af->qint_ctx_sz = 1ULL << af_const3.s.qint_log2bytes;
+	nix_af->sqb_size = sq_const.s.sqb_size;
 
-	err = nix_lf_alloc_cq(nix_af, nix);
-	if (err) {
-		printf("%s: Error %d allocating completion queue for pf %d\n",
-		       __func__, err, pcifunc);
-		return NULL;
-	}
-#if 0
-	rsp->lso_tsov4_idx = NIX_LSO_FORMAT_IDX_TSOV4;
-	rsp->lso_tsov6_idx = NIX_LSO_FORMAT_IDX_TSOV6;
-#endif
-	list_add(&nix->nix_list, &nix_list);
-
-	return nix;
-
-error:
-	qmem_free(&(nix->rq));
-	qmem_free(&(nix->sq));
-	for (idx = 0; idx < NIX_CQ_COUNT; idx++)
-		qmem_free(&(nix->cq[idx]));
-	qmem_free(&(nix->rss));
-	qmem_free(&(nix->cq_ints));
-	qmem_free(&(nix->qints));
-	return NULL;
+	return 0;
 }
 
-/**
- * Allocate and setup a new Completion Queue for use
- *
- * @param nix_af	Handle for admin function
- * @param nix		Handle for pf
- *
- * @return Completion Queue number, or negative on failure
- */
-static int nix_lf_alloc_cq(struct nix_af_handle *nix_af, struct nix_handle *nix)
+int nix_af_shutdown(struct nix_af *nix_af)
 {
-	struct nix_aq_cq_request aq_request ALIGNED;
-	int cq = af_state.next_free_cq++;
-	int err;
-
-	err = cavm_rvu_aq_alloc(&nix_af->aq, Q_COUNT(AQ_SIZE),
-			sizeof(union cavm_nix_aq_inst_s),
-			ALIGN(sizeof(union cavm_nix_aq_res_s), 128) + 256);
-
-	if (err) {
-		printf("%s: Error %d allocating completion queue\n",
-		       __func__, err);
-		return err;
-	}
+	union cavm_nixx_af_blk_rst blk_rst;
 
-	memset(&aq_request, 0, sizeof(aq_request));
-	aq_request.cq.s.ena = 1;
-	aq_request.cq.s.bpid = nix->pki_channel;
-	aq_request.cq.s.substream = 0;	/* FIXME: Substream IDs? */
-	aq_request.cq.s.drop_ena = 1;
-	aq_request.cq.s.caching = 1;
-	aq_request.cq.s.qsize = CQS_QSIZE;
-	aq_request.cq.s.drop = 255 * 7 / 8;
-	aq_request.cq.s.qint_idx = 0;
-	aq_request.cq.s.cint_idx = 0;
-	aq_request.cq.s.base = nix->cq[NIX_CQ_TX].iova;
-
-	err = nix_aq_issue_command(nix_af, CAVM_NIX_AQ_INSTOP_E_INIT,
-				   CAVM_NIX_AQ_CTYPE_E_CQ, nix->lf, cq,
-				   &aq_request.resp);
-	if (err) {
-		printf("%s: Error requesting completion queue\n", __func__);
-		return err;
-	}
-	debug("%s: CQ(%d) allocated, base %p, %p\n", __func__, cq,
-	      nix->cq[NIX_CQ_TX].base, nix->cq[NIX_CQ_RX].base);
+	blk_rst.u = 0;
+	blk_rst.s.rst = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
 
-	nix->cq_idx = cq;
+	/* Wait for reset to complete */
+	do {
+		blk_rst.u = nix_af_reg_read(nix_af, CAVM_NIXX_AF_BLK_RST());
+		WATCHDOG_RESET();
+	} while (blk_rst.s.busy);
 
-	return nix->cq_idx;
-}
-#if 0
-int nix_af_setup_tx_resources(struct nix_af_handle *nix)
-{
-	struct rvu_hwinfo *hw = nix->hw;
-	struct nix_txsch *txsch;
-	union cavm_nixx_af_const af_const;
-	union cavm_nixx_af_tl1_const tl_const;
-	u64 reg;
-	int err, lvl;
-
-	/* Set number of links of each type */
-	af_const.u = nix_af_reg_read(nix, CAVM_NIXX_AF_CONST());
-	hw->cgx = af_const.s.num_cgx;
-	hw->lmac_per_cgx = af_const.s.cgx_lmacs;
-	hw->cgx_links = hw->cgx * hw->lmac_per_cgx;
-	hw->lbk_links = 1;
-	hw->sdp_links = 1;
-
-	for (lvl = 0; lvl < NIX_TXSCH_LVL_CNT; lvl++) {
-		txsch = &hw->txsch[lvl];
-		txsch->lvl = lvl;
-		switch (lvl) {
-		case NIX_TXSCH_LVL_SMQ:
-			reg = CAVM_NIXX_AF_MDQ_CONST();
-			break;
-		case NIX_TXSCH_LVL_TL4:
-			reg = CAVM_NIXX_AF_TL4_CONST();
-			break;
-		case NIX_TXSCH_LVL_TL3:
-			reg = CAVM_NIXX_AF_TL3_CONST();
-			break;
-		case NIX_TXSCH_LVL_TL2:
-			reg = CAVM_NIXX_AF_TL2_CONST();
-			break;
-		case NIX_TXSCH_LVL_TL1:
-			reg = CAVM_NIXX_AF_TL1_CONST();
-			break;
-		}
-		tl_const.u = nix_af_reg_read(reg);
-		txsch->rsrc.max = tl_const.s.count;
-		err = rvu_alloc_bitmap(&txsch->rsrc);
-		if (err)
-			return err;
+	blk_rst.u = 0;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_BLK_RST(), blk_rst.u);
+	rvu_aq_free(&nix_af->npa_af->aq);
+	rvu_aq_free(&nix_af->aq);
 
-		/* Allocate mem for scheduler to PF/VF pcifunc mapping info */
-		txsch->pfvf_map = calloc(txsch->rsrc.max, sizeof(u16));
-		if (!txsch->pfvf_map)
-			return -ENOMEM;
-	}
 	return 0;
 }
-#endif
diff --git a/drivers/net/cavium/octeontx2/nix_af.h b/drivers/net/cavium/octeontx2/nix_af.h
deleted file mode 100644
index 805d99b939..0000000000
--- a/drivers/net/cavium/octeontx2/nix_af.h
+++ /dev/null
@@ -1,15 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Cavium OcteonTx2 RVU Admin function driver
- *
- * Copyright (C) 2018 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- */
-
-#ifndef __NIX_AF_H__
-#define __NIX_AF_H__
-
-
-#endif /* __NIX_AF_H__ */
diff --git a/drivers/net/cavium/octeontx2/nix_lf.h b/drivers/net/cavium/octeontx2/nix_lf.h
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/drivers/net/cavium/octeontx2/npa_hw.h b/drivers/net/cavium/octeontx2/npa_hw.h
deleted file mode 100644
index 60f006d998..0000000000
--- a/drivers/net/cavium/octeontx2/npa_hw.h
+++ /dev/null
@@ -1,2734 +0,0 @@
-/*
- * Copyright (C) 2018 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This file defines the NPA registers for the Cavium OcteonTX2.
- */
-
-#ifndef __NPA_HW_H__
-#define __NPA_HW_H__
-
-/**
- * Enumeration npa_af_int_vec_e
- *
- * NPA Admin Function Interrupt Vector Enumeration
- * Enumerates the NPA AF MSI-X interrupt vectors.
- */
-#define CAVM_NPA_AF_INT_VEC_E_AF_ERR (3)
-#define CAVM_NPA_AF_INT_VEC_E_AQ_DONE (2)
-#define CAVM_NPA_AF_INT_VEC_E_GEN (1)
-#define CAVM_NPA_AF_INT_VEC_E_POISON (4)
-#define CAVM_NPA_AF_INT_VEC_E_RVU (0)
-
-/**
- * Enumeration npa_aq_comp_e
- *
- * NPA Admin Queue Completion Enumeration
- * Enumerates the values of NPA_AQ_RES_S[COMPCODE].
- */
-#define CAVM_NPA_AQ_COMP_E_CTX_FAULT (4)
-#define CAVM_NPA_AQ_COMP_E_CTX_POISON (3)
-#define CAVM_NPA_AQ_COMP_E_GOOD (1)
-#define CAVM_NPA_AQ_COMP_E_LOCKERR (5)
-#define CAVM_NPA_AQ_COMP_E_NOTDONE (0)
-#define CAVM_NPA_AQ_COMP_E_SWERR (2)
-
-/**
- * Enumeration npa_aq_ctype_e
- *
- * NPA Admin Queue Context Type Enumeration
- * Enumerates NPA_AQ_INST_S[CTYPE] values.
- */
-#define CAVM_NPA_AQ_CTYPE_E_AURA (0)
-#define CAVM_NPA_AQ_CTYPE_E_POOL (1)
-
-/**
- * Enumeration npa_aq_instop_e
- *
- * NPA Admin Queue Opcode Enumeration
- * Enumerates NPA_AQ_INST_S[OP] values.
- */
-#define CAVM_NPA_AQ_INSTOP_E_INIT (1)
-#define CAVM_NPA_AQ_INSTOP_E_LOCK (4)
-#define CAVM_NPA_AQ_INSTOP_E_NOP (0)
-#define CAVM_NPA_AQ_INSTOP_E_READ (3)
-#define CAVM_NPA_AQ_INSTOP_E_UNLOCK (5)
-#define CAVM_NPA_AQ_INSTOP_E_WRITE (2)
-
-/**
- * Enumeration npa_aura_err_int_e
- *
- * NPA Aura Error Interrupt Enumeration
- * Enumerates the bit index of NPA_AURA_S[ERR_INT], and NPA_AURA_S[ERR_INT_ENA].
- */
-#define CAVM_NPA_AURA_ERR_INT_E_AURA_ADD_OVER (1)
-#define CAVM_NPA_AURA_ERR_INT_E_AURA_ADD_UNDER (2)
-#define CAVM_NPA_AURA_ERR_INT_E_AURA_FREE_UNDER (0)
-#define CAVM_NPA_AURA_ERR_INT_E_POOL_DIS (3)
-#define CAVM_NPA_AURA_ERR_INT_E_RX(a) (0 + (a))
-
-/**
- * Enumeration npa_bpintf_e
- *
- * NPA Backpressure Interface Enumeration
- * Enumerates index of NPA_AURA_S[BP_ENA].
- */
-#define CAVM_NPA_BPINTF_E_NIXX_RX(a) (0 + (a))
-
-/**
- * Enumeration npa_inpq_e
- *
- * NPA Input Queue Enumeration
- * Enumerates ALLOC/FREE input queues from coprocessors.
- */
-#define CAVM_NPA_INPQ_E_AURA_OP (0xe)
-#define CAVM_NPA_INPQ_E_DPI (6)
-#define CAVM_NPA_INPQ_E_INTERNAL_RSV (0xf)
-#define CAVM_NPA_INPQ_E_NIXX_RX(a) (0 + 2 * (a))
-#define CAVM_NPA_INPQ_E_NIXX_TX(a) (1 + 2 * (a))
-#define CAVM_NPA_INPQ_E_RX(a) (0 + (a))
-#define CAVM_NPA_INPQ_E_SSO (4)
-#define CAVM_NPA_INPQ_E_TIM (5)
-
-/**
- * Enumeration npa_lf_int_vec_e
- *
- * NPA Local Function Interrupt Vector Enumeration
- * Enumerates the NPA MSI-X interrupt vectors per LF.
- */
-#define CAVM_NPA_LF_INT_VEC_E_ERR_INT (0x40)
-#define CAVM_NPA_LF_INT_VEC_E_POISON (0x41)
-#define CAVM_NPA_LF_INT_VEC_E_QINTX(a) (0 + (a))
-
-/**
- * Enumeration npa_ndc0_port_e
- *
- * NPA NDC0 Port Enumeration
- * Enumerates NPA NDC0 (NDC_IDX_E::NPA_U(0)) ports and the PORT index of
- * NDC_AF_PORT()_RT()_RW()_REQ_PC and NDC_AF_PORT()_RT()_RW()_LAT_PC.
- */
-#define CAVM_NPA_NDC0_PORT_E_AURA0 (0)
-#define CAVM_NPA_NDC0_PORT_E_AURA1 (1)
-#define CAVM_NPA_NDC0_PORT_E_POOL0 (2)
-#define CAVM_NPA_NDC0_PORT_E_POOL1 (3)
-#define CAVM_NPA_NDC0_PORT_E_STACK0 (4)
-#define CAVM_NPA_NDC0_PORT_E_STACK1 (5)
-
-/**
- * Enumeration npa_pool_err_int_e
- *
- * NPA Pool Error Interrupt Enumeration
- * Enumerates the bit index of NPA_POOL_S[ERR_INT] and NPA_POOL_S[ERR_INT_ENA].
- */
-#define CAVM_NPA_POOL_ERR_INT_E_OVFLS (0)
-#define CAVM_NPA_POOL_ERR_INT_E_PERR (2)
-#define CAVM_NPA_POOL_ERR_INT_E_RX(a) (0 + (a))
-#define CAVM_NPA_POOL_ERR_INT_E_RANGE (1)
-
-#define NPA_AF_BLK_RST                  (0x0ull)
-#define NPA_AF_CONST                    (0x10ull)
-#define NPA_AF_CONST1                   (0x18ull)
-#define NPA_AF_LF_RST                   (0x20ull)
-#define NPA_AF_GEN_CFG                  (0x30ull)
-#define NPA_AF_NDC_CFG                  (0x40ull)
-#define NPA_AF_NDC_SYNC                 (0x50ull)
-#define NPA_AF_INP_CTL                  (0xd0ull)
-#define NPA_AF_ACTIVE_CYCLES_PC         (0xf0ull)
-#define NPA_AF_AVG_DELAY                (0x100ull)
-#define NPA_AF_GEN_INT                  (0x140ull)
-#define NPA_AF_GEN_INT_W1S              (0x148ull)
-#define NPA_AF_GEN_INT_ENA_W1S          (0x150ull)
-#define NPA_AF_GEN_INT_ENA_W1C          (0x158ull)
-#define NPA_AF_RVU_INT                  (0x160ull)
-#define NPA_AF_RVU_INT_W1S              (0x168ull)
-#define NPA_AF_RVU_INT_ENA_W1S          (0x170ull)
-#define NPA_AF_RVU_INT_ENA_W1C          (0x178ull)
-#define NPA_AF_ERR_INT                  (0x180ull)
-#define NPA_AF_ERR_INT_W1S              (0x188ull)
-#define NPA_AF_ERR_INT_ENA_W1S          (0x190ull)
-#define NPA_AF_ERR_INT_ENA_W1C          (0x198ull)
-#define NPA_AF_RAS                      (0x1a0ull)
-#define NPA_AF_RAS_W1S                  (0x1a8ull)
-#define NPA_AF_RAS_ENA_W1S              (0x1b0ull)
-#define NPA_AF_RAS_ENA_W1C              (0x1b8ull)
-#define NPA_AF_AQ_CFG                   (0x600ull)
-#define NPA_AF_AQ_BASE                  (0x610ull)
-#define NPA_AF_AQ_STATUS                (0x620ull)
-#define NPA_AF_AQ_DOOR                  (0x630ull)
-#define NPA_AF_AQ_DONE_WAIT             (0x640ull)
-#define NPA_AF_AQ_DONE                  (0x650ull)
-#define NPA_AF_AQ_DONE_ACK              (0x660ull)
-#define NPA_AF_AQ_DONE_TIMER            (0x670ull)
-#define NPA_AF_AQ_DONE_INT              (0x680ull)
-#define NPA_AF_AQ_DONE_ENA_W1S          (0x690ull)
-#define NPA_AF_AQ_DONE_ENA_W1C          (0x698ull)
-#define NPA_AF_LFX_AURAS_CFG(a)         (0x4000ull | (uint64_t)(a) << 18)
-#define NPA_AF_LFX_LOC_AURAS_BASE(a)    (0x4010ull | (uint64_t)(a) << 18)
-#define NPA_AF_LFX_QINTS_CFG(a)         (0x4100ull | (uint64_t)(a) << 18)
-#define NPA_AF_LFX_QINTS_BASE(a)        (0x4110ull | (uint64_t)(a) << 18)
-#define NPA_PRIV_AF_INT_CFG             (0x10000ull)
-#define NPA_PRIV_LFX_CFG(a)             (0x10010ull | (uint64_t)(a) << 8)
-#define NPA_PRIV_LFX_INT_CFG(a)         (0x10020ull | (uint64_t)(a) << 8)
-#define NPA_AF_RVU_LF_CFG_DEBUG         (0x10030ull)
-#define NPA_AF_DTX_FILTER_CTL           (0x10040ull)
-
-#define NPA_LF_AURA_OP_ALLOCX(a)        (0x10ull | (uint64_t)(a) << 3)
-#define NPA_LF_AURA_OP_FREE0            (0x20ull)
-#define NPA_LF_AURA_OP_FREE1            (0x28ull)
-#define NPA_LF_AURA_OP_CNT              (0x30ull)
-#define NPA_LF_AURA_OP_LIMIT            (0x50ull)
-#define NPA_LF_AURA_OP_INT              (0x60ull)
-#define NPA_LF_AURA_OP_THRESH           (0x70ull)
-#define NPA_LF_POOL_OP_PC               (0x100ull)
-#define NPA_LF_POOL_OP_AVAILABLE        (0x110ull)
-#define NPA_LF_POOL_OP_PTR_START0       (0x120ull)
-#define NPA_LF_POOL_OP_PTR_START1       (0x128ull)
-#define NPA_LF_POOL_OP_PTR_END0         (0x130ull)
-#define NPA_LF_POOL_OP_PTR_END1         (0x138ull)
-#define NPA_LF_POOL_OP_INT              (0x160ull)
-#define NPA_LF_POOL_OP_THRESH           (0x170ull)
-#define NPA_LF_ERR_INT                  (0x200ull)
-#define NPA_LF_ERR_INT_W1S              (0x208ull)
-#define NPA_LF_ERR_INT_ENA_W1C          (0x210ull)
-#define NPA_LF_ERR_INT_ENA_W1S          (0x218ull)
-#define NPA_LF_RAS                      (0x220ull)
-#define NPA_LF_RAS_W1S                  (0x228ull)
-#define NPA_LF_RAS_ENA_W1C              (0x230ull)
-#define NPA_LF_RAS_ENA_W1S              (0x238ull)
-#define NPA_LF_QINTX_CNT(a)             (0x300ull | (uint64_t)(a) << 12)
-#define NPA_LF_QINTX_INT(a)             (0x310ull | (uint64_t)(a) << 12)
-#define NPA_LF_QINTX_ENA_W1S(a)         (0x320ull | (uint64_t)(a) << 12)
-#define NPA_LF_QINTX_ENA_W1C(a)         (0x330ull | (uint64_t)(a) << 12)
-
-
-/* Enum offsets */
-
-#define NPA_AQ_COMP_NOTDONE                 (0x0ull)
-#define NPA_AQ_COMP_GOOD                    (0x1ull)
-#define NPA_AQ_COMP_SWERR                   (0x2ull)
-#define NPA_AQ_COMP_CTX_POISON              (0x3ull)
-#define NPA_AQ_COMP_CTX_FAULT               (0x4ull)
-#define NPA_AQ_COMP_LOCKERR                 (0x5ull)
-
-#define NPA_AF_INT_VEC_RVU                  (0x0ull)
-#define NPA_AF_INT_VEC_GEN                  (0x1ull)
-#define NPA_AF_INT_VEC_AQ_DONE              (0x2ull)
-#define NPA_AF_INT_VEC_AF_ERR               (0x3ull)
-#define NPA_AF_INT_VEC_POISON               (0x4ull)
-
-#define NPA_AQ_INSTOP_NOP                   (0x0ull)
-#define NPA_AQ_INSTOP_INIT                  (0x1ull)
-#define NPA_AQ_INSTOP_WRITE                 (0x2ull)
-#define NPA_AQ_INSTOP_READ                  (0x3ull)
-#define NPA_AQ_INSTOP_LOCK                  (0x4ull)
-#define NPA_AQ_INSTOP_UNLOCK                (0x5ull)
-
-#define NPA_AQ_CTYPE_AURA                   (0x0ull)
-#define NPA_AQ_CTYPE_POOL                   (0x1ull)
-
-#define NPA_BPINTF_NIX0_RX                  (0x0ull)
-#define NPA_BPINTF_NIX1_RX                  (0x1ull)
-
-#define NPA_AURA_ERR_INT_AURA_FREE_UNDER    (0x0ull)
-#define NPA_AURA_ERR_INT_AURA_ADD_OVER      (0x1ull)
-#define NPA_AURA_ERR_INT_AURA_ADD_UNDER     (0x2ull)
-#define NPA_AURA_ERR_INT_POOL_DIS           (0x3ull)
-#define NPA_AURA_ERR_INT_R4                 (0x4ull)
-#define NPA_AURA_ERR_INT_R5                 (0x5ull)
-#define NPA_AURA_ERR_INT_R6                 (0x6ull)
-#define NPA_AURA_ERR_INT_R7                 (0x7ull)
-
-#define NPA_LF_INT_VEC_ERR_INT              (0x40ull)
-#define NPA_LF_INT_VEC_POISON               (0x41ull)
-#define NPA_LF_INT_VEC_QINT_END             (0x3full)
-#define NPA_LF_INT_VEC_QINT_START           (0x0ull)
-
-#define NPA_INPQ_SSO                        (0x4ull)
-#define NPA_INPQ_TIM                        (0x5ull)
-#define NPA_INPQ_DPI                        (0x6ull)
-#define NPA_INPQ_AURA_OP                    (0xeull)
-#define NPA_INPQ_INTERNAL_RSV               (0xfull)
-#define NPA_INPQ_NIX0_RX                    (0x0ull)
-#define NPA_INPQ_NIX1_RX                    (0x2ull)
-#define NPA_INPQ_NIX0_TX                    (0x1ull)
-#define NPA_INPQ_NIX1_TX                    (0x3ull)
-#define NPA_INPQ_R_END                      (0xdull)
-#define NPA_INPQ_R_START                    (0x7ull)
-
-#define NPA_POOL_ERR_INT_OVFLS              (0x0ull)
-#define NPA_POOL_ERR_INT_RANGE              (0x1ull)
-#define NPA_POOL_ERR_INT_PERR               (0x2ull)
-#define NPA_POOL_ERR_INT_R3                 (0x3ull)
-#define NPA_POOL_ERR_INT_R4                 (0x4ull)
-#define NPA_POOL_ERR_INT_R5                 (0x5ull)
-#define NPA_POOL_ERR_INT_R6                 (0x6ull)
-#define NPA_POOL_ERR_INT_R7                 (0x7ull)
-
-#define NPA_NDC0_PORT_AURA0                 (0x0ull)
-#define NPA_NDC0_PORT_AURA1                 (0x1ull)
-#define NPA_NDC0_PORT_POOL0                 (0x2ull)
-#define NPA_NDC0_PORT_POOL1                 (0x3ull)
-#define NPA_NDC0_PORT_STACK0                (0x4ull)
-
-/**
- * Structure npa_aq_inst_s
- *
- * NPA Admin Queue Instruction Structure
- * This structure specifies the AQ instruction.
- * Instructions and associated software structures are stored in memory as
- * little-endian unless NPA_AF_GEN_CFG[AF_BE] is set.
- *
- * Hardware reads of NPA_AQ_INST_S do not allocate into LLC.
- *
- * Hardware reads and writes of the context structure selected by [CTYPE], [LF]
- * and [CINDEX] use the NDC and LLC caching style configured for that context,
- * i.e.:
- * * NPA_AURA_HW_S reads and writes use NPA_AF_LF()_AURAS_CFG[CACHING] and
- * NPA_AF_LF()_AURAS_CFG[WAY_MASK].
- * * NPA_POOL_HW_S reads and writes use NPA_AURA_HW_S[POOL_CACHING] and
- * NPA_AURA_HW_S[POOL_WAY_MASK].
- */
-union cavm_npa_aq_inst_s
-{
-    uint64_t u[2];
-    struct cavm_npa_aq_inst_s_s
-    {
-        uint64_t op                    : 4;  /**< [  3:  0] Instruction op code enumerated by NPA_AQ_INSTOP_E. */
-        uint64_t ctype                 : 4;  /**< [  7:  4] Context type of instruction enumerated by NPA_AQ_CTYPE_E. */
-        uint64_t lf                    : 9;  /**< [ 16:  8] Local function. Software must map the LF to a PF and function with
-                                                                 NPA_PRIV_LF()_CFG[PF_FUNC] before issuing the AQ instruction.
-                                                                 NPA_PRIV_LF()_CFG[ENA] is not required to be set when executing AQ
-                                                                 instructions.
-
-                                                                 Internal:
-                                                                 Hardware uses PF(0)'s stream ID when accessing hardware context structures
-                                                                 in LLC/DRAM, but NDC tracks the LF for context structures in its cache
-                                                                 using the PF_FUNC's stream ID. */
-        uint64_t reserved_17_23        : 7;
-        uint64_t cindex                : 20; /**< [ 43: 24] Context index. Aura index of the instruction within [LF]. */
-        uint64_t reserved_44_62        : 19;
-        uint64_t doneint               : 1;  /**< [ 63: 63] Done interrupt.
-                                                                 0 = No interrupts related to this instruction.
-                                                                 1 = When the instruction completes, NPA_AF_AQ_DONE[DONE] will be incremented,
-                                                                 and based on the rules described there, an interrupt may occur. */
-        uint64_t res_addr              : 64; /**< [127: 64] Result AF IOVA. Specifies where to write NPA_AQ_RES_S.
-
-                                                                 Bits \<6:0\> must be zero; address must be 128-byte aligned. Bits \<63:53\> are
-                                                                 ignored by hardware; software should use a sign-extended bit \<52\> for
-                                                                 forward compatibility.
-
-                                                                 Software must reserve one, two or three 128-byte cache lines at this
-                                                                 address, as follows:
-                                                                 * When [OP] = NPA_AQ_INSTOP_E::INIT or READ, software must reserve at least
-                                                                 two cache lines.
-                                                                 * When [OP] = NPA_AQ_INSTOP_E::WRITE, software must reserve at least three
-                                                                 cache lines.
-                                                                 * Otherwise, software must reserve at least one cache line.
-
-                                                                 Hardware always stores full cache lines when writing NPA_AQ_RES_S and
-                                                                 following NPA_AURA_S/NPA_POOL_S structures, if any.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-    } s;
-};
-
-/**
- * Structure npa_aq_res_s
- *
- * NPA Admin Queue Result Structure
- * NPA writes this structure after it completes the NPA_AQ_INST_S instruction.
- * The result structure is exactly 16 bytes, and each instruction completion produces
- * exactly one result structure.
- *
- * Results and associated software structures are stored in memory as
- * little-endian unless NPA_AF_GEN_CFG[AF_BE] is set.
- *
- * When [OP] = NPA_AQ_INSTOP_E::INIT, WRITE or READ, this structure is
- * immediately followed by context read or write data. See NPA_AQ_INSTOP_E.
- *
- * Hardware writes of NPA_AQ_RES_S and context data always allocate into LLC.
- * Hardware reads of context data do not allocate into LLC.
- */
-union cavm_npa_aq_res_s
-{
-    uint64_t u[2];
-    struct cavm_npa_aq_res_s_s
-    {
-        uint64_t op                    : 4;  /**< [  3:  0] Copy of NPA_AQ_INST_S[OP] for the completed instruction; enumerated
-                                                                 by NPA_AQ_INSTOP_E. */
-        uint64_t ctype                 : 4;  /**< [  7:  4] Copy of NPA_AQ_INST_S[CTYPE] for the completed instruction; enumerated by
-                                                                 NPA_AQ_CTYPE_E. */
-        uint64_t compcode              : 8;  /**< [ 15:  8] Indicates completion/error status of the NPA coprocessor for the associated
-                                                                 instruction, as enumerated by NPA_AQ_COMP_E. Core software may write the memory
-                                                                 location containing [COMPCODE] to 0x0 before ringing the doorbell, and then poll
-                                                                 for completion by checking for a nonzero value.
-
-                                                                 Once the core observes a nonzero [COMPCODE] value in this case, NPA will have also
-                                                                 completed LLC/DRAM reads and writes for the operation. */
-        uint64_t doneint               : 1;  /**< [ 16: 16] Done interrupt. This bit is copied from the corresponding instruction's
-                                                                 NPA_AQ_INST_S[DONEINT]. */
-        uint64_t reserved_17_63        : 47;
-        uint64_t reserved_64_127       : 64;
-    } s;
-};
-
-/**
- * Structure npa_aura_op_wdata_s
- *
- * NPA Aura Operation Write Data Structure
- * This structure specifies the write data format of a 64-bit atomic load-and-add
- * to NPA_LF_AURA_OP_ALLOC() and NPA_LF_POOL_OP_PC, and a 128-bit atomic CASP
- * operation to NPA_LF_AURA_OP_ALLOC().
- */
-union cavm_npa_aura_op_wdata_s
-{
-    uint64_t u;
-    struct cavm_npa_aura_op_wdata_s_s
-    {
-        uint64_t aura                  : 20; /**< [ 19:  0] Aura of instruction. */
-        uint64_t reserved_20_62        : 43;
-        uint64_t drop                  : 1;  /**< [ 63: 63] Perform DROP processing on allocation. See NPA_AURA_S[POOL_DROP],
-                                                                 NPA_AURA_S[AURA_DROP].
-                                                                 Not used when accessing NPA_LF_POOL_OP_PC. */
-    } s;
-};
-
-/**
- * Structure npa_aura_s
- *
- * NPA Aura Context Structure
- * This structure specifies the format used by software with the NPA admin queue
- * to read and write an aura's NPA_AURA_HW_S structure maintained by hardware in
- * LLC/DRAM.
- */
-union cavm_npa_aura_s
-{
-    uint64_t u[8];
-    struct cavm_npa_aura_s_s
-    {
-        uint64_t pool_addr             : 64; /**< [ 63:  0] AF IOVA of the associated pool's NPA_POOL_HW_S structure in NDC/LLC/DRAM. The
-                                                                 size of the structure is 1 \<\< NPA_AF_CONST1[POOL_LOG2BYTES] bytes.
-
-                                                                 Bits \<5:0\> must be zero; address must be 64-byte aligned. Bits \<63:53\> are
-                                                                 ignored by hardware; software should use a sign-extended bit \<52\> for forward
-                                                                 compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<5:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t ena                   : 1;  /**< [ 64: 64] Enable. If clear any allocations will fail and returns will be dropped. */
-        uint64_t reserved_65_66        : 2;
-        uint64_t pool_caching          : 1;  /**< [ 67: 67] Selects the style read for accessing NPA_POOL_HW_S in LLC/DRAM:
-                                                                 0x0 = NPA_POOL_HW_S reads will not allocate into the LLC.
-                                                                 0x1 = NPA_POOL_HW_S reads are allocated into the LLC.
-
-                                                                 NPA_POOL_HW_S writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-        uint64_t pool_way_mask         : 16; /**< [ 83: 68] Way partitioning mask for allocating associated NPA_POOL_HW_S in NDC (1 means do not use).
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-        uint64_t avg_con               : 9;  /**< [ 92: 84] This value controls how much of the present average resource level is used
-                                                                 to calculate the new resource level. The value is a number from 0 to 256,
-                                                                 which represents [AVG_CON]/256 of the average resource level that will be
-                                                                 used in the calculation.
-
-                                                                 NPA updates the average resource level as follows whenever the immediate resource
-                                                                 count changes:
-
-                                                                 \<pre\>
-                                                                 // norm_CNT = 255 - (8-bit shifted and saturated aura count); see [SHIFT].
-                                                                 adjusted_CON = [AVG_CON] \>\> log2(NPA_AF_AVG_DELAY[AVG_TIMER] - [UPDATE_TIME]);
-                                                                 [AVG_LEVEL] = (adjusted_CON * [AVG_LEVEL] + (256 - adjusted_CON) * norm_CNT) / 256;
-                                                                 [UPDATE_TIME] = NPA_AF_AVG_DELAY[AVG_TIMER];
-                                                                 \</pre\>
-
-                                                                 Note setting this value to zero will disable averaging, and always use the most
-                                                                 immediate levels. NPA_AF_AVG_DELAY[AVG_DLY] controls the periodicity of the level
-                                                                 calculations. */
-        uint64_t reserved_93           : 1;
-        uint64_t pool_drop_ena         : 1;  /**< [ 94: 94] Enable aura-unique pool DROP based on the [POOL_DROP] level. */
-        uint64_t aura_drop_ena         : 1;  /**< [ 95: 95] Enable aura DROP based on the [AURA_DROP] level. */
-        uint64_t bp_ena                : 2;  /**< [ 97: 96] Enable aura backpressure to NIX-RX based on [BP] level. One bit per
-                                                                 NIX-RX; index enumerated by NPA_BPINTF_E. */
-        uint64_t reserved_98_103       : 6;
-        uint64_t aura_drop             : 8;  /**< [111:104] If [AURA_DROP_ENA] is set and DROP processing is requested, the packet will
-                                                                 be dropped if the current 8-bit shifted and saturated aura count is equal
-                                                                 to or greater than this value. */
-        uint64_t shift                 : 6;  /**< [117:112] Right shift to aura [COUNT] to create a narrower depth for aura QOS and backpressure
-                                                                 calculations. NPA saturates the aura [COUNT] to 8-bits for the aura, and compares this
-                                                                 8-bit shifted and saturated count directly to [AURA_DROP] and [BP]. */
-        uint64_t reserved_118_119      : 2;
-        uint64_t avg_level             : 8;  /**< [127:120] Current moving average of the 8-bit shifted and saturated aura count. The
-                                                                 higher [AVG_LEVEL] is, the more free resources. The lower levels indicate
-                                                                 buffer exhaustion. See [SHIFT] and [AVG_CON].
-
-                                                                 NPA_INPQ_E::NIX()_RX uses [AVG_LEVEL] in receive queue QOS calculations. */
-        uint64_t count                 : 36; /**< [163:128] Number of pointers allocated to the aura. Increments on ALLOC and decrements on FREE. */
-        uint64_t reserved_164_167      : 4;
-        uint64_t nix0_bpid             : 9;  /**< [176:168] NIX(0) RX BPID (BPID index of NIX_AF_RX_BPID()_STATUS) to which backpressure
-                                                                 is asserted when the corresponding [BP_ENA] bit is set. */
-        uint64_t reserved_177_179      : 3;
-        uint64_t nix1_bpid             : 9;  /**< [188:180] Reserved.
-                                                                 Internal:
-                                                                 NIX(1) RX BPID (BPID index of NIX_AF_RX_BPID()_STATUS) to which backpressure
-                                                                 is asserted when the corresponding [BP_ENA] bit is set. */
-        uint64_t reserved_189_191      : 3;
-        uint64_t limit                 : 36; /**< [227:192] When the aura [COUNT] is equal to or greater than this value, any allocations
-                                                                 using this aura will fail. This allows a hard resource division between multiple
-                                                                 auras sharing a common pool. */
-        uint64_t reserved_228_231      : 4;
-        uint64_t bp                    : 8;  /**< [239:232] Backpressure to [NIX0_BPID]/[NIX1_BPID] NPA_BPINTF_E::NIX()_RX is asserted if
-                                                                 the corresponding [BP_ENA] bit is set and the current 8-bit shifted and
-                                                                 saturated aura [COUNT] is greater than or equal to this value. */
-        uint64_t reserved_240_243      : 4;
-        uint64_t fc_ena                : 1;  /**< [244:244] Enable flow control. When enabled NPA will periodically store the [COUNT] value
-                                                                 as an unsigned 64-bit to the LF IOVA specified by [FC_ADDR] for flow control
-                                                                 purposes. The frequency of the stores is controlled via [FC_HYST_BITS].
-
-                                                                 When set, software should also enable the associated pool's flow control
-                                                                 with NPA_POOL_S[FC_ENA] and monitor the pool level stored in LLC/DRAM. */
-        uint64_t fc_up_crossing        : 1;  /**< [245:245] Flow control up-crossing flag. Set on an aura count up-crossing, and cleared on
-                                                                 a down-crossing. see [FC_HYST_BITS]. NPA maintains this value and software may
-                                                                 ignore it. */
-        uint64_t fc_stype              : 2;  /**< [247:246] Type of store to write [COUNT] in LLC/DRAM:
-                                                                 0x0 = Store full cache line, allocate cache (STF).
-                                                                 0x1 = Store full cache line, no allocate (STT).
-                                                                 0x2 = Store partial cache line, allocate cache (STP).
-                                                                 0x3 = Reserved. */
-        uint64_t fc_hyst_bits          : 4;  /**< [251:248] Flow control hysteresis bits. Use hysteresis to reduce the number of stores that
-                                                                 NPA does to update [COUNT] in LLC/DRAM. Hysteresis is accomplished by monitoring
-                                                                 a range of least significant bits of [COUNT] and triggering stores as follows:
-
-                                                                 * When [FC_HYST_BITS] == 0, no count bits are monitored.
-
-                                                                 * Otherwise, count bits \<[FC_HYST_BITS]-1:0\> are monitored.
-
-                                                                 For purposes of describing the hysteresis algorithm, a down-crossing is defined
-                                                                 as the case where a count decrement causes the specified LSB range to transition
-                                                                 from all zeros to all ones, and an up-crossing as the case where a count
-                                                                 increment causes the specified LSB range to transition from all ones to all
-                                                                 zeros. A zero-crossing is defined as a down-crossing or up-crossing.
-
-                                                                 The hysteresis algorithm triggers stores upon down-crossings that follow a
-                                                                 down-crossing and upon up-crossings that follow an up-crossing. Conversely
-                                                                 down-crossings that follow an up-crossing and up-crossings that follow a
-                                                                 down-crossing do not trigger stores. This prevents the repeated updates that
-                                                                 would otherwise occur if the count oscillated around some zero-crossing. When
-                                                                 [FC_HYST_BITS] = 0, there is no hysteresis and all count updates trigger stores. */
-        uint64_t reserved_252_255      : 4;
-        uint64_t fc_addr               : 64; /**< [319:256] Flow control address. LF IOVA in LLC/DRAM to write the count. See also
-                                                                 [FC_ENA] and [FC_STYPE]. Must be on a dedicated 128-byte cache line when
-                                                                 [FC_STYPE] indicates full cache line.
-
-                                                                 Bits \<2:0\> must be zero; address must be 8-byte aligned.
-                                                                 Bits \<63:53\> are ignored by hardware; software should use a sign-extended bit \<52\> for
-                                                                 forward compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<2:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t pool_drop             : 8;  /**< [327:320] If [POOL_DROP_ENA] is set and DROP processing is requested, the packet will
-                                                                 be dropped if the current 8-bit shifted and saturated free pointer count in
-                                                                 the aura's pool is less than or equal this value. See
-                                                                 NPA_POOL_S[SHIFT] and NPA_POOL_S[STACK_PAGES]. */
-        uint64_t update_time           : 16; /**< [343:328] NPA_AF_AVG_DELAY[AVG_TIMER] value captured when [AVG_LEVEL] is updated.
-                                                                 NPA maintains this value and software may ignore it. */
-        uint64_t err_int               : 8;  /**< [351:344] Error interrupts. Bits enumerated by NPA_AURA_ERR_INT_E, which also defines
-                                                                 when hardware sets each bit. Software can read, set or clear these bits
-                                                                 with NPA_LF_AURA_OP_INT. */
-        uint64_t err_int_ena           : 8;  /**< [359:352] Error interrupt enables. Bits enumerated by NPA_AURA_ERR_INT_E. Software
-                                                                 can read, set or clear these bits with NPA_LF_AURA_OP_INT. */
-        uint64_t thresh_int            : 1;  /**< [360:360] Threshold interrupt. When [THRESH_UP] is set, hardware sets this bit when
-                                                                 [COUNT] goes to or above [THRESH]. When [THRESH_UP] is clear, hardware sets
-                                                                 this bit when [COUNT] drops below [THRESH].
-
-                                                                 Software can read, set or clear this bit with NPA_LF_AURA_OP_INT.
-
-                                                                 Internal:
-                                                                 "When [THRESH_UP]==0:
-                                                                 * Interrupt set to QINT when ([THRESH_INT] &
-                                                                 [THRESH_INT_ENA]) goes from 0 to 1.
-                                                                 * Interrupt clear to QINT when ([THRESH_INT] &
-                                                                 [THRESH_INT_ENA]) goes from 1 to 0.
-                                                                 * Interrupt resend to QINT when [THRESH_INT_ENA] = 1, software clears
-                                                                 [THRESH_INT], and [COUNT] \< [THRESH].
-                                                                 Similar when [THRESH_UP]==1, except:
-                                                                 * Interrupt resend to QINT when [THRESH_INT_ENA] = 1, software clears
-                                                                 [THRESH_INT], and [COUNT] \>= [THRESH].
-                                                                 " */
-        uint64_t thresh_int_ena        : 1;  /**< [361:361] Threshold interrupt enable. Software can read, set or clear this bit with
-                                                                 NPA_LF_AURA_OP_INT. */
-        uint64_t thresh_up             : 1;  /**< [362:362] Threshold up direction. When set, [THRESH_INT] is set when [COUNT] rises to
-                                                                 or above [THRESH]. When clear, [THRESH_INT] is set when [COUNT] drops below
-                                                                 [THRESH]. Software can read or write this bit with
-                                                                 NPA_LF_AURA_OP_THRESH. */
-        uint64_t reserved_363          : 1;
-        uint64_t thresh_qint_idx       : 7;  /**< [370:364] Threshold queue interrupt index. Select the QINT within VF/PF (QINT index
-                                                                 of NPA_LF_QINT()_INT) which receives [THRESH_INT] events. */
-        uint64_t reserved_371          : 1;
-        uint64_t err_qint_idx          : 7;  /**< [378:372] Error queue interrupt index. Select the QINT within VF/PF (QINT index of
-                                                                 NPA_LF_QINT()_INT) which receives [ERR_INT] events. */
-        uint64_t reserved_379_383      : 5;
-        uint64_t thresh                : 36; /**< [419:384] Interrupt threshold count. See [THRESH_INT]. Software can read or write
-                                                                 this field with NPA_LF_AURA_OP_THRESH. */
-        uint64_t reserved_420_447      : 28;
-        uint64_t reserved_448_511      : 64;
-    } s;
-};
-
-/**
- * Structure npa_pool_s
- *
- * NPA Pool Context Structure
- * This structure specifies the format used by software with the NPA admin queue
- * to read and write a pool's NPA_POOL_HW_S structure maintained by hardware in
- * LLC/DRAM.
- */
-union cavm_npa_pool_s
-{
-    uint64_t u[16];
-    struct cavm_npa_pool_s_s
-    {
-        uint64_t stack_base            : 64; /**< [ 63:  0] Pool stack base LF IOVA in NDC/LLC/DRAM. This is the lowest address used by the stack.
-
-                                                                 Bits \<6:0\> must be zero; address must be 128-byte aligned.
-                                                                 Bits \<63:53\> are ignored by hardware; software should use a sign-extended bit \<52\> for
-                                                                 forward compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t ena                   : 1;  /**< [ 64: 64] Enable. Must be set after writing pool configuration, if clear any allocations will fail
-                                                                 and returns will be dropped. If any pool configuration is changed while this bit is set
-                                                                 (or until traffic is quiesced after clearing), the NPA may operate incorrectly. */
-        uint64_t nat_align             : 1;  /**< [ 65: 65] Returning buffers should be rounded to the nearest natural alignment specified with
-                                                                 [BUF_SIZE]. */
-        uint64_t reserved_66_67        : 2;
-        uint64_t stack_caching         : 1;  /**< [ 68: 68] Selects the style read for accessing NPA_STACK_PAGE_S in LLC/DRAM:
-                                                                 0x0 = NPA_STACK_PAGE_S reads will not allocate into the LLC.
-                                                                 0x1 = NPA_STACK_PAGE_S reads are allocated into the LLC.
-
-                                                                 NPA_STACK_PAGE_S writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-        uint64_t reserved_69_71        : 3;
-        uint64_t stack_way_mask        : 16; /**< [ 87: 72] Way partitioning mask for allocating stack pages in NDC (1 means do not use).
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-        uint64_t buf_offset            : 12; /**< [ 99: 88] Number of 128-byte cache lines to offset the stored pointer. This field is sign extended
-                                                                 so that two's complement numbers may be used to do subtractions.
-
-                                                                 If [NAT_ALIGN] is clear, the pointer stored in the pool is normally the freed pointer
-                                                                 adjusted by [BUF_OFFSET]. [BUF_OFFSET] will normally be zero or negative to adjust the
-                                                                 pointer back to the beginning of the buffer.)
-
-                                                                 If [NAT_ALIGN] is set, the pointer stored in the pool is normally [BUF_OFFSET] from the
-                                                                 beginning of the buffer. [BUF_OFFSET] will normally be zero or positive to adjust the
-                                                                 pointer into the buffer. */
-        uint64_t reserved_100_103      : 4;
-        uint64_t buf_size              : 11; /**< [114:104] Buffer size in 128-byte cache lines. Must be zero if [NAT_ALIGN] is clear. Buffer sizes
-                                                                 are supported that are any multiple of 128 bytes in the range of 128 bytes to 128 KB. */
-        uint64_t reserved_115_127      : 13;
-        uint64_t stack_max_pages       : 32; /**< [159:128] Maximum number of pages in the stack starting at [STACK_BASE], with
-                                                                 NPA_AF_CONST[STACK_PAGE_PTRS] free pointers per page. Stack is full if
-                                                                 [STACK_PAGES] equals this value.
-
-                                                                 Internal:
-                                                                 Provides more than 2^35 pointers, 2^42 phisical memory with one cache line
-                                                                 per pointer. */
-        uint64_t stack_pages           : 32; /**< [191:160] Number of nonpartial pages in the stack, with NPA_AF_CONST[STACK_PAGE_PTRS]
-                                                                 pointers per page. Must be initialized to zero when stack is created.
-                                                                 The stack page format is defined by NPA_STACK_PAGE_S.
-                                                                 The number of free pointers in this pool is:
-                                                                 _ COUNT = NPA_AF_CONST[STACK_PAGE_PTRS]*[STACK_PAGES] + [STACK_OFFSET]. */
-        uint64_t op_pc                 : 48; /**< [239:192] Performance counter. Number of allocations or returns performed to this pool, including
-                                                                 those that fail, e.g. due to DROP, stack empty/full, etc. */
-        uint64_t reserved_240_255      : 16;
-        uint64_t stack_offset          : 4;  /**< [259:256] Number of valid pointers in partially populated NPA_STACK_PAGE_S following
-                                                                 the number of full pages specified by [STACK_PAGES]. Must be initialized to
-                                                                 0 when stack is created. */
-        uint64_t reserved_260_263      : 4;
-        uint64_t shift                 : 6;  /**< [269:264] Right shift to COUNT (see [STACK_PAGES]) used to create a narrower depth for pool QOS
-                                                                 calculations. NPA saturates the shifted COUNT to 8-bits, and compares this 8-bit shifted
-                                                                 and saturated count directly to NPA_AURA_S[POOL_DROP]. */
-        uint64_t reserved_270_271      : 2;
-        uint64_t avg_level             : 8;  /**< [279:272] Current moving average of the 8-bit shifted and saturated COUNT (see
-                                                                 [STACK_PAGES]). The higher [AVG_LEVEL] is, the more free resources. The
-                                                                 lowest levels indicate buffer exhaustion. See [SHIFT] and [AVG_CON].
-
-                                                                 NPA_INPQ_E::NIX()_RX uses [AVG_LEVEL] in receive queue QOS calculations.
-                                                                 See NIX_RQ_CTX_S[XQE_DROP]. */
-        uint64_t avg_con               : 9;  /**< [288:280] This value controls how much of the present average resource level is used
-                                                                 to calculate the new resource level. The value is a number from 0 to 256,
-                                                                 which represents [AVG_CON]/256 of the average resource level that will be
-                                                                 used in the calculation.
-
-                                                                 NPA updates the average resource level as follows whenever the immediate resource
-                                                                 count changes:
-
-                                                                 \<pre\>
-                                                                 // norm_CNT = 8-bit shifted and saturated pool count; see [SHIFT].
-                                                                 adjusted_CON = [AVG_CON] \>\> log2(NPA_AF_AVG_DELAY[AVG_TIMER] - [UPDATE_TIME]);
-                                                                 [AVG_LEVEL] = (adjusted_CON * [AVG_LEVEL] + (256 - adjusted_CON) * norm_CNT) / 256;
-                                                                 [UPDATE_TIME] = NPA_AF_AVG_DELAY[AVG_TIMER];
-                                                                 \</pre\>
-
-                                                                 Note setting this value to zero will disable averaging, and always use the most
-                                                                 immediate levels. NPA_AF_AVG_DELAY[AVG_DLY] controls the periodicity of the level
-                                                                 calculations. */
-        uint64_t fc_ena                : 1;  /**< [289:289] Enable flow control. When enabled NPA will periodically store the free
-                                                                 pointer COUNT value (see [STACK_PAGES]) as an unsigned 64-bit to the IOVA
-                                                                 specified by [FC_ADDR] for flow control purposes. The frequency of the
-                                                                 stores is controlled via [FC_HYST_BITS]. */
-        uint64_t fc_stype              : 2;  /**< [291:290] Type of store to write COUNT in LLC/DRAM:
-                                                                 0x0 = Store full cache line, allocate cache (STF).
-                                                                 0x1 = Store full cache line, no allocate (STT).
-                                                                 0x2 = Store partial cache line, allocate cache (STP).
-                                                                 0x3 = Reserved. */
-        uint64_t fc_hyst_bits          : 4;  /**< [295:292] Flow control hysteresis bits. Use hysteresis to reduce the number of stores that
-                                                                 NPA does to update COUNT in LLC/DRAM. Hysteresis is accomplished by monitoring a
-                                                                 range of least significant bits of COUNT and triggering stores as follows:
-
-                                                                 * When [FC_HYST_BITS] == 0, no count bits are monitored.
-
-                                                                 * Otherwise, count bits \<[FC_HYST_BITS]-1:0\> are monitored.
-
-                                                                 For purposes of describing the hysteresis algorithm, a down-crossing is defined
-                                                                 as the case where a count decrement causes the specified LSB range to transition
-                                                                 from all zeros to all ones, and an up-crossing as the case where a count
-                                                                 increment causes the specified LSB range to transition from all ones to all
-                                                                 zeros. A zero-crossing is defined as a down-crossing or up-crossing.
-
-                                                                 The hysteresis algorithm triggers stores upon down-crossings that follow a
-                                                                 down-crossing and upon up-crossings that follow an up-crossing. Conversely
-                                                                 down-crossings that follow an up-crossing and up-crossings that follow a
-                                                                 down-crossing do not trigger stores. This prevents the repeated updates that
-                                                                 would otherwise occur if the count oscillated around some zero-crossing. When
-                                                                 [FC_HYST_BITS] = 0, there is no hysteresis and all count updates trigger stores. */
-        uint64_t fc_up_crossing        : 1;  /**< [296:296] Flow control up-crossing flag. Set on an aura count up-crossing, and cleared on
-                                                                 a down-crossing. see [FC_HYST_BITS]. NPA maintains this value and software may
-                                                                 ignore it. */
-        uint64_t reserved_297_299      : 3;
-        uint64_t update_time           : 16; /**< [315:300] NPA_AF_AVG_DELAY[AVG_TIMER] value captured when [AVG_LEVEL] is updated.
-                                                                 NPA maintains this value and software may ignore it. */
-        uint64_t reserved_316_319      : 4;
-        uint64_t fc_addr               : 64; /**< [383:320] Flow control address. LF IOVA in LLC/DRAM to write the count. See also
-                                                                 [FC_ENA] and [FC_STYPE]. Must be on a dedicated 128-byte cache line when
-                                                                 [FC_STYPE] indicates full cache line.
-
-                                                                 Bits \<2:0\> must be zero; address must be 8-byte aligned.
-                                                                 Bits \<63:53\> are ignored by hardware; software should use a sign-extended bit \<52\> for
-                                                                 forward compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<2:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t ptr_start             : 64; /**< [447:384] Pointer start LF IOVA. Pointers freed to this pool after alignment must be
-                                                                 greater that or equal to this value. Typically nonzero so that a NULL
-                                                                 pointer free causes an exception.
-
-                                                                 Bits \<6:0\> must be zero; address must be 128-byte aligned. Bits \<63:53\> are
-                                                                 ignored by hardware; software should use a sign-extended bit \<52\> for forward
-                                                                 compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t ptr_end               : 64; /**< [511:448] Pointer end LF IOVA. Pointers freed to this pool after alignment must be equal to or
-                                                                 less than this address.
-
-                                                                 Bits \<6:0\> must be zero; address must be 128-byte aligned. Bits \<63:53\> are
-                                                                 ignored by hardware; software should use a sign-extended bit \<52\> for forward
-                                                                 compatibility.
-
-                                                                 Internal:
-                                                                 Bits \<63:53\>, \<6:0\> are ignored by hardware, treated as always 0x0. */
-        uint64_t reserved_512_535      : 24;
-        uint64_t err_int               : 8;  /**< [543:536] Error interrupts. Bits enumerated by NPA_POOL_ERR_INT_E, which also defines
-                                                                 when hardware sets each bit. Software can read, set or clear these bits
-                                                                 with NPA_LF_POOL_OP_INT. */
-        uint64_t err_int_ena           : 8;  /**< [551:544] Error interrupt enables. Bits enumerated by NPA_POOL_ERR_INT_E. Software
-                                                                 can read, set or clear these bits with NPA_LF_POOL_OP_INT. */
-        uint64_t thresh_int            : 1;  /**< [552:552] Threshold interrupt. When [THRESH_UP] is set, hardware sets this bit when
-                                                                 the free pointer COUNT (see [STACK_PAGES]) goes to or above [THRESH]. When
-                                                                 [THRESH_UP] is clear, hardware sets this bit when COUNT drops below
-                                                                 [THRESH].
-
-                                                                 Software can read, set or clear this bit with NPA_LF_POOL_OP_INT.
-
-                                                                 Internal:
-                                                                 See NPA_AURA_S[THRESH_INT]. */
-        uint64_t thresh_int_ena        : 1;  /**< [553:553] Threshold interrupt enable. Software can read, set or clear this bit with
-                                                                 NPA_LF_POOL_OP_INT. */
-        uint64_t thresh_up             : 1;  /**< [554:554] Threshold up direction. When set, [THRESH_INT] is set when COUNT (see
-                                                                 [STACK_PAGES]) rises to or above [THRESH]. When clear, [THRESH_INT] is set
-                                                                 when COUNT drops below [THRESH]. Software can read, set or clear this bit
-                                                                 with NPA_LF_POOL_OP_THRESH. */
-        uint64_t reserved_555          : 1;
-        uint64_t thresh_qint_idx       : 7;  /**< [562:556] Threshold queue interrupt index. Select the QINT within VF/PF (QINT index
-                                                                 of NPA_LF_QINT()_INT) which receives [THRESH_INT] events. */
-        uint64_t reserved_563          : 1;
-        uint64_t err_qint_idx          : 7;  /**< [570:564] Error queue interrupt index. Select the QINT within VF/PF (QINT index of
-                                                                 NPA_LF_QINT()_INT) which receives [ERR_INT] events. */
-        uint64_t reserved_571_575      : 5;
-        uint64_t thresh                : 36; /**< [611:576] Interrupt threshold count. See [THRESH_INT]. Software can read or write
-                                                                 this field with NPA_LF_POOL_OP_THRESH. */
-        uint64_t reserved_612_639      : 28;
-        uint64_t reserved_640_703      : 64;
-        uint64_t reserved_704_767      : 64;
-        uint64_t reserved_768_831      : 64;
-        uint64_t reserved_832_895      : 64;
-        uint64_t reserved_896_959      : 64;
-        uint64_t reserved_960_1023     : 64;
-    } s;
-};
-
-/**
- * Structure npa_qint_hw_s
- *
- * NPA Queue Interrupt Context Hardware Structure
- * This structure contains context state maintained by hardware for each queue
- * interrupt (QINT) in in NDC/LLC/DRAM. Software accesses this structure with the
- * NPA_LF_QINT()_* registers.
- * Hardware maintains a table of NPA_AF_CONST[QINTS] contiguous NPA_QINT_HW_S
- * structures per LF starting at IOVA NPA_AF_LF()_QINTS_BASE.
- * Always stored in byte invariant little-endian format (LE8).
- */
-union cavm_npa_qint_hw_s
-{
-    uint64_t u;
-    struct cavm_npa_qint_hw_s_s
-    {
-        uint64_t count                 : 22; /**< [ 21:  0] Interrupt count. See NPA_LF_QINT()_CNT[COUNT]. */
-        uint64_t reserved_22_30        : 9;
-        uint64_t ena                   : 1;  /**< [ 31: 31] Interrupt enable. See also NPA_LF_QINT()_ENA_W1S[INTR] and
-                                                                 NPA_LF_QINT()_ENA_W1C[INTR]. */
-        uint64_t reserved_32_63        : 32;
-    } s;
-    struct cavm_npa_qint_hw_s_cn
-    {
-        uint64_t count                 : 22; /**< [ 21:  0] Interrupt count. See NPA_LF_QINT()_CNT[COUNT]. */
-        uint64_t reserved_22_30        : 9;
-        uint64_t ena                   : 1;  /**< [ 31: 31] Interrupt enable. See also NPA_LF_QINT()_ENA_W1S[INTR] and
-                                                                 NPA_LF_QINT()_ENA_W1C[INTR]. */
-    } cn;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_active_cycles_pc
- *
- * NPA AF Active Cycles Register
- */
-union cavm_npa_af_active_cycles_pc
-{
-    uint64_t u;
-    struct cavm_npa_af_active_cycles_pc_s
-    {
-        uint64_t act_cyc               : 64; /**< [ 63:  0](R/W/H) Counts every coprocessor-clock cycle that the conditional clocks are active. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_base
- *
- * NPA AF Admin Queue Base Address Register
- */
-union cavm_npa_af_aq_base
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_base_s
-    {
-        uint64_t reserved_0_6          : 7;
-        uint64_t base_addr             : 46; /**< [ 52:  7](R/W) AF IOVA\<52:7\> of AQ ring in LLC/DRAM. IOVA bits \<6:0\> are always zero. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_cfg
- *
- * NPA AF Admin Queue Configuration Register
- */
-union cavm_npa_af_aq_cfg
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_cfg_s
-    {
-        uint64_t qsize                 : 4;  /**< [  3:  0](R/W) Specifies AQ ring size in entries of 16 bytes:
-                                                                 0x0 = 16 entries.
-                                                                 0x1 = 64 entries.
-                                                                 0x2 = 256 entries.
-                                                                 0x3 = 1K entries.
-                                                                 0x4 = 4K entries.
-                                                                 0x5 = 16K entries.
-                                                                 0x6 = 64K entries.
-                                                                 0x7 = 256K entries.
-                                                                 0x8 = 1M entries.
-                                                                 0x9-0xF = Reserved.
-
-                                                                 Note that the usable size of the ring is the specified size minus 1 (HEAD==TAIL always
-                                                                 means empty). */
-        uint64_t reserved_4_63         : 60;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done
- *
- * NPA AF AQ Done Count Register
- */
-union cavm_npa_af_aq_done
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_s
-    {
-        uint64_t done                  : 20; /**< [ 19:  0](R/W/H) Done count. When NPA_AQ_INST_S[DONEINT] set and that instruction completes,
-                                                                 NPA_AF_AQ_DONE[DONE] is incremented. Write to this field are for diagnostic
-                                                                 use only; instead software writes NPA_AF_AQ_DONE_ACK with the number of
-                                                                 decrements for this field.
-
-                                                                 Interrupts are sent as follows:
-
-                                                                 * When NPA_AF_AQ_DONE[DONE] = 0, then no results are pending, the interrupt
-                                                                 coalescing (NPA_AF_AQ_DONE_TIMER[COUNT]) timer is held to zero, and an
-                                                                 interrupt is not sent.
-
-                                                                 * When NPA_AF_AQ_DONE[DONE] != 0, then NPA_AF_AQ_DONE_TIMER[COUNT]
-                                                                 counts every microsecond. If the counter is \>= NPA_AF_AQ_DONE_WAIT[TIME_WAIT],
-                                                                 or NPA_AF_AQ_DONE[DONE] \>= NPA_AF_AQ_DONE_WAIT[NUM_WAIT], i.e. enough time
-                                                                 has passed or enough results have arrived, then the interrupt is sent.
-                                                                 Otherwise, it is not sent due to coalescing.
-
-                                                                 * When NPA_AF_AQ_DONE_ACK is written (or NPA_AF_AQ_DONE is written but this
-                                                                 is not typical), the NPA_AF_AQ_DONE_TIMER[COUNT] restarts. Note after
-                                                                 decrementing this interrupt equation is recomputed, for example if
-                                                                 NPA_AF_AQ_DONE[DONE] \>= NPA_AF_AQ_DONE_WAIT[NUM_WAIT] and because the timer
-                                                                 is zero, the interrupt will be resent immediately. (This covers the race
-                                                                 case between software acknowledging an interrupt and a result returning.)
-
-                                                                 * When NPA_AF_AQ_DONE_ENA_W1S[DONE] = 0, interrupts are not sent, but the
-                                                                 counting described above still occurs.
-
-                                                                 AQ instructions complete in order.
-
-                                                                 Software is responsible for making sure [DONE] does not overflow; for example by
-                                                                 insuring there are not more than 2^20-1 instructions in flight that may request
-                                                                 interrupts. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_ack
- *
- * NPA AF AQ Done Count Ack Register
- * This register is written by software to acknowledge interrupts.
- */
-union cavm_npa_af_aq_done_ack
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_ack_s
-    {
-        uint64_t done_ack              : 20; /**< [ 19:  0](R/W/H) Number of decrements to NPA_AF_AQ_DONE[DONE]. Reads NPA_AF_AQ_DONE[DONE].
-
-                                                                 Written by software to acknowledge interrupts. If NPA_AF_AQ_DONE[DONE] is
-                                                                 still nonzero the interrupt will be re-sent if the conditions described in
-                                                                 NPA_AF_AQ_DONE[DONE] are satisfied.
-
-                                                                 Internal:
-                                                                 If [DONE_ACK] write value is greater than NPA_AF_AQ_DONE[DONE], hardware
-                                                                 resets NPA_AF_AQ_DONE[DONE] to zero. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_ena_w1c
- *
- * NPA AF AQ Done Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_af_aq_done_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_ena_w1c_s
-    {
-        uint64_t done                  : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for NPA_AF_AQ_DONE_INT[DONE]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_ena_w1s
- *
- * NPA AF AQ Done Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_af_aq_done_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_ena_w1s_s
-    {
-        uint64_t done                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for NPA_AF_AQ_DONE_INT[DONE]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_int
- *
- * NPA AF AQ Done Interrupt Register
- */
-union cavm_npa_af_aq_done_int
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_int_s
-    {
-        uint64_t done                  : 1;  /**< [  0:  0](RO/H) Done interrupt. See NPA_AF_AQ_DONE[DONE]. Note this bit is read-only, to
-                                                                 acknowledge interrupts use NPA_AF_AQ_DONE_ACK. To test interrupts, write
-                                                                 nonzero to NPA_AF_AQ_DONE[DONE]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_int_w1s
- *
- * INTERNAL: NPA AF AQ Done Interrupt Set Register
- */
-union cavm_npa_af_aq_done_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_int_w1s_s
-    {
-        uint64_t done                  : 1;  /**< [  0:  0](RO/H) Done interrupt. See NPA_AF_AQ_DONE[DONE]. Note this bit is read-only, to
-                                                                 acknowledge interrupts use NPA_AF_AQ_DONE_ACK. To test interrupts, write
-                                                                 nonzero to NPA_AF_AQ_DONE[DONE]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_timer
- *
- * NPA AF Admin Queue Done Interrupt Timer Register
- * Used to debug the queue interrupt coalescing timer.
- */
-union cavm_npa_af_aq_done_timer
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_timer_s
-    {
-        uint64_t count                 : 16; /**< [ 15:  0](R/W/H) Timer count. Hardware counter that increments every microsecond when
-                                                                 interrupt coalescing is active; coalescing ends when the counter reaches
-                                                                 NPA_AF_AQ_DONE_WAIT[TIME_WAIT]. Writes to this field are for diagnostic use
-                                                                 only. See also NPA_AF_AQ_DONE[DONE]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_done_wait
- *
- * NPA AF AQ Done Interrupt Coalescing Wait Register
- * Specifies the queue interrupt coalescing settings.
- */
-union cavm_npa_af_aq_done_wait
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_done_wait_s
-    {
-        uint64_t num_wait              : 20; /**< [ 19:  0](R/W) Number of messages hold-off. When NPA_AF_AQ_DONE[DONE] \>= [NUM_WAIT] then
-                                                                 interrupt coalescing ends; see NPA_AF_AQ_DONE[DONE]. If 0x0, same behavior
-                                                                 as 0x1. */
-        uint64_t reserved_20_31        : 12;
-        uint64_t time_wait             : 16; /**< [ 47: 32](R/W) Time hold-off in microseconds. When NPA_AF_AQ_DONE[DONE] = 0, or
-                                                                 NPA_AF_AQ_DONE_ACK is written, the interrupt coalescing timer
-                                                                 (NPA_AF_AQ_DONE_TIMER[COUNT]) is cleared. The timer increments every
-                                                                 microsecond, and interrupt coalescing ends when timer reaches [TIME_WAIT];
-                                                                 see NPA_AF_AQ_DONE[DONE]. If 0x0, time coalescing is disabled. */
-        uint64_t reserved_48_63        : 16;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_door
- *
- * NPA AF Admin Queue Doorbell Register
- * Software writes to this register to enqueue one or more entries to AQ.
- */
-union cavm_npa_af_aq_door
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_door_s
-    {
-        uint64_t count                 : 16; /**< [ 15:  0](WO) Number of enqueued 16-byte entries. Hardware advances
-                                                                 NPA_AF_AQ_STATUS[TAIL_PTR] by this value.
-
-                                                                 A doorbell write that would overflow the AQ ring is suppressed and sets
-                                                                 NPA_AF_AQ_STATUS[AQ_ERR] and NPA_AF_ERR_INT[AQ_DOOR_ERR]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_aq_status
- *
- * NPA AF Admin Queue Status Register
- */
-union cavm_npa_af_aq_status
-{
-    uint64_t u;
-    struct cavm_npa_af_aq_status_s
-    {
-        uint64_t reserved_0_3          : 4;
-        uint64_t head_ptr              : 20; /**< [ 23:  4](R/W/H) Head pointer \<24:4\> of AQ ring relative to NPA_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the head pointer when it pops an entry
-                                                                 from the AQ. */
-        uint64_t reserved_24_35        : 12;
-        uint64_t tail_ptr              : 20; /**< [ 55: 36](R/W/H) Tail pointer \<24:4\> of AQ ring relative to NPA_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the tail pointer when software writes to
-                                                                 NPA_AF_AQ_DOOR. */
-        uint64_t reserved_56_61        : 6;
-        uint64_t aq_busy               : 1;  /**< [ 62: 62](RO/H) This bit is set when an AQ command is currently being processed. */
-        uint64_t aq_err                : 1;  /**< [ 63: 63](R/W1C/H) AQ error. See NPA_AF_ERR_INT[AQ_INST_FAULT,AQ_RES_FAULT,AQ_DOOR_ERR] and
-                                                                 NPA_AF_RAS[AQ_INST_POISON,AQ_RES_POISON].
-                                                                 When set, hardware stops reading instructions from the AQ ring. Software
-                                                                 clears the error by writing a one back. */
-    } s;
-    struct cavm_npa_af_aq_status_cn
-    {
-        uint64_t reserved_0_3          : 4;
-        uint64_t head_ptr              : 20; /**< [ 23:  4](R/W/H) Head pointer \<24:4\> of AQ ring relative to NPA_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the head pointer when it pops an entry
-                                                                 from the AQ. */
-        uint64_t reserved_24_31        : 8;
-        uint64_t reserved_32_35        : 4;
-        uint64_t tail_ptr              : 20; /**< [ 55: 36](R/W/H) Tail pointer \<24:4\> of AQ ring relative to NPA_AF_AQ_BASE. Address bits \<3:0\>
-                                                                 are always 0x0. Hardware advances the tail pointer when software writes to
-                                                                 NPA_AF_AQ_DOOR. */
-        uint64_t reserved_56_61        : 6;
-        uint64_t aq_busy               : 1;  /**< [ 62: 62](RO/H) This bit is set when an AQ command is currently being processed. */
-        uint64_t aq_err                : 1;  /**< [ 63: 63](R/W1C/H) AQ error. See NPA_AF_ERR_INT[AQ_INST_FAULT,AQ_RES_FAULT,AQ_DOOR_ERR] and
-                                                                 NPA_AF_RAS[AQ_INST_POISON,AQ_RES_POISON].
-                                                                 When set, hardware stops reading instructions from the AQ ring. Software
-                                                                 clears the error by writing a one back. */
-    } cn;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_avg_delay
- *
- * NPA AF Queue Average Delay Register
- */
-union cavm_npa_af_avg_delay
-{
-    uint64_t u;
-    struct cavm_npa_af_avg_delay_s
-    {
-        uint64_t avg_dly               : 19; /**< [ 18:  0](R/W) Average-queue-size delay. [AVG_DLY]+1 is the number of microseconds per timer
-                                                                 tick for calculating the moving average for each aura and pool level. Note the
-                                                                 minimum of one microsecond implies that at 100 M packets/sec, approximately 100
-                                                                 packets may arrive between average calculations.
-
-                                                                 Larger [AVG_DLY] causes the moving averages of all aura and pool levels to track changes
-                                                                 in the actual free space more slowly. Larger NPA_AURA_S[AVG_CON]) values causes
-                                                                 a specific aura or pool to track more slowly, but only affects an individual level,
-                                                                 rather than all. */
-        uint64_t reserved_19_23        : 5;
-        uint64_t avg_timer             : 16; /**< [ 39: 24](R/W/H) Running counter that is incremented every [AVG_DLY]+1 microseconds when
-                                                                 [AVG_TIMER_DIS] is clear. */
-        uint64_t reserved_40_62        : 23;
-        uint64_t avg_timer_dis         : 1;  /**< [ 63: 63](R/W) When set, [AVG_TIMER] updates are disabled. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_bar2_alias#
- *
- * INTERNAL: NPA Admin Function  BAR2 Alias Registers
- *
- * These registers alias to the NPA BAR2 registers for the PF and function
- * selected by NPA_AF_BAR2_SEL[PF_FUNC].
- *
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_npa_af_bar2_aliasx
-{
-    uint64_t u;
-    struct cavm_npa_af_bar2_aliasx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Aliased register data. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_bar2_sel
- *
- * INTERNAL: NPA Admin Function BAR2 Select Register
- *
- * This register configures BAR2 accesses from the NPA_AF_BAR2_ALIAS() registers in BAR0.
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_npa_af_bar2_sel
-{
-    uint64_t u;
-    struct cavm_npa_af_bar2_sel_s
-    {
-        uint64_t alias_pf_func         : 16; /**< [ 15:  0](R/W) PF and function whose BAR2 registers may be accessed from the AF BAR2 alias
-                                                                 registers. Format specified by RVU_PF_FUNC_S. */
-        uint64_t alias_ena             : 1;  /**< [ 16: 16](R/W) Enable BAR2 register accesses from the AF BAR2 alias registers in BAR0. */
-        uint64_t reserved_17_63        : 47;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_blk_rst
- *
- * NPA AF Block Reset Register
- */
-union cavm_npa_af_blk_rst
-{
-    uint64_t u;
-    struct cavm_npa_af_blk_rst_s
-    {
-        uint64_t rst                   : 1;  /**< [  0:  0](WO/H) Write one to reset the block, except for privileged AF registers in PF BAR0
-                                                                 (block_PRIV_*). Software must ensure that all block activity is quiesced before
-                                                                 writing 1. */
-        uint64_t reserved_1_62         : 62;
-        uint64_t busy                  : 1;  /**< [ 63: 63](RO/H) When one, the block is busy completing reset. No access except the reading of
-                                                                 this bit should occur to the block until this is clear. */
-    } s;
-};
-
-
-/**
- * Register (RVU_PF_BAR0) npa_af_bp_test
- *
- * INTERNAL: NPA AF Backpressure Test Register
- */
-union cavm_npa_af_bp_test
-{
-    uint64_t u;
-    struct cavm_npa_af_bp_test_s
-    {
-        uint64_t lfsr_freq             : 12; /**< [ 11:  0](R/W) Test LFSR update frequency in coprocessor-clocks minus one. */
-        uint64_t reserved_12_15        : 4;
-        uint64_t bp_cfg                : 32; /**< [ 47: 16](R/W) Backpressure weight. For diagnostic use only.
-                                                                 Internal:
-                                                                 There are 2 backpressure configuration bits per enable, with the two bits
-                                                                 defined as 0x0=100% of the time, 0x1=25% of the time, 0x2=50% of the time,
-                                                                 0x3=75% of the time.
-                                                                   \<47:46\> = Config 15.
-                                                                   \<45:44\> = Config 14.
-                                                                   \<43:42\> = Config 13.
-                                                                   \<41:40\> = Config 12.
-                                                                   \<39:38\> = Config 11.
-                                                                   \<37:36\> = Config 10.
-                                                                   \<35:34\> = Config 9.
-                                                                   \<33:32\> = Config 8.
-                                                                   \<31:30\> = Config 7.
-                                                                   \<29:28\> = Config 6.
-                                                                   \<27:26\> = Config 5.
-                                                                   \<25:24\> = Config 4.
-                                                                   \<23:22\> = Config 3.
-                                                                   \<21:20\> = Config 2.
-                                                                   \<19:18\> = Config 1.
-                                                                   \<17:16\> = Config 0. */
-        uint64_t enable                : 16; /**< [ 63: 48](R/W) Enable test mode. For diagnostic use only.
-                                                                 Internal:
-                                                                 FIXME: the following is copied from FPA; to be updated for NPA.
-
-                                                                 Once a bit is set, random backpressure is generated
-                                                                 at the corresponding point to allow for more frequent backpressure.
-                                                                 \<63\> = Reserved.
-                                                                 \<62\> = Reserved.
-                                                                 \<61\> = Reserved.
-                                                                 \<60\> = Apply backpressure to adp to csr traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<24:23\>.
-                                                                 \<59\> = Apply backpressure to adp to l2s traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<23:22\>.
-                                                                 \<58\> = Apply backpressure to adp to l2l traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<21:20\>.
-                                                                 \<57\> = Apply backpressure to red read to csr traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<19:18\>.
-                                                                 \<56\> = Apply backpressure to l2arb to csr traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<17:16\>.
-                                                                 \<55\> = Apply backpressure to csr to adp traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<15:14\>.
-                                                                 \<54\> = Apply backpressure to pcc to gib traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<13:12\>.
-                                                                 \<53\> = Apply backpressure to adp to pfc traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<11:10\>.
-                                                                 \<52\> = generate pmc to pfc backpressure. Backpressure weight controlled
-                                                                 by [BP_CFG]\<9:8\>.
-                                                                 \<51\> = Apply backpressure to pmc to ncbi traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<7:6\>.
-                                                                 \<50\> = Apply backpressure to csr to ncbi traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<5:4\>.
-                                                                 \<49\> = Apply backpressure to l2s to ncbi traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<3:2\>.
-                                                                 \<48\> = Apply backpressure to l2l to ncbi traffic. Backpressure weight controlled
-                                                                 by [BP_CFG]\<1:0\>. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_const
- *
- * NPA AF Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_npa_af_const
-{
-    uint64_t u;
-    struct cavm_npa_af_const_s
-    {
-        uint64_t stack_page_bytes      : 8;  /**< [  7:  0](RO) NPA_STACK_PAGE_S size in bytes. */
-        uint64_t stack_page_ptrs       : 8;  /**< [ 15:  8](RO) Number of pointers stored in a stack page. */
-        uint64_t lfs                   : 12; /**< [ 27: 16](RO) Number of NPA Local Functions. */
-        uint64_t qints                 : 12; /**< [ 39: 28](RO) Number of queue interrupts per VF/PF. */
-        uint64_t num_ndc               : 3;  /**< [ 42: 40](RO) Number of NDCs enumerated by NDC_IDX_E::NPA_U(). */
-        uint64_t reserved_43_63        : 21;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_const1
- *
- * NPA AF Constants Register 1
- * This register contains constants for software discovery.
- */
-union cavm_npa_af_const1
-{
-    uint64_t u;
-    struct cavm_npa_af_const1_s
-    {
-        uint64_t aura_log2bytes        : 4;  /**< [  3:  0](RO) Aura context size as log2(bytes). Size of each NPA_AURA_HW_S structure in a
-                                                                 local function's aura context table in NDC/LLC/DRAM. See
-                                                                 NPA_AF_LF()_LOC_AURAS_BASE and NPA_AF_LF()_AURAS_CFG. */
-        uint64_t pool_log2bytes        : 4;  /**< [  7:  4](RO) Pool context size as log2(bytes). Size of each NPA_POOL_HW_S structure at
-                                                                 IOVA NPA_AURA_S[POOL_ADDR]. */
-        uint64_t qint_log2bytes        : 4;  /**< [ 11:  8](RO) Queue interrupt context size as log2(bytes). Size of each NPA_QINT_HW_S
-                                                                 structure in a local function's queue interrupt context table NDC/LLC/DRAM.
-                                                                 See NPA_AF_LF()_QINTS_BASE and NPA_AF_LF()_QINTS_CFG. */
-        uint64_t reserved_12_63        : 52;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_dtx_filter_ctl
- *
- * NPA AF DTX LF Filter Control Register
- */
-union cavm_npa_af_dtx_filter_ctl
-{
-    uint64_t u;
-    struct cavm_npa_af_dtx_filter_ctl_s
-    {
-        uint64_t ena                   : 1;  /**< [  0:  0](R/W) Enable DTX pointer debug filtering based on LF.
-                                                                 When combined with appropriate DTX selects, permits observation of full aura values for that LF. */
-        uint64_t reserved_1_3          : 3;
-        uint64_t lf                    : 7;  /**< [ 10:  4](R/W) LF value used for DTX pointer debug filtering when [ENA] is one. */
-        uint64_t reserved_11_63        : 53;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_eco
- *
- * INTERNAL: NPA AF ECO Register
- */
-union cavm_npa_af_eco
-{
-    uint64_t u;
-    struct cavm_npa_af_eco_s
-    {
-        uint64_t eco_rw                : 32; /**< [ 31:  0](R/W) Reserved for ECO usage. */
-        uint64_t reserved_32_63        : 32;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_err_int
- *
- * NPA Admin Function Error Interrupt Register
- */
-union cavm_npa_af_err_int
-{
-    uint64_t u;
-    struct cavm_npa_af_err_int_s
-    {
-        uint64_t reserved_0_11         : 12;
-        uint64_t aq_door_err           : 1;  /**< [ 12: 12](R/W1C/H) AQ doorbell error. See NPA_AF_AQ_DOOR[COUNT]. Hardware also sets
-                                                                 NPA_AF_AQ_STATUS[AQ_ERR]. */
-        uint64_t aq_res_fault          : 1;  /**< [ 13: 13](R/W1C/H) Memory fault on NPA_AQ_RES_S write, or on read/write data following
-                                                                 NPA_AQ_RES_S. Hardware also sets NPA_AF_AQ_STATUS[AQ_ERR]. */
-        uint64_t aq_inst_fault         : 1;  /**< [ 14: 14](R/W1C/H) Memory fault on NPA_AQ_INST_S read. Hardware also sets
-                                                                 NPA_AF_AQ_STATUS[AQ_ERR]. */
-        uint64_t reserved_15_63        : 49;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_err_int_ena_w1c
- *
- * NPA Admin Function Error Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_af_err_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_af_err_int_ena_w1c_s
-    {
-        uint64_t reserved_0_11         : 12;
-        uint64_t aq_door_err           : 1;  /**< [ 12: 12](R/W1C/H) Reads or clears enable for NPA_AF_ERR_INT[AQ_DOOR_ERR]. */
-        uint64_t aq_res_fault          : 1;  /**< [ 13: 13](R/W1C/H) Reads or clears enable for NPA_AF_ERR_INT[AQ_RES_FAULT]. */
-        uint64_t aq_inst_fault         : 1;  /**< [ 14: 14](R/W1C/H) Reads or clears enable for NPA_AF_ERR_INT[AQ_INST_FAULT]. */
-        uint64_t reserved_15_63        : 49;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_err_int_ena_w1s
- *
- * NPA Admin Function Error Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_af_err_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_err_int_ena_w1s_s
-    {
-        uint64_t reserved_0_11         : 12;
-        uint64_t aq_door_err           : 1;  /**< [ 12: 12](R/W1S/H) Reads or sets enable for NPA_AF_ERR_INT[AQ_DOOR_ERR]. */
-        uint64_t aq_res_fault          : 1;  /**< [ 13: 13](R/W1S/H) Reads or sets enable for NPA_AF_ERR_INT[AQ_RES_FAULT]. */
-        uint64_t aq_inst_fault         : 1;  /**< [ 14: 14](R/W1S/H) Reads or sets enable for NPA_AF_ERR_INT[AQ_INST_FAULT]. */
-        uint64_t reserved_15_63        : 49;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_err_int_w1s
- *
- * NPA Admin Function Error Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_af_err_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_err_int_w1s_s
-    {
-        uint64_t reserved_0_11         : 12;
-        uint64_t aq_door_err           : 1;  /**< [ 12: 12](R/W1S/H) Reads or sets NPA_AF_ERR_INT[AQ_DOOR_ERR]. */
-        uint64_t aq_res_fault          : 1;  /**< [ 13: 13](R/W1S/H) Reads or sets NPA_AF_ERR_INT[AQ_RES_FAULT]. */
-        uint64_t aq_inst_fault         : 1;  /**< [ 14: 14](R/W1S/H) Reads or sets NPA_AF_ERR_INT[AQ_INST_FAULT]. */
-        uint64_t reserved_15_63        : 49;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_gen_cfg
- *
- * NPA AF General Configuration Register
- * This register provides NPA control and status information.
- */
-union cavm_npa_af_gen_cfg
-{
-    uint64_t u;
-    struct cavm_npa_af_gen_cfg_s
-    {
-        uint64_t reserved_0            : 1;
-        uint64_t af_be                 : 1;  /**< [  1:  1](R/W) Admin function big-endian select. Specifies endianness of all admin queue
-                                                                 instructions, results and associated structures stored in LLC/DRAM:
-
-                                                                 0 = Little-endian. All AF software data structures are in byte invariant
-                                                                 little-endian format (LE8) with the following ordering within each 64-bit
-                                                                 word: \<7:0\> at byte address 0, \<15:8\> at address 1, ..., \<63:56\> at address
-                                                                 0x7.
-
-                                                                 1 = Big-endian. All AF software data structures are in byte invariant
-                                                                 big-endian format (BE8) with the following ordering within each 64-bit
-                                                                 word: \<63:56\> at byte address 0, \<55:48\> at address 1, ..., \<7:0\> at
-                                                                 address 0x7.
-
-                                                                 The affected data structures are:
-                                                                 * NPA_AQ_INST_S.
-                                                                 * NPA_AQ_RES_S.
-                                                                 * Software context READ/WRITE/INIT data following NPA_AQ_RES_S. */
-        uint64_t reserved_2            : 1;
-        uint64_t force_cond_clk_en     : 1;  /**< [  3:  3](R/W) Force clock enables within block. For diagnostic use only. */
-        uint64_t force_intf_clk_en     : 1;  /**< [  4:  4](R/W) Force clock enables on interface busses between blocks. For diagnostic use only. */
-        uint64_t reserved_5_9          : 5;
-        uint64_t ocla_bp               : 1;  /**< [ 10: 10](R/W) OCLA backpressure enable. When OCLA FIFOs are near full, allow OCLA to backpressure
-                                                                 alloc/frees. See also [RATEM1]. */
-        uint64_t reserved_11           : 1;
-        uint64_t ratem1                : 4;  /**< [ 15: 12](R/W) Issue rate minus one. Limit peak alloc/frees to once per [RATEM1]+1
-                                                                 clock cycles to insure all alloc/frees are visible to OCLA. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_gen_int
- *
- * NPA AF General Interrupt Register
- * This register contains general error interrupt summary bits.
- */
-union cavm_npa_af_gen_int
-{
-    uint64_t u;
-    struct cavm_npa_af_gen_int_s
-    {
-        uint64_t free_dis              : 16; /**< [ 15:  0](R/W1C/H) Free input disabled. A FREE request was dropped because the
-                                                                 corresponding NPA_AF_INP_CTL[FREE_DIS] bit was set.
-                                                                 Each bit corresponds to a hardware free input queue from a coprocessor. Bit
-                                                                 indices are enumerated by NPA_INPQ_E. */
-        uint64_t alloc_dis             : 16; /**< [ 31: 16](R/W1C/H) Allocation input disabled. An ALLOC request was dropped because the
-                                                                 corresponding NPA_AF_INP_CTL[ALLOC_DIS] bit was set.
-                                                                 Each bit corresponds to a hardware allocation input queue from a
-                                                                 coprocessor. Bit indices are enumerated by NPA_INPQ_E. */
-        uint64_t unmapped_pf_func      : 1;  /**< [ 32: 32](R/W1C/H) Unmapped PF FUNC. Coprocessor ALLOC failed or FREE dropped due to that
-                                                                 coprocessor requesting with a PF FUNC that is not mapped to an NPA LF. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_gen_int_ena_w1c
- *
- * NPA AF General Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_af_gen_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_af_gen_int_ena_w1c_s
-    {
-        uint64_t free_dis              : 16; /**< [ 15:  0](R/W1C/H) Reads or clears enable for NPA_AF_GEN_INT[FREE_DIS]. */
-        uint64_t alloc_dis             : 16; /**< [ 31: 16](R/W1C/H) Reads or clears enable for NPA_AF_GEN_INT[ALLOC_DIS]. */
-        uint64_t unmapped_pf_func      : 1;  /**< [ 32: 32](R/W1C/H) Reads or clears enable for NPA_AF_GEN_INT[UNMAPPED_PF_FUNC]. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_gen_int_ena_w1s
- *
- * NPA AF General Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_af_gen_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_gen_int_ena_w1s_s
-    {
-        uint64_t free_dis              : 16; /**< [ 15:  0](R/W1S/H) Reads or sets enable for NPA_AF_GEN_INT[FREE_DIS]. */
-        uint64_t alloc_dis             : 16; /**< [ 31: 16](R/W1S/H) Reads or sets enable for NPA_AF_GEN_INT[ALLOC_DIS]. */
-        uint64_t unmapped_pf_func      : 1;  /**< [ 32: 32](R/W1S/H) Reads or sets enable for NPA_AF_GEN_INT[UNMAPPED_PF_FUNC]. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_gen_int_w1s
- *
- * NPA AF General Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_af_gen_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_gen_int_w1s_s
-    {
-        uint64_t free_dis              : 16; /**< [ 15:  0](R/W1S/H) Reads or sets NPA_AF_GEN_INT[FREE_DIS]. */
-        uint64_t alloc_dis             : 16; /**< [ 31: 16](R/W1S/H) Reads or sets NPA_AF_GEN_INT[ALLOC_DIS]. */
-        uint64_t unmapped_pf_func      : 1;  /**< [ 32: 32](R/W1S/H) Reads or sets NPA_AF_GEN_INT[UNMAPPED_PF_FUNC]. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_inp_ctl
- *
- * NPA AF Input Control Register
- */
-union cavm_npa_af_inp_ctl
-{
-    uint64_t u;
-    struct cavm_npa_af_inp_ctl_s
-    {
-        uint64_t free_dis              : 16; /**< [ 15:  0](R/W) Free input disable.
-                                                                 Each bit corresponds to a hardware allocation input queue from a coprocessor. Bit indices
-                                                                 are enumerated by NPA_INPQ_E.
-                                                                 If set, a FREE request to the queue is dropped and NPA_AF_GEN_INT[FREE_DIS] is set.
-
-                                                                 Internal:
-                                                                 Once the grant is sent, the request is marked and it is dropped when the request
-                                                                 data is received. */
-        uint64_t alloc_dis             : 16; /**< [ 31: 16](R/W) Allocation input disable.
-                                                                 Each bit corresponds to a hardware allocation input queue from a coprocessor. Bit indices
-                                                                 are enumerated by NPA_INPQ_E.
-                                                                 If set, an ALLOC request to the queue is dropped and NPA_AF_GEN_INT[ALLOC_DIS] is set. */
-        uint64_t reserved_32_63        : 32;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_lf#_auras_cfg
- *
- * NPA AF Local Function Auras Configuration Registers
- */
-union cavm_npa_af_lfx_auras_cfg
-{
-    uint64_t u;
-    struct cavm_npa_af_lfx_auras_cfg_s
-    {
-        uint64_t way_mask              : 16; /**< [ 15:  0](R/W) Way partitioning mask for allocating associated NPA_AURA_HW_S in NDC (1
-                                                                 means do not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-        uint64_t loc_aura_size         : 4;  /**< [ 19: 16](R/W) Local aura size. Specifies number of auras managed by this NPA as follows:
-                                                                 0x0 = 0 auras.
-                                                                 0x1 = 128 auras.
-                                                                 0x2 = 256 auras.
-                                                                 0x3 = 512 auras.
-                                                                 0x4 = 1K auras.
-                                                                 0x5 = 2K auras.
-                                                                 0x6 = 4K auras.
-                                                                 0x7 = 8K auras.
-                                                                 0x8 = 16K auras.
-                                                                 0x9 = 32K auras.
-                                                                 0xA = 64K auras.
-                                                                 0xB = 128K auras
-                                                                 0xC = 256K auras.
-                                                                 0xD = 512K auras.
-                                                                 0xE = 1M auras.
-                                                                 0xF = Reserved.
-
-                                                                 See [LOC_AURA_OFFSET]. */
-        uint64_t loc_aura_offset       : 14; /**< [ 33: 20](R/W) Local aura offset. Minimum aura number managed by this NPA divided by 64
-                                                                 when [LOC_AURA_SIZE] is nonzero.
-
-                                                                 When [LOC_AURA_SIZE] is zero, there are no local auras for this LF.
-                                                                 Otherwise, the range of local aura numbers managed by this NPA is loc_start
-                                                                 through loc_limit-1, inclusive, where:
-                                                                 _ loc_start = [LOC_AURA_OFFSET]*64
-                                                                 _ loc_limit = [LOC_AURA_OFFSET]*64 + (1 \<\< ([LOC_AURA_SIZE] + 6))
-
-                                                                 See also NPA_AF_LF()_LOC_AURAS_BASE.
-
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Likewise, when [RMT_AURA_SIZE] is zero, there are no remote auras for this
-                                                                 LF. Otherwise, the range of remote aura numbers managed by the NPA on
-                                                                 the remote node is rmt_start through rmt_limit-1, inclusive, where:
-                                                                 _ rmt_start = [RMT_AURA_OFFSET]*64
-                                                                 _ rmt_limit = [RMT_AURA_OFFSET]*64 + (1 \<\< ([RMT_AURA_SIZE] + 6))
-
-                                                                 The local and remote aura ranges must not overlap. */
-        uint64_t caching               : 1;  /**< [ 34: 34](R/W) Selects the style read for accessing NPA_AURA_HW_S in LLC/DRAM:
-                                                                 0x0 = NPA_AURA_HW_S reads will not allocate into the LLC.
-                                                                 0x1 = NPA_AURA_HW_S reads are allocated into the LLC.
-
-                                                                 NPA_AURA_HW_S writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-        uint64_t reserved_35           : 1;
-        uint64_t rmt_aura_size         : 4;  /**< [ 39: 36](R/W) Reserved. Must be zero.
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Specifies number of auras managed by the NPA on the remote node. See
-                                                                 [LOC_AURA_SIZE] and [LOC_AURA_OFFSET]. */
-        uint64_t rmt_aura_offset       : 14; /**< [ 53: 40](R/W) Reserved.
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Minimum aura number managed by the NPA on the remote node divided by 64.
-                                                                 See [LOC_AURA_OFFSET]. */
-        uint64_t rmt_lf                : 7;  /**< [ 60: 54](R/W) Reserved.
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Remote local function. NPA LF on the remote node that manages the aura
-                                                                 range specified by [RMT_AURA_OFFSET] and [RMT_AURA_SIZE]. See
-                                                                 [LOC_AURA_OFFSET]. */
-        uint64_t reserved_61_63        : 3;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_lf#_loc_auras_base
- *
- * NPA AF Local Function Auras Base Registers
- */
-union cavm_npa_af_lfx_loc_auras_base
-{
-    uint64_t u;
-    struct cavm_npa_af_lfx_loc_auras_base_s
-    {
-        uint64_t reserved_0_6          : 7;
-        uint64_t addr                  : 46; /**< [ 52:  7](R/W) AF IOVA\<52:7\> of local aura context table in NDC/LLC/DRAM.
-                                                                 The table consists of 1 \<\< (NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE] + 6)
-                                                                 contiguous NPA_AURA_HW_S structures, where the size of each structure is
-                                                                 1 \<\< NPA_AF_CONST1[AURA_LOG2BYTES] bytes.
-                                                                 Aura number NPA_AF_LF()_AURAS_CFG[LOC_AURA_OFFSET]*64 stored at index 0 of
-                                                                 the table. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_lf#_qints_base
- *
- * NPA AF Local Function Queue Interrupts Base Registers
- */
-union cavm_npa_af_lfx_qints_base
-{
-    uint64_t u;
-    struct cavm_npa_af_lfx_qints_base_s
-    {
-        uint64_t reserved_0_6          : 7;
-        uint64_t addr                  : 46; /**< [ 52:  7](R/W) AF IOVA\<52:7\> of local queue interrupt context table in LLC/DRAM.
-                                                                 The table consists of NPA_AF_CONST[QINTS] contiguous NPA_QINT_HW_S structures.
-                                                                 The size of each structure is 1 \<\< NPA_AF_CONST1[QINT_LOG2BYTES] bytes. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_lf#_qints_cfg
- *
- * NPA AF Local Function Queue Interrupts Configuration Registers
- * This register controls access to the LF's queue interrupt context table in
- * LLC/DRAM. The table consists of NPA_AF_CONST[QINTS] contiguous NPA_QINT_HW_S
- * structures. The size of each structure is 1 \<\< NPA_AF_CONST1[QINT_LOG2BYTES]
- * bytes.
- */
-union cavm_npa_af_lfx_qints_cfg
-{
-    uint64_t u;
-    struct cavm_npa_af_lfx_qints_cfg_s
-    {
-        uint64_t reserved_0_19         : 20;
-        uint64_t way_mask              : 16; /**< [ 35: 20](R/W) Way partitioning mask for allocating context structures in NDC (1 means do
-                                                                 not use). All ones disables allocation in NDC.
-
-                                                                 Internal:
-                                                                 Bypass NDC when all ones. */
-        uint64_t caching               : 2;  /**< [ 37: 36](R/W) Selects the style read for accessing NPA_QINT_HW_S in LLC/DRAM:
-                                                                 0x0 = NPA_QINT_HW_S reads will not allocate into the LLC.
-                                                                 0x1 = NPA_QINT_HW_S reads are allocated into the LLC.
-                                                                 0x2 = Reserved.
-                                                                 0x3 = Reserved.
-
-                                                                 NPA_QINT_HW_S writes that are not allocated in NDC will always allocate
-                                                                 into LLC. */
-        uint64_t reserved_38_63        : 26;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_lf_rst
- *
- * NPA Admin Function LF Reset Register
- */
-union cavm_npa_af_lf_rst
-{
-    uint64_t u;
-    struct cavm_npa_af_lf_rst_s
-    {
-        uint64_t lf                    : 8;  /**< [  7:  0](R/W) Local function that is reset when [EXEC] is set. */
-        uint64_t reserved_8_11         : 4;
-        uint64_t exec                  : 1;  /**< [ 12: 12](R/W1S/H) Execute LF software-initiated reset. When software writes a one to set this bit, hardware
-                                                                 resets the local function selected by [LF]. Hardware clears this bit when
-                                                                 done.
-
-                                                                 Internal:
-                                                                 This comment applies to all blocks that refer to this register:
-
-                                                                 This should preferrably reset all registers/state associated with the LF, including
-                                                                 any BLK_LF_* and BLK_AF_LF()_* registers. It would also be nice to reset any per-LF
-                                                                 bits in other registers but its OK to have exceptions as long as the AF software has
-                                                                 another way to reset them, e.g. by writing to the bits. Such additional steps
-                                                                 expected from software should be documented in the HRM, e.g. in section 19.11.5
-                                                                 "VF Function Level Reset". */
-        uint64_t reserved_13_63        : 51;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ndc_cfg
- *
- * NDC AF General Configuration Register
- * This register provides NDC control.
- */
-union cavm_npa_af_ndc_cfg
-{
-    uint64_t u;
-    struct cavm_npa_af_ndc_cfg_s
-    {
-        uint64_t ndc_bypass            : 1;  /**< [  0:  0](R/W) Forces all NDC transations to bypass the NDC cache. */
-        uint64_t ndc_ign_pois          : 1;  /**< [  1:  1](R/W) Ignore poison responses from NDC. */
-        uint64_t byp_aura              : 1;  /**< [  2:  2](R/W) Force all NPA_AURA_HW_S transactions to bypass NDC. */
-        uint64_t byp_pool              : 1;  /**< [  3:  3](R/W) Force all NPA_POOL_HW_S transactions to bypass NDC. */
-        uint64_t byp_stack             : 1;  /**< [  4:  4](R/W) Force all NPA_STACK_PAGE_S transactions to bypass NDC. */
-        uint64_t byp_qint              : 1;  /**< [  5:  5](R/W) Force all NPA_QINT_HW_S transactions to bypass NDC. */
-        uint64_t reserved_6_63         : 58;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ndc_sync
- *
- * NPA AF NDC Sync Register
- * Used to synchronize the NPA NDC.
- */
-union cavm_npa_af_ndc_sync
-{
-    uint64_t u;
-    struct cavm_npa_af_ndc_sync_s
-    {
-        uint64_t lf                    : 8;  /**< [  7:  0](R/W) Local function whose data is synced when [EXEC] is set. */
-        uint64_t reserved_8_11         : 4;
-        uint64_t exec                  : 1;  /**< [ 12: 12](R/W1S/H) Execute sync. When software writes a one to set this bit, NDC writes back
-                                                                 to LLC/DRAM all dirty lines associated with the local function selected by
-                                                                 [LF]. Hardware clears this bit when done. */
-        uint64_t reserved_13_63        : 51;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ras
- *
- * NPA AF RAS Interrupt Register
- * This register is intended for delivery of RAS events to the SCP, so should be
- * ignored by OS drivers.
- */
-union cavm_npa_af_ras
-{
-    uint64_t u;
-    struct cavm_npa_af_ras_s
-    {
-        uint64_t reserved_0_31         : 32;
-        uint64_t aq_ctx_poison         : 1;  /**< [ 32: 32](R/W1C/H) Poisoned data returned on read of hardware context data selected by
-                                                                 NPA_AQ_INST_S[LF,CTYPE,AURA]. If NPA_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware
-                                                                 also returns NPA_AQ_RES_S[COMPCODE] = NPA_AQ_COMP_E::CTX_POISON. */
-        uint64_t aq_res_poison         : 1;  /**< [ 33: 33](R/W1C/H) Poisoned read data returned following NPA_AQ_RES_S. If
-                                                                 NPA_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware also sets
-                                                                 NPA_AF_AQ_STATUS[AQ_ERR]. */
-        uint64_t aq_inst_poison        : 1;  /**< [ 34: 34](R/W1C/H) Poisoned data returned on NPA_AQ_INST_S read. If
-                                                                 NPA_AF_NDC_CFG[NDC_IGN_POIS]=0, hardware also sets
-                                                                 NPA_AF_AQ_STATUS[AQ_ERR]. */
-        uint64_t reserved_35_63        : 29;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ras_ena_w1c
- *
- * NPA AF RAS Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_af_ras_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_af_ras_ena_w1c_s
-    {
-        uint64_t reserved_0_31         : 32;
-        uint64_t aq_ctx_poison         : 1;  /**< [ 32: 32](R/W1C/H) Reads or clears enable for NPA_AF_RAS[AQ_CTX_POISON]. */
-        uint64_t aq_res_poison         : 1;  /**< [ 33: 33](R/W1C/H) Reads or clears enable for NPA_AF_RAS[AQ_RES_POISON]. */
-        uint64_t aq_inst_poison        : 1;  /**< [ 34: 34](R/W1C/H) Reads or clears enable for NPA_AF_RAS[AQ_INST_POISON]. */
-        uint64_t reserved_35_63        : 29;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ras_ena_w1s
- *
- * NPA AF RAS Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_af_ras_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_ras_ena_w1s_s
-    {
-        uint64_t reserved_0_31         : 32;
-        uint64_t aq_ctx_poison         : 1;  /**< [ 32: 32](R/W1S/H) Reads or sets enable for NPA_AF_RAS[AQ_CTX_POISON]. */
-        uint64_t aq_res_poison         : 1;  /**< [ 33: 33](R/W1S/H) Reads or sets enable for NPA_AF_RAS[AQ_RES_POISON]. */
-        uint64_t aq_inst_poison        : 1;  /**< [ 34: 34](R/W1S/H) Reads or sets enable for NPA_AF_RAS[AQ_INST_POISON]. */
-        uint64_t reserved_35_63        : 29;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_ras_w1s
- *
- * NPA AF RAS Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_af_ras_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_ras_w1s_s
-    {
-        uint64_t reserved_0_31         : 32;
-        uint64_t aq_ctx_poison         : 1;  /**< [ 32: 32](R/W1S/H) Reads or sets NPA_AF_RAS[AQ_CTX_POISON]. */
-        uint64_t aq_res_poison         : 1;  /**< [ 33: 33](R/W1S/H) Reads or sets NPA_AF_RAS[AQ_RES_POISON]. */
-        uint64_t aq_inst_poison        : 1;  /**< [ 34: 34](R/W1S/H) Reads or sets NPA_AF_RAS[AQ_INST_POISON]. */
-        uint64_t reserved_35_63        : 29;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_rvu_int
- *
- * NPA AF RVU Interrupt Register
- * This register contains RVU error interrupt summary bits.
- */
-union cavm_npa_af_rvu_int
-{
-    uint64_t u;
-    struct cavm_npa_af_rvu_int_s
-    {
-        uint64_t unmapped_slot         : 1;  /**< [  0:  0](R/W1C/H) Unmapped slot. Received an IO request to a VF/PF slot in BAR2 that is not
-                                                                 reverse mapped to an LF. See NPA_PRIV_LF()_CFG and NPA_AF_RVU_LF_CFG_DEBUG. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_rvu_int_ena_w1c
- *
- * NPA AF RVU Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_af_rvu_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_af_rvu_int_ena_w1c_s
-    {
-        uint64_t unmapped_slot         : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for NPA_AF_RVU_INT[UNMAPPED_SLOT]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_rvu_int_ena_w1s
- *
- * NPA AF RVU Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_af_rvu_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_rvu_int_ena_w1s_s
-    {
-        uint64_t unmapped_slot         : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for NPA_AF_RVU_INT[UNMAPPED_SLOT]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_rvu_int_w1s
- *
- * NPA AF RVU Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_af_rvu_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_af_rvu_int_w1s_s
-    {
-        uint64_t unmapped_slot         : 1;  /**< [  0:  0](R/W1S/H) Reads or sets NPA_AF_RVU_INT[UNMAPPED_SLOT]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_af_rvu_lf_cfg_debug
- *
- * NPA Privileged LF Configuration Debug Register
- * This debug register allows software to lookup the reverse mapping from VF/PF
- * slot to LF. The forward mapping is programmed with NPA_PRIV_LF()_CFG.
- */
-union cavm_npa_af_rvu_lf_cfg_debug
-{
-    uint64_t u;
-    struct cavm_npa_af_rvu_lf_cfg_debug_s
-    {
-        uint64_t lf                    : 12; /**< [ 11:  0](RO/H) When [LF_VALID] is set, local function provisioned to the VF/PF slot. */
-        uint64_t lf_valid              : 1;  /**< [ 12: 12](RO/H) When set, indicates local function [LF] is provisioned to the VF/PF slot
-                                                                 indexed by this register. When clear, a local function is not provisioned
-                                                                 to the VF/PF slot. */
-        uint64_t exec                  : 1;  /**< [ 13: 13](R/W1S/H) Execute lookup. Writing a one to this bits initiates the reverse lookup
-                                                                 from {[PF_FUNC], [SLOT]}. Hardware writes the lookup result to {[LF_VALID],
-                                                                 [LF]} and clears this bit when done. */
-        uint64_t reserved_14_15        : 2;
-        uint64_t slot                  : 8;  /**< [ 23: 16](R/W) Slot within the VF/PF selected by [PF_FUNC] for reverse lookup. Must be
-                                                                 zero for NIX and NPA. */
-        uint64_t pf_func               : 16; /**< [ 39: 24](R/W) RVU VF/PF for reverse lookup. Format defined by RVU_PF_FUNC_S. */
-        uint64_t reserved_40_63        : 24;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_alloc#
- *
- * NPA Aura Allocate Operation Registers
- * These registers are used to allocate one or two pointers from a given aura's pool.
- * A 64-bit atomic load-and-add to NPA_LF_AURA_OP_ALLOC(0) allocates a single pointer.
- * A 128-bit atomic CASP operation to NPA_LF_AURA_OP_ALLOC(0..1) allocates two pointers.
- * The atomic write data format is NPA_AURA_OP_WDATA_S.
- * For CASP, the first SWAP word in the write data contains NPA_AURA_OP_WDATA_S
- * and the remaining write data words are ignored.
- *
- * All other accesses to this register (e.g. reads and writes) are RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_allocx
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_allocx_s
-    {
-        uint64_t addr                  : 64; /**< [ 63:  0](RO/H) LF IOVA newly allocated by hardware returned as atomic read data. Bits \<6:0\>
-                                                                 are always zero. Bits \<63:53\> are a sign extension of bit \<52\>.
-
-                                                                 If 0x0, the selected pool is empty, aura limit has been hit, or drop
-                                                                 (NPA_AURA_OP_WDATA_S[DROP]) was applied. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_cnt
- *
- * NPA LF Aura Count Register
- * A 64-bit atomic load-and-add to this register returns a given aura's
- * count. A write sets or adds the aura's count. A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_cnt
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_cnt_s
-    {
-        uint64_t count                 : 36; /**< [ 35:  0](R/W/H) Returns the current value of NPA_AURA_HW_S[COUNT] on a load-and-add. Value
-                                                                 to write or add to NPA_AURA_HW_S[COUNT] on a write; see [CNT_ADD]. */
-        uint64_t reserved_36_41        : 6;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. Remaining read data fields are not valid. One of the
-                                                                 following (may not be exhaustive):
-                                                                 * Memory fault on NPA_AURA_HW_S read; also sets NPA_LF_ERR_INT[AURA_FAULT].
-                                                                 * Poisoned data returned on NPA_AURA_HW_S read; also sets
-                                                                 NPA_LF_RAS[AURA_POISON].
-                                                                 * [AURA] is outside of the range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET].
-                                                                 * Aura is disabled (NPA_AURA_HW_S[ENA] = 0); also sets
-                                                                 NPA_LF_ERR_INT[AURA_DIS]. */
-        uint64_t cnt_add               : 1;  /**< [ 43: 43](WO) Count add. This field is present on a write. When clear, [COUNT] is
-                                                                 unsigned and written to NPA_AURA_HW_S[COUNT]. When set, [COUNT] is a signed
-                                                                 value added to NPA_AURA_HW_S[COUNT]. */
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_free0
- *
- * NPA LF Aura Free Operation Register 0
- * A 128-bit write to the NPA_LF_AURA_OP_FREE0 and NPA_LF_AURA_OP_FREE1
- * registers frees a pointer into a given aura's pool.
- * All other accesses to these registers (e.g. reads and 64-bit writes) are
- * RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_free0
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_free0_s
-    {
-        uint64_t addr                  : 64; /**< [ 63:  0](WO) LF IOVA to return to aura. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_free1
- *
- * NPA LF Aura Free Operation Register 1
- * See NPA_LF_AURA_OP_FREE0.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_free1
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_free1_s
-    {
-        uint64_t aura                  : 20; /**< [ 19:  0](WO) Aura within VF. */
-        uint64_t reserved_20_62        : 43;
-        uint64_t fabs                  : 1;  /**< [ 63: 63](WO) Free absolute. If set, the pointer is absolute and is pushed to the pool exactly
-                                                                 as provided. If clear, the freed pointer is adjusted based on
-                                                                 NPA_POOL_S[NAT_ALIGN], NPA_POOL_S[BUF_SIZE]. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_int
- *
- * NPA LF Aura Interrupt Operation Register
- * A 64-bit atomic load-and-add to this register reads
- * NPA_AURA_HW_S[ERR_INT,ERR_INT_ENA,THRESH_INT,THRESH_INT_ENA]. A write
- * optionally sets or clears these fields. A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_int
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_int_s
-    {
-        uint64_t err_int               : 8;  /**< [  7:  0](R/W/H) Returns NPA_AURA_HW_S[ERR_INT] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[ERR_INT] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t err_int_ena           : 8;  /**< [ 15:  8](R/W/H) Returns NPA_AURA_HW_S[ERR_INT_ENA] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[ERR_INT_ENA] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t thresh_int            : 1;  /**< [ 16: 16](R/W/H) Returns NPA_AURA_HW_S[THRESH_INT] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[THRESH_INT] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t thresh_int_ena        : 1;  /**< [ 17: 17](R/W/H) Returns NPA_AURA_HW_S[THRESH_INT_ENA] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[THRESH_INT_ENA] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t reserved_18_41        : 24;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. See NPA_LF_AURA_OP_CNT[OP_ERR]. */
-        uint64_t setop                 : 1;  /**< [ 43: 43](WO) Set operation. Valid on a write. Indicates write-one-to-set when set,
-                                                                 write-one-to-clear otherwise. */
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_limit
- *
- * NPA LF Aura Allocation Limit Register
- * A 64-bit atomic load-and-add to this register returns a given aura's
- * limit. A write sets the aura's limit. A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_limit
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_limit_s
-    {
-        uint64_t limit                 : 36; /**< [ 35:  0](R/W/H) Value written to or read from NPA_AURA_HW_S[LIMIT]. */
-        uint64_t reserved_36_41        : 6;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. See NPA_LF_AURA_OP_CNT[OP_ERR]. */
-        uint64_t reserved_43           : 1;
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_aura_op_thresh
- *
- * NPA LF Aura Threshold Operation Register
- * A 64-bit atomic load-and-add to this register reads
- * NPA_AURA_HW_S[THRESH_UP,THRESH]. A write to the register writes
- * NPA_AURA_HW_S[THRESH_UP,THRESH] and recomputes NPA_AURA_HW_S[THRESH_INT].
- * A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_aura_op_thresh
-{
-    uint64_t u;
-    struct cavm_npa_lf_aura_op_thresh_s
-    {
-        uint64_t thresh                : 36; /**< [ 35:  0](R/W/H) Returns NPA_AURA_HW_S[THRESH] on an atomic load-and-add. Value written to
-                                                                 NPA_AURA_HW_S[THRESH] on a write. */
-        uint64_t reserved_36_41        : 6;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. See NPA_LF_AURA_OP_CNT[OP_ERR]. */
-        uint64_t thresh_up             : 1;  /**< [ 43: 43](R/W/H) Returns NPA_AURA_HW_S[THRESH_UP] on an atomic load-and-add. Value written
-                                                                 to NPA_AURA_HW_S[THRESH_UP] on a write. */
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_err_int
- *
- * NPA LF Error Interrupt Register
- */
-union cavm_npa_lf_err_int
-{
-    uint64_t u;
-    struct cavm_npa_lf_err_int_s
-   {
-        uint64_t aura_dis              : 1;  /**< [  0:  0](R/W1C/H) Aura disabled. Coprocessor allocate/return or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped due to disabled aura
-                                                                 (NPA_AURA_HW_S[ENA] is clear). */
-        uint64_t aura_oor              : 1;  /**< [  1:  1](R/W1C/H) Aura out of range. Coprocessor ALLOC or FREE or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped because the aura number
-                                                                 was outside of the range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET].
-
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Aura out of range. Coprocessor ALLOC or FREE or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped because the aura number
-                                                                 was outside of the local and remote ranges specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET,RMT_AURA_SIZE,RMT_AURA_OFFSET]. */
-        uint64_t reserved_2            : 1;
-        uint64_t rmt_req_oor           : 1;  /**< [  3:  3](R/W1C/H) Reserved.
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Remote request out of range. ALLOC or FREE from the remote node was dropped
-                                                                 because the aura number was outside of the local range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET]. */
-        uint64_t reserved_4_11         : 8;
-        uint64_t aura_fault            : 1;  /**< [ 12: 12](R/W1C/H) Memory fault on NPA_AURA_HW_S read or write, or on write to LF IOVA
-                                                                 specified by NPA_AURA_S[FC_ADDR]. */
-        uint64_t pool_fault            : 1;  /**< [ 13: 13](R/W1C/H) Memory fault on NPA_POOL_HW_S read or write, or on write to LF IOVA
-                                                                 specified by NPA_POOL_S[FC_ADDR]. */
-        uint64_t stack_fault           : 1;  /**< [ 14: 14](R/W1C/H) Memory fault on NPA_STACK_PAGE_S read or write. */
-        uint64_t qint_fault            : 1;  /**< [ 15: 15](R/W1C/H) Memory fault on NPA_QINT_HW_S read or write. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_err_int_ena_w1c
- *
- * NPA LF Error Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_lf_err_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_lf_err_int_ena_w1c_s
-    {
-        uint64_t aura_dis              : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[AURA_DIS]. */
-        uint64_t aura_oor              : 1;  /**< [  1:  1](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[AURA_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Aura out of range. Coprocessor ALLOC or FREE or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped because the aura number
-                                                                 was outside of the local and remote ranges specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET,RMT_AURA_SIZE,RMT_AURA_OFFSET]. */
-        uint64_t reserved_2            : 1;
-        uint64_t rmt_req_oor           : 1;  /**< [  3:  3](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[RMT_REQ_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Remote request out of range. ALLOC or FREE from the remote node was dropped
-                                                                 because the aura number was outside of the local range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET]. */
-        uint64_t reserved_4_11         : 8;
-        uint64_t aura_fault            : 1;  /**< [ 12: 12](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[AURA_FAULT]. */
-        uint64_t pool_fault            : 1;  /**< [ 13: 13](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[POOL_FAULT]. */
-        uint64_t stack_fault           : 1;  /**< [ 14: 14](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[STACK_FAULT]. */
-        uint64_t qint_fault            : 1;  /**< [ 15: 15](R/W1C/H) Reads or clears enable for NPA_LF_ERR_INT[QINT_FAULT]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_err_int_ena_w1s
- *
- * NPA LF Error Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_lf_err_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_err_int_ena_w1s_s
-    {
-        uint64_t aura_dis              : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[AURA_DIS]. */
-        uint64_t aura_oor              : 1;  /**< [  1:  1](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[AURA_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Aura out of range. Coprocessor ALLOC or FREE or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped because the aura number
-                                                                 was outside of the local and remote ranges specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET,RMT_AURA_SIZE,RMT_AURA_OFFSET]. */
-        uint64_t reserved_2            : 1;
-        uint64_t rmt_req_oor           : 1;  /**< [  3:  3](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[RMT_REQ_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Remote request out of range. ALLOC or FREE from the remote node was dropped
-                                                                 because the aura number was outside of the local range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET]. */
-        uint64_t reserved_4_11         : 8;
-        uint64_t aura_fault            : 1;  /**< [ 12: 12](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[AURA_FAULT]. */
-        uint64_t pool_fault            : 1;  /**< [ 13: 13](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[POOL_FAULT]. */
-        uint64_t stack_fault           : 1;  /**< [ 14: 14](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[STACK_FAULT]. */
-        uint64_t qint_fault            : 1;  /**< [ 15: 15](R/W1S/H) Reads or sets enable for NPA_LF_ERR_INT[QINT_FAULT]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_err_int_w1s
- *
- * NPA LF Error Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_lf_err_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_err_int_w1s_s
-    {
-        uint64_t aura_dis              : 1;  /**< [  0:  0](R/W1S/H) Reads or sets NPA_LF_ERR_INT[AURA_DIS]. */
-        uint64_t aura_oor              : 1;  /**< [  1:  1](R/W1S/H) Reads or sets NPA_LF_ERR_INT[AURA_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Aura out of range. Coprocessor ALLOC or FREE or
-                                                                 NPA_LF_AURA_OP_* /NPA_LF_POOL_OP_* access dropped because the aura number
-                                                                 was outside of the local and remote ranges specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET,RMT_AURA_SIZE,RMT_AURA_OFFSET]. */
-        uint64_t reserved_2            : 1;
-        uint64_t rmt_req_oor           : 1;  /**< [  3:  3](R/W1S/H) Reads or sets NPA_LF_ERR_INT[RMT_REQ_OOR].
-                                                                 Internal:
-                                                                 For dual-node support in future products:
-                                                                 Remote request out of range. ALLOC or FREE from the remote node was dropped
-                                                                 because the aura number was outside of the local range specified by
-                                                                 NPA_AF_LF()_AURAS_CFG[LOC_AURA_SIZE,LOC_AURA_OFFSET]. */
-        uint64_t reserved_4_11         : 8;
-        uint64_t aura_fault            : 1;  /**< [ 12: 12](R/W1S/H) Reads or sets NPA_LF_ERR_INT[AURA_FAULT]. */
-        uint64_t pool_fault            : 1;  /**< [ 13: 13](R/W1S/H) Reads or sets NPA_LF_ERR_INT[POOL_FAULT]. */
-        uint64_t stack_fault           : 1;  /**< [ 14: 14](R/W1S/H) Reads or sets NPA_LF_ERR_INT[STACK_FAULT]. */
-        uint64_t qint_fault            : 1;  /**< [ 15: 15](R/W1S/H) Reads or sets NPA_LF_ERR_INT[QINT_FAULT]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_available
- *
- * NPA LF Pool Available Count Operation Register
- * A 64-bit atomic load-and-add to this register returns a given pool's free
- * pointer count. Reads and writes are RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_available
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_available_s
-    {
-        uint64_t count                 : 36; /**< [ 35:  0](RO/H) Free pointer count. See NPA_POOL_S[STACK_PAGES]. */
-        uint64_t reserved_36_41        : 6;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. Includes all conditions listed in
-                                                                 NPA_LF_AURA_OP_CNT[OP_ERR] in addition to the following:
-                                                                 * Memory fault on NPA_POOL_HW_S read; also sets NPA_LF_ERR_INT[POOL_FAULT].
-                                                                 * Poisoned data returned on NPA_POOL_HW_S read; also sets
-                                                                 NPA_LF_RAS[POOL_POISON].
-                                                                 * Pool is disabled (NPA_POOL_HW_S[ENA] = 0); also sets
-                                                                 NPA_AURA_HW_S[ERR_INT]\<NPA_AURA_ERR_INT_E::POOL_DIS\>. */
-        uint64_t reserved_43           : 1;
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF that points to this pool. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_int
- *
- * NPA LF Pool Interrupt Operation Register
- * A 64-bit atomic load-and-add to this register reads
- * NPA_POOL_S[ERR_INT,ERR_INT_ENA,THRESH_INT,THRESH_INT_ENA]. A write optionally
- * sets or clears these fields. A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_int
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_int_s
-    {
-        uint64_t err_int               : 8;  /**< [  7:  0](R/W/H) Returns NPA_AURA_HW_S[ERR_INT] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[ERR_INT] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t err_int_ena           : 8;  /**< [ 15:  8](R/W/H) Returns NPA_AURA_HW_S[ERR_INT_ENA] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[ERR_INT_ENA] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t thresh_int            : 1;  /**< [ 16: 16](R/W/H) Returns NPA_AURA_HW_S[THRESH_INT] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[THRESH_INT] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t thresh_int_ena        : 1;  /**< [ 17: 17](R/W/H) Returns NPA_AURA_HW_S[THRESH_INT_ENA] on an atomic load-and-add. On a write,
-                                                                 write-one-to-set NPA_AURA_HW_S[THRESH_INT_ENA] if [SETOP] is set, write-one-to-clear
-                                                                 otherwise. */
-        uint64_t reserved_18_41        : 24;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. See NPA_LF_AURA_OP_CNT[OP_ERR]. */
-        uint64_t setop                 : 1;  /**< [ 43: 43](WO) Set operation. Valid on a write. Indicates write-one-to-set when set,
-                                                                 write-one-to-clear otherwise. */
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_pc
- *
- * NPA LF Pool Performance Count Register
- * A 64-bit atomic load-and-add to this register reads NPA_POOL_S[OP_PC] from a
- * given aura's pool. The aura is slected by the atomic write data, whose format
- * is NPA_AURA_OP_WDATA_S. Reads and writes are RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_pc
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_pc_s
-    {
-        uint64_t op_pc                 : 48; /**< [ 47:  0](RO/H) Pool performance counter. See NPA_POOL_S[OP_PC]. */
-        uint64_t op_err                : 1;  /**< [ 48: 48](RO/H) Operation error. See NPA_LF_POOL_OP_AVAILABLE[OP_ERR]. */
-        uint64_t reserved_49_63        : 15;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_end0
- *
- * NPA LF Pool Pointer End Operation Register 0
- * A 128-bit write to the NPA_LF_POOL_OP_PTR_END0 and NPA_LF_POOL_OP_PTR_END1
- * registers writes to a given pool's pointer end value.
- * All other accesses to these registers (e.g. reads and 64-bit writes) are
- * RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_ptr_end0
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_ptr_end0_s
-    {
-        uint64_t ptr_end               : 64; /**< [ 63:  0](WO) Value written to NPA_POOL_S[PTR_END]. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_end1
- *
- * NPA LF Pool Pointer End Operation Register 1
- * See NPA_LF_POOL_OP_PTR_END0.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_ptr_end1
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_ptr_end1_s
-    {
-        uint64_t aura                  : 20; /**< [ 19:  0](WO) Aura within VF that points to this pool. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_start0
- *
- * NPA LF Pool Pointer Start Operation Register 0
- * A 128-bit write to the NPA_LF_POOL_OP_PTR_START0 and NPA_LF_POOL_OP_PTR_START1
- * registers writes to a given pool's pointer start value.
- * All other accesses to these registers (e.g. reads and 64-bit writes) are
- * RAZ/WI.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_ptr_start0
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_ptr_start0_s
-    {
-        uint64_t ptr_start             : 64; /**< [ 63:  0](WO) Value written to NPA_POOL_S[PTR_START]. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_ptr_start1
- *
- * NPA LF Pool Pointer Start Operation Register 1
- * See NPA_LF_POOL_OP_PTR_START0.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_ptr_start1
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_ptr_start1_s
-    {
-        uint64_t aura                  : 20; /**< [ 19:  0](WO) Aura within VF that points to this pool. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_pool_op_thresh
- *
- * NPA LF Pool Threshold Operation Register
- * A 64-bit atomic load-and-add to this register reads
- * NPA_POOL_S[THRESH_UP,THRESH]. A write to the register writes
- * NPA_POOL_S[THRESH_UP,THRESH]. A read is RAZ.
- *
- * RSL accesses to this register are RAZ/WI.
- */
-union cavm_npa_lf_pool_op_thresh
-{
-    uint64_t u;
-    struct cavm_npa_lf_pool_op_thresh_s
-    {
-        uint64_t thresh                : 36; /**< [ 35:  0](R/W/H) Returns NPA_AURA_HW_S[THRESH] on an atomic load-and-add. Value written to
-                                                                 NPA_AURA_HW_S[THRESH] on a write. */
-        uint64_t reserved_36_41        : 6;
-        uint64_t op_err                : 1;  /**< [ 42: 42](RO/H) Operation error. See NPA_LF_AURA_OP_CNT[OP_ERR]. */
-        uint64_t thresh_up             : 1;  /**< [ 43: 43](R/W/H) Returns NPA_AURA_HW_S[THRESH_UP] on an atomic load-and-add. Value written
-                                                                 to NPA_AURA_HW_S[THRESH_UP] on a write. */
-        uint64_t aura                  : 20; /**< [ 63: 44](WO) Aura within VF. This field is present on a write, or in the write data of
-                                                                 an atomic load-and-add. */
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_qint#_cnt
- *
- * NPA LF Queue Interrupt Count Registers
- */
-union cavm_npa_lf_qintx_cnt
-{
-    uint64_t u;
-    struct cavm_npa_lf_qintx_cnt_s
-    {
-        uint64_t count                 : 22; /**< [ 21:  0](R/W/H) Interrupt count. Value in NPA_QINT_HW_S[COUNT]. Number of pending
-                                                                 interrupts to this QINT from NPA_AURA_S and NPA_POOL_S contexts in the VF.
-                                                                 Hardware increments the counter when an interrupt is set and decrements it
-                                                                 when an interrupt is cleared. NPA_LF_QINT()_INT[INTR] interrupt is set when
-                                                                 the count is nonzero.
-
-                                                                 Writes to this field are for diagnostic use only. The write data is a two's
-                                                                 complement signed value added to the count. */
-        uint64_t reserved_22_63        : 42;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_qint#_ena_w1c
- *
- * NPA LF Queue Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_npa_lf_qintx_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_lf_qintx_ena_w1c_s
-    {
-        uint64_t intr                  : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for NPA_LF_QINT(0..63)_INT[INTR]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_qint#_ena_w1s
- *
- * NPA LF Queue Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_npa_lf_qintx_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_qintx_ena_w1s_s
-    {
-        uint64_t intr                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for NPA_LF_QINT(0..63)_INT[INTR]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_qint#_int
- *
- * NPA LF Queue Interrupt Registers
- */
-union cavm_npa_lf_qintx_int
-{
-    uint64_t u;
-    struct cavm_npa_lf_qintx_int_s
-    {
-        uint64_t intr                  : 1;  /**< [  0:  0](RO/H) Interrupt pending. Set when NPA_LF_QINT()_CNT[COUNT] is nonzero. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_qint#_int_w1s
- *
- * INTERNAL: NPA LF Queue Interrupt Set Registers
- */
-union cavm_npa_lf_qintx_int_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_qintx_int_w1s_s
-    {
-        uint64_t intr                  : 1;  /**< [  0:  0](RO/H) Interrupt pending. Set when NPA_LF_QINT()_CNT[COUNT] is nonzero. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_ras
- *
- * NPA LF RAS Interrupt Register
- */
-union cavm_npa_lf_ras
-{
-    uint64_t u;
-    struct cavm_npa_lf_ras_s
-    {
-        uint64_t aura_poison           : 1;  /**< [  0:  0](R/W1C/H) Poisoned data returned on NPA_AURA_HW_S read. */
-        uint64_t pool_poison           : 1;  /**< [  1:  1](R/W1C/H) Poisoned data returned on NPA_POOL_HW_S read. */
-        uint64_t stack_poison          : 1;  /**< [  2:  2](R/W1C/H) Poisoned data returned on NPA_STACK_PAGE_S read. */
-        uint64_t qint_poison           : 1;  /**< [  3:  3](R/W1C/H) Poisoned data returned on NPA_QINT_HW_S read. */
-        uint64_t reserved_4_63         : 60;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_ras_ena_w1c
- *
- * NPA LF RAS Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_npa_lf_ras_ena_w1c
-{
-    uint64_t u;
-    struct cavm_npa_lf_ras_ena_w1c_s
-    {
-        uint64_t aura_poison           : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for NPA_LF_RAS[AURA_POISON]. */
-        uint64_t pool_poison           : 1;  /**< [  1:  1](R/W1C/H) Reads or clears enable for NPA_LF_RAS[POOL_POISON]. */
-        uint64_t stack_poison          : 1;  /**< [  2:  2](R/W1C/H) Reads or clears enable for NPA_LF_RAS[STACK_POISON]. */
-        uint64_t qint_poison           : 1;  /**< [  3:  3](R/W1C/H) Reads or clears enable for NPA_LF_RAS[QINT_POISON]. */
-        uint64_t reserved_4_63         : 60;
-    } s;
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_ras_ena_w1s
- *
- * NPA LF RAS Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_npa_lf_ras_ena_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_ras_ena_w1s_s
-    {
-        uint64_t aura_poison           : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for NPA_LF_RAS[AURA_POISON]. */
-        uint64_t pool_poison           : 1;  /**< [  1:  1](R/W1S/H) Reads or sets enable for NPA_LF_RAS[POOL_POISON]. */
-        uint64_t stack_poison          : 1;  /**< [  2:  2](R/W1S/H) Reads or sets enable for NPA_LF_RAS[STACK_POISON]. */
-        uint64_t qint_poison           : 1;  /**< [  3:  3](R/W1S/H) Reads or sets enable for NPA_LF_RAS[QINT_POISON]. */
-        uint64_t reserved_4_63         : 60;
-    } s;
-    /* struct cavm_npa_lf_ras_ena_w1s_s cn; */
-};
-
-/**
- * Register (RVU_PFVF_BAR2) npa_lf_ras_w1s
- *
- * NPA LF RAS Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_npa_lf_ras_w1s
-{
-    uint64_t u;
-    struct cavm_npa_lf_ras_w1s_s
-    {
-        uint64_t aura_poison           : 1;  /**< [  0:  0](R/W1S/H) Reads or sets NPA_LF_RAS[AURA_POISON]. */
-        uint64_t pool_poison           : 1;  /**< [  1:  1](R/W1S/H) Reads or sets NPA_LF_RAS[POOL_POISON]. */
-        uint64_t stack_poison          : 1;  /**< [  2:  2](R/W1S/H) Reads or sets NPA_LF_RAS[STACK_POISON]. */
-        uint64_t qint_poison           : 1;  /**< [  3:  3](R/W1S/H) Reads or sets NPA_LF_RAS[QINT_POISON]. */
-        uint64_t reserved_4_63         : 60;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_priv_af_int_cfg
- *
- * NPA Privileged AF Interrupt Configuration Register
- */
-union cavm_npa_priv_af_int_cfg
-{
-    uint64_t u;
-    struct cavm_npa_priv_af_int_cfg_s
-    {
-        uint64_t msix_offset           : 11; /**< [ 10:  0](R/W) MSI-X offset. Offset of AF interrupt vectors enumerated by
-                                                                 NPA_AF_INT_VEC_E in RVU PF(0)'s MSI-X table. This offset is added to each
-                                                                 enumerated value to obtain the corresponding MSI-X vector index. The
-                                                                 highest enumerated value plus [MSIX_OFFSET] must be less than or equal to
-                                                                 RVU_PRIV_PF(0)_MSIX_CFG[PF_MSIXT_SIZEM1]. */
-        uint64_t reserved_11           : 1;
-        uint64_t msix_size             : 8;  /**< [ 19: 12](RO) Number of interrupt vectors enumerated by NPA_AF_INT_VEC_E. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_priv_lf#_cfg
- *
- * NPA Privileged Local Function Configuration Registers
- * These registers allow each NPA local function (LF) to be provisioned to a VF/PF
- * slot for RVU. See also NPA_AF_RVU_LF_CFG_DEBUG.
- *
- * Software should read this register after write to ensure that the LF is mapped to
- * [PF_FUNC] before issuing transactions to the mapped PF and function.
- *
- * [SLOT] must be zero.
- *
- * Internal:
- * Hardware ignores [SLOT] and always assumes 0x0.
- */
-union cavm_npa_priv_lfx_cfg
-{
-    uint64_t u;
-    struct cavm_npa_priv_lfx_cfg_s
-    {
-        uint64_t slot                  : 8;  /**< [  7:  0](R/W) Slot within the VF/PF selected by [PF_FUNC] to which the LF is
-                                                                 provisioned. */
-        uint64_t pf_func               : 16; /**< [ 23:  8](R/W) RVU VF/PF to which the LF is provisioned. Format defined by RVU_PF_FUNC_S.
-                                                                 Interrupts from the LF are delivered to the selected PF/VF. */
-        uint64_t reserved_24_62        : 39;
-        uint64_t ena                   : 1;  /**< [ 63: 63](R/W) Enable. When set, the LF is enabled and provisioned to the VF/PF slot
-                                                                 selected by [PF_FUNC] and [SLOT]. When clear, the LF is not provisioned.
-
-                                                                 LF to slot mapping must be 1-to-1. Thus, each enabled LF must be provisioned
-                                                                 to a unique {[PF_FUNC], [SLOT]} combination. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) npa_priv_lf#_int_cfg
- *
- * NPA Privileged LF Interrupt Configuration Registers
- */
-union cavm_npa_priv_lfx_int_cfg
-{
-    uint64_t u;
-    struct cavm_npa_priv_lfx_int_cfg_s
-    {
-        uint64_t msix_offset           : 11; /**< [ 10:  0](R/W) MSI-X offset. Offset of LF interrupt vectors enumerated by the block's
-                                                                 NPA_LF_INT_VEC_E in the MSI-X table of the corresponding RVU VF/PF (see
-                                                                 NPA_PRIV_LF()_CFG[PF_FUNC]). This offset is added to each enumerated value
-                                                                 to obtain the corresponding MSI-X vector index. The highest enumerated
-                                                                 value plus [MSIX_OFFSET] must be less than or equal to
-                                                                 RVU_PRIV_PF()_MSIX_CFG[PF_MSIXT_SIZEM1,VF_MSIXT_SIZEM1]. */
-        uint64_t reserved_11           : 1;
-        uint64_t msix_size             : 8;  /**< [ 19: 12](RO) Number of interrupt vectors enumerated by NPA_LF_INT_VEC_E. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-    /* struct cavm_npa_priv_lfx_int_cfg_s cn; */
-
-#endif /* __NPA_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/npc.c b/drivers/net/cavium/octeontx2/npc.c
index 97dcd5f8da..1fa5ae4ee3 100644
--- a/drivers/net/cavium/octeontx2/npc.c
+++ b/drivers/net/cavium/octeontx2/npc.c
@@ -30,7 +30,7 @@
 
 #define RSVD_MCAM_ENTRIES_PER_PF	2 /** Ucast & Bcast */
 #define RSVD_MCAM_ENTRIES_PER_NIXLF	1 /** Ucast for VFs */
-
+#if 0
 static u64 npc_af_reg_read(struct npc_af *npc, u64 offset)
 {
 	return readq(npc->npc_af_base + offset);
@@ -40,7 +40,7 @@ static void npc_af_reg_write(struct npc_af *npc, u64 offset, u64 val)
 {
 	writeq(va, npc->npc_af_base + offset);
 }
-
+#endif
 static inline u64 enable_mask(int count)
 {
 	return ((count < 64) ? ~(BIT_ULL(count) - 1) : (0x00ULL));
diff --git a/drivers/net/cavium/octeontx2/npc_hw.h b/drivers/net/cavium/octeontx2/npc_hw.h
deleted file mode 100644
index b4c149d7e7..0000000000
--- a/drivers/net/cavium/octeontx2/npc_hw.h
+++ /dev/null
@@ -1,331 +0,0 @@
-/* This file is auto-generated. Do not edit */
-
-/***********************license start***************
- * Copyright (c) 2003-2018  Cavium Inc. (support@cavium.com). All rights
- * reserved.
- *
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *
- *   * Redistributions in binary form must reproduce the above
- *     copyright notice, this list of conditions and the following
- *     disclaimer in the documentation and/or other materials provided
- *     with the distribution.
-
- *   * Neither the name of Cavium Inc. nor the names of
- *     its contributors may be used to endorse or promote products
- *     derived from this software without specific prior written
- *     permission.
-
- * This Software, including technical data, may be subject to U.S. export
- * control laws, including the U.S. Export Administration Act and its
- * associated regulations, and may be subject to export or import regulations
- * in other countries.
-
- * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
- * AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
- * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
- * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
- * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
- * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
- * OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
- * PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT,
- * QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING
- * OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
- ***********************license end**************************************/
-
-#ifndef __NPC_HW_H__
-#define __NPC_HW_H__
-
-/* Register offsets */
-
-#define CAVM_NPC_AF_CFG                                   (0x0ull)
-#define CAVM_NPC_AF_ACTIVE_PC                             (0x10ull)
-#define CAVM_NPC_AF_CONST                                 (0x20ull)
-#define CAVM_NPC_AF_CONST1                                (0x30ull)
-#define CAVM_NPC_AF_BLK_RST                               (0x40ull)
-#define CAVM_NPC_AF_MCAM_SCRUB_CTL                        (0xa0ull)
-#define CAVM_NPC_AF_KCAM_SCRUB_CTL                        (0xb0ull)
-#define CAVM_NPC_AF_KPUX_CFG(a)                           \
-	(0x500ull | (u64)(a) << 3)
-#define CAVM_NPC_AF_PCK_CFG                               (0x600ull)
-#define CAVM_NPC_AF_PCK_DEF_OL2                           (0x610ull)
-#define CAVM_NPC_AF_PCK_DEF_OIP4                          (0x620ull)
-#define CAVM_NPC_AF_PCK_DEF_OIP6                          (0x630ull)
-#define CAVM_NPC_AF_PCK_DEF_IIP4                          (0x640ull)
-#define CAVM_NPC_AF_KEX_LDATAX_FLAGS_CFG(a)               \
-	(0x800ull | (u64)(a) << 3)
-#define CAVM_NPC_AF_INTFX_KEX_CFG(a)                      \
-	(0x1010ull | (u64)(a) << 8)
-#define CAVM_NPC_AF_PKINDX_ACTION0(a)                     \
-	(0x80000ull | (u64)(a) << 6)
-#define CAVM_NPC_AF_PKINDX_ACTION1(a)                     \
-	(0x80008ull | (u64)(a) << 6)
-#define CAVM_NPC_AF_PKINDX_CPI_DEFX(a, b)                 \
-	(0x80020ull | (u64)(a) << 6 | (u64)(b) << 3)
-#define CAVM_NPC_AF_KPUX_ENTRYX_CAMX(a, b, c)             \
-	(0x100000ull | (u64)(a) << 14 | (u64)(b) << 6 | (u64)(c) << 3)
-#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION0(a, b)             \
-	(0x100020ull | (u64)(a) << 14 | (u64)(b) << 6)
-#define CAVM_NPC_AF_KPUX_ENTRYX_ACTION1(a, b)             \
-	(0x100028ull | (u64)(a) << 14 | (u64)(b) << 6)
-#define CAVM_NPC_AF_KPUX_ENTRY_DISX(a, b)                 \
-	(0x180000ull | (u64)(a) << 6 | (u64)(b) << 3)
-#define CAVM_NPC_AF_CPIX_CFG(a)                           \
-	(0x200000ull | (u64)(a) << 3)
-#define CAVM_NPC_AF_INTFX_LIDX_LTX_LDX_CFG(a, b, c, d)    \
-	(0x900000ull | (u64)(a) << 16 | (u64)(b) << 12 | (u64)(c) << 5 | \
-	(u64)(d) << 3)
-#define CAVM_NPC_AF_INTFX_LDATAX_FLAGSX_CFG(a, b, c)      \
-	(0x980000ull | (u64)(a) << 16 | (u64)(b) << 12 | (u64)(c) << 3)
-#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_INTF(a, b, c)       \
-	(0x1000000ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
-#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W0(a, b, c)         \
-	(0x1000010ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
-#define CAVM_NPC_AF_MCAMEX_BANKX_CAMX_W1(a, b, c)         \
-	(0x1000020ull | (u64)(a) << 10 | (u64)(b) << 6 | (u64)(c) << 3)
-#define CAVM_NPC_AF_MCAMEX_BANKX_CFG(a, b)                \
-	(0x1800000ull | (u64)(a) << 8 | (u64)(b) << 4)
-#define CAVM_NPC_AF_MCAMEX_BANKX_STAT_ACT(a, b)           \
-	(0x1880000ull | (u64)(a) << 8 | (u64)(b) << 4)
-#define CAVM_NPC_AF_MATCH_STATX(a)                        \
-	(0x1880008ull | (u64)(a) << 8)
-#define CAVM_NPC_AF_INTFX_MISS_STAT_ACT(a)                \
-	(0x1880040ull + (u64)(a) * 0x8)
-#define CAVM_NPC_AF_MCAMEX_BANKX_ACTION(a, b)             \
-	(0x1900000ull | (u64)(a) << 8 | (u64)(b) << 4)
-#define CAVM_NPC_AF_MCAMEX_BANKX_TAG_ACT(a, b)            \
-	(0x1900008ull | (u64)(a) << 8 | (u64)(b) << 4)
-#define CAVM_NPC_AF_INTFX_MISS_ACT(a)                     \
-	(0x1a00000ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_INTFX_MISS_TAG_ACT(a)                 \
-	(0x1b00008ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_MCAM_BANKX_HITX(a, b)                 \
-	(0x1c80000ull | (u64)(a) << 8 | (u64)(b) << 4)
-#define CAVM_NPC_AF_LKUP_CTL                              (0x2000000ull)
-#define CAVM_NPC_AF_LKUP_DATAX(a)                         \
-	(0x2000200ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_LKUP_RESULTX(a)                       \
-	(0x2000400ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_INTFX_STAT(a)                         \
-	(0x2000800ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_DBG_CTL                               (0x3000000ull)
-#define CAVM_NPC_AF_DBG_STATUS                            (0x3000010ull)
-#define CAVM_NPC_AF_KPUX_DBG(a)                           \
-	(0x3000020ull | (u64)(a) << 8)
-#define CAVM_NPC_AF_IKPU_ERR_CTL                          (0x3000080ull)
-#define CAVM_NPC_AF_KPUX_ERR_CTL(a)                       \
-	(0x30000a0ull | (u64)(a) << 8)
-#define CAVM_NPC_AF_MCAM_DBG                              (0x3001000ull)
-#define CAVM_NPC_AF_DBG_DATAX(a)                          \
-	(0x3001400ull | (u64)(a) << 4)
-#define CAVM_NPC_AF_DBG_RESULTX(a)                        \
-	(0x3001800ull | (u64)(a) << 4)
-
-
-/* Enum offsets */
-
-#define CAVM_NPC_INTF_NIX0_RX    (0x0ull)
-#define CAVM_NPC_INTF_NIX0_TX    (0x1ull)
-
-#define CAVM_NPC_ERRLEV_RE       (0x0ull)
-#define CAVM_NPC_ERRLEV_LA       (0x1ull)
-#define CAVM_NPC_ERRLEV_LB       (0x2ull)
-#define CAVM_NPC_ERRLEV_LC       (0x3ull)
-#define CAVM_NPC_ERRLEV_LD       (0x4ull)
-#define CAVM_NPC_ERRLEV_LE       (0x5ull)
-#define CAVM_NPC_ERRLEV_LF       (0x6ull)
-#define CAVM_NPC_ERRLEV_LG       (0x7ull)
-#define CAVM_NPC_ERRLEV_LH       (0x8ull)
-#define CAVM_NPC_ERRLEV_NIX      (0xfull)
-#define CAVM_NPC_ERRLEV_R9       (0x9ull)
-#define CAVM_NPC_ERRLEV_R10      (0xaull)
-#define CAVM_NPC_ERRLEV_R11      (0xbull)
-#define CAVM_NPC_ERRLEV_R12      (0xcull)
-#define CAVM_NPC_ERRLEV_R13      (0xdull)
-#define CAVM_NPC_ERRLEV_R14      (0xeull)
-
-#define CAVM_NPC_LKUPOP_PKT      (0x0ull)
-#define CAVM_NPC_LKUPOP_KEY      (0x1ull)
-
-#define CAVM_NPC_LID_LA          (0x0ull)
-#define CAVM_NPC_LID_LB          (0x1ull)
-#define CAVM_NPC_LID_LC          (0x2ull)
-#define CAVM_NPC_LID_LD          (0x3ull)
-#define CAVM_NPC_LID_LE          (0x4ull)
-#define CAVM_NPC_LID_LF          (0x5ull)
-#define CAVM_NPC_LID_LG          (0x6ull)
-#define CAVM_NPC_LID_LH          (0x7ull)
-
-#define CAVM_NPC_MCAMKEYW_X1     (0x0ull)
-#define CAVM_NPC_MCAMKEYW_X2     (0x1ull)
-#define CAVM_NPC_MCAMKEYW_X4     (0x2ull)
-
-
-/* Structures definitions */
-
-/**
- * NPC Layer Parse Information Structure
- * This structure specifies the format of NPC_RESULT_S[LA,LB,...,LH].
- */
-union cavm_npc_layer_info_s {
-	u32 u;
-	struct npc_layer_info_s_s {
-	
-		u32 lptr:       8;
-		u32 flags:      8;
-		u32 ltype:      4;
-		u32 rsvd_31_20: 12;
-	} s;
-};
-
-/**
- * NPC Layer MCAM Search Key Extract Structure
- * This structure specifies the format of each of the
- * NPC_PARSE_KEX_S[LA,LB,...,LH] fields. It contains the subset of
- * NPC_LAYER_INFO_S fields that can be included in the MCAM search key. See
- * NPC_PARSE_KEX_S and NPC_AF_INTF()_KEX_CFG.
- */
-union cavm_npc_layer_kex_s {
-	u16 u;
-	struct npc_layer_kex_s_s {
-	
-		u16 flags:      8;
-		u16 ltype:      4;
-		u16 rsvd_15_12: 4;
-	} s;
-};
-
-/**
- * NPC MCAM Search Key X1 Structure
- * This structure specifies the MCAM search key format used by an interface
- * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X1.
- */
-union cavm_npc_mcam_key_x1_s {
-	u64 u[3];
-	struct npc_mcam_key_x1_s_s {
-		/* Word 0 */
-		u64 intf:               2;
-		u64 rsvd_63_2:          62;
-		u64 kw0;               	/* Word 1 */
-		/* Word 2 */
-		u64 kw1:                48;
-		u64 rsvd_191_176:       16;
-	} s;
-};
-
-/**
- * NPC MCAM Search Key X2 Structure
- * This structure specifies the MCAM search key format used by an interface
- * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X2.
- */
-union cavm_npc_mcam_key_x2_s {
-	u64 u[5];
-	struct npc_mcam_key_x2_s_s {
-		/* Word 0 */
-		u64 intf:               2;
-		u64 rsvd_63_2:          62;
-		u64 kw0;               	/* Word 1 */
-		u64 kw1;               	/* Word 2 */
-		u64 kw2;               	/* Word 3 */
-		/* Word 4 */
-		u64 kw3:                32;
-		u64 rsvd_319_288:       32;
-	} s;
-};
-
-/**
- * NPC MCAM Search Key X4 Structure
- * This structure specifies the MCAM search key format used by an interface
- * when NPC_AF_INTF()_KEX_CFG[KEYW] = NPC_MCAMKEYW_E::X4.
- */
-union cavm_npc_mcam_key_x4_s {
-	u64 u[8];
-	struct npc_mcam_key_x4_s_s {
-		/* Word 0 */
-		u64 intf:       2;
-		u64 rsvd_63_2:  62;
-		u64 kw0;               	/* Word 1 */
-		u64 kw1;               	/* Word 2 */
-		u64 kw2;               	/* Word 3 */
-		u64 kw3;               	/* Word 4 */
-		u64 kw4;               	/* Word 5 */
-		u64 kw5;               	/* Word 6 */
-		u64 kw6;               	/* Word 7 */
-	} s;
-};
-
-/**
- * NPC Parse Key Extract Structure
- * This structure contains the subset of NPC_RESULT_S fields that can be
- * included in the MCAM search key. See NPC_AF_INTF()_KEX_CFG.
- */
-union cavm_npc_parse_kex_s {
-	u64 u[2];
-	struct npc_parse_kex_s_s {
-		/* Word 0 */
-		u64 chan:               12;
-		u64 errlev:             4;
-		u64 errcode:            8;
-		u64 l2m:                1;
-		u64 l2b:                1;
-		u64 l3m:                1;
-		u64 l3b:                1;
-		u64 la:                 12;
-		u64 lb:                 12;
-		u64 lc:                 12;
-		/* Word 1 */
-		u64 ld:                 12;
-		u64 le:                 12;
-		u64 lf:                 12;
-		u64 lg:                 12;
-		u64 lh:                 12;
-		u64 rsvd_127_124:       4;
-	} s;
-};
-
-/**
- * NPC Result Structure
- * This structure contains a packet's parse and flow identification
- * information.
- */
-union cavm_npc_result_s {
-	u64 u[6];
-	struct npc_result_s_s {
-		/* Word 0 */
-		u64 intf:               2;
-		u64 pkind:              6;
-		u64 chan:               12;
-		u64 errlev:             4;
-		u64 errcode:            8;
-		u64 l2m:                1;
-		u64 l2b:                1;
-		u64 l3m:                1;
-		u64 l3b:                1;
-		u64 eoh_ptr:            8;
-		u64 rsvd_63_44:         20;
-		u64 action;            	/* Word 1 */
-		u64 vtag_action;       	/* Word 2 */
-		/* Word 3 */
-		u64 la:                 20;
-		u64 lb:                 20;
-		u64 lc:                 20;
-		u64 rsvd_255_252:       4;
-		/* Word 4 */
-		u64 ld:                 20;
-		u64 le:                 20;
-		u64 lf:                 20;
-		u64 rsvd_319_316:       4;
-		/* Word 5 */
-		u64 lg:                 20;
-		u64 lh:                 20;
-		u64 rsvd_383_360:       24;
-	} s;
-};
-
-#endif /* __NPC_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/rvu.h b/drivers/net/cavium/octeontx2/rvu.h
index 4958d11e6f..1c848635af 100644
--- a/drivers/net/cavium/octeontx2/rvu.h
+++ b/drivers/net/cavium/octeontx2/rvu.h
@@ -11,48 +11,124 @@
 #ifndef __RVU_H__
 #define __RVU_H__
 
-/*#include "rvu_hw.h"*/
+#include "cavm-csrs-rvu.h"
 
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_PF	0xA063
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_VF	0xA064
-#define PCI_DEVICE_ID_OCTEONTX2_RVU_AF	0xA065
+#define ALIGNED		__aligned(CONFIG_SYS_CACHELINE_SIZE)
 
-struct nix_af_handle;
+/* PCI device IDs */
+#define	PCI_DEVID_OCTEONTX2_CGX			0xA059
+#define	PCI_DEVID_OCTEONTX2_RVU_AF		0xA065
+#define	PCI_DEVID_OCTEONTX2_RVU_PF		0xA063
+#define	PCI_DEVID_OCTEONTX2_RVU_VF		0xA064
+
+#define Q_SIZE_16		0ULL /* 16 entries */
+#define Q_SIZE_64		1ULL /* 64 entries */
+#define Q_SIZE_256		2ULL
+#define Q_SIZE_1K		3ULL
+#define Q_SIZE_4K		4ULL
+#define Q_SIZE_16K		5ULL
+#define Q_SIZE_64K		6ULL
+#define Q_SIZE_256K		7ULL
+#define Q_SIZE_1M		8ULL /* Million entries */
+#define Q_SIZE_MIN		Q_SIZE_16
+#define Q_SIZE_MAX		Q_SIZE_1M
+
+#define Q_COUNT(x)		(16ULL << (2 * x))
+#define Q_SIZE(x, n)		((ilog2(x) - (n)) / 2)
+
+/* Admin queue info */
+
+/* Since we intend to add only one instruction at a time,
+ * keep queue size to it's minimum.
+ */
+#define AQ_SIZE			Q_SIZE_16
+/* HW head & tail pointer mask */
+#define AQ_PTR_MASK		0xFFFFF
+
+struct qmem {
+	void		*base;
+	dma_addr_t	iova;
+	size_t		alloc_sz;
+	u32		qsize;
+	u8		entry_sz;
+};
+
+struct admin_queue {
+	struct qmem inst;
+	struct qmem res;
+};
 
 struct rvu_af {
 	struct udevice *dev;
-	u8 pf_id;
-	void __iomem *base;
-	void __iomem *bar2;
-	void __iomem *nix_af_base;
-	void __iomem *nix_af_bar2;
-	void __iomem *npa_af_base;
-	void __iomem *npc_af_base;
-	struct rvu_hwinfo *hw;
-	struct nix_af_handle *nix_af;
+	void __iomem *af_base;
+	struct nix_af *nix_af;
 };
 
 struct rvu_pf {
 	struct udevice *dev;
-	void __iomem *base;
-	void __iomem *nix_base;
-	void __iomem *npa_base;
-	void __iomem *npc_base;
-	void __iomem *lmt_base;
-	struct rvu_hwinfo *hw;
-	struct nix_handle *nix;
-	u8 pf_id;
-	u8 pf;
+	struct udevice *afdev;
+	void __iomem *pf_base;
+	struct nix *nix;
+	u8 pfid;
+	int nix_lfid;
+	int npa_lfid;
 };
 
 /**
- * Given the PF base address, return the NIX AF
+ * Store 128 bit value
  *
- * @param nix_pf_base		NIX PF base address
+ * @param[out]	dest	pointer to destination address
+ * @param	val0	first 64 bits to write
+ * @param	val1	second 64 bits to write
+ */
+static inline void cavm_st128(void *dest, u64 val0, u64 val1)
+{
+	__asm__ __volatile__(
+		"stp %x[x0], %x[x1], [%[pm]]"
+		:
+		: [x0]"r"(val0), [x1]"r"(val1), [pm]"r"(dest)
+		: "memory");
+}
+
+/**
+ * Load 128 bit value
  *
- * @return	nix_af handle or NULL if not found.
+ * @param[in]	source		pointer to 128 bits of data to load
+ * @param[out]	val0		first 64 bits of data
+ * @param[out]	val1		second 64 bits of data
  */
-struct nix_af_handle *nix_get_af(u64 nix_pf_base);
+static inline void cavm_ld128(const u64 *src, u64 *val0, u64 *val1)
+{
+	__asm__ __volatile__ (
+		"ldp %x[x0], %x[x1], [%[pm]]"
+		:
+		: [x0]"r"(*val0), [x1]"r"(*val1), [pm]"r"(src));
+}
+
+void qmem_free(struct qmem *q);
+int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz);
+
+/**
+ * Allocates an admin queue for instructions and results
+ *
+ * @param	aq	admin queue to allocate for
+ * @param	qsize	Number of entries in the queue
+ * @param	inst_size	Size of each instruction
+ * @param	res_size	Size of each result
+ *
+ * @return	-ENOMEM on error, 0 on success
+ */
+int rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
+		      size_t inst_size, size_t res_size);
+
+/**
+ * Frees an admin queue
+ *
+ * @param	aq	Admin queue to free
+ */
+void rvu_aq_free(struct admin_queue *aq);
+
+void rvu_get_lfid_for_pf(int pf, int *nixid, int *npaid);
 
 #endif /* __RVU_H__ */
 
diff --git a/drivers/net/cavium/octeontx2/rvu_af.c b/drivers/net/cavium/octeontx2/rvu_af.c
index b0a82f0f90..0037f5a71e 100644
--- a/drivers/net/cavium/octeontx2/rvu_af.c
+++ b/drivers/net/cavium/octeontx2/rvu_af.c
@@ -7,10 +7,8 @@
  * the License, or (at your option) any later version.
  *
  */
-#define DEBUG
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -18,119 +16,145 @@
 #include <linux/list.h>
 #include <asm/io.h>
 #include <asm/arch/octeontx2.h>
-#include "cavm-csrs-rvu.h"
-#include "rvu.h"
-#include "rvu_common.h"
+#include "cavm-csrs-npa.h"
 #include "nix.h"
 
-static LIST_HEAD(nix_af_list);
+struct udevice *rvu_af_dev=NULL;
 
-/**
- * Given the PF base address, return the NIX AF
- *
- * @param nix_pf_base		NIX PF base address
- *
- * @return	nix_af handle or NULL if not found.
- */
-struct nix_af_handle *nix_get_af(u64 nix_pf_base)
+inline struct rvu_af *get_af(void)
 {
-	struct nix_af_handle *nix_af;
-	static const u64 mask = ~(0xffffffffff);
-	nix_pf_base &= mask;
+	return rvu_af_dev ? dev_get_priv(rvu_af_dev) : NULL;
+}
+
+void rvu_get_lfid_for_pf(int pf, int *nixid, int *npaid)
+{
+	union cavm_nixx_af_rvu_lf_cfg_debug nix_lf_dbg;
+	union cavm_npa_af_rvu_lf_cfg_debug npa_lf_dbg;
+	union cavm_rvu_pf_func_s pf_func;
+	struct rvu_af *af = dev_get_priv(rvu_af_dev);
+	struct nix_af *nix_af = af->nix_af;
+
+	pf_func.u = 0;
+	pf_func.s.pf = pf;
+
+	nix_lf_dbg.u = 0;
+	nix_lf_dbg.s.pf_func = pf_func.u & 0xFFFF;
+	nix_lf_dbg.s.exec = 1;
+	nix_af_reg_write(nix_af, CAVM_NIXX_AF_RVU_LF_CFG_DEBUG(),
+			 nix_lf_dbg.u);
+	do {
+		nix_lf_dbg.u = nix_af_reg_read(nix_af,
+				CAVM_NIXX_AF_RVU_LF_CFG_DEBUG());
+	} while (nix_lf_dbg.s.exec);
+
+	if (nix_lf_dbg.s.lf_valid)
+		*nixid = nix_lf_dbg.s.lf; 
+
+	debug("%s: nix lf_valid %d lf %d nixid %d\n", __func__,
+		nix_lf_dbg.s.lf_valid,nix_lf_dbg.s.lf,*nixid);
+
+	npa_lf_dbg.u = 0;
+	npa_lf_dbg.s.pf_func = pf_func.u & 0xFFFF;
+	npa_lf_dbg.s.exec = 1;
+	npa_af_reg_write(nix_af->npa_af, CAVM_NPA_AF_RVU_LF_CFG_DEBUG(),
+			 npa_lf_dbg.u);
+	do {
+		npa_lf_dbg.u = npa_af_reg_read(nix_af->npa_af,
+				CAVM_NPA_AF_RVU_LF_CFG_DEBUG());
+	} while (npa_lf_dbg.s.exec);
+
+	if (npa_lf_dbg.s.lf_valid)
+		*npaid = npa_lf_dbg.s.lf; 
+	debug("%s: npa lf_valid %d lf %d npaid %d\n", __func__,
+		npa_lf_dbg.s.lf_valid,npa_lf_dbg.s.lf,*npaid);
 
-	list_for_each_entry(nix_af, &nix_af_list, nix_af_list) {
-		if (((u64)(nix_af->nix_af_base) & mask) == (nix_pf_base & mask))
-			return nix_af;
-	}
-	debug("%s: No NIX AF found for address 0x%llx\n", __func__,
-	      nix_pf_base);
-	return NULL;
 }
 
-/**
- * Allocates an admin queue for instructions and results
- *
- * @param	aq	admin queue to allocate for
- * @param	qsize	Number of entries in the queue
- * @param	inst_size	Size of each instruction
- * @param	res_size	Size of each result
- *
- * @return	-ENOMEM on error, 0 on success
- */
-int cavm_rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
-		      size_t inst_size, size_t res_size)
+struct nix_af *rvu_af_init(struct rvu_af *rvu_af)
 {
+	struct nix_af *nix_af;
+	union cavm_rvu_af_addr_s block_addr;
 	int err;
 
-	err = qmem_alloc(&aq->inst, qsize, inst_size);
-	if (err)
-		return err;
-	err = qmem_alloc(&aq->res, qsize, res_size);
-	if (err)
-		qmem_free(&aq->inst);
+	nix_af = (struct nix_af *)calloc(1, sizeof(struct nix_af));
+	if (!nix_af) {
+		printf("%s: out of memory\n", __func__);
+		goto error;
+	}
 
-	return err;
-}
+	nix_af->dev = rvu_af->dev;
 
-/**
- * Frees an admin queue
- *
- * @param	aq	Admin queue to free
- */
-void cavm_rvu_aq_free(struct admin_queue *aq)
-{
-	qmem_free(&aq->inst);
-	qmem_free(&aq->res);
-	memset(aq, 0, sizeof(*aq));
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
+	nix_af->nix_af_base = rvu_af->af_base + block_addr.u;
+
+	nix_af->npa_af = (struct npa_af *)calloc(1, sizeof(struct npa_af));
+	if (!nix_af->npa_af) {
+		printf("%s: out of memory\n", __func__);
+		goto error;
+	}
+
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPA;
+	nix_af->npa_af->npa_af_base = rvu_af->af_base + block_addr.u;
+
+	block_addr.u = 0;
+	block_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
+	nix_af->npc_af_base = rvu_af->af_base + block_addr.u;
+
+	debug("%s: Setting up npa admin\n", __func__);
+	err = npa_af_setup(nix_af->npa_af);
+	if (err) {
+		printf("%s: Error %d setting up NPA admin\n", __func__, err);
+		goto error;
+	}
+	debug("%s: Setting up nix af\n", __func__);
+	err = nix_af_setup(nix_af);
+	if (err) {
+		printf("%s: Error %d setting up NIX admin\n", __func__, err);
+		goto error;
+	}
+	debug("%s: nix_af: %p\n", __func__, nix_af);
+	return nix_af;
+
+error:
+	if (nix_af->npa_af) {
+		free(nix_af->npa_af);
+		memset(nix_af, 0, sizeof(*nix_af));
+	}
+	if (nix_af) {
+		free(nix_af);
+	}
+	return NULL;
 }
 
-int cavm_rvu_af_probe(struct udevice *dev)
+int rvu_af_probe(struct udevice *dev)
 {
 	struct rvu_af *af_ptr = dev_get_priv(dev);
-	struct nix_af_handle *nix_af;
 	size_t size;
-	union cavm_rvu_af_addr_s func_addr;
-	static int instance = 0;
-
-	debug("%s(%s) instance: %d\n", __func__, dev->name, instance);
-	af_ptr->base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
-	debug("RVU AF BAR0 %p\n", af_ptr->base);
-	af_ptr->bar2 = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
-	debug("RVU AF BAR2 %p\n", af_ptr->bar2);
-
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
-	af_ptr->nix_af_base = af_ptr->base + func_addr.u;
-	debug("RVU AF BAR0 NIX BASE %p\n", af_ptr->nix_af_base);
-	af_ptr->nix_af_bar2 = af_ptr->bar2 + func_addr.u;
-	debug("RVU AF BAR2 NIX BASE %p\n", af_ptr->nix_af_bar2);
-	//nix_af_init(af_ptr->nix_af_base);
-
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPA;
-	af_ptr->npa_af_base = af_ptr->base + func_addr.u;
-	debug("RVU AF BAR0 NPA BASE %p\n", af_ptr->npa_af_base);
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
-	af_ptr->npc_af_base = af_ptr->base + func_addr.u;
-	debug("RVU AF BAR0 NPC BASE %p\n", af_ptr->npc_af_base);
-
-	debug("%s: Initializing nix instance %d\n", __func__, instance);
-	nix_af = nix_af_initialize(instance++, dev,
-				   af_ptr->nix_af_base, 0,
-				   af_ptr->npa_af_base);
-	if (!nix_af) {
+
+	af_ptr->af_base = dm_pci_map_bar(dev, 0, &size, PCI_REGION_MEM);
+	debug("%s RVU AF BAR %p \n", __func__, af_ptr->af_base);
+	af_ptr->dev = rvu_af_dev = dev;
+
+	af_ptr->nix_af = rvu_af_init(af_ptr);
+	if ( !af_ptr->nix_af) {
 		printf("%s: Error: could not initialize NIX AF\n", __func__);
 		return -1;
 	}
-	debug("%s: Adding list, nix_af: %p\n", __func__, nix_af);
-	list_add(&nix_af->nix_af_list, &nix_af_list);
-	af_ptr->nix_af = nix_af;
 	debug("%s: Done\n", __func__);
 
 	return 0;
 }
 
+int rvu_af_remove(struct udevice *dev)
+{
+	struct nix_af *nix_af = dev_get_priv(dev);
+
+	nix_af_shutdown(nix_af);
+	return 0;
+}
+
 static const struct udevice_id rvu_af_ids[] = {
         { .compatible = "cavium,rvu-af" },
         {}
@@ -139,13 +163,14 @@ static const struct udevice_id rvu_af_ids[] = {
 U_BOOT_DRIVER(rvu_af) = {
         .name   = "rvu_af",
         .id     = UCLASS_MISC,
-        .probe  = cavm_rvu_af_probe,
+        .probe  = rvu_af_probe,
+        .remove = rvu_af_remove,
         .of_match = rvu_af_ids,
         .priv_auto_alloc_size = sizeof(struct rvu_af),
 };
 
 static struct pci_device_id rvu_af_supported[] = {
-        { PCI_VDEVICE(CAVIUM, PCI_DEVICE_ID_OCTEONTX2_RVU_AF) },
+        { PCI_VDEVICE(CAVIUM, PCI_DEVID_OCTEONTX2_RVU_AF) },
         {}
 };
 
diff --git a/drivers/net/cavium/octeontx2/rvu_common.c b/drivers/net/cavium/octeontx2/rvu_common.c
index 7948051f41..3bca6ed3ab 100644
--- a/drivers/net/cavium/octeontx2/rvu_common.c
+++ b/drivers/net/cavium/octeontx2/rvu_common.c
@@ -10,7 +10,6 @@
 
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -18,17 +17,6 @@
 #include <errno.h>
 
 #include "rvu.h"
-#include "rvu_common.h"
-
-int rvu_alloc_bitmap(struct rsrc_bmap *rsrc)
-{
-	size_t size = (rsrc->max + sizeof(rsrc->bmap) * 8 - 1);
-
-	rsrc->bmap = calloc(size / (sizeof(rsrc->bmap) * 8), 1);
-	if (!rsrc->bmap)
-		return -ENOMEM;
-	return 0;
-}
 
 int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz)
 {
@@ -37,8 +25,10 @@ int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz)
 		return -ENOMEM;
 	q->entry_sz = entry_sz;
 	q->qsize = qsize;
-	q->alloc_sz = qsize * entry_sz;
+	q->alloc_sz = (size_t)qsize * entry_sz;
 	q->iova = (dma_addr_t)(q->base);
+	debug("NIX: qmem alloc for (%d * %d = %ld bytes) at %p\n",
+	       q->qsize, q->entry_sz, q->alloc_sz, q->base);
 	return 0;
 }
 
@@ -48,3 +38,41 @@ void qmem_free(struct qmem *q)
 		free(q->base);
 	memset(q, 0, sizeof(*q));
 }
+
+/**
+ * Allocates an admin queue for instructions and results
+ *
+ * @param	aq	admin queue to allocate for
+ * @param	qsize	Number of entries in the queue
+ * @param	inst_size	Size of each instruction
+ * @param	res_size	Size of each result
+ *
+ * @return	-ENOMEM on error, 0 on success
+ */
+int rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
+		      size_t inst_size, size_t res_size)
+{
+	int err;
+
+	err = qmem_alloc(&aq->inst, qsize, inst_size);
+	if (err)
+		return err;
+	err = qmem_alloc(&aq->res, qsize, res_size);
+	if (err)
+		qmem_free(&aq->inst);
+
+	return err;
+}
+
+/**
+ * Frees an admin queue
+ *
+ * @param	aq	Admin queue to free
+ */
+void rvu_aq_free(struct admin_queue *aq)
+{
+	qmem_free(&aq->inst);
+	qmem_free(&aq->res);
+	memset(aq, 0, sizeof(*aq));
+}
+
diff --git a/drivers/net/cavium/octeontx2/rvu_common.h b/drivers/net/cavium/octeontx2/rvu_common.h
deleted file mode 100644
index 7bd9c492c2..0000000000
--- a/drivers/net/cavium/octeontx2/rvu_common.h
+++ /dev/null
@@ -1,202 +0,0 @@
-/*
- * Copyright (C) 2017 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of version 2 of the GNU General Public License
- * as published by the Free Software Foundation.
- */
-
-#ifndef __RVU_COMMON_H__
-#define __RVU_COMMON_H__
-
-#define ALIGNED		__aligned(CONFIG_SYS_CACHELINE_SIZE)
-
-/* PCI device IDs */
-#define	PCI_DEVID_OCTEONTX2_CGX			0xA059
-#define	PCI_DEVID_OCTEONTX2_RVU_AF		0xA065
-#define	PCI_DEVID_OCTEONTX2_RVU_PF		0xA063
-#define	PCI_DEVID_OCTEONTX2_RVU_VF		0xA064
-
-/* PCI BAR nos */
-#define	PCI_AF_REG_BAR_NUM			0
-#define	PCI_CFG_REG_BAR_NUM			2
-#define	PCI_MBOX_BAR_NUM			4
-
-#define RVU_PFVF_PF_SHIFT	10
-#define RVU_PFVF_PF_MASK	0x3F
-#define RVU_PFVF_FUNC_SHIFT	0
-#define RVU_PFVF_FUNC_MASK	0x3FF
-
-#define MAX_NIX			1
-
-#define NAME_SIZE				32
-
-#define OTX2_ALIGN	CONFIG_SYS_CACHELINE_SIZE  /* Align to cacheline */
-
-#define Q_SIZE_16		0ULL /* 16 entries */
-#define Q_SIZE_64		1ULL /* 64 entries */
-#define Q_SIZE_256		2ULL
-#define Q_SIZE_1K		3ULL
-#define Q_SIZE_4K		4ULL
-#define Q_SIZE_16K		5ULL
-#define Q_SIZE_64K		6ULL
-#define Q_SIZE_256K		7ULL
-#define Q_SIZE_1M		8ULL /* Million entries */
-#define Q_SIZE_MIN		Q_SIZE_16
-#define Q_SIZE_MAX		Q_SIZE_1M
-
-#define Q_COUNT(x)		(16ULL << (2 * x))
-#define Q_SIZE(x, n)		((ilog2(x) - (n)) / 2)
-
-#define NIX_INTF_TYPE_CGX		0
-#define NIX_INTF_TYPE_LBK		1
-#define NIX_MAX_HW_MTU			9212
-#define NIX_MIN_HW_MTU			64
-
-#define MAX_LMAC_PKIND			12
-
-/* Admin queue info */
-
-/* Since we intend to add only one instruction at a time,
- * keep queue size to it's minimum.
- */
-#define AQ_SIZE			Q_SIZE_16
-/* HW head & tail pointer mask */
-#define AQ_PTR_MASK		0xFFFFF
-
-#define RQ_LEN		QCOUNT(Q_SIZE_1K)
-#define SQ_LEN		QCOUNT(Q_SIZE_16)
-
-/** RVU Block Type Enumeration */
-enum rvu_block_type_e {
-	BLKTYPE_RVUM = 0x0,
-	BLKTYPE_MSIX = 0x1,
-	BLKTYPE_LMT  = 0x2,
-	BLKTYPE_NIX  = 0x3,
-	BLKTYPE_NPA  = 0x4,
-	BLKTYPE_NPC  = 0x5,
-	BLKTYPE_SSO  = 0x6,
-	BLKTYPE_SSOW = 0x7,
-	BLKTYPE_TIM  = 0x8,
-	BLKTYPE_CPT  = 0x9,
-	BLKTYPE_NDC  = 0xa,
-	BLKTYPE_MAX  = 0xa,
-};
-
-
-/** Resource bitmap */
-struct rsrc_bmap {
-	unsigned long *bmap;
-	u16  max;
-};
-
-struct rvu_block {
-	struct rsrc_bmap	rsrc;
-	u16			*fn_map;	/** LF to pcifunc mapping */
-	bool			multislot;
-	u8			blkid;
-	u8			addr;
-	u8			lfshift;
-	u64			lookup_reg;
-	u64			pf_lfcnt_reg;
-	u64			vf_lfcnt_reg;
-	u64			lfcfg_reg;
-	u64			msixcfg_reg;
-	u64			lfreset_reg;
-	unsigned char		name[32];
-};
-
-struct rvu_hwinfo {
-	struct rvu_block block[BLKTYPE_MAX];
-	u8	total_pfs;	/** MAX RVU PFs HW supports */
-	u8	total_vfs;	/** Max RVU VFs HW supports */
-	u16	max_vfs_per_pf;	/** Max VFs that can be attached to PF */
-	u8	ndc;		/** Number of cache units available */
-	u8	cgx;
-	u8	lmac_per_cgx;
-	u8	cgx_links;
-	u8	lbk_links;
-	u8	sdp_links;
-	u8	npc_kpus;
-	u16	sso_hwgrps;
-	u16	sso_xaq_num_works;
-	u16	sso_xaq_buf_size;
-
-	u8	sso_hws;
-};
-
-struct qmem {
-	void		*base;
-	dma_addr_t	iova;
-	size_t		alloc_sz;
-	u32		qsize;
-	u8		entry_sz;
-};
-
-struct admin_queue {
-	struct qmem inst;
-	struct qmem res;
-};
-
-/**
- * Store 128 bit value
- *
- * @param[out]	dest	pointer to destination address
- * @param	val0	first 64 bits to write
- * @param	val1	second 64 bits to write
- */
-static inline void cavm_st128(void *dest, u64 val0, u64 val1)
-{
-	__asm__ __volatile__(
-		"stp %x[x0], %x[x1], [%[pm]]"
-		:
-		: [x0]"r"(val0), [x1]"r"(val1), [pm]"r"(dest)
-		: "memory");
-}
-
-/**
- * Load 128 bit value
- *
- * @param[in]	source		pointer to 128 bits of data to load
- * @param[out]	val0		first 64 bits of data
- * @param[out]	val1		second 64 bits of data
- */
-static inline void cavm_ld128(const u64 *src, u64 *val0, u64 *val1)
-{
-	__asm__ __volatile__ (
-		"ldp %x[x0], %x[x1], [%[pm]]"
-		:
-		: [x0]"r"(*val0), [x1]"r"(*val1), [pm]"r"(src));
-}
-
-void qmem_free(struct qmem *q);
-int qmem_alloc(struct qmem *q, u32 qsize, size_t entry_sz);
-
-/**
- * Allocates an admin queue for instructions and results
- *
- * @param	aq	admin queue to allocate for
- * @param	qsize	Number of entries in the queue
- * @param	inst_size	Size of each instruction
- * @param	res_size	Size of each result
- *
- * @return	-ENOMEM on error, 0 on success
- */
-int cavm_rvu_aq_alloc(struct admin_queue *aq, unsigned qsize,
-		      size_t inst_size, size_t res_size);
-
-/**
- * Frees an admin queue
- *
- * @param	aq	Admin queue to free
- */
-void cavm_rvu_aq_free(struct admin_queue *aq);
-
-static inline uint32_t rvu_get_pf(u16 pcifunc)
-{
-	return (pcifunc >> RVU_PFVF_PF_SHIFT) & RVU_PFVF_PF_MASK;
-}
-
-int rvu_alloc_bitmap(struct rsrc_bmap *rsrc);
-
-#endif /* __RVU_COMMON_H__ */
diff --git a/drivers/net/cavium/octeontx2/rvu_hw.h b/drivers/net/cavium/octeontx2/rvu_hw.h
deleted file mode 100644
index 37cb0e42c9..0000000000
--- a/drivers/net/cavium/octeontx2/rvu_hw.h
+++ /dev/null
@@ -1,2121 +0,0 @@
-/*
- * Copyright (C) 2018 Cavium, Inc.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This file defines the RVU registers for the Cavium OcteonTX2.
- */
-
-#ifndef __RVU_HW_H__
-#define __RVU_HW_H__
-
-/* Register offsets */
-
-#define RVU_AF_MSIXTR_BASE                  (0x10ull)
-#define RVU_AF_BLK_RST                      (0x30ull)
-#define RVU_AF_PF_BAR4_ADDR                 (0x40ull)
-#define RVU_AF_RAS                          (0x100ull)
-#define RVU_AF_RAS_W1S                      (0x108ull)
-#define RVU_AF_RAS_ENA_W1S                  (0x110ull)
-#define RVU_AF_RAS_ENA_W1C                  (0x118ull)
-#define RVU_AF_GEN_INT                      (0x120ull)
-#define RVU_AF_GEN_INT_W1S                  (0x128ull)
-#define RVU_AF_GEN_INT_ENA_W1S              (0x130ull)
-#define RVU_AF_GEN_INT_ENA_W1C              (0x138ull)
-#define RVU_AF_AFPFX_MBOXX(a, b)            \
-	(0x2000ull | (uint64_t)(a) << 4 | (uint64_t)(b) << 3)
-#define RVU_AF_PFME_STATUS                  (0x2800ull)
-#define RVU_AF_PFTRPEND                     (0x2810ull)
-#define RVU_AF_PFTRPEND_W1S                 (0x2820ull)
-#define RVU_AF_PF_RST                       (0x2840ull)
-#define RVU_AF_HWVF_RST                     (0x2850ull)
-#define RVU_AF_PFAF_MBOX_INT                (0x2880ull)
-#define RVU_AF_PFAF_MBOX_INT_W1S            (0x2888ull)
-#define RVU_AF_PFAF_MBOX_INT_ENA_W1S        (0x2890ull)
-#define RVU_AF_PFAF_MBOX_INT_ENA_W1C        (0x2898ull)
-#define RVU_AF_PFFLR_INT                    (0x28a0ull)
-#define RVU_AF_PFFLR_INT_W1S                (0x28a8ull)
-#define RVU_AF_PFFLR_INT_ENA_W1S            (0x28b0ull)
-#define RVU_AF_PFFLR_INT_ENA_W1C            (0x28b8ull)
-#define RVU_AF_PFME_INT                     (0x28c0ull)
-#define RVU_AF_PFME_INT_W1S                 (0x28c8ull)
-#define RVU_AF_PFME_INT_ENA_W1S             (0x28d0ull)
-#define RVU_AF_PFME_INT_ENA_W1C             (0x28d8ull)
-#define RVU_PRIV_CONST                      (0x8000000ull)
-#define RVU_PRIV_GEN_CFG                    (0x8000010ull)
-#define RVU_PRIV_CLK_CFG                    (0x8000020ull)
-#define RVU_PRIV_ACTIVE_PC                  (0x8000030ull)
-#define RVU_PRIV_PFX_CFG(a)                 (0x8000100ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_MSIX_CFG(a)            (0x8000110ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_ID_CFG(a)              (0x8000120ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_INT_CFG(a)             (0x8000200ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_NIXX_CFG(a, b)         \
-	(0x8000300ull | (uint64_t)(a) << 16 | (uint64_t)(b) << 3)
-#define RVU_PRIV_PFX_NPA_CFG(a)             (0x8000310ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_SSO_CFG(a)             (0x8000320ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_SSOW_CFG(a)            (0x8000330ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_TIM_CFG(a)             (0x8000340ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_PFX_CPTX_CFG(a, b)         \
-	(0x8000350ull | (uint64_t)(a) << 16 | (uint64_t)(b) << 3)
-#define RVU_PRIV_BLOCK_TYPEX_REV(a)         (0x8000400ull | (uint64_t)(a) << 3)
-#define RVU_PRIV_HWVFX_INT_CFG(a)           (0x8001280ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_HWVFX_NIXX_CFG(a, b)       \
-	(0x8001300ull | (uint64_t)(a) << 16 | (uint64_t)(b) << 3)
-#define RVU_PRIV_HWVFX_NPA_CFG(a)           (0x8001310ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_HWVFX_SSO_CFG(a)           (0x8001320ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_HWVFX_SSOW_CFG(a)          (0x8001330ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_HWVFX_TIM_CFG(a)           (0x8001340ull | (uint64_t)(a) << 16)
-#define RVU_PRIV_HWVFX_CPTX_CFG(a, b)       \
-	(0x8001350ull | (uint64_t)(a) << 16 | (uint64_t)(b) << 3)
-
-#define RVU_PF_VFX_PFVF_MBOXX(a, b)         \
-	(0x0ull | (uint64_t)(a) << 12 | (uint64_t)(b) << 3)
-#define RVU_PF_VF_BAR4_ADDR                 (0x10ull)
-#define RVU_PF_BLOCK_ADDRX_DISC(a)          (0x200ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFME_STATUSX(a)              (0x800ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFTRPENDX(a)                 (0x820ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFTRPEND_W1SX(a)             (0x840ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFPF_MBOX_INTX(a)            (0x880ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFPF_MBOX_INT_W1SX(a)        (0x8a0ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFPF_MBOX_INT_ENA_W1SX(a)    (0x8c0ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFPF_MBOX_INT_ENA_W1CX(a)    (0x8e0ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFFLR_INTX(a)                (0x900ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFFLR_INT_W1SX(a)            (0x920ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFFLR_INT_ENA_W1SX(a)        (0x940ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFFLR_INT_ENA_W1CX(a)        (0x960ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFME_INTX(a)                 (0x980ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFME_INT_W1SX(a)             (0x9a0ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFME_INT_ENA_W1SX(a)         (0x9c0ull | (uint64_t)(a) << 3)
-#define RVU_PF_VFME_INT_ENA_W1CX(a)         (0x9e0ull | (uint64_t)(a) << 3)
-#define RVU_PF_PFAF_MBOXX(a)                (0xc00ull | (uint64_t)(a) << 3)
-#define RVU_PF_INT                          (0xc20ull)
-#define RVU_PF_INT_W1S                      (0xc28ull)
-#define RVU_PF_INT_ENA_W1S                  (0xc30ull)
-#define RVU_PF_INT_ENA_W1C                  (0xc38ull)
-#define RVU_PF_MSIX_VECX_ADDR(a)            (0x80000ull | (uint64_t)(a) << 4)
-#define RVU_PF_MSIX_VECX_CTL(a)             (0x80008ull | (uint64_t)(a) << 4)
-#define RVU_PF_MSIX_PBAX(a)                 (0xf0000ull | (uint64_t)(a) << 3)
-#define RVU_VF_VFPF_MBOXX(a)                (0x0ull | (uint64_t)(a) << 3)
-#define RVU_VF_INT                          (0x20ull)
-#define RVU_VF_INT_W1S                      (0x28ull)
-#define RVU_VF_INT_ENA_W1S                  (0x30ull)
-#define RVU_VF_INT_ENA_W1C                  (0x38ull)
-#define RVU_VF_BLOCK_ADDRX_DISC(a)          (0x200ull | (uint64_t)(a) << 3)
-#define RVU_VF_MSIX_VECX_ADDR(a)            (0x80000ull | (uint64_t)(a) << 4)
-#define RVU_VF_MSIX_VECX_CTL(a)             (0x80008ull | (uint64_t)(a) << 4)
-#define RVU_VF_MSIX_PBAX(a)                 (0xf0000ull | (uint64_t)(a) << 3)
-
-
-/* Enum offsets */
-
-#define RVU_BAR_RVU_PF_END_BAR0             (0x84f000000000ull)
-#define RVU_BAR_RVU_PF_START_BAR0           (0x840000000000ull)
-#define RVU_BAR_RVU_PFX_FUNCX_BAR2(a, b)    \
-	(0x840200000000ull | ((uint64_t)(a) << 36) | ((uint64_t)(b) << 25))
-
-#define RVU_AF_INT_VEC_POISON               (0x0ull)
-#define RVU_AF_INT_VEC_PFFLR                (0x1ull)
-#define RVU_AF_INT_VEC_PFME                 (0x2ull)
-#define RVU_AF_INT_VEC_GEN                  (0x3ull)
-#define RVU_AF_INT_VEC_MBOX                 (0x4ull)
-
-#define RVU_BLOCK_TYPE_RVUM                 (0x0ull)
-#define RVU_BLOCK_TYPE_LMT                  (0x2ull)
-#define RVU_BLOCK_TYPE_NIX                  (0x3ull)
-#define RVU_BLOCK_TYPE_NPA                  (0x4ull)
-#define RVU_BLOCK_TYPE_NPC                  (0x5ull)
-#define RVU_BLOCK_TYPE_SSO                  (0x6ull)
-#define RVU_BLOCK_TYPE_SSOW                 (0x7ull)
-#define RVU_BLOCK_TYPE_TIM                  (0x8ull)
-#define RVU_BLOCK_TYPE_CPT                  (0x9ull)
-#define RVU_BLOCK_TYPE_NDC                  (0xaull)
-#define RVU_BLOCK_TYPE_DDF                  (0xbull)
-#define RVU_BLOCK_TYPE_ZIP                  (0xcull)
-#define RVU_BLOCK_TYPE_RAD                  (0xdull)
-#define RVU_BLOCK_TYPE_DFA                  (0xeull)
-#define RVU_BLOCK_TYPE_HNA                  (0xfull)
-
-#define RVU_BLOCK_ADDR_RVUM                 (0x0ull)
-#define RVU_BLOCK_ADDR_LMT                  (0x1ull)
-#define RVU_BLOCK_ADDR_NPA                  (0x3ull)
-#define RVU_BLOCK_ADDR_NPC                  (0x6ull)
-#define RVU_BLOCK_ADDR_SSO                  (0x7ull)
-#define RVU_BLOCK_ADDR_SSOW                 (0x8ull)
-#define RVU_BLOCK_ADDR_TIM                  (0x9ull)
-#define RVU_BLOCK_ADDR_NIX0                 (0x4ull)
-#define RVU_BLOCK_ADDR_CPT0                 (0xaull)
-#define RVU_BLOCK_ADDR_NDC0                 (0xcull)
-#define RVU_BLOCK_ADDR_NDC1                 (0xdull)
-#define RVU_BLOCK_ADDR_NDC2                 (0xeull)
-#define RVU_BLOCK_ADDR_R_END                (0x1full)
-#define RVU_BLOCK_ADDR_R_START              (0x14ull)
-
-#define RVU_VF_INT_VEC_MBOX                 (0x0ull)
-
-#define RVU_PF_INT_VEC_AFPF_MBOX            (0x6ull)
-#define RVU_PF_INT_VEC_VFFLR0               (0x0ull)
-#define RVU_PF_INT_VEC_VFFLR1               (0x1ull)
-#define RVU_PF_INT_VEC_VFME0                (0x2ull)
-#define RVU_PF_INT_VEC_VFME1                (0x3ull)
-#define RVU_PF_INT_VEC_VFPF_MBOX0           (0x4ull)
-#define RVU_PF_INT_VEC_VFPF_MBOX1           (0x5ull)
-
-/**
- * Enumeration rvu_af_int_vec_e
- *
- * RVU Admin Function Interrupt Vector Enumeration
- * Enumerates the MSI-X interrupt vectors.
- * Internal:
- * RVU maintains the state of these vectors internally, and generates GIB
- * messages for it without accessing the MSI-X table region in LLC/DRAM.
- */
-#define CAVM_RVU_AF_INT_VEC_E_GEN (3)
-#define CAVM_RVU_AF_INT_VEC_E_MBOX (4)
-#define CAVM_RVU_AF_INT_VEC_E_PFFLR (1)
-#define CAVM_RVU_AF_INT_VEC_E_PFME (2)
-#define CAVM_RVU_AF_INT_VEC_E_POISON (0)
-
-/**
- * Enumeration rvu_bar_e
- *
- * RVU Base Address Register Enumeration
- * Enumerates the base address registers.
- * Internal:
- * For documentation only.
- */
-#define CAVM_RVU_PFX_BAR0(a) (0x840000000000ll + 0x1000000000ll * (a))
-#define CAVM_RVU_PFX_BAR0_SIZE 0x200000000ull
-#define CAVM_RVU_PFX_FUNCX_BAR2(a,b) (0x840200000000ll + 0x1000000000ll * (a) + 0x2000000ll * (b))
-#define CAVM_RVU_PFX_FUNCX_BAR2_SIZE 0x2000000ull
-
-/**
- * Enumeration rvu_block_addr_e
- *
- * RVU Block Address Enumeration
- * Enumerates addressing of RVU resource blocks within each RVU BAR, i.e. values
- * of RVU_FUNC_ADDR_S[BLOCK] and RVU_AF_ADDR_S[BLOCK].
- */
-#define CAVM_RVU_BLOCK_ADDR_E_CPTX(a) (0xa + (a))
-#define CAVM_RVU_BLOCK_ADDR_E_LMT (1)
-#define CAVM_RVU_BLOCK_ADDR_E_NDCX(a) (0xc + (a))
-#define CAVM_RVU_BLOCK_ADDR_E_NIXX(a) (4 + (a))
-#define CAVM_RVU_BLOCK_ADDR_E_NPA (3)
-#define CAVM_RVU_BLOCK_ADDR_E_NPC (6)
-#define CAVM_RVU_BLOCK_ADDR_E_RX(a) (0 + (a))
-#define CAVM_RVU_BLOCK_ADDR_E_RVUM (0)
-#define CAVM_RVU_BLOCK_ADDR_E_SSO (7)
-#define CAVM_RVU_BLOCK_ADDR_E_SSOW (8)
-#define CAVM_RVU_BLOCK_ADDR_E_TIM (9)
-
-/**
- * Enumeration rvu_block_type_e
- *
- * RVU Block Type Enumeration
- * Enumerates values of RVU_PF/RVU_VF_BLOCK_ADDR()_DISC[BTYPE].
- */
-#define CAVM_RVU_BLOCK_TYPE_E_CPT (9)
-#define CAVM_RVU_BLOCK_TYPE_E_DDF (0xb)
-#define CAVM_RVU_BLOCK_TYPE_E_DFA (0xe)
-#define CAVM_RVU_BLOCK_TYPE_E_HNA (0xf)
-#define CAVM_RVU_BLOCK_TYPE_E_LMT (2)
-#define CAVM_RVU_BLOCK_TYPE_E_NDC (0xa)
-#define CAVM_RVU_BLOCK_TYPE_E_NIX (3)
-#define CAVM_RVU_BLOCK_TYPE_E_NPA (4)
-#define CAVM_RVU_BLOCK_TYPE_E_NPC (5)
-#define CAVM_RVU_BLOCK_TYPE_E_RAD (0xd)
-#define CAVM_RVU_BLOCK_TYPE_E_RVUM (0)
-#define CAVM_RVU_BLOCK_TYPE_E_SSO (6)
-#define CAVM_RVU_BLOCK_TYPE_E_SSOW (7)
-#define CAVM_RVU_BLOCK_TYPE_E_TIM (8)
-#define CAVM_RVU_BLOCK_TYPE_E_ZIP (0xc)
-
-/**
- * Enumeration rvu_bus_lf_e
- *
- * INTERNAL: RVU Bus LF Range Enumeration
- *
- * Enumerates the LF range for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUS_LFX(a) (0 + 0x2000000 * (a))
-
-/**
- * Enumeration rvu_bus_lf_slot_e
- *
- * INTERNAL: RVU Bus LF Slot Range Enumeration
- *
- * Enumerates the LF and Slot range for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUS_LFX_SLOTX(a,b) (0 + 0x2000000 * (a) + 0x1000 * (b))
-
-/**
- * Enumeration rvu_bus_pf_e
- *
- * INTERNAL: RVU Bus PF Range Enumeration
- *
- * Enumerates the PF range for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUS_PFX(a) (0ll + 0x1000000000ll * (a))
-
-/**
- * Enumeration rvu_bus_pfvf_e
- *
- * INTERNAL: RVU Bus PFVF Range Enumeration
- *
- * Enumerates the PF and VF ranges for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUS_PFVF_E_RVU_BUS_PFX(a) (0 + 0x2000000 * (a))
-#define CAVM_RVU_BUS_PFVF_E_RVU_BUS_VFX(a) (0 + 0x2000000 * (a))
-
-/**
- * Enumeration rvu_busbar_e
- *
- * INTERNAL: RVU Bus Base Address Region Enumeration
- *
- * Enumerates the base address region for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUSBAR_E_RVU_BUSBAR0 (0)
-#define CAVM_RVU_BUSBAR_E_RVU_BUSBAR2 (0x200000000ll)
-
-/**
- * Enumeration rvu_busdid_e
- *
- * INTERNAL: RVU Bus DID Enumeration
- *
- * Enumerates the DID offset for the RVU bus.
- * Internal:
- * This is an enum used in csr3 virtual equations.
- */
-#define CAVM_RVU_BUSDID_E_RVU_BUSDID (0x840000000000ll)
-
-/**
- * Enumeration rvu_pf_int_vec_e
- *
- * RVU PF Interrupt Vector Enumeration
- * Enumerates the MSI-X interrupt vectors.
- */
-#define CAVM_RVU_PF_INT_VEC_E_AFPF_MBOX (6)
-#define CAVM_RVU_PF_INT_VEC_E_VFFLRX(a) (0 + (a))
-#define CAVM_RVU_PF_INT_VEC_E_VFMEX(a) (2 + (a))
-#define CAVM_RVU_PF_INT_VEC_E_VFPF_MBOXX(a) (4 + (a))
-
-/**
- * Enumeration rvu_vf_int_vec_e
- *
- * RVU VF Interrupt Vector Enumeration
- * Enumerates the MSI-X interrupt vectors.
- */
-#define CAVM_RVU_VF_INT_VEC_E_MBOX (0)
-
-/**
- * Structure rvu_af_addr_s
- *
- * RVU Admin Function Register Address Structure
- * Address format for accessing shared Admin Function (AF) registers in
- * RVU PF BAR0. These registers may be accessed by all RVU PFs whose
- * RVU_PRIV_PF()_CFG[AF_ENA] bit is set.
- */
-union cavm_rvu_af_addr_s
-{
-    uint64_t u;
-    struct cavm_rvu_af_addr_s_s
-    {
-        uint64_t addr                  : 28; /**< [ 27:  0] Register address within [BLOCK]. */
-        uint64_t block                 : 5;  /**< [ 32: 28] Resource block enumerated by RVU_BLOCK_ADDR_E. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Structure rvu_func_addr_s
- *
- * RVU Function-unique Address Structure
- * Address format for accessing function-unique registers in RVU PF/FUNC BAR2.
- */
-union cavm_rvu_func_addr_s
-{
-    uint32_t u;
-    struct cavm_rvu_func_addr_s_s
-    {
-        uint32_t addr                  : 12; /**< [ 11:  0] Register address within the block and LF slot. */
-        uint32_t lf_slot               : 8;  /**< [ 19: 12] Local function slot, or extended register address within the block's LF
-                                                                 slot 0, depending on [BLOCK]. */
-        uint32_t block                 : 5;  /**< [ 24: 20] Resource block enumerated by RVU_BLOCK_ADDR_E. */
-        uint32_t reserved_25_31        : 7;
-    } s;
-};
-
-/**
- * Structure rvu_msix_vec_s
- *
- * RVU MSI-X Vector Structure
- * Format of entries in the RVU MSI-X table region in LLC/DRAM. See
- * RVU_PRIV_PF()_MSIX_CFG.
- */
-union cavm_rvu_msix_vec_s
-{
-    uint64_t u[2];
-    struct cavm_rvu_msix_vec_s_s
-    {
-        uint64_t addr                  : 64; /**< [ 63:  0] PF/VF IOVA to use for MSI-X delivery of this vector. Bits \<63:53\> are reserved.
-                                                                 Bit \<1:0\> are reserved for alignment. */
-        uint64_t data                  : 32; /**< [ 95: 64] Data to use for MSI-X delivery of this vector. */
-        uint64_t mask                  : 1;  /**< [ 96: 96] When set, no MSI-X interrupts are sent to this vector. */
-        uint64_t pend                  : 1;  /**< [ 97: 97] Vector's pending bit in the MSI-X PBA. */
-        uint64_t reserved_98_127       : 30;
-    } s;
-};
-
-/**
- * Structure rvu_pf_func_s
- *
- * RVU PF Function Identification Structure
- * Identifies an RVU PF/VF, and format of *_PRIV_LF()_CFG[PF_FUNC] in RVU
- * resource blocks, e.g. NPA_PRIV_LF()_CFG[PF_FUNC].
- *
- * Internal:
- * Also used for PF/VF identification on inter-coprocessor hardware
- * interfaces (NPA, SSO, CPT, ...).
- */
-union cavm_rvu_pf_func_s
-{
-    uint32_t u;
-    struct cavm_rvu_pf_func_s_s
-    {
-        uint32_t func                  : 10; /**< [  9:  0] Function within [PF]; 0 for the PF itself, else VF number plus 1. */
-        uint32_t pf                    : 6;  /**< [ 15: 10] RVU PF number. */
-        uint32_t reserved_16_31        : 16;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_afpf#_mbox#
- *
- * RVU Admin Function AF/PF Mailbox Registers
- */
-union cavm_rvu_af_afpfx_mboxx
-{
-    uint64_t u;
-    struct cavm_rvu_af_afpfx_mboxx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Mailbox data. These AF registers access the 16-byte-per-PF PF/AF
-                                                                 mailbox.  Each corresponding PF may access the same storage using
-                                                                 RVU_PF_PFAF_MBOX(). MBOX(0) is typically used for AF to PF
-                                                                 signaling, MBOX(1) for PF to AF.
-                                                                 Writing RVU_AF_AFPF()_MBOX(0) (but not RVU_PF_PFAF_MBOX(0)) will
-                                                                 set the corresponding
-                                                                 RVU_PF_INT[MBOX] which if appropriately enabled will send an
-                                                                 interrupt to the PF. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_bar2_alias#
- *
- * INTERNAL: RVU Admin Function  BAR2 Alias Registers
- *
- * These registers alias to the RVU BAR2 registers for the PF and function
- * selected by RVU_AF_BAR2_SEL[PF_FUNC].
- *
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_rvu_af_bar2_aliasx
-{
-    uint64_t u;
-    struct cavm_rvu_af_bar2_aliasx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Aliased register data. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_bar2_sel
- *
- * INTERNAL: RVU Admin Function BAR2 Select Register
- *
- * This register configures BAR2 accesses from the RVU_AF_BAR2_ALIAS() registers in BAR0.
- * Internal:
- * Not implemented. Placeholder for bug33464.
- */
-union cavm_rvu_af_bar2_sel
-{
-    uint64_t u;
-    struct cavm_rvu_af_bar2_sel_s
-    {
-        uint64_t alias_pf_func         : 16; /**< [ 15:  0](R/W) PF and function whose BAR2 registers may be accessed from the AF BAR2 alias
-                                                                 registers. Format specified by RVU_PF_FUNC_S. */
-        uint64_t alias_ena             : 1;  /**< [ 16: 16](R/W) Enable BAR2 register accesses from the AF BAR2 alias registers in BAR0. */
-        uint64_t reserved_17_63        : 47;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_blk_rst
- *
- * RVU Master Admin Function Block Reset Register
- */
-union cavm_rvu_af_blk_rst
-{
-    uint64_t u;
-    struct cavm_rvu_af_blk_rst_s
-    {
-        uint64_t rst                   : 1;  /**< [  0:  0](WO/H) Write one to reset RVUM, except for privileged AF registers (RVU_PRIV_*).
-                                                                 Software must ensure that all RVUM activity is quiesced before writing one. */
-        uint64_t reserved_1_62         : 62;
-        uint64_t busy                  : 1;  /**< [ 63: 63](RO/H) When one, RVUM is busy completing reset. No access except the reading of this
-                                                                 bit should occur to RVUM until this is clear. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_eco
- *
- * INTERNAL: RVU Admin Function ECO Register
- */
-union cavm_rvu_af_eco
-{
-    uint64_t u;
-    struct cavm_rvu_af_eco_s
-    {
-        uint64_t eco_rw                : 32; /**< [ 31:  0](R/W) Reserved for ECO usage. */
-        uint64_t reserved_32_63        : 32;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_gen_int
- *
- * RVU Admin Function General Interrupt Register
- * This register contains General interrupt summary bits.
- */
-union cavm_rvu_af_gen_int
-{
-    uint64_t u;
-    struct cavm_rvu_af_gen_int_s
-    {
-        uint64_t unmapped              : 1;  /**< [  0:  0](R/W1C/H) Received a register read or write request to an unmapped or disabled PF or
-                                                                 VF. Specifically:
-                                                                 * A PF/VF  BAR2 access in a PF whose RVU_PRIV_PF()_CFG[ENA] is
-                                                                 clear.
-                                                                 * A VF BAR2 access to a VF number that is greater than or equal to the
-                                                                 associated PF's RVU_PRIV_PF()_CFG[NVF]. */
-        uint64_t msix_fault            : 1;  /**< [  1:  1](R/W1C/H) Received MSIX-X table read response with fault data */
-        uint64_t reserved_2_63         : 62;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_gen_int_ena_w1c
- *
- * RVU Admin Function General Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_af_gen_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_af_gen_int_ena_w1c_s
-    {
-        uint64_t unmapped              : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for RVU_AF_GEN_INT[UNMAPPED]. */
-        uint64_t msix_fault            : 1;  /**< [  1:  1](R/W1C/H) Reads or clears enable for RVU_AF_GEN_INT[MSIX_FAULT]. */
-        uint64_t reserved_2_63         : 62;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_gen_int_ena_w1s
- *
- * RVU Admin Function General Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_af_gen_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_gen_int_ena_w1s_s
-    {
-        uint64_t unmapped              : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for RVU_AF_GEN_INT[UNMAPPED]. */
-        uint64_t msix_fault            : 1;  /**< [  1:  1](R/W1S/H) Reads or sets enable for RVU_AF_GEN_INT[MSIX_FAULT]. */
-        uint64_t reserved_2_63         : 62;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_gen_int_w1s
- *
- * RVU Admin Function General Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_rvu_af_gen_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_gen_int_w1s_s
-    {
-        uint64_t unmapped              : 1;  /**< [  0:  0](R/W1S/H) Reads or sets RVU_AF_GEN_INT[UNMAPPED]. */
-        uint64_t msix_fault            : 1;  /**< [  1:  1](R/W1S/H) Reads or sets RVU_AF_GEN_INT[MSIX_FAULT]. */
-        uint64_t reserved_2_63         : 62;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_hwvf_rst
- *
- * RVU Admin Function Hardware VF Reset Register
- */
-union cavm_rvu_af_hwvf_rst
-{
-    uint64_t u;
-    struct cavm_rvu_af_hwvf_rst_s
-    {
-        uint64_t hwvf                  : 8;  /**< [  7:  0](R/W) Hardware VF that is reset when [EXEC] is set. */
-        uint64_t reserved_8_11         : 4;
-        uint64_t exec                  : 1;  /**< [ 12: 12](R/W1S/H) Execute HWVF software-initiated reset. When software writes a one to set this bit, hardware
-                                                                 resets the RVUM hardware VF selected by [HWVF] and the
-                                                                 associated MSI-X table in LLC/DRAM specified by
-                                                                 RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_OFFSET,VF_MSIXT_SIZEM1].
-                                                                 Hardware clears this bit when done. */
-        uint64_t reserved_13_63        : 51;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_msixtr_base
- *
- * RVU Admin Function MSI-X Table Region Base-Address Register
- */
-union cavm_rvu_af_msixtr_base
-{
-    uint64_t u;
-    struct cavm_rvu_af_msixtr_base_s
-    {
-        uint64_t reserved_0_6          : 7;
-        uint64_t addr                  : 46; /**< [ 52:  7](R/W) Base AF IOVA of MSI-X table region in LLC/DRAM. IOVA bits \<6:0\> are always zero.
-                                                                 See RVU_PRIV_PF()_MSIX_CFG. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pf_bar4_addr
- *
- * RVU Admin Function PF BAR4 Address Registers
- */
-union cavm_rvu_af_pf_bar4_addr
-{
-    uint64_t u;
-    struct cavm_rvu_af_pf_bar4_addr_s
-    {
-        uint64_t reserved_0_15         : 16;
-        uint64_t addr                  : 48; /**< [ 63: 16](R/W) Programmable base address of up to 16 consecutive 64 KB
-                                                                 pages in DRAM (one per PF). May be used as PF/AF mailbox memory in addition to
-                                                                 RVU_AF_AFPF()_MBOX()/RVU_PF_PFAF_MBOX().
-                                                                 Provides PCC_EA_ENTRY_S[BASEH,BASEL] value advertised by PF BAR4's entry in
-                                                                 PCCPF_XXX_EA_ENTRY(). */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pf_rst
- *
- * RVU Admin Function PF Reset Register
- */
-union cavm_rvu_af_pf_rst
-{
-    uint64_t u;
-    struct cavm_rvu_af_pf_rst_s
-    {
-        uint64_t pf                    : 4;  /**< [  3:  0](R/W) Physical function that is reset when [EXEC] is set. */
-        uint64_t reserved_4_11         : 8;
-        uint64_t exec                  : 1;  /**< [ 12: 12](R/W1S/H) Execute PF software-initiated reset. When software writes a one to set this bit, hardware
-                                                                 resets the RVUM physical function selected by [PF] and the
-                                                                 associated MSI-X table in LLC/DRAM specified by
-                                                                 RVU_PRIV_PF()_MSIX_CFG[PF_MSIXT_OFFSET,PF_MSIXT_SIZEM1].
-                                                                 Hardware clears this bit when done.
-                                                                 Note this does not reset HWVFs which are mapped to the PF. */
-        uint64_t reserved_13_63        : 51;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfaf_mbox_int
- *
- * RVU Admin Function PF to AF Mailbox Interrupt Registers
- */
-union cavm_rvu_af_pfaf_mbox_int
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfaf_mbox_int_s
-    {
-        uint64_t mbox                  : 16; /**< [ 15:  0](R/W1C/H) Mailbox interrupt bit per PF.
-                                                                 Each bit is set when the PF writes to the corresponding
-                                                                 RVU_PF_PFAF_MBOX(1) register. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfaf_mbox_int_ena_w1c
- *
- * RVU Admin Function PF to AF Mailbox Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_af_pfaf_mbox_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfaf_mbox_int_ena_w1c_s
-    {
-        uint64_t mbox                  : 16; /**< [ 15:  0](R/W1C/H) Reads or clears enable for RVU_AF_PFAF_MBOX_INT[MBOX]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfaf_mbox_int_ena_w1s
- *
- * RVU Admin Function PF to AF Mailbox Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_af_pfaf_mbox_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfaf_mbox_int_ena_w1s_s
-    {
-        uint64_t mbox                  : 16; /**< [ 15:  0](R/W1S/H) Reads or sets enable for RVU_AF_PFAF_MBOX_INT[MBOX]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfaf_mbox_int_w1s
- *
- * RVU Admin Function PF to AF Mailbox Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_af_pfaf_mbox_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfaf_mbox_int_w1s_s
-    {
-        uint64_t mbox                  : 16; /**< [ 15:  0](R/W1S/H) Reads or sets RVU_AF_PFAF_MBOX_INT[MBOX]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfflr_int
- *
- * RVU Admin Function PF Function Level Reset Interrupt Registers
- */
-union cavm_rvu_af_pfflr_int
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfflr_int_s
-    {
-        uint64_t flr                   : 16; /**< [ 15:  0](R/W1C/H) FLR interrupt bit per PF.
-
-                                                                 If RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, each bit is set along with
-                                                                 the corresponding bit in RVU_AF_PFTRPEND when function level reset is
-                                                                 initiated for the associated PF, i.e. a one is written to
-                                                                 PCCPF_XXX_E_DEV_CTL[BCR_FLR]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfflr_int_ena_w1c
- *
- * RVU Admin Function PF Function Level Reset Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_af_pfflr_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfflr_int_ena_w1c_s
-    {
-        uint64_t flr                   : 16; /**< [ 15:  0](R/W1C/H) Reads or clears enable for RVU_AF_PFFLR_INT[FLR]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfflr_int_ena_w1s
- *
- * RVU Admin Function PF Function Level Reset Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_af_pfflr_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfflr_int_ena_w1s_s
-    {
-        uint64_t flr                   : 16; /**< [ 15:  0](R/W1S/H) Reads or sets enable for RVU_AF_PFFLR_INT[FLR]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfflr_int_w1s
- *
- * RVU Admin Function PF Function Level Reset Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_af_pfflr_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfflr_int_w1s_s
-    {
-        uint64_t flr                   : 16; /**< [ 15:  0](R/W1S/H) Reads or sets RVU_AF_PFFLR_INT[FLR]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfme_int
- *
- * RVU Admin Function PF Bus Master Enable Interrupt Registers
- */
-union cavm_rvu_af_pfme_int
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfme_int_s
-    {
-        uint64_t me                    : 16; /**< [ 15:  0](R/W1C/H) Master enable interrupt bit per PF.
-                                                                 A device-dependent AF driver typically uses these bits to handle state
-                                                                 changes to PCCPF_XXX_CMD[ME], which are typically modified by
-                                                                 non-device-dependent software only.
-
-                                                                 If RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, each bit is set when the
-                                                                 corresponding PCCPF_XXX_CMD[ME] bit is either set or cleared for the
-                                                                 associated PF. The corresponding bit in RVU_AF_PFME_STATUS returns the
-                                                                 current value of PCCPF_XXX_CMD[ME].
-
-                                                                 Note that if RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, the corresponding
-                                                                 bit in RVU_AF_PFTRPEND is also set when PCCPF_XXX_CMD[ME] is set, but not
-                                                                 when PCCPF_XXX_CMD[ME] is cleared. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfme_int_ena_w1c
- *
- * RVU Admin Function PF Bus Master Enable Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_af_pfme_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfme_int_ena_w1c_s
-    {
-        uint64_t me                    : 16; /**< [ 15:  0](R/W1C/H) Reads or clears enable for RVU_AF_PFME_INT[ME]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfme_int_ena_w1s
- *
- * RVU Admin Function PF Bus Master Enable Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_af_pfme_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfme_int_ena_w1s_s
-    {
-        uint64_t me                    : 16; /**< [ 15:  0](R/W1S/H) Reads or sets enable for RVU_AF_PFME_INT[ME]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfme_int_w1s
- *
- * RVU Admin Function PF Bus Master Enable Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_af_pfme_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfme_int_w1s_s
-    {
-        uint64_t me                    : 16; /**< [ 15:  0](R/W1S/H) Reads or sets RVU_AF_PFME_INT[ME]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pfme_status
- *
- * RVU Admin Function PF Bus Master Enable Status Registers
- */
-union cavm_rvu_af_pfme_status
-{
-    uint64_t u;
-    struct cavm_rvu_af_pfme_status_s
-    {
-        uint64_t me                    : 16; /**< [ 15:  0](RO/H) Bus master enable bit per PF. Each bit returns the PF's
-                                                                 PCCPF_XXX_CMD[ME] value. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pftrpend
- *
- * RVU Admin Function PF Transaction Pending Registers
- */
-union cavm_rvu_af_pftrpend
-{
-    uint64_t u;
-    struct cavm_rvu_af_pftrpend_s
-    {
-        uint64_t trpend                : 16; /**< [ 15:  0](R/W1C/H) Transaction pending bit per PF.
-
-                                                                 A PF's bit is set when RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set and:
-                                                                 * A one is written to the corresponding PCCPF_XXX_E_DEV_CTL[BCR_FLR], or
-                                                                 * PCCPF_XXX_CMD[ME] is set or cleared.
-
-                                                                 When a PF's bit is set, forces the corresponding
-                                                                 PCCPF_XXX_E_DEV_CTL[TRPEND] to be set.
-
-                                                                 Software (typically a device-dependent AF driver) can clear the bit by
-                                                                 writing a 1. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_pftrpend_w1s
- *
- * RVU Admin Function PF Transaction Pending Set Registers
- * This register reads or sets bits.
- */
-union cavm_rvu_af_pftrpend_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_pftrpend_w1s_s
-    {
-        uint64_t trpend                : 16; /**< [ 15:  0](R/W1S/H) Reads or sets RVU_AF_PFTRPEND[TRPEND]. */
-        uint64_t reserved_16_63        : 48;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_ras
- *
- * RVU Admin Function RAS Interrupt Register
- * This register is intended for delivery of RAS events to the SCP, so should be
- * ignored by OS drivers.
- */
-union cavm_rvu_af_ras
-{
-    uint64_t u;
-    struct cavm_rvu_af_ras_s
-    {
-        uint64_t msix_poison           : 1;  /**< [  0:  0](R/W1C/H) Received MSI-X table read response with poisoned data. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_ras_ena_w1c
- *
- * RVU Admin Function RAS Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_af_ras_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_af_ras_ena_w1c_s
-    {
-        uint64_t msix_poison           : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for RVU_AF_RAS[MSIX_POISON]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_ras_ena_w1s
- *
- * RVU Admin Function RAS Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_af_ras_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_ras_ena_w1s_s
-    {
-        uint64_t msix_poison           : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for RVU_AF_RAS[MSIX_POISON]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_af_ras_w1s
- *
- * RVU Admin Function RAS Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_rvu_af_ras_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_af_ras_w1s_s
-    {
-        uint64_t msix_poison           : 1;  /**< [  0:  0](R/W1S/H) Reads or sets RVU_AF_RAS[MSIX_POISON]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_block_addr#_disc
- *
- * RVU PF Block Address Discovery Registers
- * These registers allow each PF driver to discover block resources that are
- * provisioned to its PF. The register's block address index is enumerated by
- * RVU_BLOCK_ADDR_E.
- */
-union cavm_rvu_pf_block_addrx_disc
-{
-    uint64_t u;
-    struct cavm_rvu_pf_block_addrx_disc_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](RO/H) Number of local functions from the block that are provisioned to the VF/PF.
-                                                                 When non-zero, the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in
-                                                                 the block.
-                                                                 Returns 0 for block types that do not have local functions, 0 or 1 for
-                                                                 single-slot blocks; see RVU_BLOCK_TYPE_E. */
-        uint64_t reserved_9_10         : 2;
-        uint64_t imp                   : 1;  /**< [ 11: 11](RO/H) Implemented. When set, a block is present at this block address index as
-                                                                 enumerated by RVU_BLOCK_ADDR_E. When clear, a block is not present and the
-                                                                 remaining fields in the register are RAZ.
-
-                                                                 Internal:
-                                                                 Returns zero if the block is implemented but fused out. */
-        uint64_t rid                   : 8;  /**< [ 19: 12](RO/H) Revision ID of the block from RVU_PRIV_BLOCK_TYPE()_REV[RID]. */
-        uint64_t btype                 : 8;  /**< [ 27: 20](RO/H) Block type enumerated by RVU_BLOCK_TYPE_E. */
-        uint64_t reserved_28_63        : 36;
-    } s;
-    /* struct cavm_rvu_pf_block_addrx_disc_s cn; */
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_int
- *
- * RVU PF Interrupt Registers
- */
-union cavm_rvu_pf_int
-{
-    uint64_t u;
-    struct cavm_rvu_pf_int_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1C/H) AF to PF mailbox interrupt. Set when RVU_AF_AFPF()_MBOX(0) is written. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_int_ena_w1c
- *
- * RVU PF Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_pf_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_pf_int_ena_w1c_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for RVU_PF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_int_ena_w1s
- *
- * RVU PF Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_pf_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_pf_int_ena_w1s_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for RVU_PF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_int_w1s
- *
- * RVU PF Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_rvu_pf_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_pf_int_w1s_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets RVU_PF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_msix_pba#
- *
- * RVU PF MSI-X Pending-Bit-Array Registers
- * This register is the MSI-X PF PBA table.
- */
-union cavm_rvu_pf_msix_pbax
-{
-    uint64_t u;
-    struct cavm_rvu_pf_msix_pbax_s
-    {
-        uint64_t pend                  : 64; /**< [ 63:  0](RO/H) Pending message bit for each MSI-X vector, i.e. one bit per
-                                                                 RVU_PF_MSIX_VEC()_CTL register.
-                                                                 The total number of bits for a given PF (and thus the number of PBA
-                                                                 registers) is determined by RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_SIZEM1]
-                                                                 (plus 1). */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_msix_vec#_addr
- *
- * RVU PF MSI-X Vector-Table Address Registers
- * These registers and RVU_PF_MSIX_VEC()_CTL form the PF MSI-X vector table.
- * The number of MSI-X vectors for a given PF is specified by
- * RVU_PRIV_PF()_MSIX_CFG[PF_MSIXT_SIZEM1] (plus 1).
- *
- * Internal:
- * PF vector count of 256 is sized to allow up to 120 for AF, 4 for PF/VF
- * mailboxes, and 128 for LF resources from various blocks that are directly
- * provisioned to the PF.
- */
-union cavm_rvu_pf_msix_vecx_addr
-{
-    uint64_t u;
-    struct cavm_rvu_pf_msix_vecx_addr_s
-    {
-        uint64_t secvec                : 1;  /**< [  0:  0](SR/W) Secure vector.
-                                                                 0 = This vector may be read or written by either secure or nonsecure states.
-                                                                 1 = This vector's RVU_PF_MSIX_VEC()_ADDR, RVU_PF_MSIX_VEC()_CTL, and
-                                                                 corresponding bit of RVU_PF_MSIX_PBA() are RAZ/WI and does not cause a
-                                                                 fault when accessed by the nonsecure world.
-
-                                                                 If PCCPF_RVU_VSEC_SCTL[MSIX_SEC] (for documentation, see
-                                                                 PCCPF_XXX_VSEC_SCTL[MSIX_SEC]) is set, all vectors of the function are
-                                                                 secure as if [SECVEC] was set. */
-        uint64_t reserved_1            : 1;
-        uint64_t addr                  : 51; /**< [ 52:  2](R/W) PF IOVA to use for MSI-X delivery of this vector. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_msix_vec#_ctl
- *
- * RVU PF MSI-X Vector-Table Control and Data Registers
- * These registers and RVU_PF_MSIX_VEC()_ADDR form the PF MSI-X vector table.
- */
-union cavm_rvu_pf_msix_vecx_ctl
-{
-    uint64_t u;
-    struct cavm_rvu_pf_msix_vecx_ctl_s
-    {
-        uint64_t data                  : 32; /**< [ 31:  0](R/W) Data to use for MSI-X delivery of this vector. */
-        uint64_t mask                  : 1;  /**< [ 32: 32](R/W) When set, no MSI-X interrupts are sent to this vector. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_pfaf_mbox#
- *
- * RVU PF/AF Mailbox Registers
- */
-union cavm_rvu_pf_pfaf_mboxx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_pfaf_mboxx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Mailbox data. These PF registers access the 16-byte-per-PF PF/AF
-                                                                 mailbox.  The AF may access the same storage using
-                                                                 RVU_AF_AFPF()_MBOX(). MBOX(0) is typically used for AF to PF
-                                                                 signaling, MBOX(1) for PF to AF.
-                                                                 Writing RVU_PF_PFAF_MBOX(1) (but not RVU_AF_AFPF()_MBOX(1))
-                                                                 will set the corresponding RVU_AF_PFAF_MBOX_INT bit, which if appropriately
-                                                                 enabled will send an interrupt to the AF. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vf#_pfvf_mbox#
- *
- * RVU PF/VF Mailbox Registers
- */
-union cavm_rvu_pf_vfx_pfvf_mboxx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfx_pfvf_mboxx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Mailbox data. These PF registers access the 16-byte-per-VF VF/PF mailbox
-                                                                 RAM. Each corresponding VF may access the same storage using
-                                                                 RVU_VF_VFPF_MBOX(). MBOX(0) is typically used for PF to VF
-                                                                 signaling, MBOX(1) for VF to PF. Writing RVU_PF_VF()_PFVF_MBOX(0) (but
-                                                                 not RVU_VF_VFPF_MBOX(0)) will set the corresponding
-                                                                 RVU_VF_INT[MBOX] which if appropriately enabled will send an
-                                                                 interrupt to the VF. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vf_bar4_addr
- *
- * RVU PF VF BAR4 Address Registers
- */
-union cavm_rvu_pf_vf_bar4_addr
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vf_bar4_addr_s
-    {
-        uint64_t reserved_0_15         : 16;
-        uint64_t addr                  : 48; /**< [ 63: 16](R/W) Programmable base address of RVU_PRIV_PF()_CFG[NVF] consecutive 64 KB
-                                                                 pages in DRAM. May be used as VF/PF mailbox memory in addition to
-                                                                 RVU_PF_VF()_PFVF_MBOX()/RVU_VF_VFPF_MBOX().
-                                                                 Provides PCC_EA_ENTRY_S[BASEH,BASEL] value advertised by VF BAR4's entry in
-                                                                 PCCPF_XXX_EA_ENTRY(). */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfflr_int#
- *
- * RVU PF VF Function Level Reset Interrupt Registers
- */
-union cavm_rvu_pf_vfflr_intx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfflr_intx_s
-    {
-        uint64_t flr                   : 64; /**< [ 63:  0](R/W1C/H) FLR interrupt bit per VF (RVU_PF_VFFLR_INT({a})[FLR]\<{b}\> for VF
-                                                                 number 64*{a} + {b}).
-                                                                 If RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, each bit is set along with
-                                                                 the corresponding bit in RVU_PF_VFTRPEND() when function level reset is
-                                                                 initiated for the associated VF, i.e. a one is written to
-                                                                 PCCVF_XXX_E_DEV_CTL[BCR_FLR]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfflr_int_ena_w1c#
- *
- * RVU PF VF Function Level Reset Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_pf_vfflr_int_ena_w1cx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfflr_int_ena_w1cx_s
-    {
-        uint64_t flr                   : 64; /**< [ 63:  0](R/W1C/H) Reads or clears enable for RVU_PF_VFFLR_INT(0..1)[FLR]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfflr_int_ena_w1s#
- *
- * RVU PF VF Function Level Reset Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_pf_vfflr_int_ena_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfflr_int_ena_w1sx_s
-    {
-        uint64_t flr                   : 64; /**< [ 63:  0](R/W1S/H) Reads or sets enable for RVU_PF_VFFLR_INT(0..1)[FLR]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfflr_int_w1s#
- *
- * RVU PF VF Function Level Reset Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_pf_vfflr_int_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfflr_int_w1sx_s
-    {
-        uint64_t flr                   : 64; /**< [ 63:  0](R/W1S/H) Reads or sets RVU_PF_VFFLR_INT(0..1)[FLR]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfme_int#
- *
- * RVU PF VF Bus Master Enable Interrupt Registers
- */
-union cavm_rvu_pf_vfme_intx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfme_intx_s
-    {
-        uint64_t me                    : 64; /**< [ 63:  0](R/W1C/H) Master enable interrupt bit per VF (RVU_PF_VFME_INT({a})[ME]\<{b}\> for VF
-                                                                 number 64*{a} + {b}).
-                                                                 A device-dependent PF driver typically uses these bits to handle state
-                                                                 changes to PCCPF_XXX_CMD[ME], which are typically modified by
-                                                                 non-device-dependent software only.
-
-                                                                 If RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, each bit is set when the
-                                                                 corresponding PCCVF_XXX_CMD[ME] bit is either set or cleared for the
-                                                                 associated PF. The corresponding bit in RVU_PF_VFME_STATUS() returns the
-                                                                 current value of PCCVF_XXX_CMD[ME].
-
-                                                                 If RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set, the corresponding bit in
-                                                                 RVU_PF_VFTRPEND() is also set when PCCVF_XXX_CMD[ME] is set, but not
-                                                                 when PCCVF_XXX_CMD[ME] is cleared. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfme_int_ena_w1c#
- *
- * RVU PF VF Bus Master Enable Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_pf_vfme_int_ena_w1cx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfme_int_ena_w1cx_s
-    {
-        uint64_t me                    : 64; /**< [ 63:  0](R/W1C/H) Reads or clears enable for RVU_PF_VFME_INT(0..1)[ME]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfme_int_ena_w1s#
- *
- * RVU PF VF Bus Master Enable Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_pf_vfme_int_ena_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfme_int_ena_w1sx_s
-    {
-        uint64_t me                    : 64; /**< [ 63:  0](R/W1S/H) Reads or sets enable for RVU_PF_VFME_INT(0..1)[ME]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfme_int_w1s#
- *
- * RVU PF VF Bus Master Enable Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_pf_vfme_int_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfme_int_w1sx_s
-    {
-        uint64_t me                    : 64; /**< [ 63:  0](R/W1S/H) Reads or sets RVU_PF_VFME_INT(0..1)[ME]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfme_status#
- *
- * RVU PF VF Bus Master Enable Status Registers
- */
-union cavm_rvu_pf_vfme_statusx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfme_statusx_s
-    {
-        uint64_t me                    : 64; /**< [ 63:  0](RO/H) Bus master enable bit per VF (RVU_PF_VFME_STATUS({a})[ME]\<{b}\> for VF
-                                                                 number 64*{a} + {b}).
-                                                                 Each bit returns the VF's PCCVF_XXX_CMD[ME] value. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfpf_mbox_int#
- *
- * RVU VF to PF Mailbox Interrupt Registers
- */
-union cavm_rvu_pf_vfpf_mbox_intx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfpf_mbox_intx_s
-    {
-        uint64_t mbox                  : 64; /**< [ 63:  0](R/W1C/H) Mailbox interrupt bit per VF (RVU_PF_VFPF_MBOX_INT({a})[MBOX]\<{b}\> for VF
-                                                                 number 64*{a} + {b}).
-                                                                 Each bit is set when the VF writes to the corresponding
-                                                                 RVU_VF_VFPF_MBOX(1) register. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfpf_mbox_int_ena_w1c#
- *
- * RVU VF to PF Mailbox Interrupt Enable Clear Registers
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_pf_vfpf_mbox_int_ena_w1cx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfpf_mbox_int_ena_w1cx_s
-    {
-        uint64_t mbox                  : 64; /**< [ 63:  0](R/W1C/H) Reads or clears enable for RVU_PF_VFPF_MBOX_INT(0..1)[MBOX]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfpf_mbox_int_ena_w1s#
- *
- * RVU VF to PF Mailbox Interrupt Enable Set Registers
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_pf_vfpf_mbox_int_ena_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfpf_mbox_int_ena_w1sx_s
-    {
-        uint64_t mbox                  : 64; /**< [ 63:  0](R/W1S/H) Reads or sets enable for RVU_PF_VFPF_MBOX_INT(0..1)[MBOX]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vfpf_mbox_int_w1s#
- *
- * RVU VF to PF Mailbox Interrupt Set Registers
- * This register sets interrupt bits.
- */
-union cavm_rvu_pf_vfpf_mbox_int_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vfpf_mbox_int_w1sx_s
-    {
-        uint64_t mbox                  : 64; /**< [ 63:  0](R/W1S/H) Reads or sets RVU_PF_VFPF_MBOX_INT(0..1)[MBOX]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vftrpend#
- *
- * RVU PF VF Transaction Pending Registers
- */
-union cavm_rvu_pf_vftrpendx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vftrpendx_s
-    {
-        uint64_t trpend                : 64; /**< [ 63:  0](R/W1C/H) Transaction pending bit per VF (RVU_PF_VFTRPEND({a})[TRPEND]\<{b}\> for VF
-                                                                 number 64*{a} + {b}).
-
-                                                                 A VF's bit is set when RVU_PRIV_PF()_CFG[ME_FLR_ENA] is set and:
-                                                                 * A one is written to the corresponding PCCVF_XXX_E_DEV_CTL[BCR_FLR], or
-                                                                 * PCCVF_XXX_CMD[ME] is set or cleared.
-
-                                                                 When a VF's bit is set, forces the corresponding
-                                                                 PCCVF_XXX_E_DEV_CTL[TRPEND] to be set.
-
-                                                                 Software (typically a device-dependent PF driver) can clear the bit by
-                                                                 writing a 1. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR2) rvu_pf_vftrpend_w1s#
- *
- * RVU PF VF Transaction Pending Set Registers
- * This register reads or sets bits.
- */
-union cavm_rvu_pf_vftrpend_w1sx
-{
-    uint64_t u;
-    struct cavm_rvu_pf_vftrpend_w1sx_s
-    {
-        uint64_t trpend                : 64; /**< [ 63:  0](R/W1S/H) Reads or sets RVU_PF_VFTRPEND(0..1)[TRPEND]. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_active_pc
- *
- * RVU Active Program Counter Register
- */
-union cavm_rvu_priv_active_pc
-{
-    uint64_t u;
-    struct cavm_rvu_priv_active_pc_s
-    {
-        uint64_t active_pc             : 64; /**< [ 63:  0](R/W/H) This register increments on every coprocessor-clock cycle that the RVU conditional clocks
-                                                                 are enabled. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_block_type#_rev
- *
- * RVU Privileged Block Type Revision Registers
- * These registers are used by configuration software to specify the revision ID
- * of each block type enumerated by RVU_BLOCK_TYPE_E, to assist VF/PF software
- * discovery.
- */
-union cavm_rvu_priv_block_typex_rev
-{
-    uint64_t u;
-    struct cavm_rvu_priv_block_typex_rev_s
-    {
-        uint64_t rid                   : 8;  /**< [  7:  0](R/W) Revision ID of the block. This is the read value returned by
-                                                                 RVU_VF_BLOCK_ADDR()_DISC[RID]. */
-        uint64_t reserved_8_63         : 56;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_clk_cfg
- *
- * RVU Privileged General Configuration Register
- */
-union cavm_rvu_priv_clk_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_clk_cfg_s
-    {
-        uint64_t blk_clken             : 1;  /**< [  0:  0](R/W) Force RVUM conditional clock to always be enabled. For diagnostic use only. */
-        uint64_t ncbi_clken            : 1;  /**< [  1:  1](R/W) Force the NCB interface conditional clocking and NCBI bus clock to be always on.
-                                                                 For diagnostic use only. */
-        uint64_t reserved_2_63         : 62;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_const
- *
- * RVU Privileged Constants Register
- * This register contains constants for software discovery.
- */
-union cavm_rvu_priv_const
-{
-    uint64_t u;
-    struct cavm_rvu_priv_const_s
-    {
-        uint64_t max_msix              : 20; /**< [ 19:  0](RO) Combined maximum number of MSI-X vectors that may be provisioned to the RVU
-                                                                 PFs and VFs. Also the maximum number of 16-byte RVU_MSIX_VEC_S structures
-                                                                 in RVU's MSI-X table region in LLC/DRAM. See RVU_PRIV_PF()_MSIX_CFG.
-
-                                                                 Internal:
-                                                                 Also, size of RVU's internal PBA memory.
-
-                                                                 Sized as follows:
-                                                                 \<pre\>
-                                                                 AP cores                     24
-                                                                 Vectors per LF:
-                                                                    NIX CINT                  32
-                                                                    NIX QINT                  32
-                                                                    NIX GINT                  1
-                                                                    NPA QINT                  32
-                                                                    NPA GINT                  1
-                                                                    SSO                       1
-                                                                    TIM                       1
-                                                                    CPT                       1
-                                                                    RVU                       1
-                                                                    Total per LF:             \<128
-                                                                 Num LFs                      256
-                                                                 Total LF vectors             \<32K
-                                                                 Total AF vectors             64 (budget 16 blocks * 4)
-                                                                 Total vectors budget         32K
-                                                                 \</pre\> */
-        uint64_t hwvfs                 : 12; /**< [ 31: 20](RO) Number of RVU hardware VFs (HWVFs). */
-        uint64_t pfs                   : 8;  /**< [ 39: 32](RO) Number of RVU PFs. */
-        uint64_t max_vfs_per_pf        : 8;  /**< [ 47: 40](RO) Maximum number of VFs per RVU PF. */
-        uint64_t reserved_48_63        : 16;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_gen_cfg
- *
- * RVU Privileged General Configuration Register
- */
-union cavm_rvu_priv_gen_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_gen_cfg_s
-    {
-        uint64_t lock                  : 1;  /**< [  0:  0](R/W1S) Lock privileged registers. When set, all privileged registers in RVU and
-                                                                 its resource blocks are locked down and cannot be modified. Writing a 1
-                                                                 sets this bit; once set, the bit can only be cleared by core reset. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_cpt#_cfg
- *
- * RVU Privileged Hardware VF CPT Configuration Registers
- * Similar to RVU_PRIV_HWVF()_NIX()_CFG, but for CPT({a}) block.
- */
-union cavm_rvu_priv_hwvfx_cptx_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_cptx_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_int_cfg
- *
- * RVU Privileged Hardware VF Interrupt Configuration Registers
- */
-union cavm_rvu_priv_hwvfx_int_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_int_cfg_s
-    {
-        uint64_t msix_offset           : 11; /**< [ 10:  0](R/W) MSI-X offset. Offset of VF interrupt vectors enumerated by RVU_VF_INT_VEC_E
-                                                                 in the HWVF's MSI-X table. This is added to each enumerated value to obtain
-                                                                 the corresponding MSI-X vector index.
-                                                                 The highest enumerated value plus [MSIX_OFFSET] must be less than or equal
-                                                                 to RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_SIZEM1]. */
-        uint64_t reserved_11           : 1;
-        uint64_t msix_size             : 8;  /**< [ 19: 12](RO) Number of interrupt vectors enumerated by RVU_VF_INT_VEC_E. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_nix#_cfg
- *
- * RVU Privileged Hardware VF NIX Configuration Registers
- * These registers are used to assist VF software discovery. For each HWVF, if the
- * HWVF is mapped to a VF by RVU_PRIV_PF()_CFG[FIRST_HWVF,NVF], software
- * writes NIX block's resource configuration for the VF in this register. The VF
- * driver can read RVU_VF_BLOCK_ADDR()_DISC to discover the configuration.
- */
-union cavm_rvu_priv_hwvfx_nixx_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_nixx_cfg_s
-    {
-        uint64_t has_lf                : 1;  /**< [  0:  0](R/W) Set when an LF from the block is provisioned to the VF, clear otherwise. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_npa_cfg
- *
- * RVU Privileged Hardware VF NPA Configuration Registers
- * Similar to RVU_PRIV_HWVF()_NIX()_CFG, but for NPA block.
- */
-union cavm_rvu_priv_hwvfx_npa_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_npa_cfg_s
-    {
-        uint64_t has_lf                : 1;  /**< [  0:  0](R/W) Set when an LF from the block is provisioned to the VF, clear otherwise. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_sso_cfg
- *
- * RVU Privileged Hardware VF SSO Configuration Registers
- * Similar to RVU_PRIV_HWVF()_NIX()_CFG, but for SSO block.
- */
-union cavm_rvu_priv_hwvfx_sso_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_sso_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_ssow_cfg
- *
- * RVU Privileged Hardware VF SSO Work Slot Configuration Registers
- * Similar to RVU_PRIV_HWVF()_NIX()_CFG, but for SSOW block.
- */
-union cavm_rvu_priv_hwvfx_ssow_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_ssow_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_hwvf#_tim_cfg
- *
- * RVU Privileged Hardware VF SSO Work Slot Configuration Registers
- * Similar to RVU_PRIV_HWVF()_NIX()_CFG, but for TIM block.
- */
-union cavm_rvu_priv_hwvfx_tim_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_hwvfx_tim_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_cfg
- *
- * RVU Privileged PF Configuration Registers
- */
-union cavm_rvu_priv_pfx_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_cfg_s
-    {
-        uint64_t first_hwvf            : 12; /**< [ 11:  0](R/W) HWVF index of the PF's first VF.  Valid when [NVF] is non-zero. The HWVF
-                                                                 index range for the PF is [FIRST_HWVF] to [FIRST_HWVF]+[NVF]-1, inclusive.
-                                                                 Different PFs must have non-overlapping HWVF ranges, and the maximum HWVF
-                                                                 index in any range must be less than RVU_PRIV_CONST[HWVFS]. */
-        uint64_t nvf                   : 8;  /**< [ 19: 12](R/W) Number of VFs in the PF. Must be less than or equal to
-                                                                 RVU_PRIV_CONST[MAX_VFS_PER_PF]. */
-        uint64_t ena                   : 1;  /**< [ 20: 20](R/W) Enable the PF. When clear, the PF is unused and hidden in the PCI config
-                                                                 space, and access to the PF's MSI-X tables in RVU PF/FUNC BAR2 is
-                                                                 disabled.
-                                                                 When set, the PF is enabled and remaining fields in this register are
-                                                                 valid.
-
-                                                                 Software should keep this bit set for PF(0) when RVU is used. Hardware
-                                                                 delivers all AF interrupts to PF(0). */
-        uint64_t af_ena                : 1;  /**< [ 21: 21](R/W) Admin function enable. When set, the PF is allowed to access AF
-                                                                 (RVU PF BAR0) registers in all RVU blocks. When clear, the PF is not
-                                                                 allowed to access AF registers. Must be clear when [ENA] is clear.
-
-                                                                 Software should keep this bit set for PF(0) when RVU is used. */
-        uint64_t me_flr_ena            : 1;  /**< [ 22: 22](R/W) Bus master enable (ME) and function level reset (FLR) enable. This bit
-                                                                 should be set when the PF is configured and associated PF and/or AF drivers
-                                                                 that manage VF and/or PF ME/FLR are loaded.
-
-                                                                 When clear, PCCPF/PCCVF_XXX_CMD[ME] state changes are ignored, and
-                                                                 PCCPF/PCCVF_XXX_E_DEV_CTL[BCR_FLR] reset the PF/VF configuration space.
-
-                                                                 When set, hardware updates to the following registers in response to ME/FLR
-                                                                 events are additionally enabled:
-                                                                 RVU_PF_VFTRPEND(), RVU_PF_VFFLR_INT(), RVU_PF_VFME_INT(),
-                                                                 RVU_AF_PFTRPEND, RVU_AF_PFFLR_INT, and RVU_AF_PFFLR_INT. */
-        uint64_t reserved_23_63        : 41;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_cpt#_cfg
- *
- * RVU Privileged PF CPT Configuration Registers
- * Similar to RVU_PRIV_PF()_NIX()_CFG, but for CPT({a}) block.
- */
-union cavm_rvu_priv_pfx_cptx_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_cptx_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_id_cfg
- *
- * RVU Privileged PF ID Configuration Registers
- */
-union cavm_rvu_priv_pfx_id_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_id_cfg_s
-    {
-        uint64_t pf_devid              : 8;  /**< [  7:  0](R/W) Lower bits of PF device ID to be presented in PCCPF_XXX_ID[DEVID]\<7:0\>.
-                                                                 Resets to PCC_DEV_IDL_E::RVU_AF for PF(0), PCC_DEV_IDL_E::RVU for other
-                                                                 PFs. */
-        uint64_t vf_devid              : 8;  /**< [ 15:  8](R/W) Lower bits of VF device ID to be presented in PCCPF_XXX_SRIOV_DEV[VFDEV]\<7:0\>.
-                                                                 Resets to PCC_DEV_IDL_E::RVU_VF. */
-        uint64_t class_code            : 24; /**< [ 39: 16](R/W) Class code to be presented in PCCPF_XXX_REV[BCC,SC,PI] and
-                                                                 PCCVF_XXX_REV[BCC,SC,PI]. Format specified by PCC_CLASS_CODE_S.
-                                                                 Resets to PCC_DEV_IDL_E::RVU's class code. */
-        uint64_t reserved_40_63        : 24;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_int_cfg
- *
- * RVU Privileged PF Interrupt Configuration Registers
- */
-union cavm_rvu_priv_pfx_int_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_int_cfg_s
-    {
-        uint64_t msix_offset           : 11; /**< [ 10:  0](R/W) MSI-X offset. Offset of PF interrupt vectors enumerated by RVU_PF_INT_VEC_E
-                                                                 in the PF's MSI-X table. This is added to each enumerated value to obtain
-                                                                 the corresponding MSI-X vector index.
-                                                                 The highest enumerated value plus [MSIX_OFFSET] must be less than or equal
-                                                                 to RVU_PRIV_PF()_MSIX_CFG[PF_MSIXT_SIZEM1].
-
-                                                                 Note that the AF interrupt vectors enumerated by RVU_AF_INT_VEC_E have a
-                                                                 fixed starting offset of 0 in RVU PF(0)'s MSI-X table. Other PF
-                                                                 interrupt vectors should not be mapped at the offsets used by RVU_AF_INT_VEC_E. */
-        uint64_t reserved_11           : 1;
-        uint64_t msix_size             : 8;  /**< [ 19: 12](RO) Number of interrupt vectors enumerated by RVU_PF_INT_VEC_E. */
-        uint64_t reserved_20_63        : 44;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_msix_cfg
- *
- * RVU Privileged PF MSI-X Configuration Registers
- * These registers specify MSI-X table sizes and locations for RVU PFs and
- * associated VFs. Hardware maintains all RVU MSI-X tables in a contiguous memory
- * region in LLC/DRAM called the MSI-X table region. The table region's base AF IOVA
- * is specified by RVU_AF_MSIXTR_BASE, and its size as a multiple of
- * 16-byte RVU_MSIX_VEC_S structures must be less than or equal to
- * RVU_PRIV_CONST[MAX_MSIX].
- *
- * A PF's MSI-X table consists of the following range of RVU_MSIX_VEC_S structures
- * in the table region:
- * * First index: [PF_MSIXT_OFFSET].
- * * Last index: [PF_MSIXT_OFFSET] + [PF_MSIXT_SIZEM1].
- *
- * If a PF has enabled VFs (associated RVU_PRIV_PF()_CFG[NVF] is nonzero),
- * then each VF's MSI-X table consumes the following range of RVU_MSIX_VEC_S structures:
- * * First index: [VF_MSIXT_OFFSET] + N*([VF_MSIXT_SIZEM1] + 1).
- * * Last index: [VF_MSIXT_OFFSET] + N*([VF_MSIXT_SIZEM1] + 1) + [VF_MSIXT_SIZEM1].
- *
- * N=0 for the first VF, N=1 for the second VF, etc.
- *
- * Different PFs and VFs must have non-overlapping vector ranges, and the last
- * index of any range must be less than RVU_PRIV_CONST[MAX_MSIX].
- */
-union cavm_rvu_priv_pfx_msix_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_msix_cfg_s
-    {
-        uint64_t vf_msixt_sizem1       : 12; /**< [ 11:  0](R/W) Each VF's MSI-X table size (number of MSI-X vectors) minus one.
-                                                                 Valid when RVU_PRIV_PF()_CFG[NVF] is nonzero. */
-        uint64_t vf_msixt_offset       : 20; /**< [ 31: 12](R/W) Starting offset of first VF's MSI-X table in the RVU MSI-X table region.
-                                                                 Valid when RVU_PRIV_PF()_CFG[NVF] is nonzero.
-
-                                                                 Internal:
-                                                                 Also, bit offset of the first VF's PBA table in RVU's internal PBA memory. */
-        uint64_t pf_msixt_sizem1       : 12; /**< [ 43: 32](R/W) PF's MSI-X table size (number of MSI-X vectors) minus one. */
-        uint64_t pf_msixt_offset       : 20; /**< [ 63: 44](R/W) Starting offset of PF's MSI-X table in the RVU MSI-X table region.
-                                                                 Internal:
-                                                                 Also, bit offset of the PF's PBA table in RVU's internal PBA memory. */
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_nix#_cfg
- *
- * RVU Privileged PF NIX Configuration Registers
- * These registers are used to assist PF software discovery. For each enabled RVU
- * PF, software writes the block's resource configuration for the PF in this
- * register. The PF driver can read RVU_PF_BLOCK_ADDR()_DISC to discover the
- * configuration.
- */
-union cavm_rvu_priv_pfx_nixx_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_nixx_cfg_s
-    {
-        uint64_t has_lf                : 1;  /**< [  0:  0](R/W) Set when an LF from the block is provisioned to the VF, clear otherwise. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_npa_cfg
- *
- * RVU Privileged PF NPA Configuration Registers
- * Similar to RVU_PRIV_PF()_NIX()_CFG, but for NPA block.
- */
-union cavm_rvu_priv_pfx_npa_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_npa_cfg_s
-    {
-        uint64_t has_lf                : 1;  /**< [  0:  0](R/W) Set when an LF from the block is provisioned to the VF, clear otherwise. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_sso_cfg
- *
- * RVU Privileged PF SSO Configuration Registers
- * Similar to RVU_PRIV_PF()_NIX()_CFG, but for SSO block.
- */
-union cavm_rvu_priv_pfx_sso_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_sso_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_ssow_cfg
- *
- * RVU Privileged PF SSO Work Slot Configuration Registers
- * Similar to RVU_PRIV_PF()_NIX()_CFG, but for SSOW block.
- */
-union cavm_rvu_priv_pfx_ssow_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_ssow_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_PF_BAR0) rvu_priv_pf#_tim_cfg
- *
- * RVU Privileged PF SSO Work Slot Configuration Registers
- * Similar to RVU_PRIV_PF()_NIX()_CFG, but for TIM block.
- */
-union cavm_rvu_priv_pfx_tim_cfg
-{
-    uint64_t u;
-    struct cavm_rvu_priv_pfx_tim_cfg_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](R/W) Number of LFs from the block that are provisioned to the PF/VF. When non-zero,
-                                                                 the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in the block. */
-        uint64_t reserved_9_63         : 55;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_block_addr#_disc
- *
- * RVU VF Block Address Discovery Registers
- * These registers allow each VF driver to discover block resources that are
- * provisioned to its VF. The register's block address index is enumerated by
- * RVU_BLOCK_ADDR_E.
- */
-union cavm_rvu_vf_block_addrx_disc
-{
-    uint64_t u;
-    struct cavm_rvu_vf_block_addrx_disc_s
-    {
-        uint64_t num_lfs               : 9;  /**< [  8:  0](RO/H) Number of local functions from the block that are provisioned to the VF/PF.
-                                                                 When non-zero, the provisioned LFs are mapped to slots 0 to [NUM_LFS]-1 in
-                                                                 the block.
-                                                                 Returns 0 for block types that do not have local functions, 0 or 1 for
-                                                                 single-slot blocks; see RVU_BLOCK_TYPE_E. */
-        uint64_t reserved_9_10         : 2;
-        uint64_t imp                   : 1;  /**< [ 11: 11](RO/H) Implemented. When set, a block is present at this block address index as
-                                                                 enumerated by RVU_BLOCK_ADDR_E. When clear, a block is not present and the
-                                                                 remaining fields in the register are RAZ.
-
-                                                                 Internal:
-                                                                 Returns zero if the block is implemented but fused out. */
-        uint64_t rid                   : 8;  /**< [ 19: 12](RO/H) Revision ID of the block from RVU_PRIV_BLOCK_TYPE()_REV[RID]. */
-        uint64_t btype                 : 8;  /**< [ 27: 20](RO/H) Block type enumerated by RVU_BLOCK_TYPE_E. */
-        uint64_t reserved_28_63        : 36;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_int
- *
- * RVU VF Interrupt Registers
- */
-union cavm_rvu_vf_int
-{
-    uint64_t u;
-    struct cavm_rvu_vf_int_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1C/H) PF to VF mailbox interrupt. Set when RVU_PF_VF()_PFVF_MBOX(0) is written. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_int_ena_w1c
- *
- * RVU VF Interrupt Enable Clear Register
- * This register clears interrupt enable bits.
- */
-union cavm_rvu_vf_int_ena_w1c
-{
-    uint64_t u;
-    struct cavm_rvu_vf_int_ena_w1c_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1C/H) Reads or clears enable for RVU_VF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_int_ena_w1s
- *
- * RVU VF Interrupt Enable Set Register
- * This register sets interrupt enable bits.
- */
-union cavm_rvu_vf_int_ena_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_vf_int_ena_w1s_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets enable for RVU_VF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_int_w1s
- *
- * RVU VF Interrupt Set Register
- * This register sets interrupt bits.
- */
-union cavm_rvu_vf_int_w1s
-{
-    uint64_t u;
-    struct cavm_rvu_vf_int_w1s_s
-    {
-        uint64_t mbox                  : 1;  /**< [  0:  0](R/W1S/H) Reads or sets RVU_VF_INT[MBOX]. */
-        uint64_t reserved_1_63         : 63;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_msix_pba#
- *
- * RVU VF MSI-X Pending-Bit-Array Registers
- * This register is the MSI-X VF PBA table.
- */
-union cavm_rvu_vf_msix_pbax
-{
-    uint64_t u;
-    struct cavm_rvu_vf_msix_pbax_s
-    {
-        uint64_t pend                  : 64; /**< [ 63:  0](RO/H) Pending message bit for each MSI-X vector, i.e. one bit per
-                                                                 RVU_VF_MSIX_VEC()_CTL register.
-                                                                 The total number of bits for a given VF (and thus the number of PBA
-                                                                 registers) is determined by RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_SIZEM1]
-                                                                 (plus 1). */
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_msix_vec#_addr
- *
- * RVU VF MSI-X Vector-Table Address Registers
- * These registers and RVU_VF_MSIX_VEC()_CTL form the VF MSI-X vector table.
- * The number of MSI-X vectors for a given VF is specified by
- * RVU_PRIV_PF()_MSIX_CFG[VF_MSIXT_SIZEM1] (plus 1).
- *
- * Internal:
- * VF vector count of 128 allows up to that number to be provisioned to the VF
- * from LF resources of various blocks.
- */
-union cavm_rvu_vf_msix_vecx_addr
-{
-    uint64_t u;
-    struct cavm_rvu_vf_msix_vecx_addr_s
-    {
-        uint64_t secvec                : 1;  /**< [  0:  0](SR/W) Secure vector.
-                                                                 0 = This vector may be read or written by either secure or nonsecure states.
-                                                                 1 = This vector's RVU_VF_MSIX_VEC()_ADDR, RVU_VF_MSIX_VEC()_CTL, and
-                                                                 corresponding bit of RVU_VF_MSIX_PBA() are RAZ/WI and does not cause a
-                                                                 fault when accessed by the nonsecure world.
-
-                                                                 If PCCPF_RVU_VSEC_SCTL[MSIX_SEC] (for documentation, see
-                                                                 PCCPF_XXX_VSEC_SCTL[MSIX_SEC]) is set, all vectors of the function are
-                                                                 secure as if [SECVEC] was set.
-
-                                                                 Also note the following:
-                                                                 * When PCCPF_XXX_VSEC_SCTL[MSIX_SEC_EN]=1, all secure vectors (including secure
-                                                                 VF vectors) will act as if PCCPF/PCCVF_XXX_MSIX_CAP_HDR[MSIXEN]=1,
-                                                                 PCCPF/PCCVF_XXX_MSIX_CAP_HDR[FUNM]=0 and PCCPF/PCCVF_XXX_CMD[ME]=1.
-                                                                 * When PCCPF_XXX_VSEC_SCTL[MSIX_SEC_PHYS]=1, all secure vectors (including
-                                                                 secure VF vectors) are considered physical, regardless of
-                                                                 PCCPF_XXX_VSEC_SCTL[MSIX_PHYS]. */
-        uint64_t reserved_1            : 1;
-        uint64_t addr                  : 51; /**< [ 52:  2](R/W) VF IOVA to use for MSI-X delivery of this vector. */
-        uint64_t reserved_53_63        : 11;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_msix_vec#_ctl
- *
- * RVU VF MSI-X Vector-Table Control and Data Registers
- * These registers and RVU_VF_MSIX_VEC()_ADDR form the VF MSI-X vector table.
- */
-union cavm_rvu_vf_msix_vecx_ctl
-{
-    uint64_t u;
-    struct cavm_rvu_vf_msix_vecx_ctl_s
-    {
-        uint64_t data                  : 32; /**< [ 31:  0](R/W) Data to use for MSI-X delivery of this vector. */
-        uint64_t mask                  : 1;  /**< [ 32: 32](R/W) When set, no MSI-X interrupts are sent to this vector. */
-        uint64_t reserved_33_63        : 31;
-    } s;
-};
-
-/**
- * Register (RVU_VF_BAR2) rvu_vf_vfpf_mbox#
- *
- * RVU VF/PF Mailbox Registers
- */
-union cavm_rvu_vf_vfpf_mboxx
-{
-    uint64_t u;
-    struct cavm_rvu_vf_vfpf_mboxx_s
-    {
-        uint64_t data                  : 64; /**< [ 63:  0](R/W/H) Mailbox data. These VF registers access the 16-byte-per-VF VF/PF mailbox
-                                                                 RAM. The PF may access the same storage using RVU_PF_VF()_PFVF_MBOX().
-                                                                 MBOX(0) is typically used for PF to VF signaling, MBOX(1) for VF to PF.
-                                                                 Writing RVU_VF_VFPF_MBOX(1) (but not RVU_PF_VF()_PFVF_MBOX(1))
-                                                                 will set the corresponding RVU_PF_VFPF_MBOX_INT() bit, which if appropriately
-                                                                 enabled will send an interrupt to the PF. */
-    } s;
-};
-
-#endif /* __RVU_HW_H__ */
diff --git a/drivers/net/cavium/octeontx2/rvu_pf.c b/drivers/net/cavium/octeontx2/rvu_pf.c
index 358a83fa0e..de4fd0c75a 100644
--- a/drivers/net/cavium/octeontx2/rvu_pf.c
+++ b/drivers/net/cavium/octeontx2/rvu_pf.c
@@ -7,10 +7,8 @@
  * the License, or (at your option) any later version.
  *
  */
-#define DEBUG
 #include <common.h>
 #include <net.h>
-#include <netdev.h>
 #include <malloc.h>
 #include <dm.h>
 #include <misc.h>
@@ -18,136 +16,76 @@
 #include <errno.h>
 #include <asm/types.h>
 #include <asm/arch/octeontx2.h>
-#include "cavm-csrs-rvu.h"
-#include "cavm-csrs-npa.h"
-#include "rvu_common.h"
-#include "rvu.h"
 #include "cgx.h"
 #include "nix.h"
 
-static int pfid = 1;
+extern struct udevice *rvu_af_dev;
 
-int rvu_add_nix(struct rvu_pf *rvu)
+int rvu_pf_init(struct rvu_pf *rvu)
 {
-	struct nix_af_handle *nix_af = nix_get_af((u64)(rvu->nix_base));
-	struct eth_device *netdev;
-	struct nix_handle *nix;
-	struct cgx *cgx;
-	struct lmac *lmac;
-	struct nix_lf_alloc_req req;
-	struct nix_lf_alloc_rsp res;
-	int err;
-
-	if (!nix_af) {
-		printf("%s: Error: Could not find NIX AF for PF base %p\n",
-		       __func__, rvu->nix_base);
-		return -1;
-	}
-	if (rvu->pf < 1) {
-		printf("%s: Error: RVU PF %d invalid\n", __func__, rvu->pf);
-		return -1;
-	}
-	lmac = cgx_get_lmac(rvu->pf - 1);
-	if (!lmac) {
-		printf("%s: Error: No LMAC found for pf %d\n",
-		       __func__, rvu->pf);
-		return -1;
-	}
-	cgx = lmac->cgx;
-	memset(&req, 0, sizeof(req));
-	memset(&res, 0, sizeof(res));
-	req.rq_cnt = 1;
-	req.sq_cnt = 1;
-	req.cq_cnt = 1;
-	req.rss_grps = 1;
-	req.xqe_sz = CAVM_NIX_XQESZ_E_W16;
-	req.npa_func = rvu->pf;
+	struct nix *nix;
+	struct eth_pdata *pdata = dev_get_platdata(rvu->dev);
 
 	debug("%s: Allocating nix lf\n", __func__);
-	nix = cavm_nix_lf_alloc(nix_af, rvu->dev, rvu->pf, rvu->pf,
-				rvu->nix_base,
-				rvu->npc_base, rvu->lmt_base,
-				cgx->cgx_id, lmac->lmac_id, &req, &res);
+	nix = nix_lf_alloc(rvu->dev);
 	if (!nix) {
 		printf("%s: Error allocating lf for pf %d\n",
-		       __func__, rvu->pf);
-		return -1;
-	}
-
-	netdev = calloc(sizeof(*netdev), 1);
-	if (!netdev) {
-		printf("%s: Out of memory!\n", __func__);
-		/* TODO: call cleanup function */
+		       __func__, rvu->pfid);
 		return -1;
 	}
 	rvu->nix = nix;
-	netdev->priv = rvu;
-	snprintf(netdev->name, sizeof(netdev->name), "eth%u", nix->nic_id);
-	netdev->halt = NULL;	/* TODO */
-	netdev->init = NULL;	/* TODO */
-	netdev->send = NULL;	/* TODO */
-	netdev->recv = NULL;	/* TODO */
-
-	if (!eth_env_get_enetaddr_by_index("eth", nix->nic_id,
-					   netdev->enetaddr)) {
-		eth_env_get_enetaddr("ethaddr", netdev->enetaddr);
-		netdev->enetaddr[5] += nix->nic_id;
-	}
-	err = eth_register(netdev);
-	if (!err)
-		return 0;
 
-	printf("Failed to register Ethernet device %s\n", netdev->name);
+	/* to make post_probe happy */
+	memcpy(pdata->enetaddr, nix->lmac->mac_addr, 6);
+	eth_env_set_enetaddr_by_index("eth", rvu->dev->seq, pdata->enetaddr);
 
-	return err;
+	return 0;
 }
 
+static const struct eth_ops nix_eth_ops = {
+	.start			= nix_lf_init,
+	.send			= nix_lf_xmit,
+	.recv			= nix_lf_recv,
+	.free_pkt		= nix_lf_free_pkt,
+	.stop			= nix_lf_halt,
+	.write_hwaddr		= nix_lf_setup_mac,
+	.read_rom_hwaddr	= nix_lf_read_rom_mac,
+};
+
 int rvu_pf_probe(struct udevice *dev)
 {
-	struct rvu_pf *pf_ptr = dev_get_priv(dev);
+	struct rvu_pf *rvu = dev_get_priv(dev);
 	size_t size;
-	union cavm_rvu_func_addr_s func_addr;
-	int nix_af_pf;
 	int err;
 
 	debug("%s: name: %s\n", __func__, dev->name);
 
-	pf_ptr->dev = dev;
-	pf_ptr->base = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
-	pf_ptr->pf_id = pfid++;
-	pf_ptr->pf = ((u64)(pf_ptr->base) >> 36) & 0x0f;
-
-	debug("RVU PF BAR2 RVU BASE %p, pf: %u\n", pf_ptr->base, pf_ptr->pf);
-
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NIXX(0);
-	pf_ptr->nix_base = pf_ptr->base + func_addr.u;
-	debug("RVU PF BAR2 NIX BASE %p\n", pf_ptr->nix_base);
-	//nix_lf_init(pf_ptr->pf_id, pf_ptr->nix_base);
-
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPA;
-	pf_ptr->npa_base = pf_ptr->base + func_addr.u;
-	debug("RVU PF BAR2 NPA BASE %p\n", pf_ptr->npa_base);
-
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_NPC;
-	pf_ptr->npc_base = pf_ptr->base + func_addr.u;
-	debug("RVU PF BAR2 NPC BASE %p\n", pf_ptr->npc_base);
+	rvu->pf_base = dm_pci_map_bar(dev, 2, &size, PCI_REGION_MEM);
+	rvu->pfid = dev->seq + 1;
+	rvu->dev = dev;
+	if (!rvu_af_dev) {
+		printf("%s: Error: Could not find RVU AF device\n",
+		       __func__);
+		return -1;
+	}
+	rvu->afdev = rvu_af_dev;
 
-	func_addr.u = 0;
-	func_addr.s.block = CAVM_RVU_BLOCK_ADDR_E_LMT;
-	pf_ptr->lmt_base = pf_ptr->base + func_addr.u;
-	debug("RVU PF BAR2 LMT BASE %p\n", pf_ptr->lmt_base);
+	debug("RVU PF %u BAR2 %p\n", rvu->pfid, rvu->pf_base);
 
-	err = rvu_add_nix(pf_ptr);
+	rvu_get_lfid_for_pf(rvu->pfid, &rvu->nix_lfid,
+				 &rvu->npa_lfid);
 
+	err = rvu_pf_init(rvu);
 	if (err)
 		printf("%s: Error %d adding nix\n", __func__, err);
 
 	return err;
 }
 
+int rvu_pf_remove(struct udevice *dev)
+{
+	return 0;
+}
 
 static const struct udevice_id rvu_pf_ids[] = {
         { .compatible = "cavium,rvu-pf" },
@@ -156,17 +94,19 @@ static const struct udevice_id rvu_pf_ids[] = {
 
 U_BOOT_DRIVER(rvu_pf) = {
         .name   = "rvu_pf",
-        .id     = UCLASS_MISC,
-        .probe  = rvu_pf_probe,
+        .id     = UCLASS_ETH,
         .of_match = rvu_pf_ids,
+        .probe  = rvu_pf_probe,
+        .remove = rvu_pf_remove,
+	.ops    = &nix_eth_ops,
         .priv_auto_alloc_size = sizeof(struct rvu_pf),
+	.platdata_auto_alloc_size = sizeof(struct eth_pdata),
 };
 
 static struct pci_device_id rvu_pf_supported[] = {
-        { PCI_VDEVICE(CAVIUM, PCI_DEVICE_ID_OCTEONTX2_RVU_PF) },
+        { PCI_VDEVICE(CAVIUM, PCI_DEVID_OCTEONTX2_RVU_PF) },
         {}
 };
 
 U_BOOT_PCI_DEVICE(rvu_pf, rvu_pf_supported);
 
-
diff --git a/include/configs/octeontx2_96xx.h b/include/configs/octeontx2_96xx.h
index 8b40eb4ad8..bfc99f7778 100644
--- a/include/configs/octeontx2_96xx.h
+++ b/include/configs/octeontx2_96xx.h
@@ -76,6 +76,7 @@
 /** Extra environment settings */
 #define CONFIG_EXTRA_ENV_SETTINGS	\
 					"loadaddr=040080000\0"	\
+					"ethrotate=yes\0"	\
 					"autoload=0\0"
 
 /** Environment defines */
-- 
2.29.0

